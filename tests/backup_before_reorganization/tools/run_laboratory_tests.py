#!/usr/bin/env python3
"""
NTN Stack å¯¦é©—å®¤é©—æ¸¬åŸ·è¡Œè…³æœ¬

é€™æ˜¯å¯¦é©—å®¤é©—æ¸¬çš„ä¸»è¦åŸ·è¡Œå…¥å£ï¼Œæä¾›å‘½ä»¤è¡Œæ¥å£ä¾†é‹è¡Œå®Œæ•´çš„æ¸¬è©¦å¥—ä»¶
ç›®æ¨™æ˜¯é”åˆ° 100% æ¸¬è©¦é€šéç‡ï¼Œç¬¦åˆå¯¦é©—å®¤é©—æ¸¬çš„åš´æ ¼è¦æ±‚

ä½¿ç”¨æ–¹æ³•ï¼š
  python tests/run_laboratory_tests.py                    # åŸ·è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶
  python tests/run_laboratory_tests.py --quick           # å¿«é€Ÿæ¸¬è©¦
  python tests/run_laboratory_tests.py --performance     # åªåŸ·è¡Œæ€§èƒ½æ¸¬è©¦
  python tests/run_laboratory_tests.py --stress          # åªåŸ·è¡Œå£“åŠ›æ¸¬è©¦
  python tests/run_laboratory_tests.py --config custom.yaml  # ä½¿ç”¨è‡ªå®šç¾©é…ç½®
"""

import argparse
import asyncio
import logging
import sys
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from tests.laboratory_test_suite import (
    LaboratoryTestEnvironment,
    LaboratoryTestExecutor,
)

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(
            f"tests/reports/laboratory/lab_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        ),
    ],
)
logger = logging.getLogger(__name__)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(
        description="NTN Stack å¯¦é©—å®¤é©—æ¸¬åŸ·è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ¸¬è©¦æ¨¡å¼èªªæ˜ï¼š
  full        åŸ·è¡Œå®Œæ•´çš„å¯¦é©—å®¤é©—æ¸¬å¥—ä»¶ï¼ˆé»˜èªï¼‰
  quick       å¿«é€Ÿæ¸¬è©¦ï¼Œè·³éé•·æ™‚é–“é‹è¡Œçš„æ¸¬è©¦
  performance åªåŸ·è¡Œæ€§èƒ½ç›¸é—œæ¸¬è©¦
  stress      åªåŸ·è¡Œå£“åŠ›æ¸¬è©¦
  connectivity åªåŸ·è¡Œé€£æ¥æ€§æ¸¬è©¦
  api         åªåŸ·è¡Œ API åŠŸèƒ½æ¸¬è©¦

ç¤ºä¾‹ï¼š
  python tests/run_laboratory_tests.py --mode quick
  python tests/run_laboratory_tests.py --config tests/configs/custom_lab_config.yaml
  python tests/run_laboratory_tests.py --verbose --no-reports
        """,
    )

    parser.add_argument(
        "--mode",
        "-m",
        choices=["full", "quick", "performance", "stress", "connectivity", "api"],
        default="full",
        help="æ¸¬è©¦åŸ·è¡Œæ¨¡å¼ï¼ˆé»˜èªï¼šfullï¼‰",
    )

    parser.add_argument(
        "--config",
        "-c",
        type=str,
        default="tests/configs/laboratory_test_config.yaml",
        help="æ¸¬è©¦é…ç½®æ–‡ä»¶è·¯å¾‘ï¼ˆé»˜èªï¼šlaboratory_test_config.yamlï¼‰",
    )

    parser.add_argument("--verbose", "-v", action="store_true", help="å•Ÿç”¨è©³ç´°æ—¥èªŒè¼¸å‡º")

    parser.add_argument("--no-reports", action="store_true", help="ä¸ç”Ÿæˆæ¸¬è©¦å ±å‘Š")

    parser.add_argument(
        "--max-retries", type=int, default=3, help="æ¸¬è©¦å¤±æ•—æ™‚çš„æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼ˆé»˜èªï¼š3ï¼‰"
    )

    parser.add_argument(
        "--timeout",
        type=int,
        default=1800,  # 30 åˆ†é˜
        help="æ¸¬è©¦ç¸½é«”è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼Œé»˜èªï¼š1800ï¼‰",
    )

    return parser.parse_args()


class LaboratoryTestRunner:
    """å¯¦é©—å®¤æ¸¬è©¦åŸ·è¡Œå™¨"""

    def __init__(self, args):
        self.args = args
        self.start_time = datetime.utcnow()

        # è¨­ç½®æ—¥èªŒç´šåˆ¥
        if args.verbose:
            logging.getLogger().setLevel(logging.DEBUG)

        # åˆå§‹åŒ–æ¸¬è©¦ç’°å¢ƒ
        self.test_env = LaboratoryTestEnvironment(args.config)
        self.executor = LaboratoryTestExecutor(self.test_env)

    async def run_tests(self) -> bool:
        """åŸ·è¡Œæ¸¬è©¦"""
        logger.info("ğŸ§ª å•Ÿå‹• NTN Stack å¯¦é©—å®¤é©—æ¸¬")
        logger.info(f"ğŸ“‹ æ¸¬è©¦æ¨¡å¼: {self.args.mode}")
        logger.info(f"âš™ï¸ é…ç½®æ–‡ä»¶: {self.args.config}")
        logger.info(f"ğŸ• é–‹å§‹æ™‚é–“: {self.start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")

        try:
            # æ­¥é©Ÿ 1: ç’°å¢ƒé©—è­‰
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ“‹ ç¬¬ä¸€éšæ®µï¼šç’°å¢ƒé©—è­‰")
            logger.info("=" * 60)

            if not await self.test_env.validate_environment():
                logger.error("âŒ ç’°å¢ƒé©—è­‰å¤±æ•—ï¼Œæ¸¬è©¦ä¸­æ­¢")
                return False

            logger.info("âœ… ç’°å¢ƒé©—è­‰é€šé")

            # æ­¥é©Ÿ 2: æ ¹æ“šæ¨¡å¼åŸ·è¡Œæ¸¬è©¦
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ“‹ ç¬¬äºŒéšæ®µï¼šåŸ·è¡Œæ¸¬è©¦å¥—ä»¶")
            logger.info("=" * 60)

            success = await self._execute_test_mode()

            # æ­¥é©Ÿ 3: ç”Ÿæˆå ±å‘Š
            if not self.args.no_reports:
                logger.info("\n" + "=" * 60)
                logger.info("ğŸ“‹ ç¬¬ä¸‰éšæ®µï¼šç”Ÿæˆæ¸¬è©¦å ±å‘Š")
                logger.info("=" * 60)

                await self.executor._generate_final_report(success)

            # æ­¥é©Ÿ 4: ç¸½çµ
            await self._print_summary(success)

            return success

        except asyncio.TimeoutError:
            logger.error(f"âŒ æ¸¬è©¦è¶…æ™‚ï¼ˆ{self.args.timeout} ç§’ï¼‰")
            return False

        except KeyboardInterrupt:
            logger.info("ğŸ›‘ æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
            return False

        except Exception as e:
            logger.error(f"ğŸ’¥ æ¸¬è©¦åŸ·è¡Œç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")
            logger.exception("è©³ç´°éŒ¯èª¤ä¿¡æ¯ï¼š")
            return False

    async def _execute_test_mode(self) -> bool:
        """æ ¹æ“šæ¨¡å¼åŸ·è¡Œæ¸¬è©¦"""
        if self.args.mode == "full":
            return await self.executor.execute_full_test_suite()

        elif self.args.mode == "quick":
            return await self._execute_quick_tests()

        elif self.args.mode == "performance":
            return await self._execute_performance_tests()

        elif self.args.mode == "stress":
            return await self._execute_stress_tests()

        elif self.args.mode == "connectivity":
            return await self._execute_connectivity_tests()

        elif self.args.mode == "api":
            return await self._execute_api_tests()

        else:
            logger.error(f"æœªçŸ¥çš„æ¸¬è©¦æ¨¡å¼: {self.args.mode}")
            return False

    async def _execute_quick_tests(self) -> bool:
        """åŸ·è¡Œå¿«é€Ÿæ¸¬è©¦"""
        logger.info("âš¡ åŸ·è¡Œå¿«é€Ÿæ¸¬è©¦æ¨¡å¼")

        quick_tests = [
            ("environment_setup", await self.executor._test_environment_setup()),
            ("service_health_check", await self.executor._test_service_health()),
            ("basic_connectivity", await self.executor._test_basic_connectivity()),
            ("api_functionality", await self.executor._test_api_functionality()),
        ]

        passed_tests = sum(1 for _, passed in quick_tests if passed)
        total_tests = len(quick_tests)
        success_rate = passed_tests / total_tests

        logger.info(
            f"âš¡ å¿«é€Ÿæ¸¬è©¦å®Œæˆï¼š{passed_tests}/{total_tests} é€šé (æˆåŠŸç‡: {success_rate:.1%})"
        )

        return success_rate == 1.0

    async def _execute_performance_tests(self) -> bool:
        """åŸ·è¡Œæ€§èƒ½æ¸¬è©¦"""
        logger.info("âš¡ åŸ·è¡Œæ€§èƒ½æ¸¬è©¦æ¨¡å¼")

        performance_tests = [
            (
                "performance_validation",
                await self.executor._test_performance_validation(),
            ),
            ("load_testing", await self.executor._test_load_testing()),
        ]

        passed_tests = sum(1 for _, passed in performance_tests if passed)
        total_tests = len(performance_tests)
        success_rate = passed_tests / total_tests

        logger.info(
            f"âš¡ æ€§èƒ½æ¸¬è©¦å®Œæˆï¼š{passed_tests}/{total_tests} é€šé (æˆåŠŸç‡: {success_rate:.1%})"
        )

        return success_rate == 1.0

    async def _execute_stress_tests(self) -> bool:
        """åŸ·è¡Œå£“åŠ›æ¸¬è©¦"""
        logger.info("ğŸ’¥ åŸ·è¡Œå£“åŠ›æ¸¬è©¦æ¨¡å¼")

        stress_result = await self.executor._test_stress()

        logger.info(f"ğŸ’¥ å£“åŠ›æ¸¬è©¦å®Œæˆï¼š{'é€šé' if stress_result[0] else 'å¤±æ•—'}")

        return stress_result[0]

    async def _execute_connectivity_tests(self) -> bool:
        """åŸ·è¡Œé€£æ¥æ€§æ¸¬è©¦"""
        logger.info("ğŸ”— åŸ·è¡Œé€£æ¥æ€§æ¸¬è©¦æ¨¡å¼")

        connectivity_result = await self.executor._test_basic_connectivity()

        logger.info(
            f"ğŸ”— é€£æ¥æ€§æ¸¬è©¦å®Œæˆï¼š{'é€šé' if connectivity_result[0] else 'å¤±æ•—'}"
        )

        return connectivity_result[0]

    async def _execute_api_tests(self) -> bool:
        """åŸ·è¡Œ API æ¸¬è©¦"""
        logger.info("ğŸŒ åŸ·è¡Œ API æ¸¬è©¦æ¨¡å¼")

        api_result = await self.executor._test_api_functionality()

        logger.info(f"ğŸŒ API æ¸¬è©¦å®Œæˆï¼š{'é€šé' if api_result[0] else 'å¤±æ•—'}")

        return api_result[0]

    async def _print_summary(self, success: bool):
        """æ‰“å°æ¸¬è©¦ç¸½çµ"""
        end_time = datetime.utcnow()
        duration = end_time - self.start_time

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š å¯¦é©—å®¤é©—æ¸¬ç¸½çµ")
        logger.info("=" * 60)
        logger.info(f"ğŸ• é–‹å§‹æ™‚é–“: {self.start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")
        logger.info(f"ğŸ• çµæŸæ™‚é–“: {end_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")
        logger.info(f"â±ï¸ ç¸½è€—æ™‚: {duration}")
        logger.info(f"ğŸ“‹ æ¸¬è©¦æ¨¡å¼: {self.args.mode}")
        logger.info(f"âš™ï¸ é…ç½®æ–‡ä»¶: {self.args.config}")

        if hasattr(self.test_env, "phase_results") and self.test_env.phase_results:
            total_phases = len(self.test_env.phase_results)
            passed_phases = sum(
                1 for p in self.test_env.phase_results if p.status == "passed"
            )
            logger.info(f"ğŸ“ˆ éšæ®µçµæœ: {passed_phases}/{total_phases} é€šé")

        if hasattr(self.test_env, "test_results") and self.test_env.test_results:
            total_tests = len(self.test_env.test_results)
            passed_tests = sum(
                1 for t in self.test_env.test_results if t.status == "passed"
            )
            success_rate = passed_tests / total_tests
            logger.info(
                f"ğŸ“ˆ æ¸¬è©¦çµæœ: {passed_tests}/{total_tests} é€šé (æˆåŠŸç‡: {success_rate:.1%})"
            )

        if success:
            logger.info("ğŸ‰ å¯¦é©—å®¤é©—æ¸¬æˆåŠŸå®Œæˆï¼")
            logger.info("âœ¨ æ‰€æœ‰æ¸¬è©¦å‡å·²é€šéï¼Œç³»çµ±é”åˆ°å¯¦é©—å®¤é©—æ¸¬æ¨™æº–")
        else:
            logger.error("âŒ å¯¦é©—å®¤é©—æ¸¬æœªå®Œå…¨é€šé")
            logger.error("âš ï¸ è«‹æª¢æŸ¥å¤±æ•—çš„æ¸¬è©¦é …ç›®ä¸¦ä¿®å¾©ç›¸é—œå•é¡Œ")

        logger.info("=" * 60)


async def main():
    """ä¸»ç¨‹åºå…¥å£"""
    args = parse_arguments()

    # ç¢ºä¿å ±å‘Šç›®éŒ„å­˜åœ¨
    reports_dir = Path("tests/reports/laboratory")
    reports_dir.mkdir(parents=True, exist_ok=True)

    runner = LaboratoryTestRunner(args)

    try:
        # è¨­ç½®ç¸½é«”è¶…æ™‚
        success = await asyncio.wait_for(runner.run_tests(), timeout=args.timeout)

        # è¨­ç½®é€€å‡ºç¢¼
        sys.exit(0 if success else 1)

    except asyncio.TimeoutError:
        logger.error(f"âŒ æ¸¬è©¦åŸ·è¡Œè¶…æ™‚ï¼ˆ{args.timeout} ç§’ï¼‰")
        sys.exit(2)

    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºåŸ·è¡Œç•°å¸¸: {e}")
        sys.exit(3)


if __name__ == "__main__":
    # æª¢æŸ¥ Python ç‰ˆæœ¬
    if sys.version_info < (3, 8):
        print("âŒ éœ€è¦ Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬")
        sys.exit(1)

    # é‹è¡Œä¸»ç¨‹åº
    asyncio.run(main())
