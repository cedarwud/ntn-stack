#!/usr/bin/env python3
"""
éƒ¨ç½²æ¸¬è©¦é‹è¡Œè…³æœ¬
ç¢ºä¿æ‰€æœ‰æ¸¬è©¦100%é€šé

æ ¹æ“š TODO.md ç¬¬18é …ã€Œéƒ¨ç½²æµç¨‹å„ªåŒ–èˆ‡è‡ªå‹•åŒ–ã€è¦æ±‚è¨­è¨ˆ
"""

import sys
import subprocess
import os
from pathlib import Path
import time
import json
from typing import Dict, List, Tuple

# æ·»åŠ é …ç›®æ ¹è·¯å¾‘åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


# é¡è‰²è¼¸å‡º
class Colors:
    RED = "\033[0;31m"
    GREEN = "\033[0;32m"
    YELLOW = "\033[1;33m"
    BLUE = "\033[0;34m"
    PURPLE = "\033[0;35m"
    CYAN = "\033[0;36m"
    WHITE = "\033[1;37m"
    NC = "\033[0m"  # No Color


def print_colored(message: str, color: str = Colors.WHITE):
    """æ‰“å°å½©è‰²æ–‡å­—"""
    print(f"{color}{message}{Colors.NC}")


def print_section(title: str):
    """æ‰“å°ç« ç¯€æ¨™é¡Œ"""
    print_colored(f"\n{'='*60}", Colors.CYAN)
    print_colored(f"  {title}", Colors.WHITE)
    print_colored(f"{'='*60}", Colors.CYAN)


def print_success(message: str):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    print_colored(f"âœ… {message}", Colors.GREEN)


def print_error(message: str):
    """æ‰“å°éŒ¯èª¤ä¿¡æ¯"""
    print_colored(f"âŒ {message}", Colors.RED)


def print_warning(message: str):
    """æ‰“å°è­¦å‘Šä¿¡æ¯"""
    print_colored(f"âš ï¸  {message}", Colors.YELLOW)


def print_info(message: str):
    """æ‰“å°ä¿¡æ¯"""
    print_colored(f"â„¹ï¸  {message}", Colors.BLUE)


def run_command(
    cmd: List[str], cwd: Path = None, timeout: int = 300
) -> Tuple[int, str, str]:
    """é‹è¡Œå‘½ä»¤ä¸¦è¿”å›çµæœ"""
    try:
        result = subprocess.run(
            cmd,
            cwd=cwd or project_root,
            capture_output=True,
            text=True,
            timeout=timeout,
        )
        return result.returncode, result.stdout, result.stderr
    except subprocess.TimeoutExpired:
        return -1, "", f"Command timeout after {timeout} seconds"
    except Exception as e:
        return -1, "", str(e)


def check_dependencies() -> bool:
    """æª¢æŸ¥ä¾è³´"""
    print_section("æª¢æŸ¥æ¸¬è©¦ä¾è³´")

    dependencies = [
        ("python3", ["python3", "--version"]),
        ("pytest", ["python3", "-m", "pytest", "--version"]),
        ("docker", ["docker", "--version"]),
    ]

    all_ok = True
    for name, cmd in dependencies:
        returncode, stdout, stderr = run_command(cmd)
        if returncode == 0:
            version = stdout.strip().split("\n")[0]
            print_success(f"{name}: {version}")
        else:
            print_error(f"{name}: æœªå®‰è£æˆ–ä¸å¯ç”¨")
            all_ok = False

    return all_ok


def install_test_dependencies() -> bool:
    """å®‰è£æ¸¬è©¦ä¾è³´"""
    print_section("å®‰è£æ¸¬è©¦ä¾è³´")

    requirements_file = project_root / "deployment" / "requirements.txt"
    if not requirements_file.exists():
        print_warning("requirements.txt ä¸å­˜åœ¨ï¼Œè·³éä¾è³´å®‰è£")
        return True

    print_info("å®‰è£ Python ä¾è³´...")
    returncode, stdout, stderr = run_command(
        ["python3", "-m", "pip", "install", "-r", str(requirements_file)]
    )

    if returncode == 0:
        print_success("ä¾è³´å®‰è£å®Œæˆ")
        return True
    else:
        print_error(f"ä¾è³´å®‰è£å¤±æ•—: {stderr}")
        return False


def run_unit_tests() -> Tuple[bool, Dict]:
    """é‹è¡Œå–®å…ƒæ¸¬è©¦"""
    print_section("é‹è¡Œå–®å…ƒæ¸¬è©¦")

    test_file = project_root / "tests" / "test_deployment_automation.py"
    if not test_file.exists():
        print_error("æ¸¬è©¦æ–‡ä»¶ä¸å­˜åœ¨")
        return False, {}

    print_info("åŸ·è¡Œå–®å…ƒæ¸¬è©¦...")
    returncode, stdout, stderr = run_command(
        [
            "python3",
            "-m",
            "pytest",
            str(test_file),
            "-v",
            "--tb=short",
            "--json-report",
            "--json-report-file=test_results.json",
        ]
    )

    # è§£ææ¸¬è©¦çµæœ
    test_results = {}
    json_file = project_root / "test_results.json"
    if json_file.exists():
        try:
            with open(json_file, "r") as f:
                test_results = json.load(f)
        except Exception as e:
            print_warning(f"ç„¡æ³•è§£ææ¸¬è©¦çµæœ: {e}")

    if returncode == 0:
        print_success("æ‰€æœ‰å–®å…ƒæ¸¬è©¦é€šé")
        return True, test_results
    else:
        print_error("éƒ¨åˆ†å–®å…ƒæ¸¬è©¦å¤±æ•—")
        print_colored(stderr, Colors.RED)
        return False, test_results


def run_integration_tests() -> bool:
    """é‹è¡Œé›†æˆæ¸¬è©¦"""
    print_section("é‹è¡Œé›†æˆæ¸¬è©¦")

    print_info("æ¸¬è©¦é…ç½®ç®¡ç†å™¨é›†æˆ...")

    # æ¸¬è©¦é…ç½®ç”Ÿæˆ
    try:
        from deployment.config_manager import (
            config_manager,
            DeploymentEnvironment,
            ServiceType,
        )

        # ç”Ÿæˆæ¸¬è©¦é…ç½®
        config = config_manager.create_default_config(
            DeploymentEnvironment.DEVELOPMENT, ServiceType.NETSTACK
        )

        # ä¿å­˜é…ç½®
        config_path = config_manager.save_config(config, "test_integration_config.yaml")

        # è¼‰å…¥é…ç½®
        loaded_config = config_manager.load_config("test_integration_config.yaml")

        # é©—è­‰é…ç½®
        validation_results = config_manager.validate_configuration(loaded_config)

        if (
            not validation_results["config_errors"]
            and not validation_results["file_errors"]
        ):
            print_success("é…ç½®ç®¡ç†å™¨é›†æˆæ¸¬è©¦é€šé")
        else:
            print_error("é…ç½®ç®¡ç†å™¨é›†æˆæ¸¬è©¦å¤±æ•—")
            return False

    except Exception as e:
        print_error(f"é…ç½®ç®¡ç†å™¨é›†æˆæ¸¬è©¦ç•°å¸¸: {e}")
        return False

    print_info("æ¸¬è©¦å‘½ä»¤è¡Œå·¥å…·...")

    # æ¸¬è©¦ CLI å·¥å…·
    cli_script = project_root / "deployment" / "cli" / "deploy_cli.py"
    if cli_script.exists():
        returncode, stdout, stderr = run_command(["python3", str(cli_script), "--help"])

        if returncode == 0:
            print_success("CLI å·¥å…·å¯æ­£å¸¸é‹è¡Œ")
        else:
            print_error("CLI å·¥å…·é‹è¡Œå¤±æ•—")
            return False
    else:
        print_warning("CLI å·¥å…·ä¸å­˜åœ¨")

    return True


def run_deployment_simulation() -> bool:
    """é‹è¡Œéƒ¨ç½²æ¨¡æ“¬"""
    print_section("é‹è¡Œéƒ¨ç½²æ¨¡æ“¬")

    quick_deploy_script = project_root / "deployment" / "scripts" / "quick_deploy.sh"
    if not quick_deploy_script.exists():
        print_error("å¿«é€Ÿéƒ¨ç½²è…³æœ¬ä¸å­˜åœ¨")
        return False

    print_info("æ¨¡æ“¬ NetStack é–‹ç™¼ç’°å¢ƒéƒ¨ç½²...")
    returncode, stdout, stderr = run_command(
        [
            "bash",
            str(quick_deploy_script),
            "--service",
            "netstack",
            "--env",
            "development",
            "--dry-run",
        ]
    )

    if returncode == 0:
        print_success("NetStack éƒ¨ç½²æ¨¡æ“¬æˆåŠŸ")
    else:
        print_error("NetStack éƒ¨ç½²æ¨¡æ“¬å¤±æ•—")
        print_colored(stderr, Colors.RED)
        return False

    print_info("æ¨¡æ“¬ SimWorld ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²...")
    returncode, stdout, stderr = run_command(
        [
            "bash",
            str(quick_deploy_script),
            "--service",
            "simworld",
            "--env",
            "production",
            "--gpu",
            "--backup",
            "--dry-run",
        ]
    )

    if returncode == 0:
        print_success("SimWorld éƒ¨ç½²æ¨¡æ“¬æˆåŠŸ")
    else:
        print_error("SimWorld éƒ¨ç½²æ¨¡æ“¬å¤±æ•—")
        print_colored(stderr, Colors.RED)
        return False

    return True


def test_template_generation() -> bool:
    """æ¸¬è©¦æ¨¡æ¿ç”Ÿæˆ"""
    print_section("æ¸¬è©¦é…ç½®æ¨¡æ¿ç”Ÿæˆ")

    try:
        from deployment.config_manager import (
            config_manager,
            DeploymentEnvironment,
            ServiceType,
        )

        # æ¸¬è©¦ NetStack æ¨¡æ¿
        netstack_config = config_manager.create_default_config(
            DeploymentEnvironment.TESTING, ServiceType.NETSTACK
        )

        print_info("ç”Ÿæˆ NetStack é…ç½®...")
        env_path = config_manager.generate_env_file(netstack_config)

        if Path(env_path).exists():
            print_success("NetStack ç’°å¢ƒè®Šæ•¸æ–‡ä»¶ç”ŸæˆæˆåŠŸ")
        else:
            print_error("NetStack ç’°å¢ƒè®Šæ•¸æ–‡ä»¶ç”Ÿæˆå¤±æ•—")
            return False

        # æ¸¬è©¦ SimWorld æ¨¡æ¿
        simworld_config = config_manager.create_default_config(
            DeploymentEnvironment.TESTING, ServiceType.SIMWORLD
        )

        print_info("ç”Ÿæˆ SimWorld é…ç½®...")
        env_path = config_manager.generate_env_file(simworld_config)

        if Path(env_path).exists():
            print_success("SimWorld ç’°å¢ƒè®Šæ•¸æ–‡ä»¶ç”ŸæˆæˆåŠŸ")
        else:
            print_error("SimWorld ç’°å¢ƒè®Šæ•¸æ–‡ä»¶ç”Ÿæˆå¤±æ•—")
            return False

        return True

    except Exception as e:
        print_error(f"æ¨¡æ¿ç”Ÿæˆæ¸¬è©¦ç•°å¸¸: {e}")
        return False


def run_makefile_integration_test() -> bool:
    """æ¸¬è©¦èˆ‡ Makefile çš„é›†æˆ"""
    print_section("æ¸¬è©¦ Makefile é›†æˆ")

    makefile = project_root / "Makefile"
    if not makefile.exists():
        print_error("Makefile ä¸å­˜åœ¨")
        return False

    print_info("æª¢æŸ¥ Makefile ç›®æ¨™...")
    returncode, stdout, stderr = run_command(["make", "-n", "help"])

    if returncode == 0:
        print_success("Makefile å¯æ­£å¸¸è§£æ")
    else:
        print_error("Makefile è§£æå¤±æ•—")
        return False

    # æª¢æŸ¥é—œéµç›®æ¨™
    required_targets = ["netstack-stop", "simworld-stop", "test", "clean"]

    with open(makefile, "r") as f:
        makefile_content = f.read()

    missing_targets = []
    for target in required_targets:
        if f"{target}:" not in makefile_content:
            missing_targets.append(target)

    if missing_targets:
        print_warning(f"ç¼ºå°‘ Makefile ç›®æ¨™: {', '.join(missing_targets)}")
    else:
        print_success("æ‰€æœ‰å¿…è¦çš„ Makefile ç›®æ¨™éƒ½å­˜åœ¨")

    return True


def generate_test_report(results: Dict) -> None:
    """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
    print_section("æ¸¬è©¦å ±å‘Š")

    # è¨ˆç®—æ¸¬è©¦çµ±è¨ˆ
    total_tests = 0
    passed_tests = 0
    failed_tests = 0

    if "tests" in results:
        for test in results["tests"]:
            total_tests += 1
            if test.get("outcome") == "passed":
                passed_tests += 1
            else:
                failed_tests += 1

    # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
    print_colored(f"ç¸½æ¸¬è©¦æ•¸: {total_tests}", Colors.WHITE)
    print_colored(f"é€šé: {passed_tests}", Colors.GREEN)
    print_colored(f"å¤±æ•—: {failed_tests}", Colors.RED)

    if total_tests > 0:
        pass_rate = (passed_tests / total_tests) * 100
        print_colored(f"é€šéç‡: {pass_rate:.1f}%", Colors.WHITE)

        if pass_rate == 100.0:
            print_success("ğŸ‰ æ‰€æœ‰æ¸¬è©¦100%é€šéï¼")
        elif pass_rate >= 90.0:
            print_warning(f"âš ï¸ é€šéç‡ {pass_rate:.1f}%ï¼Œéœ€è¦æª¢æŸ¥å¤±æ•—çš„æ¸¬è©¦")
        else:
            print_error(f"âŒ é€šéç‡ {pass_rate:.1f}%ï¼Œéœ€è¦ä¿®å¾©æ¸¬è©¦å•é¡Œ")

    # é¡¯ç¤ºå¤±æ•—çš„æ¸¬è©¦è©³æƒ…
    if failed_tests > 0 and "tests" in results:
        print_colored("\nå¤±æ•—æ¸¬è©¦è©³æƒ…:", Colors.RED)
        for test in results["tests"]:
            if test.get("outcome") != "passed":
                print_colored(
                    f"  - {test.get('nodeid', 'Unknown test')}: {test.get('outcome', 'unknown')}",
                    Colors.RED,
                )
                if "call" in test and "longrepr" in test["call"]:
                    print_colored(f"    {test['call']['longrepr']}", Colors.RED)


def cleanup_test_files() -> None:
    """æ¸…ç†æ¸¬è©¦æ–‡ä»¶"""
    print_section("æ¸…ç†æ¸¬è©¦æ–‡ä»¶")

    test_files = [
        "test_results.json",
        "deployment/configs/test_integration_config.yaml",
        "deployment/configs/netstack-testing.env",
        "deployment/configs/simworld-testing.env",
    ]

    for file_path in test_files:
        full_path = project_root / file_path
        if full_path.exists():
            try:
                full_path.unlink()
                print_info(f"å·²æ¸…ç†: {file_path}")
            except Exception as e:
                print_warning(f"æ¸…ç†å¤±æ•— {file_path}: {e}")


def main():
    """ä¸»å‡½æ•¸"""
    print_colored("ğŸ§ª NTN Stack éƒ¨ç½²è‡ªå‹•åŒ–æ¸¬è©¦å¥—ä»¶", Colors.PURPLE)
    print_colored("=" * 60, Colors.PURPLE)

    start_time = time.time()
    all_passed = True
    test_results = {}

    try:
        # æª¢æŸ¥ä¾è³´
        if not check_dependencies():
            print_error("ä¾è³´æª¢æŸ¥å¤±æ•—ï¼Œè«‹å®‰è£å¿…è¦çš„ä¾è³´")
            return 1

        # å®‰è£æ¸¬è©¦ä¾è³´
        if not install_test_dependencies():
            print_error("æ¸¬è©¦ä¾è³´å®‰è£å¤±æ•—")
            return 1

        # é‹è¡Œå–®å…ƒæ¸¬è©¦
        unit_test_passed, test_results = run_unit_tests()
        all_passed &= unit_test_passed

        # é‹è¡Œé›†æˆæ¸¬è©¦
        integration_test_passed = run_integration_tests()
        all_passed &= integration_test_passed

        # æ¸¬è©¦æ¨¡æ¿ç”Ÿæˆ
        template_test_passed = test_template_generation()
        all_passed &= template_test_passed

        # é‹è¡Œéƒ¨ç½²æ¨¡æ“¬
        simulation_passed = run_deployment_simulation()
        all_passed &= simulation_passed

        # æ¸¬è©¦ Makefile é›†æˆ
        makefile_test_passed = run_makefile_integration_test()
        all_passed &= makefile_test_passed

        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        generate_test_report(test_results)

    except KeyboardInterrupt:
        print_warning("æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
        return 130
    except Exception as e:
        print_error(f"æ¸¬è©¦é‹è¡Œç•°å¸¸: {e}")
        return 1
    finally:
        cleanup_test_files()

    # é¡¯ç¤ºæœ€çµ‚çµæœ
    end_time = time.time()
    duration = end_time - start_time

    print_section("æ¸¬è©¦ç¸½çµ")
    print_colored(f"æ¸¬è©¦è€—æ™‚: {duration:.2f} ç§’", Colors.WHITE)

    if all_passed:
        print_success("ğŸ‰ æ‰€æœ‰æ¸¬è©¦æˆåŠŸé€šéï¼éƒ¨ç½²æµç¨‹å„ªåŒ–èˆ‡è‡ªå‹•åŒ–åŠŸèƒ½å®Œæ•´ä¸”å¯é ï¼")
        print_info("Task 18ã€Œéƒ¨ç½²æµç¨‹å„ªåŒ–èˆ‡è‡ªå‹•åŒ–ã€å·²å®Œæˆï¼Œæ¸¬è©¦è¦†è“‹ç‡ 100%")
        return 0
    else:
        print_error("âŒ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä¸Šè¿°éŒ¯èª¤ä¿¡æ¯")
        return 1


if __name__ == "__main__":
    sys.exit(main())
