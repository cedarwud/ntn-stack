#!/usr/bin/env python3
"""
NTN-Stack çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨

ä¸€ç«™å¼åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦çš„å…¥å£ç¨‹å¼ï¼Œæä¾›å®Œæ•´çš„æ¸¬è©¦æ§åˆ¶å’Œå ±å‘ŠåŠŸèƒ½ã€‚

åŸ·è¡Œæ–¹å¼:
python run_all_tests.py [options]

é¸é …:
--quick                å¿«é€Ÿæ¨¡å¼ï¼ˆè·³éè€—æ™‚æ¸¬è©¦ï¼‰
--type=TYPE           æ¸¬è©¦é¡å‹: unit,integration,performance,e2e,paper,frontend,all
--stage=STAGE         è«–æ–‡æ¸¬è©¦éšæ®µ: 1,2,all
--frontend-type=TYPE  å‰ç«¯æ¸¬è©¦é¡å‹: components,api,e2e,console,all
--verbose             è©³ç´°è¼¸å‡º
--report              ç”Ÿæˆå ±å‘Š
"""

import sys
import os
import time
import argparse
import subprocess
import logging
from datetime import datetime
from typing import List
from pathlib import Path

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class UnifiedTestRunner:
    """çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨"""

    def __init__(self):
        self.test_results = {}
        self.start_time = datetime.now()
        self.total_tests = 0
        self.passed_tests = 0
        self.failed_tests = 0

    def run_test_module(
            self,
            module_name: str,
            args: List[str] = None) -> bool:
        """åŸ·è¡Œæ¸¬è©¦æ¨¡çµ„"""
        logger.info(f"ğŸ§ª åŸ·è¡Œ {module_name}...")

        cmd = [sys.executable, f"{module_name}.py"]
        if args:
            cmd.extend(args)

        try:
            start_time = time.time()
            result = subprocess.run(
                cmd, capture_output=True, text=True, cwd=Path(__file__).parent)
            duration = time.time() - start_time

            success = result.returncode == 0
            self.test_results[module_name] = {
                'success': success,
                'duration': duration,
                'stdout': result.stdout,
                'stderr': result.stderr
            }

            if success:
                logger.info(f"âœ… {module_name} å®Œæˆ ({duration:.2f}s)")
                self.passed_tests += 1
            else:
                logger.error(f"âŒ {module_name} å¤±æ•— ({duration:.2f}s)")
                if result.stderr:
                    logger.error(f"éŒ¯èª¤è©³æƒ…: {result.stderr}")
                self.failed_tests += 1

            self.total_tests += 1
            return success

        except Exception as e:
            logger.error(f"âŒ åŸ·è¡Œ {module_name} æ™‚ç™¼ç”Ÿç•°å¸¸: {e}")
            self.test_results[module_name] = {
                'success': False,
                'duration': 0,
                'stdout': '',
                'stderr': str(e)
            }
            self.failed_tests += 1
            self.total_tests += 1
            return False

    def run_unified_tests(
            self,
            test_type: str = "all",
            quick_mode: bool = False):
        """åŸ·è¡Œçµ±ä¸€æ¸¬è©¦"""
        args = [f"--type={test_type}"]
        if quick_mode:
            args.append("--quick")
        return self.run_test_module("unified_tests", args)

    def run_paper_tests(self, stage: str = "all", quick_mode: bool = False):
        """åŸ·è¡Œè«–æ–‡æ¸¬è©¦"""
        args = [f"--stage={stage}"]
        if quick_mode:
            args.append("--quick")
        return self.run_test_module("paper_tests", args)


    def run_frontend_tests(
            self,
            frontend_type: str = "all",
            quick_mode: bool = False):
        """åŸ·è¡Œå‰ç«¯æ¸¬è©¦"""
        logger.info(f"ğŸ¯ åŸ·è¡Œå‰ç«¯æ¸¬è©¦ (é¡å‹: {frontend_type})...")

        try:
            start_time = time.time()

            # å‰ç«¯é …ç›®è·¯å¾‘
            frontend_path = Path("/home/sat/ntn-stack/simworld/frontend")
            if not frontend_path.exists():
                logger.error("âŒ å‰ç«¯é …ç›®è·¯å¾‘ä¸å­˜åœ¨")
                return False

            # æª¢æŸ¥æ˜¯å¦æœ‰ npm/yarn
            package_manager = None
            if (frontend_path / "package.json").exists():
                # æª¢æŸ¥ npm
                try:
                    subprocess.run(["npm", "--version"],
                                   capture_output=True, check=True)
                    package_manager = "npm"
                except (subprocess.CalledProcessError, FileNotFoundError):
                    logger.warning("npm ä¸å¯ç”¨ï¼Œå˜—è©¦ä½¿ç”¨ yarn")
                    try:
                        subprocess.run(["yarn", "--version"],
                                       capture_output=True, check=True)
                        package_manager = "yarn"
                    except (subprocess.CalledProcessError, FileNotFoundError):
                        logger.error("âŒ npm å’Œ yarn éƒ½ä¸å¯ç”¨")
                        return False

            if not package_manager:
                logger.error("âŒ æ‰¾ä¸åˆ° package.json æˆ–åŒ…ç®¡ç†å™¨")
                return False

            # æ§‹å»ºæ¸¬è©¦å‘½ä»¤
            test_cmd = [package_manager, "run", "test"]

            # æ ¹æ“šæ¸¬è©¦é¡å‹æ·»åŠ åƒæ•¸
            if frontend_type != "all":
                # Vitest æ”¯æ´æŒ‰æ–‡ä»¶åéæ¿¾
                if frontend_type == "components":
                    test_cmd.extend(["--", "components.test.tsx"])
                elif frontend_type == "api":
                    test_cmd.extend(["--", "api.test.ts"])
                elif frontend_type == "e2e":
                    test_cmd.extend(["--", "e2e.test.tsx"])
                elif frontend_type == "console":
                    test_cmd.extend(["--", "console-errors.test.ts"])

            # æ·»åŠ æ¸¬è©¦ç’°å¢ƒè®Šæ•¸
            env = os.environ.copy()
            env['NODE_ENV'] = 'test'
            env['VITEST_ENV'] = 'test'

            # åŸ·è¡Œå‰ç«¯æ¸¬è©¦
            logger.info(f"åŸ·è¡Œå‘½ä»¤: {' '.join(test_cmd)}")
            result = subprocess.run(
                test_cmd,
                cwd=frontend_path,
                capture_output=True,
                text=True,
                env=env,
                timeout=300  # 5åˆ†é˜è¶…æ™‚
            )

            duration = time.time() - start_time

            # è¨˜éŒ„çµæœ
            success = result.returncode == 0
            self.test_results["frontend_tests"] = {
                'success': success,
                'duration': duration,
                'stdout': result.stdout,
                'stderr': result.stderr,
                'test_type': frontend_type
            }

            if success:
                logger.info(f"âœ… å‰ç«¯æ¸¬è©¦å®Œæˆ ({duration:.2f}s)")
                self.passed_tests += 1
            else:
                logger.error(f"âŒ å‰ç«¯æ¸¬è©¦å¤±æ•— ({duration:.2f}s)")
                if result.stderr:
                    logger.error(f"éŒ¯èª¤è©³æƒ…: {result.stderr}")
                if result.stdout:
                    logger.info(f"æ¸¬è©¦è¼¸å‡º: {result.stdout}")
                self.failed_tests += 1

            self.total_tests += 1
            return success

        except subprocess.TimeoutExpired:
            logger.error("âŒ å‰ç«¯æ¸¬è©¦è¶…æ™‚")
            self.test_results["frontend_tests"] = {
                'success': False,
                'duration': 300,
                'stdout': '',
                'stderr': 'Test timeout after 5 minutes',
                'test_type': frontend_type
            }
            self.failed_tests += 1
            self.total_tests += 1
            return False
        except Exception as e:
            logger.error(f"âŒ åŸ·è¡Œå‰ç«¯æ¸¬è©¦æ™‚ç™¼ç”Ÿç•°å¸¸: {e}")
            self.test_results["frontend_tests"] = {
                'success': False,
                'duration': 0,
                'stdout': '',
                'stderr': str(e),
                'test_type': frontend_type
            }
            self.failed_tests += 1
            self.total_tests += 1
            return False

    def generate_report(self) -> str:
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š - ç´”æ–‡å­—æ ¼å¼"""
        end_time = datetime.now()
        total_duration = (end_time - self.start_time).total_seconds()

        report = "\n=== NTN-Stack æ¸¬è©¦å ±å‘Š ===\n"
        report += f"é–‹å§‹æ™‚é–“: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += f"çµæŸæ™‚é–“: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += f"ç¸½è€—æ™‚: {total_duration:.2f} ç§’\n\n"

        report += "æ¸¬è©¦çµ±è¨ˆ:\n"
        report += f"  ç¸½æ¸¬è©¦æ•¸: {self.total_tests}\n"
        report += f"  é€šéæ•¸é‡: {self.passed_tests}\n"
        report += f"  å¤±æ•—æ•¸é‡: {self.failed_tests}\n"
        report += f"  æˆåŠŸç‡: {(self.passed_tests/max(self.total_tests,1)*100):.1f}%\n\n"

        report += "æ¸¬è©¦è©³æƒ…:\n"
        for module, result in self.test_results.items():
            status = "âœ… PASS" if result['success'] else "âŒ FAIL"
            report += f"  {module:15s} {status} ({result['duration']:6.2f}s)\n"

        return report


def main():
    parser = argparse.ArgumentParser(description='NTN-Stack çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæ¨¡å¼')
    parser.add_argument(
        '--type',
        choices=[
            'unit',
            'integration',
            'performance',
            'e2e',
            'paper',
            'frontend',
            'all'],
        default='all',
        help='æ¸¬è©¦é¡å‹')
    parser.add_argument(
        '--stage', choices=['1', '2', 'all'], default='all', help='è«–æ–‡æ¸¬è©¦éšæ®µ')
    parser.add_argument(
        '--env',
        choices=[
            'satellite',
            'handover',
            'all'],
        default='all',
        help='Gymnasiumç’°å¢ƒ')
    parser.add_argument(
        '--frontend-type',
        choices=[
            'components',
            'api',
            'e2e',
            'console',
            'all'],
        default='all',
        help='å‰ç«¯æ¸¬è©¦é¡å‹')
    parser.add_argument('--verbose', action='store_true', help='è©³ç´°è¼¸å‡º')
    parser.add_argument('--report', action='store_true', help='ç”Ÿæˆå ±å‘Š')

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    runner = UnifiedTestRunner()

    logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œ NTN-Stack æ¸¬è©¦å¥—ä»¶...")

    # æ ¹æ“šæŒ‡å®šçš„æ¸¬è©¦é¡å‹åŸ·è¡Œæ¸¬è©¦
    if args.type in ['all', 'unit', 'integration', 'performance', 'e2e']:
        if args.type == 'all':
            # åˆ†åˆ¥åŸ·è¡Œå„é¡æ¸¬è©¦
            runner.run_unified_tests('unit', args.quick)
            runner.run_unified_tests('integration', args.quick)
            runner.run_unified_tests('performance', args.quick)
            runner.run_unified_tests('e2e', args.quick)
        else:
            runner.run_unified_tests(args.type, args.quick)

    if args.type in ['all', 'paper']:
        runner.run_paper_tests(args.stage, args.quick)


    if args.type in ['all', 'frontend']:
        runner.run_frontend_tests(
            getattr(args, 'frontend_type', 'all'), args.quick)

    # ç”Ÿæˆä¸¦é¡¯ç¤ºå ±å‘Š
    report = runner.generate_report()
    print(report)

    if args.report:
        report_file = f"reports/test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        logger.info(f"ğŸ“„ å ±å‘Šå·²ä¿å­˜åˆ° {report_file}")

    # æ ¹æ“šæ¸¬è©¦çµæœè¨­ç½®é€€å‡ºç¢¼
    exit_code = 0 if runner.failed_tests == 0 else 1
    logger.info(f"ğŸ æ¸¬è©¦å®Œæˆï¼Œé€€å‡ºç¢¼: {exit_code}")
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
