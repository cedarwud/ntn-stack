#!/usr/bin/env python3
"""
å£“åŠ›æ¸¬è©¦æ¨¡çµ„
æ¸¬è©¦ç³»çµ±åœ¨æ¥µé™æ¢ä»¶ä¸‹çš„æ€§èƒ½è¡¨ç¾å’Œç©©å®šæ€§

æ¸¬è©¦ç¯„åœï¼š
- æ¥µé«˜è² è¼‰æ¸¬è©¦
- é•·æ™‚é–“é‹è¡Œç©©å®šæ€§
- è¨˜æ†¶é«”å’Œ CPU æ¥µé™æ¸¬è©¦
- åŒæ™‚é€£æ¥æ•¸æ¥µé™æ¸¬è©¦
- ç³»çµ±æ¢å¾©èƒ½åŠ›æ¸¬è©¦
"""

import asyncio
import logging
import psutil
import time
import statistics
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any
import aiohttp
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class StressTestResult:
    """å£“åŠ›æ¸¬è©¦çµæœ"""

    test_name: str
    peak_load: int
    duration_seconds: float
    success_rate: float
    max_response_time_ms: float
    avg_response_time_ms: float
    memory_peak_mb: float
    cpu_peak_percent: float
    errors_count: int
    system_stable: bool
    recovery_successful: bool


class StressTester:
    """å£“åŠ›æ¸¬è©¦å™¨"""

    def __init__(self, config: Dict):
        self.config = config
        self.environment = config["environment"]
        self.services = self.environment["services"]
        self.results: List[StressTestResult] = []

        # å£“åŠ›æ¸¬è©¦åƒæ•¸
        self.max_concurrent_requests = 500
        self.test_duration_seconds = 120
        self.ramp_up_time_seconds = 30

    async def run_stress_tests(self) -> Tuple[bool, Dict]:
        """åŸ·è¡Œå£“åŠ›æ¸¬è©¦å¥—ä»¶"""
        logger.info("ğŸ’¥ é–‹å§‹åŸ·è¡Œå£“åŠ›æ¸¬è©¦")

        test_scenarios = [
            ("extreme_load_test", await self._test_extreme_load()),
            ("memory_stress_test", await self._test_memory_stress()),
            ("long_duration_stability", await self._test_long_duration_stability()),
            (
                "concurrent_connections_limit",
                await self._test_concurrent_connections_limit(),
            ),
            ("recovery_after_overload", await self._test_recovery_after_overload()),
        ]

        passed_tests = sum(1 for _, passed in test_scenarios if passed)
        total_tests = len(test_scenarios)

        details = {
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "success_rate": passed_tests / total_tests,
            "test_results": {name: passed for name, passed in test_scenarios},
            "detailed_results": [
                {
                    "test": r.test_name,
                    "peak_load": r.peak_load,
                    "duration": r.duration_seconds,
                    "success_rate": r.success_rate,
                    "avg_response_ms": r.avg_response_time_ms,
                    "system_stable": r.system_stable,
                }
                for r in self.results
            ],
        }

        overall_success = passed_tests == total_tests
        logger.info(f"ğŸ’¥ å£“åŠ›æ¸¬è©¦å®Œæˆï¼ŒæˆåŠŸç‡: {details['success_rate']:.1%}")

        return overall_success, details

    async def _test_extreme_load(self) -> bool:
        """æ¥µé™è² è¼‰æ¸¬è©¦"""
        logger.info("ğŸ”¥ åŸ·è¡Œæ¥µé™è² è¼‰æ¸¬è©¦")

        test_name = "extreme_load_test"
        start_time = time.time()
        url = f"{self.services['netstack']['url']}/health"

        # è¨˜éŒ„ç³»çµ±è³‡æºç‹€æ…‹
        initial_memory = psutil.virtual_memory().used / 1024 / 1024
        peak_memory = initial_memory
        peak_cpu = 0

        response_times = []
        success_count = 0
        total_requests = 0
        errors_count = 0

        # å‰µå»ºå¤§é‡ä¸¦ç™¼è«‹æ±‚
        semaphore = asyncio.Semaphore(100)  # é™åˆ¶åŒæ™‚é€²è¡Œçš„è«‹æ±‚æ•¸

        async def make_request(session):
            nonlocal success_count, total_requests, errors_count, peak_memory, peak_cpu

            async with semaphore:
                start_req = time.time()
                try:
                    async with session.get(url, timeout=10) as response:
                        response_time = (time.time() - start_req) * 1000
                        response_times.append(response_time)
                        total_requests += 1

                        if response.status == 200:
                            success_count += 1
                        else:
                            errors_count += 1

                        # ç›£æ§ç³»çµ±è³‡æº
                        current_memory = psutil.virtual_memory().used / 1024 / 1024
                        current_cpu = psutil.cpu_percent()
                        peak_memory = max(peak_memory, current_memory)
                        peak_cpu = max(peak_cpu, current_cpu)

                except Exception as e:
                    total_requests += 1
                    errors_count += 1
                    logger.debug(f"è«‹æ±‚å¤±æ•—: {e}")

        # é€æ­¥å¢åŠ è² è¼‰
        async with aiohttp.ClientSession() as session:
            for load_level in [50, 100, 200, 300, 500]:
                logger.debug(f"æ¸¬è©¦è² è¼‰ç´šåˆ¥: {load_level} ä¸¦ç™¼è«‹æ±‚")

                # å‰µå»ºæŒ‡å®šæ•¸é‡çš„ä¸¦ç™¼è«‹æ±‚
                tasks = [make_request(session) for _ in range(load_level)]
                await asyncio.gather(*tasks, return_exceptions=True)

                # çŸ­æš«é–“éš”è®“ç³»çµ±ç©©å®š
                await asyncio.sleep(2)

        total_duration = time.time() - start_time
        success_rate = success_count / total_requests if total_requests > 0 else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0
        max_response_time = max(response_times) if response_times else 0

        # åˆ¤æ–·ç³»çµ±æ˜¯å¦ç©©å®š
        system_stable = (
            success_rate >= 0.8
            and peak_cpu < 95
            and errors_count < total_requests * 0.2
        )

        result = StressTestResult(
            test_name=test_name,
            peak_load=500,
            duration_seconds=total_duration,
            success_rate=success_rate,
            max_response_time_ms=max_response_time,
            avg_response_time_ms=avg_response_time,
            memory_peak_mb=peak_memory,
            cpu_peak_percent=peak_cpu,
            errors_count=errors_count,
            system_stable=system_stable,
            recovery_successful=True,  # æš«æ™‚è¨­ç‚º True
        )

        self.results.append(result)

        if system_stable:
            logger.info(
                f"âœ… æ¥µé™è² è¼‰æ¸¬è©¦é€šé - æˆåŠŸç‡: {success_rate:.1%}, å³°å€¼è² è¼‰: 500"
            )
        else:
            logger.error(
                f"âŒ æ¥µé™è² è¼‰æ¸¬è©¦å¤±æ•— - æˆåŠŸç‡: {success_rate:.1%}, éŒ¯èª¤æ•¸: {errors_count}"
            )

        return system_stable

    async def _test_memory_stress(self) -> bool:
        """è¨˜æ†¶é«”å£“åŠ›æ¸¬è©¦"""
        logger.info("ğŸ§  åŸ·è¡Œè¨˜æ†¶é«”å£“åŠ›æ¸¬è©¦")

        test_name = "memory_stress_test"
        start_time = time.time()

        initial_memory = psutil.virtual_memory().used / 1024 / 1024
        peak_memory = initial_memory

        # æŒçºŒç™¼é€å¤§é‡è«‹æ±‚ä»¥å¢åŠ è¨˜æ†¶é«”ä½¿ç”¨
        url = f"{self.services['netstack']['url']}/health"
        success_count = 0
        total_requests = 0
        response_times = []

        async with aiohttp.ClientSession() as session:
            # æŒçºŒ 60 ç§’çš„è¨˜æ†¶é«”å£“åŠ›æ¸¬è©¦
            end_time = time.time() + 60

            while time.time() < end_time:
                # æ‰¹é‡å‰µå»ºè«‹æ±‚
                tasks = []
                for _ in range(20):  # æ¯æ‰¹ 20 å€‹è«‹æ±‚
                    tasks.append(self._memory_stress_request(session, url))

                results = await asyncio.gather(*tasks, return_exceptions=True)

                # è™•ç†çµæœ
                for result in results:
                    total_requests += 1
                    if isinstance(result, tuple) and result[0]:
                        success_count += 1
                        response_times.append(result[1])

                # ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨
                current_memory = psutil.virtual_memory().used / 1024 / 1024
                peak_memory = max(peak_memory, current_memory)

                # çŸ­æš«ä¼‘æ¯
                await asyncio.sleep(0.5)

        total_duration = time.time() - start_time
        memory_growth = peak_memory - initial_memory
        success_rate = success_count / total_requests if total_requests > 0 else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0

        # åˆ¤æ–·è¨˜æ†¶é«”æ˜¯å¦ç©©å®šï¼ˆæˆé•·ä¸è¶…é 200MBï¼‰
        memory_stable = memory_growth < 200
        performance_stable = success_rate >= 0.9

        result = StressTestResult(
            test_name=test_name,
            peak_load=total_requests,
            duration_seconds=total_duration,
            success_rate=success_rate,
            max_response_time_ms=max(response_times) if response_times else 0,
            avg_response_time_ms=avg_response_time,
            memory_peak_mb=peak_memory,
            cpu_peak_percent=psutil.cpu_percent(),
            errors_count=total_requests - success_count,
            system_stable=memory_stable and performance_stable,
            recovery_successful=True,
        )

        self.results.append(result)

        if memory_stable and performance_stable:
            logger.info(
                f"âœ… è¨˜æ†¶é«”å£“åŠ›æ¸¬è©¦é€šé - è¨˜æ†¶é«”æˆé•·: {memory_growth:.1f}MB, æˆåŠŸç‡: {success_rate:.1%}"
            )
        else:
            logger.error(
                f"âŒ è¨˜æ†¶é«”å£“åŠ›æ¸¬è©¦å¤±æ•— - è¨˜æ†¶é«”æˆé•·: {memory_growth:.1f}MB, æˆåŠŸç‡: {success_rate:.1%}"
            )

        return memory_stable and performance_stable

    async def _test_long_duration_stability(self) -> bool:
        """é•·æ™‚é–“é‹è¡Œç©©å®šæ€§æ¸¬è©¦"""
        logger.info("â° åŸ·è¡Œé•·æ™‚é–“é‹è¡Œç©©å®šæ€§æ¸¬è©¦ (5åˆ†é˜)")

        test_name = "long_duration_stability"
        start_time = time.time()
        test_duration = 300  # 5 åˆ†é˜

        url = f"{self.services['netstack']['url']}/health"
        success_count = 0
        total_requests = 0
        response_times = []
        memory_samples = []
        cpu_samples = []

        async with aiohttp.ClientSession() as session:
            end_time = time.time() + test_duration

            while time.time() < end_time:
                # æŒçºŒç™¼é€ç©©å®šè² è¼‰
                batch_start = time.time()

                # æ¯ç§’ 5 å€‹è«‹æ±‚çš„ç©©å®šè² è¼‰
                for _ in range(5):
                    start_req = time.time()
                    try:
                        async with session.get(url, timeout=10) as response:
                            response_time = (time.time() - start_req) * 1000
                            response_times.append(response_time)
                            total_requests += 1

                            if response.status == 200:
                                success_count += 1
                    except Exception:
                        total_requests += 1

                # è¨˜éŒ„ç³»çµ±è³‡æº
                memory_samples.append(psutil.virtual_memory().used / 1024 / 1024)
                cpu_samples.append(psutil.cpu_percent())

                # ç­‰å¾…åˆ°ä¸‹ä¸€ç§’
                elapsed = time.time() - batch_start
                if elapsed < 1.0:
                    await asyncio.sleep(1.0 - elapsed)

        total_duration = time.time() - start_time
        success_rate = success_count / total_requests if total_requests > 0 else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0

        # åˆ†æç©©å®šæ€§
        memory_trend = self._calculate_trend(memory_samples)
        cpu_stability = statistics.stdev(cpu_samples) if len(cpu_samples) > 1 else 0

        # ç©©å®šæ€§åˆ¤æ–·æ¨™æº–
        stability_good = (
            success_rate >= 0.95
            and memory_trend < 5.0  # è¨˜æ†¶é«”æˆé•·æ–œç‡å°æ–¼ 5MB/åˆ†é˜
            and cpu_stability < 20  # CPU ä½¿ç”¨ç‡æ¨™æº–å·®å°æ–¼ 20%
            and avg_response_time < 100  # å¹³å‡éŸ¿æ‡‰æ™‚é–“å°æ–¼ 100ms
        )

        result = StressTestResult(
            test_name=test_name,
            peak_load=5,  # æ¯ç§’ 5 å€‹è«‹æ±‚
            duration_seconds=total_duration,
            success_rate=success_rate,
            max_response_time_ms=max(response_times) if response_times else 0,
            avg_response_time_ms=avg_response_time,
            memory_peak_mb=max(memory_samples) if memory_samples else 0,
            cpu_peak_percent=max(cpu_samples) if cpu_samples else 0,
            errors_count=total_requests - success_count,
            system_stable=stability_good,
            recovery_successful=True,
        )

        self.results.append(result)

        if stability_good:
            logger.info(
                f"âœ… é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦é€šé - æˆåŠŸç‡: {success_rate:.1%}, è¨˜æ†¶é«”è¶¨å‹¢: {memory_trend:.2f}MB/min"
            )
        else:
            logger.error(
                f"âŒ é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦å¤±æ•— - æˆåŠŸç‡: {success_rate:.1%}, è¨˜æ†¶é«”è¶¨å‹¢: {memory_trend:.2f}MB/min"
            )

        return stability_good

    async def _test_concurrent_connections_limit(self) -> bool:
        """åŒæ™‚é€£æ¥æ•¸æ¥µé™æ¸¬è©¦"""
        logger.info("ğŸ”€ åŸ·è¡ŒåŒæ™‚é€£æ¥æ•¸æ¥µé™æ¸¬è©¦")

        test_name = "concurrent_connections_limit"
        start_time = time.time()
        url = f"{self.services['netstack']['url']}/health"

        max_successful_connections = 0

        # æ¸¬è©¦ä¸åŒçš„åŒæ™‚é€£æ¥æ•¸
        for connection_count in [10, 25, 50, 100, 200, 300]:
            logger.debug(f"æ¸¬è©¦ {connection_count} åŒæ™‚é€£æ¥")

            success_count = 0
            tasks = []

            # å‰µå»ºé•·æ™‚é–“ä¿æŒçš„é€£æ¥
            async def maintain_connection():
                try:
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, timeout=30) as response:
                            if response.status == 200:
                                nonlocal success_count
                                success_count += 1
                                # ä¿æŒé€£æ¥ä¸€æ®µæ™‚é–“
                                await asyncio.sleep(5)
                            return True
                except Exception:
                    return False

            # åŒæ™‚å»ºç«‹æŒ‡å®šæ•¸é‡çš„é€£æ¥
            tasks = [maintain_connection() for _ in range(connection_count)]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            success_rate = success_count / connection_count

            if success_rate >= 0.8:  # 80% æˆåŠŸç‡
                max_successful_connections = connection_count
                logger.debug(
                    f"âœ… {connection_count} é€£æ¥æ¸¬è©¦é€šé (æˆåŠŸç‡: {success_rate:.1%})"
                )
            else:
                logger.debug(
                    f"âŒ {connection_count} é€£æ¥æ¸¬è©¦å¤±æ•— (æˆåŠŸç‡: {success_rate:.1%})"
                )
                break

            # çµ¦ç³»çµ±æ™‚é–“æ¢å¾©
            await asyncio.sleep(3)

        total_duration = time.time() - start_time

        # åˆ¤æ–·æ˜¯å¦é”åˆ°åˆç†çš„é€£æ¥æ•¸é™åˆ¶
        connection_limit_reasonable = max_successful_connections >= 50

        result = StressTestResult(
            test_name=test_name,
            peak_load=max_successful_connections,
            duration_seconds=total_duration,
            success_rate=1.0 if connection_limit_reasonable else 0.0,
            max_response_time_ms=0,
            avg_response_time_ms=0,
            memory_peak_mb=psutil.virtual_memory().used / 1024 / 1024,
            cpu_peak_percent=psutil.cpu_percent(),
            errors_count=0,
            system_stable=connection_limit_reasonable,
            recovery_successful=True,
        )

        self.results.append(result)

        if connection_limit_reasonable:
            logger.info(
                f"âœ… åŒæ™‚é€£æ¥æ•¸æ¥µé™æ¸¬è©¦é€šé - æœ€å¤§æˆåŠŸé€£æ¥æ•¸: {max_successful_connections}"
            )
        else:
            logger.error(
                f"âŒ åŒæ™‚é€£æ¥æ•¸æ¥µé™æ¸¬è©¦å¤±æ•— - æœ€å¤§æˆåŠŸé€£æ¥æ•¸: {max_successful_connections}"
            )

        return connection_limit_reasonable

    async def _test_recovery_after_overload(self) -> bool:
        """è¶…è¼‰å¾Œæ¢å¾©èƒ½åŠ›æ¸¬è©¦"""
        logger.info("ğŸ”„ åŸ·è¡Œè¶…è¼‰å¾Œæ¢å¾©èƒ½åŠ›æ¸¬è©¦")

        test_name = "recovery_after_overload"
        start_time = time.time()
        url = f"{self.services['netstack']['url']}/health"

        # éšæ®µ 1: æ­£å¸¸è² è¼‰åŸºç·šæ¸¬è©¦
        baseline_success_rate = await self._measure_baseline_performance(url)

        # éšæ®µ 2: è¶…è¼‰æ¸¬è©¦
        await self._apply_overload(url)

        # éšæ®µ 3: æ¢å¾©æœŸç­‰å¾…
        await asyncio.sleep(10)  # ç­‰å¾…ç³»çµ±æ¢å¾©

        # éšæ®µ 4: æ¢å¾©å¾Œæ€§èƒ½æ¸¬è©¦
        recovery_success_rate = await self._measure_recovery_performance(url)

        total_duration = time.time() - start_time

        # åˆ¤æ–·æ¢å¾©æ˜¯å¦æˆåŠŸï¼ˆæ¢å¾©å¾Œæ€§èƒ½æ‡‰è©²æ¥è¿‘åŸºç·šï¼‰
        recovery_successful = recovery_success_rate >= baseline_success_rate * 0.9

        result = StressTestResult(
            test_name=test_name,
            peak_load=1000,  # è¶…è¼‰éšæ®µçš„è² è¼‰
            duration_seconds=total_duration,
            success_rate=recovery_success_rate,
            max_response_time_ms=0,
            avg_response_time_ms=0,
            memory_peak_mb=psutil.virtual_memory().used / 1024 / 1024,
            cpu_peak_percent=psutil.cpu_percent(),
            errors_count=0,
            system_stable=True,
            recovery_successful=recovery_successful,
        )

        self.results.append(result)

        if recovery_successful:
            logger.info(
                f"âœ… è¶…è¼‰å¾Œæ¢å¾©æ¸¬è©¦é€šé - åŸºç·š: {baseline_success_rate:.1%}, æ¢å¾©: {recovery_success_rate:.1%}"
            )
        else:
            logger.error(
                f"âŒ è¶…è¼‰å¾Œæ¢å¾©æ¸¬è©¦å¤±æ•— - åŸºç·š: {baseline_success_rate:.1%}, æ¢å¾©: {recovery_success_rate:.1%}"
            )

        return recovery_successful

    # ===== è¼”åŠ©æ–¹æ³• =====

    async def _memory_stress_request(self, session, url) -> Tuple[bool, float]:
        """è¨˜æ†¶é«”å£“åŠ›æ¸¬è©¦çš„å–®å€‹è«‹æ±‚"""
        start_time = time.time()
        try:
            async with session.get(url, timeout=5) as response:
                response_time = (time.time() - start_time) * 1000
                return response.status == 200, response_time
        except Exception:
            response_time = (time.time() - start_time) * 1000
            return False, response_time

    def _calculate_trend(self, values: List[float]) -> float:
        """è¨ˆç®—æ•¸å€¼åºåˆ—çš„è¶¨å‹¢ï¼ˆæ–œç‡ï¼‰"""
        if len(values) < 2:
            return 0.0

        n = len(values)
        x_values = list(range(n))

        # è¨ˆç®—ç·šæ€§å›æ­¸æ–œç‡
        x_mean = sum(x_values) / n
        y_mean = sum(values) / n

        numerator = sum((x_values[i] - x_mean) * (values[i] - y_mean) for i in range(n))
        denominator = sum((x_values[i] - x_mean) ** 2 for i in range(n))

        if denominator == 0:
            return 0.0

        slope = numerator / denominator
        return slope  # æ¯å€‹æ™‚é–“å–®ä½çš„è®ŠåŒ–é‡

    async def _measure_baseline_performance(self, url: str) -> float:
        """æ¸¬é‡åŸºç·šæ€§èƒ½"""
        success_count = 0
        total_requests = 20

        async with aiohttp.ClientSession() as session:
            for _ in range(total_requests):
                try:
                    async with session.get(url, timeout=5) as response:
                        if response.status == 200:
                            success_count += 1
                except Exception:
                    pass
                await asyncio.sleep(0.1)

        return success_count / total_requests

    async def _apply_overload(self, url: str):
        """æ‡‰ç”¨è¶…è¼‰å£“åŠ›"""
        logger.debug("æ‡‰ç”¨è¶…è¼‰å£“åŠ›...")

        async def overload_request(session):
            try:
                async with session.get(url, timeout=1) as response:
                    pass
            except Exception:
                pass

        async with aiohttp.ClientSession() as session:
            # å‰µå»ºå¤§é‡ä¸¦ç™¼è«‹æ±‚é€ æˆè¶…è¼‰
            tasks = [overload_request(session) for _ in range(1000)]
            await asyncio.gather(*tasks, return_exceptions=True)

    async def _measure_recovery_performance(self, url: str) -> float:
        """æ¸¬é‡æ¢å¾©å¾Œæ€§èƒ½"""
        success_count = 0
        total_requests = 20

        async with aiohttp.ClientSession() as session:
            for _ in range(total_requests):
                try:
                    async with session.get(url, timeout=10) as response:
                        if response.status == 200:
                            success_count += 1
                except Exception:
                    pass
                await asyncio.sleep(0.2)

        return success_count / total_requests
