#!/usr/bin/env python3
"""
å¤§è¦æ¨¡è² è¼‰æ¸¬è©¦å¥—ä»¶
å¯¦ç¾éšæ®µä¸ƒè¦æ±‚çš„å¤§è¦æ¨¡è² è¼‰å’Œå£“åŠ›æ¸¬è©¦

åŠŸèƒ½ï¼š
1. ä¸¦ç™¼ç”¨æˆ¶è² è¼‰æ¸¬è©¦
2. æ¼¸é€²å¼è² è¼‰å¢é•·æ¸¬è©¦
3. æŒçºŒè² è¼‰æ¸¬è©¦
4. å³°å€¼è² è¼‰æ¸¬è©¦
5. å¤šæœå‹™è² è¼‰åˆ†æ•£æ¸¬è©¦
6. å¯¦éš›å ´æ™¯æ¨¡æ“¬è² è¼‰æ¸¬è©¦
"""

import asyncio
import time
import logging
import statistics
import random
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
import aiohttp
import numpy as np
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import json
import psutil

logger = logging.getLogger(__name__)


@dataclass
class LoadTestConfig:
    """è² è¼‰æ¸¬è©¦é…ç½®"""
    
    base_url: str
    max_concurrent_users: int = 100
    ramp_up_time_seconds: int = 60
    test_duration_seconds: int = 300
    steady_state_duration_seconds: int = 180
    think_time_ms: int = 1000
    timeout_seconds: int = 30
    target_scenarios: List[str] = field(default_factory=list)


@dataclass
class LoadTestResult:
    """è² è¼‰æ¸¬è©¦çµæœ"""
    
    test_name: str
    start_time: datetime
    end_time: datetime
    total_requests: int
    successful_requests: int
    failed_requests: int
    avg_response_time_ms: float
    p95_response_time_ms: float
    p99_response_time_ms: float
    requests_per_second: float
    error_rate: float
    throughput_mbps: float
    concurrent_users_peak: int
    detailed_metrics: List[Dict] = field(default_factory=list)


class VirtualUser:
    """è™›æ“¬ç”¨æˆ¶é¡"""
    
    def __init__(self, user_id: int, session: aiohttp.ClientSession, config: LoadTestConfig):
        self.user_id = user_id
        self.session = session
        self.config = config
        self.requests_sent = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.response_times = []
        self.is_active = False
        
    async def run_user_scenario(self, scenario_name: str, duration_seconds: int) -> Dict[str, Any]:
        """åŸ·è¡Œç”¨æˆ¶å ´æ™¯"""
        self.is_active = True
        start_time = time.time()
        
        try:
            while time.time() - start_time < duration_seconds and self.is_active:
                # åŸ·è¡Œå ´æ™¯æ­¥é©Ÿ
                await self._execute_scenario_step(scenario_name)
                
                # æ€è€ƒæ™‚é–“
                await asyncio.sleep(self.config.think_time_ms / 1000.0)
                
        except Exception as e:
            logger.error(f"ç”¨æˆ¶ {self.user_id} åŸ·è¡Œå ´æ™¯ {scenario_name} å¤±æ•—: {e}")
        
        finally:
            self.is_active = False
            
        return self._get_user_metrics()
    
    async def _execute_scenario_step(self, scenario_name: str):
        """åŸ·è¡Œå ´æ™¯æ­¥é©Ÿ"""
        # æ ¹æ“šå ´æ™¯åç¨±é¸æ“‡ä¸åŒçš„è«‹æ±‚æ¨¡å¼
        if scenario_name == "uav_data_collection":
            await self._uav_data_collection_scenario()
        elif scenario_name == "satellite_tracking":
            await self._satellite_tracking_scenario()
        elif scenario_name == "interference_monitoring":
            await self._interference_monitoring_scenario()
        elif scenario_name == "mesh_network_operation":
            await self._mesh_network_operation_scenario()
        else:
            await self._default_api_scenario()
    
    async def _uav_data_collection_scenario(self):
        """ç„¡äººæ©Ÿæ•¸æ“šæ”¶é›†å ´æ™¯"""
        endpoints = [
            "/api/v1/uav/status",
            "/api/v1/uav/metrics",
            "/api/v1/uav/trajectory"
        ]
        
        for endpoint in endpoints:
            await self._make_request("GET", endpoint)
            await asyncio.sleep(0.1)  # å°å»¶é²
    
    async def _satellite_tracking_scenario(self):
        """è¡›æ˜Ÿè¿½è¹¤å ´æ™¯"""
        endpoints = [
            "/api/v1/satellite-gnb/status",
            "/api/v1/oneweb/constellation",
            "/api/v1/satellite-gnb/mapping"
        ]
        
        for endpoint in endpoints:
            await self._make_request("GET", endpoint)
            await asyncio.sleep(0.1)
    
    async def _interference_monitoring_scenario(self):
        """å¹²æ“¾ç›£æ§å ´æ™¯"""
        endpoints = [
            "/api/v1/interference/current",
            "/api/v1/interference/mitigation-status",
            "/api/v1/ai-ran/metrics"
        ]
        
        for endpoint in endpoints:
            await self._make_request("GET", endpoint)
            await asyncio.sleep(0.1)
    
    async def _mesh_network_operation_scenario(self):
        """Meshç¶²çµ¡æ“ä½œå ´æ™¯"""
        endpoints = [
            "/api/v1/mesh/status",
            "/api/v1/mesh/topology",
            "/api/v1/mesh/failover-status"
        ]
        
        for endpoint in endpoints:
            await self._make_request("GET", endpoint)
            await asyncio.sleep(0.1)
    
    async def _default_api_scenario(self):
        """é è¨­APIå ´æ™¯"""
        endpoints = [
            "/health",
            "/api/v1/status",
            "/metrics"
        ]
        
        endpoint = random.choice(endpoints)
        await self._make_request("GET", endpoint)
    
    async def _make_request(self, method: str, endpoint: str, data: Optional[Dict] = None):
        """ç™¼é€HTTPè«‹æ±‚"""
        url = f"{self.config.base_url}{endpoint}"
        start_time = time.time()
        
        try:
            timeout = aiohttp.ClientTimeout(total=self.config.timeout_seconds)
            
            if method.upper() == "GET":
                async with self.session.get(url, timeout=timeout) as response:
                    await response.text()
                    response_time_ms = (time.time() - start_time) * 1000
                    
                    if response.status < 400:
                        self.successful_requests += 1
                    else:
                        self.failed_requests += 1
                        
            elif method.upper() == "POST":
                async with self.session.post(url, json=data, timeout=timeout) as response:
                    await response.text()
                    response_time_ms = (time.time() - start_time) * 1000
                    
                    if response.status < 400:
                        self.successful_requests += 1
                    else:
                        self.failed_requests += 1
            
            self.response_times.append(response_time_ms)
            self.requests_sent += 1
            
        except Exception as e:
            response_time_ms = (time.time() - start_time) * 1000
            self.response_times.append(response_time_ms)
            self.failed_requests += 1
            self.requests_sent += 1
            
            logger.debug(f"ç”¨æˆ¶ {self.user_id} è«‹æ±‚å¤±æ•—: {method} {url} - {e}")
    
    def _get_user_metrics(self) -> Dict[str, Any]:
        """ç²å–ç”¨æˆ¶æŒ‡æ¨™"""
        if not self.response_times:
            return {
                "user_id": self.user_id,
                "requests_sent": 0,
                "successful_requests": 0,
                "failed_requests": 0,
                "avg_response_time_ms": 0,
                "error_rate": 1.0,
                "response_times": []
            }
        
        return {
            "user_id": self.user_id,
            "requests_sent": self.requests_sent,
            "successful_requests": self.successful_requests,
            "failed_requests": self.failed_requests,
            "avg_response_time_ms": statistics.mean(self.response_times),
            "error_rate": self.failed_requests / self.requests_sent if self.requests_sent > 0 else 0,
            "response_times": self.response_times
        }


class LoadTestSuite:
    """å¤§è¦æ¨¡è² è¼‰æ¸¬è©¦å¥—ä»¶"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.test_results = []
        self.active_users = []

    async def run_concurrent_load_test(
        self, 
        concurrent_users: int = 50,
        duration_seconds: int = 60,
        base_url: str = "http://localhost:8080"
    ) -> Dict[str, Any]:
        """åŸ·è¡Œä¸¦ç™¼è² è¼‰æ¸¬è©¦"""
        
        self.logger.info(f"ğŸš€ é–‹å§‹ä¸¦ç™¼è² è¼‰æ¸¬è©¦: {concurrent_users} ä¸¦ç™¼ç”¨æˆ¶, {duration_seconds} ç§’")
        
        config = LoadTestConfig(
            base_url=base_url,
            max_concurrent_users=concurrent_users,
            test_duration_seconds=duration_seconds
        )
        
        start_time = datetime.utcnow()
        
        # å‰µå»ºHTTPæœƒè©±
        connector = aiohttp.TCPConnector(limit=concurrent_users * 2)
        async with aiohttp.ClientSession(connector=connector) as session:
            
            # å‰µå»ºè™›æ“¬ç”¨æˆ¶
            users = [
                VirtualUser(i, session, config) 
                for i in range(concurrent_users)
            ]
            
            # ä¸¦ç™¼åŸ·è¡Œç”¨æˆ¶å ´æ™¯
            tasks = [
                user.run_user_scenario("default_api", duration_seconds)
                for user in users
            ]
            
            user_results = await asyncio.gather(*tasks, return_exceptions=True)
            
        end_time = datetime.utcnow()
        
        # èšåˆçµæœ
        result = self._aggregate_load_test_results(
            "concurrent_load_test",
            start_time,
            end_time,
            user_results,
            concurrent_users
        )
        
        self.test_results.append(result)
        
        self.logger.info(f"âœ… ä¸¦ç™¼è² è¼‰æ¸¬è©¦å®Œæˆ: æˆåŠŸç‡ {(1-result.error_rate)*100:.1f}%, "
                        f"å¹³å‡éŸ¿æ‡‰æ™‚é–“ {result.avg_response_time_ms:.1f}ms")
        
        return {
            "success": result.error_rate < 0.1,
            "success_rate": 1 - result.error_rate,
            "avg_response_time_ms": result.avg_response_time_ms,
            "requests_per_second": result.requests_per_second
        }

    async def run_ramp_up_load_test(
        self,
        max_users: int = 100,
        ramp_up_time_seconds: int = 300,
        steady_state_time_seconds: int = 600,
        base_url: str = "http://localhost:8080"
    ) -> LoadTestResult:
        """åŸ·è¡Œæ¼¸é€²å¼è² è¼‰æ¸¬è©¦"""
        
        self.logger.info(f"ğŸ“ˆ é–‹å§‹æ¼¸é€²å¼è² è¼‰æ¸¬è©¦: æœ€å¤§ {max_users} ç”¨æˆ¶, "
                        f"æ¼¸é€²æ™‚é–“ {ramp_up_time_seconds}s, ç©©å®šæ™‚é–“ {steady_state_time_seconds}s")
        
        config = LoadTestConfig(
            base_url=base_url,
            max_concurrent_users=max_users,
            ramp_up_time_seconds=ramp_up_time_seconds,
            steady_state_duration_seconds=steady_state_time_seconds
        )
        
        start_time = datetime.utcnow()
        user_results = []
        
        connector = aiohttp.TCPConnector(limit=max_users * 2)
        async with aiohttp.ClientSession(connector=connector) as session:
            
            # æ¼¸é€²å¼å¢åŠ ç”¨æˆ¶
            active_tasks = []
            users_added = 0
            
            for step in range(ramp_up_time_seconds):
                # è¨ˆç®—æ­¤æ­¥é©Ÿæ‡‰è©²çš„ç”¨æˆ¶æ•¸
                target_users = int((step + 1) * max_users / ramp_up_time_seconds)
                
                # æ·»åŠ æ–°ç”¨æˆ¶
                while users_added < target_users:
                    user = VirtualUser(users_added, session, config)
                    task = asyncio.create_task(
                        user.run_user_scenario(
                            "mixed_scenarios", 
                            ramp_up_time_seconds - step + steady_state_time_seconds
                        )
                    )
                    active_tasks.append(task)
                    users_added += 1
                
                await asyncio.sleep(1)  # æ¯ç§’æª¢æŸ¥ä¸€æ¬¡
            
            # ç­‰å¾…ç©©å®šç‹€æ…‹çµæŸ
            self.logger.info(f"ğŸ¯ é€²å…¥ç©©å®šç‹€æ…‹: {max_users} ä¸¦ç™¼ç”¨æˆ¶")
            await asyncio.sleep(steady_state_time_seconds)
            
            # æ”¶é›†æ‰€æœ‰çµæœ
            user_results = await asyncio.gather(*active_tasks, return_exceptions=True)
        
        end_time = datetime.utcnow()
        
        result = self._aggregate_load_test_results(
            "ramp_up_load_test",
            start_time,
            end_time,
            user_results,
            max_users
        )
        
        self.test_results.append(result)
        
        self.logger.info(f"âœ… æ¼¸é€²å¼è² è¼‰æ¸¬è©¦å®Œæˆ: æˆåŠŸç‡ {(1-result.error_rate)*100:.1f}%, "
                        f"å³°å€¼ RPS {result.requests_per_second:.1f}")
        
        return result

    async def run_spike_load_test(
        self,
        baseline_users: int = 10,
        spike_users: int = 100,
        spike_duration_seconds: int = 60,
        base_url: str = "http://localhost:8080"
    ) -> LoadTestResult:
        """åŸ·è¡Œå³°å€¼è² è¼‰æ¸¬è©¦"""
        
        self.logger.info(f"âš¡ é–‹å§‹å³°å€¼è² è¼‰æ¸¬è©¦: åŸºç·š {baseline_users} -> å³°å€¼ {spike_users} ç”¨æˆ¶")
        
        config = LoadTestConfig(
            base_url=base_url,
            max_concurrent_users=spike_users,
            test_duration_seconds=spike_duration_seconds * 3  # åŸºç·š + å³°å€¼ + æ¢å¾©
        )
        
        start_time = datetime.utcnow()
        
        connector = aiohttp.TCPConnector(limit=spike_users * 2)
        async with aiohttp.ClientSession(connector=connector) as session:
            
            # éšæ®µ1: åŸºç·šè² è¼‰
            self.logger.info(f"ğŸ“Š åŸºç·šéšæ®µ: {baseline_users} ç”¨æˆ¶")
            baseline_users_list = [
                VirtualUser(i, session, config) 
                for i in range(baseline_users)
            ]
            
            baseline_tasks = [
                user.run_user_scenario("baseline_load", spike_duration_seconds * 3)
                for user in baseline_users_list
            ]
            
            # ç­‰å¾…åŸºç·šç©©å®š
            await asyncio.sleep(spike_duration_seconds)
            
            # éšæ®µ2: å³°å€¼è² è¼‰
            self.logger.info(f"ğŸš€ å³°å€¼éšæ®µ: å¢åŠ åˆ° {spike_users} ç”¨æˆ¶")
            spike_users_list = [
                VirtualUser(i + baseline_users, session, config)
                for i in range(spike_users - baseline_users)
            ]
            
            spike_tasks = [
                user.run_user_scenario("spike_load", spike_duration_seconds)
                for user in spike_users_list
            ]
            
            # ç­‰å¾…å³°å€¼éšæ®µ
            spike_results = await asyncio.gather(*spike_tasks, return_exceptions=True)
            
            # éšæ®µ3: æ¢å¾©éšæ®µ
            self.logger.info("ğŸ“‰ æ¢å¾©éšæ®µ: å›åˆ°åŸºç·šè² è¼‰")
            await asyncio.sleep(spike_duration_seconds)
            
            # æ”¶é›†åŸºç·šçµæœ
            baseline_results = await asyncio.gather(*baseline_tasks, return_exceptions=True)
        
        end_time = datetime.utcnow()
        
        # åˆä½µæ‰€æœ‰çµæœ
        all_results = baseline_results + spike_results
        
        result = self._aggregate_load_test_results(
            "spike_load_test",
            start_time,
            end_time,
            all_results,
            spike_users
        )
        
        self.test_results.append(result)
        
        self.logger.info(f"âœ… å³°å€¼è² è¼‰æ¸¬è©¦å®Œæˆ: å³°å€¼è™•ç†èƒ½åŠ›é©—è­‰")
        
        return result

    async def run_endurance_load_test(
        self,
        concurrent_users: int = 30,
        duration_hours: int = 2,
        base_url: str = "http://localhost:8080"
    ) -> LoadTestResult:
        """åŸ·è¡ŒæŒä¹…æ€§è² è¼‰æ¸¬è©¦"""
        
        duration_seconds = duration_hours * 3600
        
        self.logger.info(f"â±ï¸ é–‹å§‹æŒä¹…æ€§è² è¼‰æ¸¬è©¦: {concurrent_users} ç”¨æˆ¶, {duration_hours} å°æ™‚")
        
        config = LoadTestConfig(
            base_url=base_url,
            max_concurrent_users=concurrent_users,
            test_duration_seconds=duration_seconds
        )
        
        start_time = datetime.utcnow()
        
        connector = aiohttp.TCPConnector(limit=concurrent_users * 2)
        async with aiohttp.ClientSession(connector=connector) as session:
            
            users = [
                VirtualUser(i, session, config)
                for i in range(concurrent_users)
            ]
            
            # æ¯å°æ™‚è¼ªæ›å ´æ™¯ä»¥æ¨¡æ“¬çœŸå¯¦ä½¿ç”¨æ¨¡å¼
            scenarios = ["uav_data_collection", "satellite_tracking", "interference_monitoring", "mesh_network_operation"]
            
            tasks = []
            for i, user in enumerate(users):
                scenario = scenarios[i % len(scenarios)]
                task = asyncio.create_task(
                    user.run_user_scenario(scenario, duration_seconds)
                )
                tasks.append(task)
            
            # å®šæœŸè¨˜éŒ„ä¸­é–“çµæœ
            intermediate_results = []
            for hour in range(duration_hours):
                await asyncio.sleep(3600)  # ç­‰å¾…1å°æ™‚
                
                # è¨˜éŒ„ä¸­é–“æŒ‡æ¨™
                current_metrics = self._collect_intermediate_metrics(users)
                intermediate_results.append({
                    "hour": hour + 1,
                    "metrics": current_metrics
                })
                
                self.logger.info(f"â° æŒä¹…æ€§æ¸¬è©¦é€²åº¦: {hour + 1}/{duration_hours} å°æ™‚å®Œæˆ")
            
            # æ”¶é›†æœ€çµ‚çµæœ
            user_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = datetime.utcnow()
        
        result = self._aggregate_load_test_results(
            "endurance_load_test",
            start_time,
            end_time,
            user_results,
            concurrent_users
        )
        
        # æ·»åŠ ä¸­é–“çµæœåˆ°è©³ç´°æŒ‡æ¨™
        result.detailed_metrics.extend(intermediate_results)
        
        self.test_results.append(result)
        
        self.logger.info(f"âœ… æŒä¹…æ€§è² è¼‰æ¸¬è©¦å®Œæˆ: {duration_hours} å°æ™‚ç©©å®šé‹è¡Œ")
        
        return result
    
    def _aggregate_load_test_results(
        self,
        test_name: str,
        start_time: datetime,
        end_time: datetime,
        user_results: List,
        concurrent_users_peak: int
    ) -> LoadTestResult:
        """èšåˆè² è¼‰æ¸¬è©¦çµæœ"""
        
        # éæ¿¾æœ‰æ•ˆçµæœ
        valid_results = [
            result for result in user_results 
            if isinstance(result, dict) and "requests_sent" in result
        ]
        
        if not valid_results:
            return LoadTestResult(
                test_name=test_name,
                start_time=start_time,
                end_time=end_time,
                total_requests=0,
                successful_requests=0,
                failed_requests=0,
                avg_response_time_ms=0,
                p95_response_time_ms=0,
                p99_response_time_ms=0,
                requests_per_second=0,
                error_rate=1.0,
                throughput_mbps=0,
                concurrent_users_peak=concurrent_users_peak
            )
        
        # èšåˆæŒ‡æ¨™
        total_requests = sum(r["requests_sent"] for r in valid_results)
        successful_requests = sum(r["successful_requests"] for r in valid_results)
        failed_requests = sum(r["failed_requests"] for r in valid_results)
        
        # æ”¶é›†æ‰€æœ‰éŸ¿æ‡‰æ™‚é–“
        all_response_times = []
        for result in valid_results:
            if "response_times" in result:
                all_response_times.extend(result["response_times"])
        
        # è¨ˆç®—éŸ¿æ‡‰æ™‚é–“æŒ‡æ¨™
        if all_response_times:
            avg_response_time_ms = statistics.mean(all_response_times)
            p95_response_time_ms = np.percentile(all_response_times, 95)
            p99_response_time_ms = np.percentile(all_response_times, 99)
        else:
            avg_response_time_ms = 0
            p95_response_time_ms = 0
            p99_response_time_ms = 0
        
        # è¨ˆç®—å…¶ä»–æŒ‡æ¨™
        duration_seconds = (end_time - start_time).total_seconds()
        requests_per_second = total_requests / duration_seconds if duration_seconds > 0 else 0
        error_rate = failed_requests / total_requests if total_requests > 0 else 0
        
        # ä¼°ç®—åé‡ (1KB å¹³å‡éŸ¿æ‡‰å¤§å°)
        throughput_mbps = (successful_requests * 1024 * 8) / (duration_seconds * 1024 * 1024) if duration_seconds > 0 else 0
        
        return LoadTestResult(
            test_name=test_name,
            start_time=start_time,
            end_time=end_time,
            total_requests=total_requests,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            avg_response_time_ms=avg_response_time_ms,
            p95_response_time_ms=p95_response_time_ms,
            p99_response_time_ms=p99_response_time_ms,
            requests_per_second=requests_per_second,
            error_rate=error_rate,
            throughput_mbps=throughput_mbps,
            concurrent_users_peak=concurrent_users_peak
        )
    
    def _collect_intermediate_metrics(self, users: List[VirtualUser]) -> Dict[str, Any]:
        """æ”¶é›†ä¸­é–“æŒ‡æ¨™"""
        active_users = sum(1 for user in users if user.is_active)
        total_requests = sum(user.requests_sent for user in users)
        total_successful = sum(user.successful_requests for user in users)
        total_failed = sum(user.failed_requests for user in users)
        
        all_response_times = []
        for user in users:
            all_response_times.extend(user.response_times)
        
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "active_users": active_users,
            "total_requests": total_requests,
            "successful_requests": total_successful,
            "failed_requests": total_failed,
            "error_rate": total_failed / total_requests if total_requests > 0 else 0,
            "avg_response_time_ms": statistics.mean(all_response_times) if all_response_times else 0
        }
    
    def get_load_test_summary(self) -> Dict[str, Any]:
        """ç²å–è² è¼‰æ¸¬è©¦æ‘˜è¦"""
        if not self.test_results:
            return {"status": "no_tests_run"}
        
        return {
            "total_tests": len(self.test_results),
            "test_results": [
                {
                    "test_name": result.test_name,
                    "success_rate": 1 - result.error_rate,
                    "avg_response_time_ms": result.avg_response_time_ms,
                    "requests_per_second": result.requests_per_second,
                    "throughput_mbps": result.throughput_mbps,
                    "duration_minutes": (result.end_time - result.start_time).total_seconds() / 60
                }
                for result in self.test_results
            ],
            "overall_metrics": {
                "avg_success_rate": statistics.mean([1 - r.error_rate for r in self.test_results]),
                "avg_response_time_ms": statistics.mean([r.avg_response_time_ms for r in self.test_results]),
                "max_requests_per_second": max([r.requests_per_second for r in self.test_results]),
                "total_requests_processed": sum([r.total_requests for r in self.test_results])
            }
        }


# å…¼å®¹çš„LoadTesteré¡ (for backward compatibility)
class LoadTester:
    """è² è¼‰æ¸¬è©¦å™¨ (å…¼å®¹æ€§ç‰ˆæœ¬)"""

    def __init__(self, config: Dict):
        self.config = config
        self.environment = config["environment"]
        self.services = self.environment["services"]
        self.load_test_suite = LoadTestSuite()

    async def run_load_tests(self) -> Tuple[bool, Dict]:
        """åŸ·è¡Œè² è¼‰æ¸¬è©¦"""
        logger.info("ğŸ”¥ é–‹å§‹åŸ·è¡Œè² è¼‰æ¸¬è©¦")

        # ä½¿ç”¨æ–°çš„LoadTestSuiteåŸ·è¡Œæ¸¬è©¦
        base_url = self.services.get('netstack', {}).get('url', 'http://localhost:8080')
        
        test_results = []
        
        # é«˜ä¸¦ç™¼æ¸¬è©¦
        concurrent_result = await self.load_test_suite.run_concurrent_load_test(
            concurrent_users=50,
            duration_seconds=30,
            base_url=base_url
        )
        test_results.append(("high_concurrency", concurrent_result["success"]))
        
        # å³°å€¼è² è¼‰æ¸¬è©¦
        spike_result = await self.load_test_suite.run_spike_load_test(
            baseline_users=10,
            spike_users=50,
            spike_duration_seconds=30,
            base_url=base_url
        )
        test_results.append(("spike_load", spike_result.error_rate < 0.2))

        passed_tests = sum(1 for _, passed in test_results if passed)
        total_tests = len(test_results)

        details = {
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "success_rate": passed_tests / total_tests,
            "test_results": {name: passed for name, passed in test_results},
        }

        overall_success = passed_tests == total_tests
        logger.info(f"ğŸ”¥ è² è¼‰æ¸¬è©¦å®Œæˆï¼ŒæˆåŠŸç‡: {details['success_rate']:.1%}")

        return overall_success, details


async def main():
    """ä¸»å‡½æ•¸ - ç¤ºä¾‹ç”¨æ³•"""
    load_test_suite = LoadTestSuite()
    
    # åŸ·è¡Œä¸åŒé¡å‹çš„è² è¼‰æ¸¬è©¦
    print("ğŸš€ é–‹å§‹åŸ·è¡Œè² è¼‰æ¸¬è©¦å¥—ä»¶")
    
    # 1. ä¸¦ç™¼è² è¼‰æ¸¬è©¦
    await load_test_suite.run_concurrent_load_test(
        concurrent_users=50,
        duration_seconds=60
    )
    
    # 2. æ¼¸é€²å¼è² è¼‰æ¸¬è©¦
    await load_test_suite.run_ramp_up_load_test(
        max_users=100,
        ramp_up_time_seconds=120,
        steady_state_time_seconds=180
    )
    
    # 3. å³°å€¼è² è¼‰æ¸¬è©¦
    await load_test_suite.run_spike_load_test(
        baseline_users=20,
        spike_users=80,
        spike_duration_seconds=60
    )
    
    # ç²å–æ‘˜è¦
    summary = load_test_suite.get_load_test_summary()
    print(f"ğŸ“Š è² è¼‰æ¸¬è©¦æ‘˜è¦: {json.dumps(summary, indent=2, ensure_ascii=False)}")


if __name__ == "__main__":
    asyncio.run(main())
