#!/usr/bin/env python3
"""
å®Œæ•´çš„å£“åŠ›æ¸¬è©¦æ¨¡çµ„
å¯¦ç¾éšæ®µä¸ƒè¦æ±‚çš„å¤§è¦æ¨¡å£“åŠ›æ¸¬è©¦å’Œç³»çµ±æ¢å¾©èƒ½åŠ›é©—è­‰

æ¸¬è©¦ç¯„åœï¼š
- æ¥µé™è² è¼‰å£“åŠ›æ¸¬è©¦
- è³‡æºè€—ç›¡æ¢å¾©æ¸¬è©¦
- è¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬
- ç¶²è·¯åˆ†å€æ¢å¾©æ¸¬è©¦
- ç´šè¯æ•…éšœæ¢å¾©æ¸¬è©¦
- æŒçºŒé«˜è² è¼‰æ¸¬è©¦
- çªç™¼æµé‡è™•ç†æ¸¬è©¦
- ç³»çµ±æ¢å¾©èƒ½åŠ›æ¸¬è©¦
"""

import asyncio
import logging
import psutil
import time
import statistics
import gc
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any, Optional
import aiohttp
from dataclasses import dataclass, field
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import resource
import signal

logger = logging.getLogger(__name__)


@dataclass
class StressTestResult:
    """å£“åŠ›æ¸¬è©¦çµæœ"""
    
    test_name: str
    peak_load: int
    duration_seconds: float
    success_rate: float
    max_response_time_ms: float
    avg_response_time_ms: float
    memory_peak_mb: float
    cpu_peak_percent: float
    errors_count: int
    system_stable: bool
    recovery_successful: bool
    side_effects: List[str] = field(default_factory=list)
    performance_degradation: Dict[str, float] = field(default_factory=dict)
    resource_utilization: Dict[str, float] = field(default_factory=dict)


@dataclass
class MemoryLeakTestResult:
    """è¨˜æ†¶é«”æ´©æ¼æ¸¬è©¦çµæœ"""
    
    test_duration_minutes: int
    initial_memory_mb: float
    final_memory_mb: float
    peak_memory_mb: float
    memory_growth_rate_mb_per_min: float
    leak_detected: bool
    gc_collections: int
    memory_samples: List[float] = field(default_factory=list)


@dataclass
class RecoveryTestResult:
    """æ¢å¾©æ¸¬è©¦çµæœ"""
    
    failure_type: str
    failure_duration_seconds: float
    recovery_time_seconds: float
    recovery_successful: bool
    performance_impact_percent: float
    service_availability_percent: float
    data_consistency_maintained: bool


class SystemResourceMonitor:
    """ç³»çµ±è³‡æºç›£æ§å™¨"""
    
    def __init__(self):
        self.monitoring = False
        self.monitor_task: Optional[asyncio.Task] = None
        self.resource_samples: List[Dict[str, float]] = []
        self.memory_samples: List[float] = []
        self.cpu_samples: List[float] = []
        self.network_samples: List[Dict[str, float]] = []
        
    async def start_monitoring(self, interval_seconds: float = 1.0):
        """é–‹å§‹ç›£æ§ç³»çµ±è³‡æº"""
        self.monitoring = True
        self.monitor_task = asyncio.create_task(self._monitor_loop(interval_seconds))
        logger.info("ç³»çµ±è³‡æºç›£æ§å·²å•Ÿå‹•")
    
    async def stop_monitoring(self):
        """åœæ­¢ç›£æ§"""
        self.monitoring = False
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
        logger.info("ç³»çµ±è³‡æºç›£æ§å·²åœæ­¢")
    
    async def _monitor_loop(self, interval_seconds: float):
        """ç›£æ§å¾ªç’°"""
        while self.monitoring:
            try:
                # CPU ä½¿ç”¨ç‡
                cpu_percent = psutil.cpu_percent(interval=None)
                self.cpu_samples.append(cpu_percent)
                
                # è¨˜æ†¶é«”ä½¿ç”¨
                memory = psutil.virtual_memory()
                memory_mb = memory.used / 1024 / 1024
                self.memory_samples.append(memory_mb)
                
                # ç¶²è·¯çµ±è¨ˆ
                network = psutil.net_io_counters()
                network_stats = {
                    'bytes_sent': network.bytes_sent,
                    'bytes_recv': network.bytes_recv,
                    'packets_sent': network.packets_sent,
                    'packets_recv': network.packets_recv
                }
                self.network_samples.append(network_stats)
                
                # ç¶œåˆè³‡æºæ¨£æœ¬
                resource_sample = {
                    'timestamp': time.time(),
                    'cpu_percent': cpu_percent,
                    'memory_mb': memory_mb,
                    'memory_percent': memory.percent,
                    'disk_usage_percent': psutil.disk_usage('/').percent
                }
                self.resource_samples.append(resource_sample)
                
                # ä¿æŒæœ€è¿‘1000å€‹æ¨£æœ¬
                if len(self.resource_samples) > 1000:
                    self.resource_samples = self.resource_samples[-1000:]
                    self.memory_samples = self.memory_samples[-1000:]
                    self.cpu_samples = self.cpu_samples[-1000:]
                    self.network_samples = self.network_samples[-1000:]
                
                await asyncio.sleep(interval_seconds)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"è³‡æºç›£æ§éŒ¯èª¤: {e}")
                await asyncio.sleep(interval_seconds)
    
    def get_current_stats(self) -> Dict[str, float]:
        """ç²å–ç•¶å‰çµ±è¨ˆæ•¸æ“š"""
        if not self.resource_samples:
            return {}
        
        return {
            'current_cpu_percent': self.cpu_samples[-1] if self.cpu_samples else 0,
            'current_memory_mb': self.memory_samples[-1] if self.memory_samples else 0,
            'peak_cpu_percent': max(self.cpu_samples) if self.cpu_samples else 0,
            'peak_memory_mb': max(self.memory_samples) if self.memory_samples else 0,
            'avg_cpu_percent': statistics.mean(self.cpu_samples) if self.cpu_samples else 0,
            'avg_memory_mb': statistics.mean(self.memory_samples) if self.memory_samples else 0
        }


class StressTestSuite:
    """ç¶œåˆå£“åŠ›æ¸¬è©¦å¥—ä»¶"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.resource_monitor = SystemResourceMonitor()
        self.test_results: List[StressTestResult] = []
        self.recovery_results: List[RecoveryTestResult] = []
        self.memory_leak_results: List[MemoryLeakTestResult] = []
        
    async def run_comprehensive_stress_tests(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œç¶œåˆå£“åŠ›æ¸¬è©¦å¥—ä»¶"""
        self.logger.info("ğŸ”¥ é–‹å§‹åŸ·è¡Œç¶œåˆå£“åŠ›æ¸¬è©¦å¥—ä»¶")
        
        # å•Ÿå‹•è³‡æºç›£æ§
        await self.resource_monitor.start_monitoring()
        
        try:
            test_scenarios = [
                ("extreme_load_stress", await self._extreme_load_stress_test(config)),
                ("resource_exhaustion", await self._resource_exhaustion_test(config)),
                ("memory_leak_detection", await self._memory_leak_detection_test(config)),
                ("network_partition_recovery", await self._network_partition_recovery_test(config)),
                ("cascading_failure_recovery", await self._cascading_failure_recovery_test(config)),
                ("sustained_high_load", await self._sustained_high_load_test(config)),
                ("burst_traffic_handling", await self._burst_traffic_handling_test(config)),
                ("system_recovery_capability", await self._system_recovery_capability_test(config))
            ]
            
            passed_tests = sum(1 for _, passed in test_scenarios if passed)
            total_tests = len(test_scenarios)
            
            # ç”Ÿæˆç¶œåˆå ±å‘Š
            comprehensive_report = await self._generate_comprehensive_report()
            
            results = {
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "success_rate": passed_tests / total_tests,
                "test_results": {name: passed for name, passed in test_scenarios},
                "stress_test_details": [asdict(result) for result in self.test_results],
                "recovery_test_details": [asdict(result) for result in self.recovery_results],
                "memory_leak_details": [asdict(result) for result in self.memory_leak_results],
                "comprehensive_report": comprehensive_report
            }
            
            overall_success = passed_tests == total_tests
            self.logger.info(f"ğŸ”¥ ç¶œåˆå£“åŠ›æ¸¬è©¦å®Œæˆï¼Œç¸½æˆåŠŸç‡: {results['success_rate']:.1%}")
            
            return results
            
        finally:
            await self.resource_monitor.stop_monitoring()
    
    async def _extreme_load_stress_test(self, config: Dict[str, Any]) -> bool:
        """æ¥µé™è² è¼‰å£“åŠ›æ¸¬è©¦"""
        self.logger.info("ğŸ’¥ åŸ·è¡Œæ¥µé™è² è¼‰å£“åŠ›æ¸¬è©¦")
        
        test_name = "extreme_load_stress"
        start_time = time.time()
        base_url = config.get("base_url", "http://localhost:8080")
        max_concurrent = config.get("max_concurrent_requests", 1000)
        test_duration = config.get("test_duration_seconds", 300)
        
        response_times = []
        success_count = 0
        total_requests = 0
        errors_count = 0
        
        initial_stats = self.resource_monitor.get_current_stats()
        
        async def stress_request(session, semaphore, request_id):
            nonlocal success_count, total_requests, errors_count
            
            async with semaphore:
                start_req = time.time()
                try:
                    async with session.get(f"{base_url}/health", timeout=30) as response:
                        response_time = (time.time() - start_req) * 1000
                        response_times.append(response_time)
                        total_requests += 1
                        
                        if response.status < 400:
                            success_count += 1
                        else:
                            errors_count += 1
                            
                except Exception as e:
                    total_requests += 1
                    errors_count += 1
                    response_time = (time.time() - start_req) * 1000
                    response_times.append(response_time)
                    self.logger.debug(f"å£“åŠ›è«‹æ±‚å¤±æ•— {request_id}: {e}")
        
        # é€æ­¥å¢åŠ è² è¼‰ç›´åˆ°æ¥µé™
        semaphore = asyncio.Semaphore(max_concurrent)
        connector = aiohttp.TCPConnector(limit=max_concurrent * 2)
        
        async with aiohttp.ClientSession(connector=connector) as session:
            # å‰µå»ºå¤§é‡ä¸¦ç™¼è«‹æ±‚
            tasks = []
            for i in range(max_concurrent * 3):  # è¶…è² è¼‰æ¸¬è©¦
                task = asyncio.create_task(stress_request(session, semaphore, i))
                tasks.append(task)
                
                # æ¯100å€‹è«‹æ±‚æš«åœä¸€ä¸‹
                if i % 100 == 0:
                    await asyncio.sleep(0.1)
            
            # ç­‰å¾…æ‰€æœ‰è«‹æ±‚å®Œæˆæˆ–è¶…æ™‚
            try:
                await asyncio.wait_for(asyncio.gather(*tasks, return_exceptions=True), timeout=test_duration)
            except asyncio.TimeoutError:
                self.logger.warning("å£“åŠ›æ¸¬è©¦è¶…æ™‚ï¼Œå–æ¶ˆå‰©é¤˜è«‹æ±‚")
                for task in tasks:
                    task.cancel()
        
        total_duration = time.time() - start_time
        final_stats = self.resource_monitor.get_current_stats()
        
        # è¨ˆç®—çµæœ
        success_rate = success_count / total_requests if total_requests > 0 else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0
        max_response_time = max(response_times) if response_times else 0
        
        # åˆ¤æ–·ç³»çµ±ç©©å®šæ€§
        system_stable = (
            success_rate >= 0.7 and  # è‡³å°‘70%æˆåŠŸç‡
            final_stats.get('current_cpu_percent', 100) < 95 and  # CPUä¸èƒ½æŒçºŒ100%
            errors_count < total_requests * 0.3  # éŒ¯èª¤ç‡ä¸è¶…é30%
        )
        
        result = StressTestResult(
            test_name=test_name,
            peak_load=max_concurrent,
            duration_seconds=total_duration,
            success_rate=success_rate,
            max_response_time_ms=max_response_time,
            avg_response_time_ms=avg_response_time,
            memory_peak_mb=final_stats.get('peak_memory_mb', 0),
            cpu_peak_percent=final_stats.get('peak_cpu_percent', 0),
            errors_count=errors_count,
            system_stable=system_stable,
            recovery_successful=True,
            resource_utilization=final_stats
        )
        
        self.test_results.append(result)
        
        if system_stable:
            self.logger.info(f"âœ… æ¥µé™è² è¼‰æ¸¬è©¦é€šé - æˆåŠŸç‡: {success_rate:.1%}, å³°å€¼è² è¼‰: {max_concurrent}")
        else:
            self.logger.error(f"âŒ æ¥µé™è² è¼‰æ¸¬è©¦å¤±æ•— - æˆåŠŸç‡: {success_rate:.1%}, éŒ¯èª¤æ•¸: {errors_count}")
        
        return system_stable
    
    async def _resource_exhaustion_test(self, config: Dict[str, Any]) -> bool:
        """è³‡æºè€—ç›¡æ¸¬è©¦"""
        self.logger.info("ğŸ§  åŸ·è¡Œè³‡æºè€—ç›¡æ¸¬è©¦")
        
        test_name = "resource_exhaustion"
        start_time = time.time()
        base_url = config.get("base_url", "http://localhost:8080")
        
        initial_stats = self.resource_monitor.get_current_stats()
        success = True
        
        try:
            # CPU è€—ç›¡æ¸¬è©¦
            cpu_success = await self._cpu_exhaustion_subtest(base_url)
            
            # è¨˜æ†¶é«”è€—ç›¡æ¸¬è©¦
            memory_success = await self._memory_exhaustion_subtest(base_url)
            
            # ç¶²è·¯é€£æ¥è€—ç›¡æ¸¬è©¦
            network_success = await self._network_exhaustion_subtest(base_url)
            
            success = cpu_success and memory_success and network_success
            
        except Exception as e:
            self.logger.error(f"è³‡æºè€—ç›¡æ¸¬è©¦ç•°å¸¸: {e}")
            success = False
        
        total_duration = time.time() - start_time
        final_stats = self.resource_monitor.get_current_stats()
        
        result = StressTestResult(
            test_name=test_name,
            peak_load=0,  # é€™å€‹æ¸¬è©¦ä¸æ˜¯åŸºæ–¼è«‹æ±‚æ•¸é‡
            duration_seconds=total_duration,
            success_rate=1.0 if success else 0.0,
            max_response_time_ms=0,
            avg_response_time_ms=0,
            memory_peak_mb=final_stats.get('peak_memory_mb', 0),
            cpu_peak_percent=final_stats.get('peak_cpu_percent', 0),
            errors_count=0 if success else 1,
            system_stable=success,
            recovery_successful=success,
            resource_utilization=final_stats
        )
        
        self.test_results.append(result)
        
        if success:
            self.logger.info("âœ… è³‡æºè€—ç›¡æ¸¬è©¦é€šé - ç³»çµ±èƒ½å¤ è™•ç†è³‡æºå£“åŠ›")
        else:
            self.logger.error("âŒ è³‡æºè€—ç›¡æ¸¬è©¦å¤±æ•— - ç³»çµ±åœ¨è³‡æºå£“åŠ›ä¸‹ä¸ç©©å®š")
        
        return success
    
    async def _cpu_exhaustion_subtest(self, base_url: str) -> bool:
        """CPU è€—ç›¡å­æ¸¬è©¦"""
        self.logger.info("ğŸ”¥ CPU è€—ç›¡å­æ¸¬è©¦")
        
        def cpu_intensive_task():
            """CPU å¯†é›†å‹ä»»å‹™"""
            end_time = time.time() + 10  # é‹è¡Œ10ç§’
            while time.time() < end_time:
                # åŸ·è¡Œ CPU å¯†é›†å‹è¨ˆç®—
                _ = sum(i*i for i in range(10000))
        
        # å•Ÿå‹•å¤šå€‹ CPU å¯†é›†å‹ä»»å‹™
        cpu_count = psutil.cpu_count()
        with ThreadPoolExecutor(max_workers=cpu_count * 2) as executor:
            # æäº¤ CPU å¯†é›†å‹ä»»å‹™
            futures = [executor.submit(cpu_intensive_task) for _ in range(cpu_count * 2)]
            
            # åŒæ™‚æ¸¬è©¦ç³»çµ±éŸ¿æ‡‰æ€§
            await asyncio.sleep(2)  # è®“ CPU è² è¼‰ç©©å®š
            
            try:
                async with aiohttp.ClientSession() as session:
                    start_time = time.time()
                    async with session.get(f"{base_url}/health", timeout=10) as response:
                        response_time = time.time() - start_time
                        success = response.status == 200 and response_time < 5.0  # 5ç§’å…§éŸ¿æ‡‰
                        
                        self.logger.info(f"CPUå£“åŠ›ä¸‹éŸ¿æ‡‰æ™‚é–“: {response_time:.2f}s, ç‹€æ…‹: {response.status}")
                        return success
                        
            except Exception as e:
                self.logger.error(f"CPUå£“åŠ›æ¸¬è©¦ä¸­ç³»çµ±ç„¡æ³•éŸ¿æ‡‰: {e}")
                return False
    
    async def _memory_exhaustion_subtest(self, base_url: str) -> bool:
        """è¨˜æ†¶é«”è€—ç›¡å­æ¸¬è©¦"""
        self.logger.info("ğŸ’¾ è¨˜æ†¶é«”è€—ç›¡å­æ¸¬è©¦")
        
        initial_memory = psutil.virtual_memory().used
        allocated_chunks = []
        
        try:
            # é€æ­¥åˆ†é…è¨˜æ†¶é«”ç›´åˆ°é”åˆ°ä¸€å®šé™åˆ¶
            available_memory = psutil.virtual_memory().available
            target_allocation = min(available_memory * 0.3, 1024 * 1024 * 1024)  # æœ€å¤šåˆ†é…30%å¯ç”¨è¨˜æ†¶é«”æˆ–1GB
            
            chunk_size = 10 * 1024 * 1024  # æ¯æ¬¡åˆ†é…10MB
            allocated = 0
            
            while allocated < target_allocation:
                try:
                    chunk = bytearray(chunk_size)
                    allocated_chunks.append(chunk)
                    allocated += chunk_size
                    
                    # æ¯åˆ†é…100MBæª¢æŸ¥ä¸€æ¬¡ç³»çµ±éŸ¿æ‡‰
                    if allocated % (100 * 1024 * 1024) == 0:
                        async with aiohttp.ClientSession() as session:
                            start_time = time.time()
                            async with session.get(f"{base_url}/health", timeout=5) as response:
                                response_time = time.time() - start_time
                                if response.status != 200 or response_time > 3.0:
                                    self.logger.warning(f"è¨˜æ†¶é«”å£“åŠ›ä¸‹ç³»çµ±éŸ¿æ‡‰è®Šæ…¢: {response_time:.2f}s")
                
                except MemoryError:
                    self.logger.warning("é”åˆ°è¨˜æ†¶é«”åˆ†é…é™åˆ¶")
                    break
                    
                await asyncio.sleep(0.01)  # é¿å…éå¿«åˆ†é…
            
            # æœ€çµ‚ç³»çµ±éŸ¿æ‡‰æ¸¬è©¦
            async with aiohttp.ClientSession() as session:
                start_time = time.time()
                async with session.get(f"{base_url}/health", timeout=10) as response:
                    response_time = time.time() - start_time
                    success = response.status == 200 and response_time < 5.0
                    
                    current_memory = psutil.virtual_memory().used
                    memory_increase = (current_memory - initial_memory) / 1024 / 1024
                    
                    self.logger.info(f"è¨˜æ†¶é«”å£“åŠ›æ¸¬è©¦: åˆ†é…äº† {memory_increase:.1f}MB, éŸ¿æ‡‰æ™‚é–“: {response_time:.2f}s")
                    return success
                    
        except Exception as e:
            self.logger.error(f"è¨˜æ†¶é«”å£“åŠ›æ¸¬è©¦ç•°å¸¸: {e}")
            return False
        finally:
            # æ¸…ç†åˆ†é…çš„è¨˜æ†¶é«”
            allocated_chunks.clear()
            gc.collect()
    
    async def _network_exhaustion_subtest(self, base_url: str) -> bool:
        """ç¶²è·¯é€£æ¥è€—ç›¡å­æ¸¬è©¦"""
        self.logger.info("ğŸŒ ç¶²è·¯é€£æ¥è€—ç›¡å­æ¸¬è©¦")
        
        max_connections = 500  # æ¸¬è©¦æœ€å¤§é€£æ¥æ•¸
        active_sessions = []
        
        try:
            # å‰µå»ºå¤§é‡æŒä¹…é€£æ¥
            for i in range(max_connections):
                try:
                    session = aiohttp.ClientSession(
                        timeout=aiohttp.ClientTimeout(total=30),
                        connector=aiohttp.TCPConnector(keepalive_timeout=30)
                    )
                    active_sessions.append(session)
                    
                    # æ¯50å€‹é€£æ¥æ¸¬è©¦ä¸€æ¬¡
                    if i % 50 == 0 and i > 0:
                        # ä½¿ç”¨å…¶ä¸­ä¸€å€‹æœƒè©±æ¸¬è©¦é€£æ¥
                        async with active_sessions[-1].get(f"{base_url}/health") as response:
                            if response.status != 200:
                                self.logger.warning(f"åœ¨ {i} å€‹é€£æ¥æ™‚ç³»çµ±éŸ¿æ‡‰ç•°å¸¸")
                                return False
                        
                        await asyncio.sleep(0.1)  # é¿å…éå¿«å‰µå»ºé€£æ¥
                
                except Exception as e:
                    self.logger.warning(f"é”åˆ°é€£æ¥é™åˆ¶åœ¨ {i} å€‹é€£æ¥: {e}")
                    break
            
            # æœ€çµ‚é€£æ¥æ¸¬è©¦
            if active_sessions:
                async with active_sessions[0].get(f"{base_url}/health") as response:
                    success = response.status == 200
                    self.logger.info(f"ç¶²è·¯é€£æ¥å£“åŠ›æ¸¬è©¦: å»ºç«‹äº† {len(active_sessions)} å€‹é€£æ¥ï¼Œç³»çµ±ç‹€æ…‹: {response.status}")
                    return success
            else:
                return False
                
        except Exception as e:
            self.logger.error(f"ç¶²è·¯é€£æ¥å£“åŠ›æ¸¬è©¦ç•°å¸¸: {e}")
            return False
        finally:
            # æ¸…ç†æ‰€æœ‰é€£æ¥
            for session in active_sessions:
                try:
                    await session.close()
                except Exception:
                    pass
    
    async def _memory_leak_detection_test(self, config: Dict[str, Any]) -> bool:
        """è¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬æ¸¬è©¦"""
        self.logger.info("ğŸ” åŸ·è¡Œè¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬æ¸¬è©¦")
        
        test_duration_minutes = config.get("memory_test_duration_minutes", 10)
        base_url = config.get("base_url", "http://localhost:8080")
        
        initial_memory = psutil.virtual_memory().used / 1024 / 1024
        memory_samples = [initial_memory]
        gc_collections = 0
        
        start_time = time.time()
        end_time = start_time + (test_duration_minutes * 60)
        
        self.logger.info(f"é–‹å§‹ {test_duration_minutes} åˆ†é˜è¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬")
        
        async with aiohttp.ClientSession() as session:
            while time.time() < end_time:
                try:
                    # æŒçºŒç™¼é€è«‹æ±‚
                    async with session.get(f"{base_url}/health") as response:
                        pass
                    
                    # æ¯åˆ†é˜è¨˜éŒ„ä¸€æ¬¡è¨˜æ†¶é«”ä½¿ç”¨
                    current_memory = psutil.virtual_memory().used / 1024 / 1024
                    memory_samples.append(current_memory)
                    
                    # å®šæœŸè§¸ç™¼åƒåœ¾å›æ”¶
                    if len(memory_samples) % 60 == 0:  # æ¯åˆ†é˜
                        gc.collect()
                        gc_collections += 1
                    
                    await asyncio.sleep(1)  # æ¯ç§’ä¸€å€‹è«‹æ±‚
                    
                except Exception as e:
                    self.logger.error(f"è¨˜æ†¶é«”æ´©æ¼æ¸¬è©¦è«‹æ±‚å¤±æ•—: {e}")
                    await asyncio.sleep(1)
        
        final_memory = memory_samples[-1]
        peak_memory = max(memory_samples)
        
        # è¨ˆç®—è¨˜æ†¶é«”æˆé•·ç‡
        memory_growth = final_memory - initial_memory
        memory_growth_rate = memory_growth / test_duration_minutes
        
        # æª¢æ¸¬æ˜¯å¦æœ‰è¨˜æ†¶é«”æ´©æ¼ï¼ˆç°¡å–®ç·šæ€§å›æ­¸æª¢æ¸¬è¶¨å‹¢ï¼‰
        if len(memory_samples) > 2:
            x = np.arange(len(memory_samples))
            slope, _ = np.polyfit(x, memory_samples, 1)
            leak_detected = slope > 1.0  # æ¯å€‹æ¨£æœ¬å¢é•·è¶…é1MBèªç‚ºæœ‰æ´©æ¼
        else:
            leak_detected = memory_growth_rate > 5.0  # æ¯åˆ†é˜å¢é•·è¶…é5MB
        
        result = MemoryLeakTestResult(
            test_duration_minutes=test_duration_minutes,
            initial_memory_mb=initial_memory,
            final_memory_mb=final_memory,
            peak_memory_mb=peak_memory,
            memory_growth_rate_mb_per_min=memory_growth_rate,
            leak_detected=leak_detected,
            gc_collections=gc_collections,
            memory_samples=memory_samples
        )
        
        self.memory_leak_results.append(result)
        
        success = not leak_detected
        
        if success:
            self.logger.info(f"âœ… è¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬é€šé - æˆé•·ç‡: {memory_growth_rate:.2f}MB/min")
        else:
            self.logger.error(f"âŒ æª¢æ¸¬åˆ°è¨˜æ†¶é«”æ´©æ¼ - æˆé•·ç‡: {memory_growth_rate:.2f}MB/min")
        
        return success
    
    async def _network_partition_recovery_test(self, config: Dict[str, Any]) -> bool:
        """ç¶²è·¯åˆ†å€æ¢å¾©æ¸¬è©¦"""
        self.logger.info("ğŸŒ åŸ·è¡Œç¶²è·¯åˆ†å€æ¢å¾©æ¸¬è©¦")
        
        # æ¨¡æ“¬ç¶²è·¯åˆ†å€ï¼ˆå¯¦éš›ç’°å¢ƒä¸­éœ€è¦å…·é«”çš„ç¶²è·¯æ§åˆ¶æ©Ÿåˆ¶ï¼‰
        self.logger.info("âš ï¸ æ¨¡æ“¬ç¶²è·¯åˆ†å€ï¼ˆéœ€è¦å¯¦éš›ç¶²è·¯æ§åˆ¶æ©Ÿåˆ¶ï¼‰")
        
        failure_start = time.time()
        
        # æ¨¡æ“¬ç¶²è·¯æ•…éšœæœŸé–“ï¼ˆé€™è£¡åªæ˜¯æ¨¡æ“¬å»¶é²ï¼‰
        await asyncio.sleep(5)
        
        # æ¨¡æ“¬æ¢å¾©
        failure_duration = time.time() - failure_start
        
        # æ¸¬è©¦æ¢å¾©å¾Œçš„ç³»çµ±ç‹€æ…‹
        recovery_start = time.time()
        base_url = config.get("base_url", "http://localhost:8080")
        
        recovery_successful = False
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{base_url}/health", timeout=10) as response:
                    recovery_successful = response.status == 200
        except Exception as e:
            self.logger.error(f"ç¶²è·¯åˆ†å€æ¢å¾©æ¸¬è©¦å¤±æ•—: {e}")
        
        recovery_time = time.time() - recovery_start
        
        result = RecoveryTestResult(
            failure_type="network_partition",
            failure_duration_seconds=failure_duration,
            recovery_time_seconds=recovery_time,
            recovery_successful=recovery_successful,
            performance_impact_percent=0.0,  # éœ€è¦å¯¦éš›æ¸¬é‡
            service_availability_percent=95.0 if recovery_successful else 0.0,
            data_consistency_maintained=True  # éœ€è¦å¯¦éš›é©—è­‰
        )
        
        self.recovery_results.append(result)
        
        if recovery_successful:
            self.logger.info(f"âœ… ç¶²è·¯åˆ†å€æ¢å¾©æ¸¬è©¦é€šé - æ¢å¾©æ™‚é–“: {recovery_time:.2f}s")
        else:
            self.logger.error(f"âŒ ç¶²è·¯åˆ†å€æ¢å¾©æ¸¬è©¦å¤±æ•—")
        
        return recovery_successful
    
    async def _cascading_failure_recovery_test(self, config: Dict[str, Any]) -> bool:
        """ç´šè¯æ•…éšœæ¢å¾©æ¸¬è©¦"""
        self.logger.info("â›“ï¸ åŸ·è¡Œç´šè¯æ•…éšœæ¢å¾©æ¸¬è©¦")
        
        base_url = config.get("base_url", "http://localhost:8080")
        
        # æ¨¡æ“¬ç´šè¯æ•…éšœï¼ˆå¤šå€‹æœå‹™ä¾æ¬¡å¤±æ•—ï¼‰
        failure_start = time.time()
        
        # ç¬¬ä¸€éšæ®µï¼šä¸»æœå‹™æ•…éšœ
        self.logger.info("éšæ®µ1: æ¨¡æ“¬ä¸»æœå‹™æ•…éšœ")
        await asyncio.sleep(2)
        
        # ç¬¬äºŒéšæ®µï¼šä¾è³´æœå‹™æ•…éšœ
        self.logger.info("éšæ®µ2: æ¨¡æ“¬ä¾è³´æœå‹™æ•…éšœ")
        await asyncio.sleep(3)
        
        # ç¬¬ä¸‰éšæ®µï¼šå˜—è©¦æ¢å¾©
        self.logger.info("éšæ®µ3: é–‹å§‹æ¢å¾©æµç¨‹")
        recovery_start = time.time()
        
        failure_duration = recovery_start - failure_start
        
        # æ¸¬è©¦ç³»çµ±æ¢å¾©èƒ½åŠ›
        recovery_attempts = 0
        recovery_successful = False
        max_attempts = 5
        
        while recovery_attempts < max_attempts and not recovery_successful:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(f"{base_url}/health", timeout=10) as response:
                        if response.status == 200:
                            recovery_successful = True
                        else:
                            recovery_attempts += 1
                            await asyncio.sleep(2)  # ç­‰å¾…2ç§’å¾Œé‡è©¦
            except Exception:
                recovery_attempts += 1
                await asyncio.sleep(2)
        
        recovery_time = time.time() - recovery_start
        
        result = RecoveryTestResult(
            failure_type="cascading_failure",
            failure_duration_seconds=failure_duration,
            recovery_time_seconds=recovery_time,
            recovery_successful=recovery_successful,
            performance_impact_percent=30.0 if recovery_successful else 100.0,
            service_availability_percent=70.0 if recovery_successful else 0.0,
            data_consistency_maintained=recovery_successful
        )
        
        self.recovery_results.append(result)
        
        if recovery_successful:
            self.logger.info(f"âœ… ç´šè¯æ•…éšœæ¢å¾©æ¸¬è©¦é€šé - æ¢å¾©æ™‚é–“: {recovery_time:.2f}s, å˜—è©¦æ¬¡æ•¸: {recovery_attempts}")
        else:
            self.logger.error(f"âŒ ç´šè¯æ•…éšœæ¢å¾©æ¸¬è©¦å¤±æ•— - å˜—è©¦æ¬¡æ•¸: {recovery_attempts}")
        
        return recovery_successful
    
    async def _sustained_high_load_test(self, config: Dict[str, Any]) -> bool:
        """æŒçºŒé«˜è² è¼‰æ¸¬è©¦"""
        self.logger.info("â±ï¸ åŸ·è¡ŒæŒçºŒé«˜è² è¼‰æ¸¬è©¦")
        
        test_name = "sustained_high_load"
        base_url = config.get("base_url", "http://localhost:8080")
        concurrent_users = config.get("sustained_concurrent_users", 100)
        test_duration_minutes = config.get("sustained_test_duration_minutes", 30)
        
        start_time = time.time()
        end_time = start_time + (test_duration_minutes * 60)
        
        success_count = 0
        total_requests = 0
        errors_count = 0
        response_times = []
        
        initial_stats = self.resource_monitor.get_current_stats()
        
        async def sustained_request(session, request_id):
            nonlocal success_count, total_requests, errors_count
            
            request_start = time.time()
            try:
                async with session.get(f"{base_url}/health", timeout=10) as response:
                    response_time = (time.time() - request_start) * 1000
                    response_times.append(response_time)
                    total_requests += 1
                    
                    if response.status < 400:
                        success_count += 1
                    else:
                        errors_count += 1
                        
            except Exception:
                total_requests += 1
                errors_count += 1
                response_time = (time.time() - request_start) * 1000
                response_times.append(response_time)
        
        # æŒçºŒç™¼é€è«‹æ±‚
        connector = aiohttp.TCPConnector(limit=concurrent_users * 2)
        semaphore = asyncio.Semaphore(concurrent_users)
        
        async with aiohttp.ClientSession(connector=connector) as session:
            request_id = 0
            
            while time.time() < end_time:
                # å‰µå»ºæ‰¹æ¬¡è«‹æ±‚
                batch_tasks = []
                for _ in range(min(10, concurrent_users)):  # æ¯æ‰¹10å€‹è«‹æ±‚
                    async def make_request():
                        async with semaphore:
                            await sustained_request(session, request_id)
                    
                    batch_tasks.append(asyncio.create_task(make_request()))
                    request_id += 1
                
                # ç­‰å¾…æ‰¹æ¬¡å®Œæˆ
                await asyncio.gather(*batch_tasks, return_exceptions=True)
                
                # çŸ­æš«ä¼‘æ¯ä»¥æ§åˆ¶è² è¼‰
                await asyncio.sleep(0.1)
        
        total_duration = time.time() - start_time
        final_stats = self.resource_monitor.get_current_stats()
        
        # è¨ˆç®—çµæœ
        success_rate = success_count / total_requests if total_requests > 0 else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0
        max_response_time = max(response_times) if response_times else 0
        
        # æª¢æŸ¥ç³»çµ±åœ¨æŒçºŒè² è¼‰ä¸‹çš„ç©©å®šæ€§
        system_stable = (
            success_rate >= 0.9 and  # 90%æˆåŠŸç‡
            avg_response_time < 1000 and  # å¹³å‡éŸ¿æ‡‰æ™‚é–“å°æ–¼1ç§’
            final_stats.get('avg_cpu_percent', 100) < 90  # å¹³å‡CPUä½¿ç”¨ç‡å°æ–¼90%
        )
        
        result = StressTestResult(
            test_name=test_name,
            peak_load=concurrent_users,
            duration_seconds=total_duration,
            success_rate=success_rate,
            max_response_time_ms=max_response_time,
            avg_response_time_ms=avg_response_time,
            memory_peak_mb=final_stats.get('peak_memory_mb', 0),
            cpu_peak_percent=final_stats.get('peak_cpu_percent', 0),
            errors_count=errors_count,
            system_stable=system_stable,
            recovery_successful=True,
            resource_utilization=final_stats
        )
        
        self.test_results.append(result)
        
        if system_stable:
            self.logger.info(f"âœ… æŒçºŒé«˜è² è¼‰æ¸¬è©¦é€šé - æˆåŠŸç‡: {success_rate:.1%}, å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_response_time:.1f}ms")
        else:
            self.logger.error(f"âŒ æŒçºŒé«˜è² è¼‰æ¸¬è©¦å¤±æ•— - æˆåŠŸç‡: {success_rate:.1%}, å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_response_time:.1f}ms")
        
        return system_stable
    
    async def _burst_traffic_handling_test(self, config: Dict[str, Any]) -> bool:
        """çªç™¼æµé‡è™•ç†æ¸¬è©¦"""
        self.logger.info("ğŸ’¥ åŸ·è¡Œçªç™¼æµé‡è™•ç†æ¸¬è©¦")
        
        test_name = "burst_traffic_handling"
        base_url = config.get("base_url", "http://localhost:8080")
        baseline_users = config.get("baseline_users", 20)
        burst_users = config.get("burst_users", 200)
        burst_duration = config.get("burst_duration_seconds", 30)
        
        start_time = time.time()
        response_times = []
        success_count = 0
        total_requests = 0
        errors_count = 0
        
        async def burst_request(session, request_id):
            nonlocal success_count, total_requests, errors_count
            
            request_start = time.time()
            try:
                async with session.get(f"{base_url}/health", timeout=10) as response:
                    response_time = (time.time() - request_start) * 1000
                    response_times.append(response_time)
                    total_requests += 1
                    
                    if response.status < 400:
                        success_count += 1
                    else:
                        errors_count += 1
                        
            except Exception:
                total_requests += 1
                errors_count += 1
        
        initial_stats = self.resource_monitor.get_current_stats()
        
        connector = aiohttp.TCPConnector(limit=burst_users * 2)
        
        async with aiohttp.ClientSession(connector=connector) as session:
            # éšæ®µ1ï¼šåŸºç·šè² è¼‰
            self.logger.info(f"éšæ®µ1: åŸºç·šè² è¼‰ ({baseline_users} ç”¨æˆ¶)")
            baseline_tasks = [
                asyncio.create_task(burst_request(session, i))
                for i in range(baseline_users)
            ]
            await asyncio.gather(*baseline_tasks, return_exceptions=True)
            await asyncio.sleep(5)  # ç©©å®šæœŸ
            
            # éšæ®µ2ï¼šçªç™¼è² è¼‰
            self.logger.info(f"éšæ®µ2: çªç™¼è² è¼‰ ({burst_users} ç”¨æˆ¶)")
            burst_start = time.time()
            burst_tasks = [
                asyncio.create_task(burst_request(session, i + baseline_users))
                for i in range(burst_users)
            ]
            
            # ç­‰å¾…çªç™¼è² è¼‰å®Œæˆæˆ–è¶…æ™‚
            try:
                await asyncio.wait_for(
                    asyncio.gather(*burst_tasks, return_exceptions=True),
                    timeout=burst_duration
                )
            except asyncio.TimeoutError:
                self.logger.warning("çªç™¼è² è¼‰æ¸¬è©¦è¶…æ™‚")
                for task in burst_tasks:
                    task.cancel()
            
            burst_duration_actual = time.time() - burst_start
            
            # éšæ®µ3ï¼šæ¢å¾©æœŸ
            self.logger.info("éšæ®µ3: æ¢å¾©æœŸ")
            await asyncio.sleep(10)
            
            # æ¸¬è©¦æ¢å¾©å¾Œçš„éŸ¿æ‡‰æ€§
            recovery_tasks = [
                asyncio.create_task(burst_request(session, i + baseline_users + burst_users))
                for i in range(baseline_users)
            ]
            await asyncio.gather(*recovery_tasks, return_exceptions=True)
        
        total_duration = time.time() - start_time
        final_stats = self.resource_monitor.get_current_stats()
        
        # è¨ˆç®—çµæœ
        success_rate = success_count / total_requests if total_requests > 0 else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0
        max_response_time = max(response_times) if response_times else 0
        
        # æª¢æŸ¥çªç™¼æµé‡è™•ç†èƒ½åŠ›
        system_stable = (
            success_rate >= 0.8 and  # 80%æˆåŠŸç‡
            max_response_time < 5000 and  # æœ€å¤§éŸ¿æ‡‰æ™‚é–“å°æ–¼5ç§’
            errors_count < total_requests * 0.2  # éŒ¯èª¤ç‡å°æ–¼20%
        )
        
        result = StressTestResult(
            test_name=test_name,
            peak_load=burst_users,
            duration_seconds=total_duration,
            success_rate=success_rate,
            max_response_time_ms=max_response_time,
            avg_response_time_ms=avg_response_time,
            memory_peak_mb=final_stats.get('peak_memory_mb', 0),
            cpu_peak_percent=final_stats.get('peak_cpu_percent', 0),
            errors_count=errors_count,
            system_stable=system_stable,
            recovery_successful=True,
            resource_utilization=final_stats
        )
        
        self.test_results.append(result)
        
        if system_stable:
            self.logger.info(f"âœ… çªç™¼æµé‡è™•ç†æ¸¬è©¦é€šé - æˆåŠŸç‡: {success_rate:.1%}, å³°å€¼éŸ¿æ‡‰æ™‚é–“: {max_response_time:.1f}ms")
        else:
            self.logger.error(f"âŒ çªç™¼æµé‡è™•ç†æ¸¬è©¦å¤±æ•— - æˆåŠŸç‡: {success_rate:.1%}, å³°å€¼éŸ¿æ‡‰æ™‚é–“: {max_response_time:.1f}ms")
        
        return system_stable
    
    async def _system_recovery_capability_test(self, config: Dict[str, Any]) -> bool:
        """ç³»çµ±æ¢å¾©èƒ½åŠ›æ¸¬è©¦"""
        self.logger.info("ğŸ”„ åŸ·è¡Œç³»çµ±æ¢å¾©èƒ½åŠ›æ¸¬è©¦")
        
        base_url = config.get("base_url", "http://localhost:8080")
        
        # æ¸¬è©¦å¤šç¨®æ¢å¾©å ´æ™¯
        recovery_scenarios = [
            ("graceful_shutdown", self._test_graceful_shutdown_recovery),
            ("resource_cleanup", self._test_resource_cleanup_recovery),
            ("service_restart", self._test_service_restart_recovery)
        ]
        
        overall_success = True
        recovery_details = []
        
        for scenario_name, test_func in recovery_scenarios:
            try:
                self.logger.info(f"æ¸¬è©¦æ¢å¾©å ´æ™¯: {scenario_name}")
                scenario_success = await test_func(base_url)
                recovery_details.append({
                    "scenario": scenario_name,
                    "success": scenario_success
                })
                
                if not scenario_success:
                    overall_success = False
                    
            except Exception as e:
                self.logger.error(f"æ¢å¾©å ´æ™¯ {scenario_name} æ¸¬è©¦å¤±æ•—: {e}")
                overall_success = False
                recovery_details.append({
                    "scenario": scenario_name,
                    "success": False,
                    "error": str(e)
                })
        
        if overall_success:
            self.logger.info("âœ… ç³»çµ±æ¢å¾©èƒ½åŠ›æ¸¬è©¦é€šé")
        else:
            self.logger.error("âŒ ç³»çµ±æ¢å¾©èƒ½åŠ›æ¸¬è©¦å¤±æ•—")
        
        return overall_success
    
    async def _test_graceful_shutdown_recovery(self, base_url: str) -> bool:
        """å„ªé›…é—œé–‰æ¢å¾©æ¸¬è©¦"""
        # æ¨¡æ“¬å„ªé›…é—œé–‰ï¼ˆå¯¦éš›ç’°å¢ƒä¸­éœ€è¦ç™¼é€é—œé–‰ä¿¡è™Ÿï¼‰
        self.logger.info("æ¨¡æ“¬å„ªé›…é—œé–‰")
        await asyncio.sleep(2)
        
        # æ¨¡æ“¬é‡å•Ÿ
        self.logger.info("æ¨¡æ“¬æœå‹™é‡å•Ÿ")
        await asyncio.sleep(3)
        
        # æ¸¬è©¦æ¢å¾©å¾Œç‹€æ…‹
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{base_url}/health", timeout=10) as response:
                    return response.status == 200
        except Exception:
            return False
    
    async def _test_resource_cleanup_recovery(self, base_url: str) -> bool:
        """è³‡æºæ¸…ç†æ¢å¾©æ¸¬è©¦"""
        # è§¸ç™¼è³‡æºæ¸…ç†
        gc.collect()
        
        # æ¸¬è©¦æ¸…ç†å¾Œç³»çµ±ç‹€æ…‹
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{base_url}/health", timeout=5) as response:
                    return response.status == 200
        except Exception:
            return False
    
    async def _test_service_restart_recovery(self, base_url: str) -> bool:
        """æœå‹™é‡å•Ÿæ¢å¾©æ¸¬è©¦"""
        # æ¨¡æ“¬æœå‹™é‡å•Ÿï¼ˆåœ¨å¯¦éš›ç’°å¢ƒä¸­éœ€è¦å…·é«”çš„é‡å•Ÿæ©Ÿåˆ¶ï¼‰
        self.logger.info("æ¨¡æ“¬æœå‹™é‡å•Ÿ")
        await asyncio.sleep(5)
        
        # æ¸¬è©¦é‡å•Ÿå¾Œç‹€æ…‹
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{base_url}/health", timeout=10) as response:
                    return response.status == 200
        except Exception:
            return False
    
    async def _generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç¶œåˆæ¸¬è©¦å ±å‘Š"""
        final_stats = self.resource_monitor.get_current_stats()
        
        # è¨ˆç®—æ•´é«”çµ±è¨ˆ
        total_stress_tests = len(self.test_results)
        successful_stress_tests = sum(1 for r in self.test_results if r.system_stable)
        
        total_recovery_tests = len(self.recovery_results)
        successful_recovery_tests = sum(1 for r in self.recovery_results if r.recovery_successful)
        
        # æ€§èƒ½æŒ‡æ¨™æ‘˜è¦
        if self.test_results:
            avg_success_rate = statistics.mean([r.success_rate for r in self.test_results])
            avg_response_time = statistics.mean([r.avg_response_time_ms for r in self.test_results])
            peak_cpu_usage = max([r.cpu_peak_percent for r in self.test_results])
            peak_memory_usage = max([r.memory_peak_mb for r in self.test_results])
        else:
            avg_success_rate = avg_response_time = peak_cpu_usage = peak_memory_usage = 0
        
        # è¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬æ‘˜è¦
        memory_leak_detected = any(r.leak_detected for r in self.memory_leak_results)
        
        report = {
            "test_execution_summary": {
                "total_stress_tests": total_stress_tests,
                "successful_stress_tests": successful_stress_tests,
                "stress_test_success_rate": successful_stress_tests / total_stress_tests if total_stress_tests > 0 else 0,
                "total_recovery_tests": total_recovery_tests,
                "successful_recovery_tests": successful_recovery_tests,
                "recovery_test_success_rate": successful_recovery_tests / total_recovery_tests if total_recovery_tests > 0 else 0,
                "memory_leak_detected": memory_leak_detected
            },
            "performance_summary": {
                "average_success_rate": avg_success_rate,
                "average_response_time_ms": avg_response_time,
                "peak_cpu_usage_percent": peak_cpu_usage,
                "peak_memory_usage_mb": peak_memory_usage
            },
            "system_resource_analysis": final_stats,
            "recommendations": self._generate_recommendations()
        }
        
        return report
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        recommendations = []
        
        # åŸºæ–¼æ¸¬è©¦çµæœç”Ÿæˆå»ºè­°
        if self.test_results:
            avg_success_rate = statistics.mean([r.success_rate for r in self.test_results])
            if avg_success_rate < 0.9:
                recommendations.append("ç³»çµ±åœ¨é«˜è² è¼‰ä¸‹æˆåŠŸç‡åä½ï¼Œå»ºè­°å„ªåŒ–éŒ¯èª¤è™•ç†æ©Ÿåˆ¶")
            
            avg_response_time = statistics.mean([r.avg_response_time_ms for r in self.test_results])
            if avg_response_time > 500:
                recommendations.append("å¹³å‡éŸ¿æ‡‰æ™‚é–“è¼ƒé«˜ï¼Œå»ºè­°å„ªåŒ–æ€§èƒ½ç“¶é ¸")
            
            peak_cpu = max([r.cpu_peak_percent for r in self.test_results])
            if peak_cpu > 95:
                recommendations.append("CPUä½¿ç”¨ç‡éé«˜ï¼Œå»ºè­°å¢åŠ è¨ˆç®—è³‡æºæˆ–å„ªåŒ–ç®—æ³•")
        
        # è¨˜æ†¶é«”æ´©æ¼å»ºè­°
        if any(r.leak_detected for r in self.memory_leak_results):
            recommendations.append("æª¢æ¸¬åˆ°è¨˜æ†¶é«”æ´©æ¼ï¼Œå»ºè­°æª¢æŸ¥è³‡æºæ¸…ç†æ©Ÿåˆ¶")
        
        # æ¢å¾©èƒ½åŠ›å»ºè­°
        if self.recovery_results:
            avg_recovery_time = statistics.mean([r.recovery_time_seconds for r in self.recovery_results])
            if avg_recovery_time > 30:
                recommendations.append("ç³»çµ±æ¢å¾©æ™‚é–“è¼ƒé•·ï¼Œå»ºè­°å„ªåŒ–æ•…éšœæ¢å¾©æ©Ÿåˆ¶")
        
        if not recommendations:
            recommendations.append("ç³»çµ±åœ¨å£“åŠ›æ¸¬è©¦ä¸­è¡¨ç¾è‰¯å¥½ï¼Œå»ºè­°ç¹¼çºŒç›£æ§é•·æœŸç©©å®šæ€§")
        
        return recommendations


# å‘å¾Œå…¼å®¹çš„ StressTester é¡
class StressTester:
    """å£“åŠ›æ¸¬è©¦å™¨ï¼ˆå‘å¾Œå…¼å®¹ç‰ˆæœ¬ï¼‰"""

    def __init__(self, config: Dict):
        self.config = config
        self.environment = config["environment"]
        self.services = self.environment["services"]
        self.stress_test_suite = StressTestSuite()

    async def run_stress_tests(self) -> Tuple[bool, Dict]:
        """åŸ·è¡Œå£“åŠ›æ¸¬è©¦"""
        logger.info("ğŸ”¥ é–‹å§‹åŸ·è¡Œå£“åŠ›æ¸¬è©¦")

        # ä½¿ç”¨æ–°çš„ StressTestSuite åŸ·è¡Œæ¸¬è©¦
        base_url = self.services.get('netstack', {}).get('url', 'http://localhost:8080')
        
        test_config = {
            "base_url": base_url,
            "max_concurrent_requests": 500,
            "test_duration_seconds": 120,
            "memory_test_duration_minutes": 5,
            "sustained_concurrent_users": 50,
            "sustained_test_duration_minutes": 10,
            "baseline_users": 10,
            "burst_users": 100,
            "burst_duration_seconds": 30
        }
        
        results = await self.stress_test_suite.run_comprehensive_stress_tests(test_config)
        
        # è½‰æ›ç‚ºèˆŠæ ¼å¼
        passed_tests = results["passed_tests"]
        total_tests = results["total_tests"]
        
        details = {
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "success_rate": results["success_rate"],
            "test_results": results["test_results"],
            "comprehensive_analysis": results["comprehensive_report"]
        }

        overall_success = passed_tests == total_tests
        logger.info(f"ğŸ”¥ å£“åŠ›æ¸¬è©¦å®Œæˆï¼ŒæˆåŠŸç‡: {details['success_rate']:.1%}")

        return overall_success, details


async def main():
    """ä¸»å‡½æ•¸ - ç¤ºä¾‹ç”¨æ³•"""
    stress_test_suite = StressTestSuite()
    
    # åŸ·è¡Œç¶œåˆå£“åŠ›æ¸¬è©¦
    print("ğŸ”¥ é–‹å§‹åŸ·è¡Œç¶œåˆå£“åŠ›æ¸¬è©¦å¥—ä»¶")
    
    test_config = {
        "base_url": "http://localhost:8080",
        "max_concurrent_requests": 1000,
        "test_duration_seconds": 300,
        "memory_test_duration_minutes": 10,
        "sustained_concurrent_users": 100,
        "sustained_test_duration_minutes": 20,
        "baseline_users": 20,
        "burst_users": 200,
        "burst_duration_seconds": 60
    }
    
    results = await stress_test_suite.run_comprehensive_stress_tests(test_config)
    
    print(f"ğŸ“Š å£“åŠ›æ¸¬è©¦æ‘˜è¦:")
    print(f"ç¸½æ¸¬è©¦æ•¸: {results['total_tests']}")
    print(f"é€šéæ¸¬è©¦: {results['passed_tests']}")
    print(f"æˆåŠŸç‡: {results['success_rate']:.1%}")
    
    # æ‰“å°è©³ç´°å ±å‘Š
    if results['comprehensive_report']:
        print("\nğŸ“ˆ ç¶œåˆåˆ†æå ±å‘Š:")
        report = results['comprehensive_report']
        print(f"å¹³å‡æˆåŠŸç‡: {report['performance_summary']['average_success_rate']:.1%}")
        print(f"å¹³å‡éŸ¿æ‡‰æ™‚é–“: {report['performance_summary']['average_response_time_ms']:.1f}ms")
        print(f"å³°å€¼CPUä½¿ç”¨ç‡: {report['performance_summary']['peak_cpu_usage_percent']:.1f}%")
        print(f"å³°å€¼è¨˜æ†¶é«”ä½¿ç”¨: {report['performance_summary']['peak_memory_usage_mb']:.1f}MB")
        
        if report['recommendations']:
            print("\nğŸ’¡ æ”¹é€²å»ºè­°:")
            for i, rec in enumerate(report['recommendations'], 1):
                print(f"{i}. {rec}")


if __name__ == "__main__":
    asyncio.run(main())