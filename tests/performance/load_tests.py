#!/usr/bin/env python3
"""
è² è¼‰æ¸¬è©¦æ¨¡çµ„
æ¸¬è©¦ç³»çµ±åœ¨é«˜è² è¼‰æƒ…æ³ä¸‹çš„æ€§èƒ½è¡¨ç¾

æ¸¬è©¦ç¯„åœï¼š
- é«˜ä¸¦ç™¼è² è¼‰æ¸¬è©¦
- æŒçºŒè² è¼‰æ¸¬è©¦
- è³‡æºæ¶ˆè€—æ¸¬è©¦
- è² è¼‰ä¸‹çš„å»¶é²æ¸¬è©¦
"""

import asyncio
import logging
import time
from typing import Dict, List, Tuple, Any
import aiohttp

logger = logging.getLogger(__name__)


class LoadTester:
    """è² è¼‰æ¸¬è©¦å™¨"""

    def __init__(self, config: Dict):
        self.config = config
        self.environment = config["environment"]
        self.services = self.environment["services"]

    async def run_load_tests(self) -> Tuple[bool, Dict]:
        """åŸ·è¡Œè² è¼‰æ¸¬è©¦"""
        logger.info("ğŸ”¥ é–‹å§‹åŸ·è¡Œè² è¼‰æ¸¬è©¦")

        # è² è¼‰æ¸¬è©¦å ´æ™¯
        test_scenarios = [
            ("high_concurrency", await self._test_high_concurrency()),
            ("sustained_load", await self._test_sustained_load()),
            ("spike_load", await self._test_spike_load()),
        ]

        passed_tests = sum(1 for _, passed in test_scenarios if passed)
        total_tests = len(test_scenarios)

        details = {
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "success_rate": passed_tests / total_tests,
            "test_results": {name: passed for name, passed in test_scenarios},
        }

        overall_success = passed_tests == total_tests
        logger.info(f"ğŸ”¥ è² è¼‰æ¸¬è©¦å®Œæˆï¼ŒæˆåŠŸç‡: {details['success_rate']:.1%}")

        return overall_success, details

    async def _test_high_concurrency(self) -> bool:
        """é«˜ä¸¦ç™¼æ¸¬è©¦"""
        logger.info("âš¡ åŸ·è¡Œé«˜ä¸¦ç™¼æ¸¬è©¦")

        concurrent_requests = 100
        url = f"{self.services['netstack']['url']}/health"

        async def make_request(session):
            try:
                async with session.get(url, timeout=10) as response:
                    return response.status == 200
            except:
                return False

        async with aiohttp.ClientSession() as session:
            tasks = [make_request(session) for _ in range(concurrent_requests)]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            success_count = sum(1 for r in results if r is True)
            success_rate = success_count / concurrent_requests

            passed = success_rate >= 0.8  # 80% æˆåŠŸç‡é–€æª»

            if passed:
                logger.info(f"âœ… é«˜ä¸¦ç™¼æ¸¬è©¦é€šé: {success_rate:.1%} æˆåŠŸç‡")
            else:
                logger.error(f"âŒ é«˜ä¸¦ç™¼æ¸¬è©¦å¤±æ•—: {success_rate:.1%} æˆåŠŸç‡")

            return passed

    async def _test_sustained_load(self) -> bool:
        """æŒçºŒè² è¼‰æ¸¬è©¦"""
        logger.info("â±ï¸ åŸ·è¡ŒæŒçºŒè² è¼‰æ¸¬è©¦")

        duration = 30  # 30 ç§’æŒçºŒè² è¼‰
        request_interval = 0.1  # æ¯ 100ms ä¸€å€‹è«‹æ±‚
        url = f"{self.services['netstack']['url']}/health"

        start_time = time.time()
        success_count = 0
        total_count = 0

        async with aiohttp.ClientSession() as session:
            while time.time() - start_time < duration:
                try:
                    async with session.get(url, timeout=5) as response:
                        total_count += 1
                        if response.status == 200:
                            success_count += 1
                except:
                    total_count += 1

                await asyncio.sleep(request_interval)

        success_rate = success_count / total_count if total_count > 0 else 0
        passed = success_rate >= 0.9  # 90% æˆåŠŸç‡é–€æª»

        if passed:
            logger.info(f"âœ… æŒçºŒè² è¼‰æ¸¬è©¦é€šé: {success_rate:.1%} æˆåŠŸç‡")
        else:
            logger.error(f"âŒ æŒçºŒè² è¼‰æ¸¬è©¦å¤±æ•—: {success_rate:.1%} æˆåŠŸç‡")

        return passed

    async def _test_spike_load(self) -> bool:
        """çªå¢è² è¼‰æ¸¬è©¦"""
        logger.info("ğŸ“ˆ åŸ·è¡Œçªå¢è² è¼‰æ¸¬è©¦")

        # æ¨¡æ“¬æµé‡çªå¢ï¼šæ­£å¸¸è² è¼‰ -> é«˜è² è¼‰ -> æ­£å¸¸è² è¼‰
        url = f"{self.services['netstack']['url']}/health"

        async def burst_requests(session, count):
            tasks = []
            for _ in range(count):
                tasks.append(session.get(url, timeout=10))

            responses = await asyncio.gather(*tasks, return_exceptions=True)
            success_count = sum(
                1 for r in responses if hasattr(r, "status") and r.status == 200
            )

            # é—œé–‰æ‰€æœ‰éŸ¿æ‡‰
            for r in responses:
                if hasattr(r, "close"):
                    r.close()

            return success_count, len(responses)

        async with aiohttp.ClientSession() as session:
            # æ­£å¸¸è² è¼‰
            normal_success, normal_total = await burst_requests(session, 10)
            await asyncio.sleep(1)

            # çªå¢è² è¼‰
            spike_success, spike_total = await burst_requests(session, 50)
            await asyncio.sleep(1)

            # æ¢å¾©æ­£å¸¸
            recovery_success, recovery_total = await burst_requests(session, 10)

        # æª¢æŸ¥ç³»çµ±æ˜¯å¦èƒ½è™•ç†çªå¢ä¸¦æ¢å¾©
        spike_success_rate = spike_success / spike_total if spike_total > 0 else 0
        recovery_success_rate = (
            recovery_success / recovery_total if recovery_total > 0 else 0
        )

        passed = spike_success_rate >= 0.7 and recovery_success_rate >= 0.9

        if passed:
            logger.info(
                f"âœ… çªå¢è² è¼‰æ¸¬è©¦é€šé: çªå¢æœŸ {spike_success_rate:.1%}, æ¢å¾©æœŸ {recovery_success_rate:.1%}"
            )
        else:
            logger.error(
                f"âŒ çªå¢è² è¼‰æ¸¬è©¦å¤±æ•—: çªå¢æœŸ {spike_success_rate:.1%}, æ¢å¾©æœŸ {recovery_success_rate:.1%}"
            )

        return passed
