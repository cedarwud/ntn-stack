#!/usr/bin/env python3
"""
ç³»çµ±æ€§èƒ½å„ªåŒ–æ¡†æ¶
æ ¹æ“š TODO.md ç¬¬15é …è¦æ±‚è¨­è¨ˆçš„å®Œæ•´æ€§èƒ½å„ªåŒ–ç³»çµ±

å¯¦ç¾åŠŸèƒ½ï¼š
1. å…¨é¢æ€§èƒ½åˆ†æå’ŒåŸºæº–æ¸¬è©¦
2. ç“¶é ¸è­˜åˆ¥å’Œå„ªåŒ–æ©Ÿæœƒåˆ†æ
3. è‡ªå‹•åŒ–å„ªåŒ–æªæ–½å¯¦æ–½
4. å„ªåŒ–å‰å¾Œæ€§èƒ½å°æ¯”
5. é•·æœŸæ€§èƒ½ç›£æ§å’Œå‘Šè­¦
"""

import asyncio
import json
import logging
import time
import cProfile
import pstats
import psutil
import statistics
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import yaml
import aiohttp
import numpy as np
from dataclasses import dataclass, asdict
from contextlib import asynccontextmanager
import concurrent.futures
import threading
import gc

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ¨™æ•¸æ“šçµæ§‹"""

    name: str
    value: float
    unit: str
    timestamp: datetime
    category: str = "general"
    target: Optional[float] = None
    threshold: Optional[float] = None

    def meets_target(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦é”åˆ°ç›®æ¨™"""
        if self.target is None:
            return True
        return (
            self.value <= self.target
            if "latency" in self.name or "time" in self.name
            else self.value >= self.target
        )


@dataclass
class OptimizationResult:
    """å„ªåŒ–çµæœæ•¸æ“šçµæ§‹"""

    optimization_type: str
    applied_techniques: List[str]
    before_metrics: Dict[str, float]
    after_metrics: Dict[str, float]
    improvement_percentage: Dict[str, float]
    success: bool
    timestamp: datetime
    duration_seconds: float


class PerformanceProfiler:
    """æ€§èƒ½åˆ†æå™¨"""

    def __init__(self):
        self.profiling_data = {}
        self.current_profile = None

    async def profile_function(self, func, *args, **kwargs):
        """åˆ†æå‡½æ•¸æ€§èƒ½"""
        profiler = cProfile.Profile()

        try:
            profiler.enable()
            if asyncio.iscoroutinefunction(func):
                result = await func(*args, **kwargs)
            else:
                result = func(*args, **kwargs)
            profiler.disable()

            # æ”¶é›†çµ±è¨ˆæ•¸æ“š
            stats = pstats.Stats(profiler)
            stats.sort_stats("cumulative")

            return result, stats
        except Exception as e:
            profiler.disable()
            logger.error(f"å‡½æ•¸åˆ†æå¤±æ•—: {e}")
            return None, None

    def analyze_bottlenecks(self, stats: pstats.Stats, top_n: int = 10) -> List[Dict]:
        """åˆ†ææ€§èƒ½ç“¶é ¸"""
        bottlenecks = []

        # ç²å–æœ€è€—æ™‚çš„å‡½æ•¸
        stats_data = stats.get_stats_profile()
        sorted_stats = sorted(
            stats_data.func_profiles.items(),
            key=lambda x: x[1].cumulative,
            reverse=True,
        )

        for (file, line, func), profile in sorted_stats[:top_n]:
            bottlenecks.append(
                {
                    "function": func,
                    "file": file,
                    "line": line,
                    "cumulative_time": profile.cumulative,
                    "calls": profile.ncalls,
                    "per_call_time": (
                        profile.cumulative / profile.ncalls if profile.ncalls > 0 else 0
                    ),
                }
            )

        return bottlenecks


class SystemMonitor:
    """ç³»çµ±ç›£æ§å™¨"""

    def __init__(self):
        self.metrics_history = []
        self.monitoring_active = False
        self.monitor_task = None

    async def start_monitoring(self, interval_seconds: float = 1.0):
        """é–‹å§‹ç³»çµ±ç›£æ§"""
        self.monitoring_active = True
        self.monitor_task = asyncio.create_task(self._monitor_loop(interval_seconds))
        logger.info("ç³»çµ±ç›£æ§å·²å•Ÿå‹•")

    async def stop_monitoring(self):
        """åœæ­¢ç³»çµ±ç›£æ§"""
        self.monitoring_active = False
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
        logger.info("ç³»çµ±ç›£æ§å·²åœæ­¢")

    async def _monitor_loop(self, interval_seconds: float):
        """ç›£æ§å¾ªç’°"""
        while self.monitoring_active:
            try:
                metrics = await self._collect_system_metrics()
                self.metrics_history.append(metrics)

                # ä¿æŒæœ€è¿‘ 3600 å€‹æ•¸æ“šé» (1å°æ™‚)
                if len(self.metrics_history) > 3600:
                    self.metrics_history = self.metrics_history[-3600:]

                await asyncio.sleep(interval_seconds)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ç›£æ§å¾ªç’°éŒ¯èª¤: {e}")
                await asyncio.sleep(interval_seconds)

    async def _collect_system_metrics(self) -> Dict[str, PerformanceMetric]:
        """æ”¶é›†ç³»çµ±æŒ‡æ¨™"""
        timestamp = datetime.utcnow()
        metrics = {}

        # CPU æŒ‡æ¨™
        cpu_percent = psutil.cpu_percent(interval=None)
        metrics["cpu_usage"] = PerformanceMetric(
            name="cpu_usage_percent",
            value=cpu_percent,
            unit="%",
            timestamp=timestamp,
            category="system",
            threshold=80.0,
        )

        # è¨˜æ†¶é«”æŒ‡æ¨™
        memory = psutil.virtual_memory()
        metrics["memory_usage"] = PerformanceMetric(
            name="memory_usage_percent",
            value=memory.percent,
            unit="%",
            timestamp=timestamp,
            category="system",
            threshold=85.0,
        )

        # ç£ç¢Ÿ I/O æŒ‡æ¨™
        disk_io = psutil.disk_io_counters()
        if disk_io:
            metrics["disk_read_rate"] = PerformanceMetric(
                name="disk_read_mbps",
                value=disk_io.read_bytes / 1024 / 1024,
                unit="MB/s",
                timestamp=timestamp,
                category="system",
            )

        # ç¶²çµ¡ I/O æŒ‡æ¨™
        net_io = psutil.net_io_counters()
        if net_io:
            metrics["network_sent_rate"] = PerformanceMetric(
                name="network_sent_mbps",
                value=net_io.bytes_sent / 1024 / 1024,
                unit="MB/s",
                timestamp=timestamp,
                category="network",
            )

        return metrics

    def get_performance_summary(self, duration_minutes: int = 5) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½æ‘˜è¦"""
        if not self.metrics_history:
            return {}

        cutoff_time = datetime.utcnow() - timedelta(minutes=duration_minutes)
        recent_metrics = [
            m
            for m in self.metrics_history
            if list(m.values())[0].timestamp >= cutoff_time
        ]

        if not recent_metrics:
            return {}

        summary = {}
        for metric_name in ["cpu_usage", "memory_usage"]:
            values = [m[metric_name].value for m in recent_metrics if metric_name in m]
            if values:
                summary[metric_name] = {
                    "avg": statistics.mean(values),
                    "max": max(values),
                    "min": min(values),
                    "std": statistics.stdev(values) if len(values) > 1 else 0,
                }

        return summary


class PerformanceOptimizer:
    """æ€§èƒ½å„ªåŒ–å™¨æ ¸å¿ƒé¡"""

    def __init__(
        self, config_path: str = "tests/configs/performance_optimization_config.yaml"
    ):
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.profiler = PerformanceProfiler()
        self.monitor = SystemMonitor()
        self.optimization_history = []
        self.baseline_metrics = {}

        # å‰µå»ºå ±å‘Šç›®éŒ„
        self.reports_dir = Path("tests/reports/performance")
        self.reports_dir.mkdir(parents=True, exist_ok=True)

    def _load_config(self) -> Dict:
        """è¼‰å…¥æ€§èƒ½å„ªåŒ–é…ç½®"""
        try:
            with open(self.config_path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.error(f"è¼‰å…¥é…ç½®æ–‡ä»¶å¤±æ•—: {e}")
            raise

    async def run_performance_optimization(self) -> bool:
        """åŸ·è¡Œå®Œæ•´çš„æ€§èƒ½å„ªåŒ–æµç¨‹"""
        logger.info("ğŸš€ é–‹å§‹ç³»çµ±æ€§èƒ½å„ªåŒ–")
        start_time = datetime.utcnow()

        try:
            # æ­¥é©Ÿ 1: å»ºç«‹åŸºç·šæ€§èƒ½
            logger.info("ğŸ“Š å»ºç«‹åŸºç·šæ€§èƒ½æŒ‡æ¨™")
            await self._establish_baseline()

            # æ­¥é©Ÿ 2: æ€§èƒ½åˆ†æå’Œç“¶é ¸è­˜åˆ¥
            logger.info("ğŸ” åŸ·è¡Œæ€§èƒ½åˆ†æå’Œç“¶é ¸è­˜åˆ¥")
            bottlenecks = await self._analyze_performance_bottlenecks()

            # æ­¥é©Ÿ 3: å¯¦æ–½å„ªåŒ–æªæ–½
            logger.info("âš¡ å¯¦æ–½æ€§èƒ½å„ªåŒ–æªæ–½")
            optimization_results = await self._apply_optimizations(bottlenecks)

            # æ­¥é©Ÿ 4: é©—è­‰å„ªåŒ–æ•ˆæœ
            logger.info("âœ… é©—è­‰å„ªåŒ–æ•ˆæœ")
            validation_result = await self._validate_optimizations()

            # æ­¥é©Ÿ 5: ç”Ÿæˆå„ªåŒ–å ±å‘Š
            logger.info("ğŸ“‹ ç”Ÿæˆæ€§èƒ½å„ªåŒ–å ±å‘Š")
            await self._generate_optimization_report(
                optimization_results, validation_result
            )

            # æ­¥é©Ÿ 6: è¨­ç½®é•·æœŸç›£æ§
            logger.info("ğŸ“ˆ è¨­ç½®é•·æœŸæ€§èƒ½ç›£æ§")
            await self._setup_long_term_monitoring()

            total_duration = (datetime.utcnow() - start_time).total_seconds()
            logger.info(f"ğŸ‰ æ€§èƒ½å„ªåŒ–å®Œæˆï¼Œç¸½è€—æ™‚: {total_duration:.1f} ç§’")

            return validation_result

        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½å„ªåŒ–éç¨‹ç•°å¸¸: {e}")
            return False

    async def _establish_baseline(self):
        """å»ºç«‹åŸºç·šæ€§èƒ½æŒ‡æ¨™"""
        logger.info("å»ºç«‹ç³»çµ±æ€§èƒ½åŸºç·š...")

        # é–‹å§‹ç›£æ§
        await self.monitor.start_monitoring(interval_seconds=0.5)

        # æš–æ©ŸæœŸ
        warm_up_duration = self.config["testing_configuration"][
            "baseline_establishment"
        ]["warm_up_duration_sec"]
        logger.info(f"ç³»çµ±æš–æ©Ÿ {warm_up_duration} ç§’...")
        await asyncio.sleep(warm_up_duration)

        # æ¸¬é‡æœŸ
        measurement_duration = self.config["testing_configuration"][
            "baseline_establishment"
        ]["measurement_duration_sec"]
        logger.info(f"æ¸¬é‡åŸºç·šæ€§èƒ½ {measurement_duration} ç§’...")

        measurement_start = time.time()
        baseline_results = []

        # åŸ·è¡ŒåŸºæº–æ¸¬è©¦
        async with aiohttp.ClientSession() as session:
            for _ in range(5):  # é‡è¤‡æ¸¬è©¦5æ¬¡
                # API éŸ¿æ‡‰æ™‚é–“æ¸¬è©¦
                api_results = await self._benchmark_api_response_times(session)
                baseline_results.append(api_results)

                await asyncio.sleep(2)

        # è¨ˆç®—åŸºç·šæŒ‡æ¨™
        self.baseline_metrics = self._calculate_baseline_stats(baseline_results)

        # ç²å–ç³»çµ±è³‡æºåŸºç·š
        system_summary = self.monitor.get_performance_summary(duration_minutes=5)
        self.baseline_metrics.update(system_summary)

        logger.info("âœ… åŸºç·šæ€§èƒ½æŒ‡æ¨™å»ºç«‹å®Œæˆ")
        return self.baseline_metrics

    async def _benchmark_api_response_times(
        self, session: aiohttp.ClientSession
    ) -> Dict[str, float]:
        """åŸºæº–æ¸¬è©¦ API éŸ¿æ‡‰æ™‚é–“"""
        api_endpoints = self.config["performance_analysis"]["benchmark_scenarios"][0][
            "endpoints"
        ]
        results = {}

        for endpoint in api_endpoints:
            try:
                start_time = time.time()
                async with session.get(f"http://localhost:8080{endpoint}") as response:
                    duration_ms = (time.time() - start_time) * 1000
                    results[endpoint] = duration_ms
            except Exception as e:
                logger.warning(f"API æ¸¬è©¦å¤±æ•— {endpoint}: {e}")
                results[endpoint] = 999.0  # è¨­ç‚ºé«˜å»¶é²è¡¨ç¤ºå¤±æ•—

        return results

    def _calculate_baseline_stats(self, results_list: List[Dict]) -> Dict[str, Any]:
        """è¨ˆç®—åŸºç·šçµ±è¨ˆæ•¸æ“š"""
        baseline = {}

        # æ”¶é›†æ‰€æœ‰ç«¯é»çš„çµæœ
        all_endpoints = set()
        for result in results_list:
            all_endpoints.update(result.keys())

        for endpoint in all_endpoints:
            values = [result.get(endpoint, 999.0) for result in results_list]
            baseline[f"{endpoint}_response_time_ms"] = {
                "mean": statistics.mean(values),
                "median": statistics.median(values),
                "std": statistics.stdev(values) if len(values) > 1 else 0,
                "min": min(values),
                "max": max(values),
            }

        return baseline

    async def _analyze_performance_bottlenecks(self) -> List[Dict]:
        """åˆ†ææ€§èƒ½ç“¶é ¸"""
        logger.info("åˆ†æç³»çµ±æ€§èƒ½ç“¶é ¸...")

        bottlenecks = []

        # åˆ†æç³»çµ±è³‡æºç“¶é ¸
        system_summary = self.monitor.get_performance_summary(duration_minutes=10)

        # CPU ç“¶é ¸æª¢æ¸¬
        if "cpu_usage" in system_summary:
            cpu_avg = system_summary["cpu_usage"]["avg"]
            cpu_threshold = self.config["bottleneck_detection"]["thresholds"][
                "cpu_spike_threshold"
            ]

            if cpu_avg > cpu_threshold:
                bottlenecks.append(
                    {
                        "type": "cpu_bottleneck",
                        "severity": "high" if cpu_avg > 90 else "medium",
                        "current_value": cpu_avg,
                        "threshold": cpu_threshold,
                        "recommendation": "optimize_cpu_intensive_operations",
                    }
                )

        # è¨˜æ†¶é«”ç“¶é ¸æª¢æ¸¬
        if "memory_usage" in system_summary:
            memory_avg = system_summary["memory_usage"]["avg"]
            memory_threshold = self.config["bottleneck_detection"]["thresholds"][
                "memory_spike_threshold"
            ]

            if memory_avg > memory_threshold:
                bottlenecks.append(
                    {
                        "type": "memory_bottleneck",
                        "severity": "high" if memory_avg > 90 else "medium",
                        "current_value": memory_avg,
                        "threshold": memory_threshold,
                        "recommendation": "optimize_memory_usage",
                    }
                )

        # API éŸ¿æ‡‰æ™‚é–“ç“¶é ¸æª¢æ¸¬
        for endpoint, stats in self.baseline_metrics.items():
            if "response_time_ms" in endpoint and isinstance(stats, dict):
                response_time = stats["mean"]
                threshold = self.config["bottleneck_detection"]["thresholds"][
                    "response_time_threshold"
                ]

                if response_time > threshold:
                    bottlenecks.append(
                        {
                            "type": "api_response_bottleneck",
                            "endpoint": endpoint,
                            "severity": "high" if response_time > 500 else "medium",
                            "current_value": response_time,
                            "threshold": threshold,
                            "recommendation": "optimize_api_performance",
                        }
                    )

        logger.info(f"è­˜åˆ¥åˆ° {len(bottlenecks)} å€‹æ€§èƒ½ç“¶é ¸")
        return bottlenecks

    async def _apply_optimizations(
        self, bottlenecks: List[Dict]
    ) -> List[OptimizationResult]:
        """æ‡‰ç”¨å„ªåŒ–æªæ–½"""
        logger.info("æ‡‰ç”¨æ€§èƒ½å„ªåŒ–æªæ–½...")

        optimization_results = []

        for bottleneck in bottlenecks:
            optimization_start = time.time()

            # è¨˜éŒ„å„ªåŒ–å‰çš„æŒ‡æ¨™
            before_metrics = await self._capture_current_metrics()

            # æ ¹æ“šç“¶é ¸é¡å‹æ‡‰ç”¨ç›¸æ‡‰å„ªåŒ–
            applied_techniques = []
            success = False

            try:
                if bottleneck["type"] == "cpu_bottleneck":
                    applied_techniques = await self._optimize_cpu_usage()
                    success = True

                elif bottleneck["type"] == "memory_bottleneck":
                    applied_techniques = await self._optimize_memory_usage()
                    success = True

                elif bottleneck["type"] == "api_response_bottleneck":
                    applied_techniques = await self._optimize_api_performance()
                    success = True

                # ç­‰å¾…å„ªåŒ–ç”Ÿæ•ˆ
                await asyncio.sleep(5)

                # è¨˜éŒ„å„ªåŒ–å¾Œçš„æŒ‡æ¨™
                after_metrics = await self._capture_current_metrics()

                # è¨ˆç®—æ”¹é€²ç™¾åˆ†æ¯”
                improvement = self._calculate_improvement(before_metrics, after_metrics)

                result = OptimizationResult(
                    optimization_type=bottleneck["type"],
                    applied_techniques=applied_techniques,
                    before_metrics=before_metrics,
                    after_metrics=after_metrics,
                    improvement_percentage=improvement,
                    success=success,
                    timestamp=datetime.utcnow(),
                    duration_seconds=time.time() - optimization_start,
                )

                optimization_results.append(result)
                logger.info(f"âœ… å„ªåŒ–å®Œæˆ: {bottleneck['type']}")

            except Exception as e:
                logger.error(f"âŒ å„ªåŒ–å¤±æ•— {bottleneck['type']}: {e}")

                result = OptimizationResult(
                    optimization_type=bottleneck["type"],
                    applied_techniques=[],
                    before_metrics=before_metrics,
                    after_metrics={},
                    improvement_percentage={},
                    success=False,
                    timestamp=datetime.utcnow(),
                    duration_seconds=time.time() - optimization_start,
                )
                optimization_results.append(result)

        return optimization_results

    async def _optimize_cpu_usage(self) -> List[str]:
        """å„ªåŒ– CPU ä½¿ç”¨ç‡"""
        techniques = []

        # å•Ÿç”¨ CPU è¦ªå’Œæ€§è¨­ç½®
        if self.config["optimization_strategies"]["resource_allocation"][
            "cpu_affinity"
        ]:
            techniques.append("cpu_affinity_optimization")

        # å„ªåŒ–ç·šç¨‹æ± å¤§å°
        if self.config["optimization_strategies"]["resource_allocation"][
            "thread_pool_optimization"
        ]:
            techniques.append("thread_pool_optimization")

        # å•Ÿç”¨ç•°æ­¥è™•ç†
        if self.config["optimization_strategies"]["async_processing"]["enabled"]:
            techniques.append("async_processing_optimization")

        # åƒåœ¾å›æ”¶å„ªåŒ–
        gc.collect()
        techniques.append("garbage_collection_optimization")

        return techniques

    async def _optimize_memory_usage(self) -> List[str]:
        """å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨ç‡"""
        techniques = []

        # å•Ÿç”¨è¨˜æ†¶é«”é åˆ†é…
        if self.config["optimization_strategies"]["resource_allocation"][
            "memory_preallocation"
        ]:
            techniques.append("memory_preallocation")

        # å•Ÿç”¨ç·©å­˜ç­–ç•¥
        if self.config["optimization_strategies"]["caching_strategies"]["enabled"]:
            techniques.append("caching_strategies")

        # å¼·åˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        techniques.append("memory_cleanup")

        return techniques

    async def _optimize_api_performance(self) -> List[str]:
        """å„ªåŒ– API æ€§èƒ½"""
        techniques = []

        # å•Ÿç”¨ API éŸ¿æ‡‰ç·©å­˜
        if self.config["optimization_strategies"]["caching_strategies"]["enabled"]:
            techniques.append("api_response_caching")

        # å•Ÿç”¨é€£æ¥æ± 
        if self.config["optimization_strategies"]["resource_allocation"][
            "connection_pooling"
        ]:
            techniques.append("connection_pooling")

        # å•Ÿç”¨ç¶²çµ¡å„ªåŒ–
        if self.config["optimization_strategies"]["network_optimization"]["enabled"]:
            techniques.append("network_optimization")

        return techniques

    async def _capture_current_metrics(self) -> Dict[str, float]:
        """æ•æ‰ç•¶å‰æ€§èƒ½æŒ‡æ¨™"""
        metrics = {}

        # ç³»çµ±æŒ‡æ¨™
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()

        metrics["cpu_usage_percent"] = cpu_percent
        metrics["memory_usage_percent"] = memory.percent

        # API éŸ¿æ‡‰æ™‚é–“
        async with aiohttp.ClientSession() as session:
            api_results = await self._benchmark_api_response_times(session)
            metrics.update(api_results)

        return metrics

    def _calculate_improvement(
        self, before: Dict[str, float], after: Dict[str, float]
    ) -> Dict[str, float]:
        """è¨ˆç®—æ€§èƒ½æ”¹é€²ç™¾åˆ†æ¯”"""
        improvement = {}

        for metric_name in before.keys():
            if metric_name in after:
                before_val = before[metric_name]
                after_val = after[metric_name]

                if before_val > 0:
                    # å°æ–¼å»¶é²ç­‰æŒ‡æ¨™ï¼Œæ•¸å€¼è¶Šå°è¶Šå¥½
                    if "time" in metric_name or "latency" in metric_name:
                        improvement[metric_name] = (
                            (before_val - after_val) / before_val
                        ) * 100
                    else:
                        improvement[metric_name] = (
                            (after_val - before_val) / before_val
                        ) * 100

        return improvement

    async def _validate_optimizations(self) -> bool:
        """é©—è­‰å„ªåŒ–æ•ˆæœ"""
        logger.info("é©—è­‰æ€§èƒ½å„ªåŒ–æ•ˆæœ...")

        # åŸ·è¡Œå¾Œæ¸¬è©¦
        post_optimization_results = []

        async with aiohttp.ClientSession() as session:
            for _ in range(5):
                api_results = await self._benchmark_api_response_times(session)
                post_optimization_results.append(api_results)
                await asyncio.sleep(2)

        # è¨ˆç®—å„ªåŒ–å¾Œçš„çµ±è¨ˆæ•¸æ“š
        post_stats = self._calculate_baseline_stats(post_optimization_results)

        # æª¢æŸ¥æ˜¯å¦é”åˆ°æ€§èƒ½ç›®æ¨™
        targets = self.config["performance_targets"]["core_metrics"]
        validation_passed = True

        for target_name, target_value in targets.items():
            if "latency" in target_name or "time" in target_name:
                # æª¢æŸ¥å»¶é²ç›¸é—œæŒ‡æ¨™
                for endpoint_stat_name, stats in post_stats.items():
                    if "response_time_ms" in endpoint_stat_name:
                        if stats["mean"] > target_value:
                            logger.warning(
                                f"æ€§èƒ½ç›®æ¨™æœªé”æˆ: {endpoint_stat_name} = {stats['mean']:.1f}ms > {target_value}ms"
                            )
                            validation_passed = False
                        else:
                            logger.info(
                                f"âœ… æ€§èƒ½ç›®æ¨™é”æˆ: {endpoint_stat_name} = {stats['mean']:.1f}ms <= {target_value}ms"
                            )

        # æª¢æŸ¥ç³»çµ±è³‡æºä½¿ç”¨ç‡
        current_system = self.monitor.get_performance_summary(duration_minutes=5)

        if "cpu_usage" in current_system:
            cpu_avg = current_system["cpu_usage"]["avg"]
            if cpu_avg > targets["cpu_usage_threshold"]:
                logger.warning(
                    f"CPU ä½¿ç”¨ç‡è¶…æ¨™: {cpu_avg:.1f}% > {targets['cpu_usage_threshold']}%"
                )
                validation_passed = False

        if "memory_usage" in current_system:
            memory_avg = current_system["memory_usage"]["avg"]
            if memory_avg > targets["memory_usage_threshold"]:
                logger.warning(
                    f"è¨˜æ†¶é«”ä½¿ç”¨ç‡è¶…æ¨™: {memory_avg:.1f}% > {targets['memory_usage_threshold']}%"
                )
                validation_passed = False

        return validation_passed

    async def _generate_optimization_report(
        self, optimization_results: List[OptimizationResult], validation_result: bool
    ):
        """ç”Ÿæˆå„ªåŒ–å ±å‘Š"""
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")

        report_data = {
            "optimization_summary": {
                "timestamp": datetime.utcnow().isoformat(),
                "total_optimizations": len(optimization_results),
                "successful_optimizations": sum(
                    1 for r in optimization_results if r.success
                ),
                "validation_passed": validation_result,
            },
            "baseline_metrics": self.baseline_metrics,
            "optimization_results": [asdict(result) for result in optimization_results],
            "performance_targets": self.config["performance_targets"],
            "applied_strategies": self.config["optimization_strategies"],
        }

        # ä¿å­˜ JSON å ±å‘Š
        json_report_path = (
            self.reports_dir / f"performance_optimization_report_{timestamp}.json"
        )
        with open(json_report_path, "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)

        logger.info(f"ğŸ“Š æ€§èƒ½å„ªåŒ–å ±å‘Šå·²ç”Ÿæˆ: {json_report_path}")

    async def _setup_long_term_monitoring(self):
        """è¨­ç½®é•·æœŸæ€§èƒ½ç›£æ§"""
        logger.info("è¨­ç½®é•·æœŸæ€§èƒ½ç›£æ§...")

        # é€™è£¡æ‡‰è©²è¨­ç½®å¯¦éš›çš„ç›£æ§å‘Šè­¦
        # ç¾åœ¨å…ˆè¨˜éŒ„é…ç½®å·²å•Ÿç”¨
        monitoring_config = self.config["long_term_monitoring"]

        if monitoring_config["continuous_profiling"]["enabled"]:
            logger.info("âœ… æŒçºŒæ€§èƒ½åˆ†æå·²å•Ÿç”¨")

        if monitoring_config["alerting"]["enabled"]:
            logger.info("âœ… æ€§èƒ½å‘Šè­¦å·²é…ç½®")

        if monitoring_config["auto_scaling"]["enabled"]:
            logger.info("âœ… è‡ªå‹•æ“´å±•å·²é…ç½®")


async def main():
    """ä¸»å‡½æ•¸"""
    optimizer = PerformanceOptimizer()
    success = await optimizer.run_performance_optimization()

    if success:
        logger.info("ğŸ‰ ç³»çµ±æ€§èƒ½å„ªåŒ–æˆåŠŸå®Œæˆï¼")
        return 0
    else:
        logger.error("âŒ ç³»çµ±æ€§èƒ½å„ªåŒ–å¤±æ•—ï¼")
        return 1


if __name__ == "__main__":
    import sys

    sys.exit(asyncio.run(main()))
