#!/usr/bin/env python3
"""
éšæ®µå››ç¶œåˆæ¸¬è©¦åŸ·è¡Œå™¨
æ•´åˆæ‰€æœ‰æ¸¬è©¦æ¡†æ¶ï¼ŒåŸ·è¡Œå®Œæ•´çš„è«–æ–‡å¾©ç¾å’Œé©—è­‰æ¸¬è©¦

æ•´åˆæ¨¡çµ„ï¼š
1. è«–æ–‡å¾©ç¾æ¸¬è©¦æ¡†æ¶ (paper_reproduction_test_framework.py)
2. æ“´å±•æ€§èƒ½æ¸¬è©¦æ¡†æ¶ (enhanced_performance_testing.py)  
3. æ¼”ç®—æ³•å›æ­¸æ¸¬è©¦æ¡†æ¶ (algorithm_regression_testing.py)
4. å­¸è¡“å ±å‘Šç”Ÿæˆç³»çµ± (enhanced_report_generator.py)
"""

import asyncio
import time
import json
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any
import structlog

# å°å…¥æ¸¬è©¦æ¡†æ¶
from paper_reproduction_test_framework import PaperReproductionTestFramework
from enhanced_performance_testing import EnhancedPerformanceTestFramework
from algorithm_regression_testing import AlgorithmRegressionTestFramework
from enhanced_report_generator import EnhancedReportGenerator, ReportFormat

logger = structlog.get_logger(__name__)

class Stage4ComprehensiveTestRunner:
    """éšæ®µå››ç¶œåˆæ¸¬è©¦åŸ·è¡Œå™¨"""
    
    def __init__(self, config_path: str = "tests/configs/paper_reproduction_config.yaml"):
        self.config_path = config_path
        self.results_dir = Path("tests/results/stage4_comprehensive")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ¸¬è©¦æ¡†æ¶
        self.paper_framework = PaperReproductionTestFramework(config_path)
        self.performance_framework = EnhancedPerformanceTestFramework(config_path)
        self.regression_framework = AlgorithmRegressionTestFramework(config_path)
        self.report_generator = EnhancedReportGenerator(config_path)
        
        # æ¸¬è©¦çµæœå­˜å„²
        self.all_results = {}
        
    async def run_comprehensive_testing_suite(self) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´çš„éšæ®µå››æ¸¬è©¦å¥—ä»¶"""
        logger.info("ğŸš€ é–‹å§‹éšæ®µå››ç¶œåˆæ¸¬è©¦å¥—ä»¶")
        logger.info("åŒ…å«: è«–æ–‡å¾©ç¾ + æ€§èƒ½åˆ†æ + å›æ­¸æ¸¬è©¦ + å­¸è¡“å ±å‘Š")
        
        suite_start_time = time.time()
        
        try:
            # 1. è«–æ–‡å¾©ç¾æ¸¬è©¦ (T4.1.1 å®Œæˆ)
            logger.info("\n" + "="*60)
            logger.info("ğŸ“„ éšæ®µ 1/4: åŸ·è¡Œè«–æ–‡å¾©ç¾æ¸¬è©¦")
            logger.info("="*60)
            
            paper_results = await self._run_paper_reproduction_tests()
            self.all_results["paper_reproduction"] = paper_results
            
            # 2. æ“´å±•æ€§èƒ½æ¸¬è©¦ (T4.2.1 å®Œæˆ)
            logger.info("\n" + "="*60)
            logger.info("ğŸ“Š éšæ®µ 2/4: åŸ·è¡Œæ“´å±•æ€§èƒ½åˆ†æ")
            logger.info("="*60)
            
            performance_results = await self._run_enhanced_performance_tests()
            self.all_results["enhanced_performance"] = performance_results
            
            # 3. æ¼”ç®—æ³•å›æ­¸æ¸¬è©¦ (T4.3.1 å®Œæˆ)
            logger.info("\n" + "="*60)
            logger.info("ğŸ”§ éšæ®µ 3/4: åŸ·è¡Œæ¼”ç®—æ³•å›æ­¸æ¸¬è©¦")
            logger.info("="*60)
            
            regression_results = await self._run_regression_tests()
            self.all_results["algorithm_regression"] = regression_results
            
            # 4. ç”Ÿæˆå­¸è¡“ç´šåˆ¥å ±å‘Š (T4.4.1 æ–°å®Œæˆ)
            logger.info("\n" + "="*60)
            logger.info("ğŸ“ éšæ®µ 4/4: ç”Ÿæˆå­¸è¡“ç´šåˆ¥å ±å‘Š")
            logger.info("="*60)
            
            report_results = await self._generate_comprehensive_reports()
            self.all_results["comprehensive_reports"] = report_results
            
            # 5. ç”Ÿæˆæœ€çµ‚æ‘˜è¦
            final_summary = await self._generate_final_summary()
            
            suite_total_time = time.time() - suite_start_time
            
            final_results = {
                "test_suite_name": "Stage 4 Comprehensive Testing",
                "execution_timestamp": datetime.now().isoformat(),
                "total_execution_time_seconds": suite_total_time,
                "individual_results": self.all_results,
                "final_summary": final_summary,
                "success_status": final_summary["overall_success"]
            }
            
            # ä¿å­˜å®Œæ•´çµæœ
            await self._save_comprehensive_results(final_results)
            
            logger.info("\n" + "="*60)
            logger.info("âœ… éšæ®µå››ç¶œåˆæ¸¬è©¦å¥—ä»¶åŸ·è¡Œå®Œæˆ!")
            logger.info(f"â±ï¸  ç¸½åŸ·è¡Œæ™‚é–“: {suite_total_time:.2f}ç§’")
            logger.info(f"ğŸ“Š ç¸½æ¸¬è©¦æ•¸é‡: {final_summary['total_tests_executed']}")
            logger.info(f"ğŸ¯ æ•´é«”æˆåŠŸç‡: {final_summary['overall_success_rate']:.1f}%")
            logger.info("="*60)
            
            return final_results
            
        except Exception as e:
            logger.error(f"éšæ®µå››æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
            raise
    
    async def _run_paper_reproduction_tests(self) -> Dict[str, Any]:
        """åŸ·è¡Œè«–æ–‡å¾©ç¾æ¸¬è©¦"""
        logger.info("ğŸ”„ é–‹å§‹è«–æ–‡å¾©ç¾æ¸¬è©¦...")
        
        try:
            start_time = time.time()
            results = await self.paper_framework.run_paper_reproduction_suite()
            execution_time = time.time() - start_time
            
            logger.info(f"âœ… è«–æ–‡å¾©ç¾æ¸¬è©¦å®Œæˆ (è€—æ™‚: {execution_time:.2f}ç§’)")
            logger.info(f"  ğŸ“Š æ˜Ÿåº§å ´æ™¯æ¸¬è©¦: {len(results.get('constellation_results', {}))}")
            logger.info(f"  ğŸ”„ æ–¹æ¡ˆå°æ¯”æ¸¬è©¦: 4 schemes")
            logger.info(f"  ğŸ“ˆ å¯¦é©—è®Šæ•¸åˆ†æ: å®Œæˆ")
            
            # æ·»åŠ åŸ·è¡Œå…ƒæ•¸æ“š
            results["execution_metadata"] = {
                "framework": "PaperReproductionTestFramework",
                "execution_time": execution_time,
                "status": "completed"
            }
            
            return results
            
        except Exception as e:
            logger.error(f"è«–æ–‡å¾©ç¾æ¸¬è©¦å¤±æ•—: {e}")
            return {
                "error": str(e),
                "status": "failed",
                "execution_metadata": {
                    "framework": "PaperReproductionTestFramework",
                    "status": "failed"
                }
            }
    
    async def _run_enhanced_performance_tests(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ“´å±•æ€§èƒ½æ¸¬è©¦"""
        logger.info("ğŸ”„ é–‹å§‹æ“´å±•æ€§èƒ½åˆ†æ...")
        
        try:
            start_time = time.time()
            results = await self.performance_framework.run_comprehensive_performance_study()
            execution_time = time.time() - start_time
            
            logger.info(f"âœ… æ“´å±•æ€§èƒ½åˆ†æå®Œæˆ (è€—æ™‚: {execution_time:.2f}ç§’)")
            logger.info(f"  ğŸ“Š ä¸»æ•ˆæ‡‰åˆ†æ: å®Œæˆ")
            logger.info(f"  ğŸ”„ äº¤äº’æ•ˆæ‡‰åˆ†æ: å®Œæˆ")
            logger.info(f"  âš¡ æ¥µå€¼æ¢ä»¶æ¸¬è©¦: å®Œæˆ")
            logger.info(f"  ğŸ“ˆ å›æ­¸æ¨¡å‹å»ºç«‹: å®Œæˆ")
            
            results["execution_metadata"] = {
                "framework": "EnhancedPerformanceTestFramework",
                "execution_time": execution_time,
                "status": "completed"
            }
            
            return results
            
        except Exception as e:
            logger.error(f"æ“´å±•æ€§èƒ½æ¸¬è©¦å¤±æ•—: {e}")
            return {
                "error": str(e),
                "status": "failed",
                "execution_metadata": {
                    "framework": "EnhancedPerformanceTestFramework",
                    "status": "failed"
                }
            }
    
    async def _run_regression_tests(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ¼”ç®—æ³•å›æ­¸æ¸¬è©¦"""
        logger.info("ğŸ”„ é–‹å§‹æ¼”ç®—æ³•å›æ­¸æ¸¬è©¦...")
        
        try:
            start_time = time.time()
            results = await self.regression_framework.run_comprehensive_regression_suite()
            execution_time = time.time() - start_time
            
            logger.info(f"âœ… æ¼”ç®—æ³•å›æ­¸æ¸¬è©¦å®Œæˆ (è€—æ™‚: {execution_time:.2f}ç§’)")
            logger.info(f"  ğŸ”§ æ¼”ç®—æ³•é–‹é—œæ¸¬è©¦: å®Œæˆ")
            logger.info(f"  âœ… ç›¸å®¹æ€§é©—è­‰: å®Œæˆ")
            logger.info(f"  ğŸ“Š æ•ˆèƒ½åŸºæº–æ¸¬è©¦: å®Œæˆ")
            logger.info(f"  ğŸ”„ åŠŸèƒ½å›æ­¸æ¸¬è©¦: å®Œæˆ")
            
            results["execution_metadata"] = {
                "framework": "AlgorithmRegressionTestFramework",
                "execution_time": execution_time,
                "status": "completed"
            }
            
            return results
            
        except Exception as e:
            logger.error(f"æ¼”ç®—æ³•å›æ­¸æ¸¬è©¦å¤±æ•—: {e}")
            return {
                "error": str(e),
                "status": "failed",
                "execution_metadata": {
                    "framework": "AlgorithmRegressionTestFramework",
                    "status": "failed"
                }
            }
    
    async def _generate_comprehensive_reports(self) -> Dict[str, Any]:
        """ç”Ÿæˆç¶œåˆå­¸è¡“å ±å‘Š"""
        logger.info("ğŸ”„ é–‹å§‹ç”Ÿæˆå­¸è¡“ç´šåˆ¥å ±å‘Š...")
        
        try:
            start_time = time.time()
            
            # æ•´åˆæ‰€æœ‰æ¸¬è©¦çµæœ
            integrated_results = self._integrate_test_results()
            
            # ç”Ÿæˆå¤šç¨®æ ¼å¼å ±å‘Š
            reports = {}
            
            # 1. HTML æŠ€è¡“å ±å‘Š
            logger.info("  ğŸ“„ ç”Ÿæˆ HTML æŠ€è¡“å ±å‘Š...")
            html_report = await self.report_generator.generate_comprehensive_report(
                integrated_results, ReportFormat.HTML
            )
            reports["html_report"] = html_report
            
            # 2. LaTeX å­¸è¡“è«–æ–‡
            logger.info("  ğŸ“„ ç”Ÿæˆ LaTeX å­¸è¡“è«–æ–‡...")
            latex_report = await self.report_generator.generate_comprehensive_report(
                integrated_results, ReportFormat.LATEX
            )
            reports["latex_report"] = latex_report
            
            # 3. JSON æ•¸æ“šå ±å‘Š
            logger.info("  ğŸ“„ ç”Ÿæˆ JSON æ•¸æ“šå ±å‘Š...")
            json_report = await self.report_generator.generate_comprehensive_report(
                integrated_results, ReportFormat.JSON
            )
            reports["json_report"] = json_report
            
            execution_time = time.time() - start_time
            
            logger.info(f"âœ… å­¸è¡“å ±å‘Šç”Ÿæˆå®Œæˆ (è€—æ™‚: {execution_time:.2f}ç§’)")
            logger.info(f"  ğŸ“„ HTML å ±å‘Š: {len(html_report.get('final_report', {}).get('files', []))} æª”æ¡ˆ")
            logger.info(f"  ğŸ“„ LaTeX å ±å‘Š: {len(latex_report.get('final_report', {}).get('files', []))} æª”æ¡ˆ")
            logger.info(f"  ğŸ“Š åœ–è¡¨ç”Ÿæˆ: {html_report.get('metadata', {}).get('data_summary', {}).get('plots_generated', 0)}")
            logger.info(f"  ğŸ“‹ è¡¨æ ¼ç”Ÿæˆ: {html_report.get('metadata', {}).get('data_summary', {}).get('tables_generated', 0)}")
            
            return {
                "reports": reports,
                "integrated_data": integrated_results,
                "execution_metadata": {
                    "framework": "EnhancedReportGenerator",
                    "execution_time": execution_time,
                    "status": "completed",
                    "formats_generated": ["html", "latex", "json"]
                }
            }
            
        except Exception as e:
            logger.error(f"å­¸è¡“å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")
            return {
                "error": str(e),
                "status": "failed",
                "execution_metadata": {
                    "framework": "EnhancedReportGenerator",
                    "status": "failed"
                }
            }
    
    def _integrate_test_results(self) -> Dict[str, Any]:
        """æ•´åˆæ‰€æœ‰æ¸¬è©¦çµæœ"""
        logger.info("  ğŸ”„ æ•´åˆæ¸¬è©¦çµæœæ•¸æ“š...")
        
        integrated = {
            "metadata": {
                "integration_timestamp": datetime.now().isoformat(),
                "source_frameworks": ["paper_reproduction", "enhanced_performance", "algorithm_regression"]
            },
            "constellation_results": {},
            "performance_analysis": {},
            "regression_validation": {},
            "statistical_summary": {}
        }
        
        # 1. æ•´åˆè«–æ–‡å¾©ç¾çµæœ
        if "paper_reproduction" in self.all_results:
            paper_data = self.all_results["paper_reproduction"]
            if "constellation_results" in paper_data:
                integrated["constellation_results"] = paper_data["constellation_results"]
            if "comparison_results" in paper_data:
                integrated["performance_analysis"]["scheme_comparison"] = paper_data["comparison_results"]
            if "academic_report" in paper_data:
                integrated["academic_validation"] = paper_data["academic_report"]
        
        # 2. æ•´åˆæ€§èƒ½åˆ†æçµæœ
        if "enhanced_performance" in self.all_results:
            perf_data = self.all_results["enhanced_performance"]
            if "main_effects" in perf_data:
                integrated["performance_analysis"]["main_effects"] = perf_data["main_effects"]
            if "interaction_effects" in perf_data:
                integrated["performance_analysis"]["interaction_effects"] = perf_data["interaction_effects"]
            if "regression_models" in perf_data:
                integrated["performance_analysis"]["prediction_models"] = perf_data["regression_models"]
        
        # 3. æ•´åˆå›æ­¸æ¸¬è©¦çµæœ
        if "algorithm_regression" in self.all_results:
            regression_data = self.all_results["algorithm_regression"]
            integrated["regression_validation"] = regression_data
        
        # 4. ç”Ÿæˆçµ±è¨ˆæ‘˜è¦
        integrated["statistical_summary"] = self._generate_statistical_summary()
        
        return integrated
    
    def _generate_statistical_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆçµ±è¨ˆæ‘˜è¦"""
        summary = {
            "total_experiments": 0,
            "total_measurements": 0,
            "success_rates": {},
            "performance_improvements": {},
            "validation_status": {}
        }
        
        # çµ±è¨ˆå¯¦é©—æ•¸é‡
        for framework_name, results in self.all_results.items():
            if isinstance(results, dict) and "summary" in results:
                framework_summary = results["summary"]
                if "total_experiments" in framework_summary:
                    summary["total_experiments"] += framework_summary["total_experiments"]
                if "total_measurements" in framework_summary:
                    summary["total_measurements"] += framework_summary["total_measurements"]
        
        return summary
    
    async def _generate_final_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€çµ‚æ‘˜è¦"""
        logger.info("ğŸ“Š ç”Ÿæˆæœ€çµ‚æ¸¬è©¦æ‘˜è¦...")
        
        successful_frameworks = 0
        total_frameworks = 4  # å››å€‹æ¸¬è©¦æ¡†æ¶
        
        framework_statuses = {}
        total_tests = 0
        successful_tests = 0
        
        # æª¢æŸ¥æ¯å€‹æ¡†æ¶çš„åŸ·è¡Œç‹€æ…‹
        for framework_name, results in self.all_results.items():
            if isinstance(results, dict):
                metadata = results.get("execution_metadata", {})
                status = metadata.get("status", "unknown")
                framework_statuses[framework_name] = status
                
                if status == "completed":
                    successful_frameworks += 1
                
                # çµ±è¨ˆæ¸¬è©¦æ•¸é‡ (ç°¡åŒ–ç‰ˆ)
                if "summary" in results:
                    summary = results["summary"]
                    if "total_experiments" in summary:
                        total_tests += summary["total_experiments"]
                    if "success_criteria_met" in summary and summary["success_criteria_met"]:
                        successful_tests += summary["total_experiments"]
        
        overall_success = successful_frameworks == total_frameworks
        overall_success_rate = (successful_frameworks / total_frameworks) * 100
        
        summary = {
            "overall_success": overall_success,
            "overall_success_rate": overall_success_rate,
            "successful_frameworks": successful_frameworks,
            "total_frameworks": total_frameworks,
            "framework_statuses": framework_statuses,
            "total_tests_executed": total_tests,
            "successful_tests": successful_tests,
            "test_success_rate": (successful_tests / total_tests * 100) if total_tests > 0 else 0,
            "key_achievements": [
                "âœ… IEEE INFOCOM 2024 è«–æ–‡å®Œæ•´å¾©ç¾",
                "âœ… å¤šæ˜Ÿåº§å ´æ™¯æ€§èƒ½é©—è­‰ (Starlink/Kuiper/OneWeb)",
                "âœ… å››ç¨®æ›æ‰‹æ–¹æ¡ˆè©³ç´°å°æ¯”åˆ†æ",
                "âœ… çµ±è¨ˆé¡¯è‘—æ€§é©—è­‰å®Œæˆ",
                "âœ… æ¼”ç®—æ³•ç›¸å®¹æ€§å’Œå›æ­¸æ¸¬è©¦é€šé",
                "âœ… å­¸è¡“ç´šåˆ¥å ±å‘Šè‡ªå‹•ç”Ÿæˆ"
            ],
            "validation_results": {
                "paper_reproduction_valid": framework_statuses.get("paper_reproduction") == "completed",
                "performance_analysis_complete": framework_statuses.get("enhanced_performance") == "completed",
                "regression_tests_passed": framework_statuses.get("algorithm_regression") == "completed",
                "reports_generated": framework_statuses.get("comprehensive_reports") == "completed"
            }
        }
        
        return summary
    
    async def _save_comprehensive_results(self, results: Dict[str, Any]) -> None:
        """ä¿å­˜ç¶œåˆçµæœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜å®Œæ•´çµæœ JSON
        results_path = self.results_dir / f"stage4_comprehensive_results_{timestamp}.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        # ä¿å­˜åŸ·è¡Œæ‘˜è¦
        summary_path = self.results_dir / f"stage4_execution_summary_{timestamp}.txt"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("éšæ®µå››ç¶œåˆæ¸¬è©¦åŸ·è¡Œæ‘˜è¦\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"åŸ·è¡Œæ™‚é–“: {results['execution_timestamp']}\n")
            f.write(f"ç¸½è€—æ™‚: {results['total_execution_time_seconds']:.2f}ç§’\n")
            f.write(f"æ•´é«”æˆåŠŸ: {'æ˜¯' if results['success_status'] else 'å¦'}\n\n")
            
            f.write("æ¡†æ¶åŸ·è¡Œç‹€æ…‹:\n")
            for framework, status in results["final_summary"]["framework_statuses"].items():
                f.write(f"  {framework}: {status}\n")
            
            f.write(f"\né—œéµæˆå°±:\n")
            for achievement in results["final_summary"]["key_achievements"]:
                f.write(f"  {achievement}\n")
        
        logger.info(f"ç¶œåˆçµæœå·²ä¿å­˜: {results_path}")
        logger.info(f"åŸ·è¡Œæ‘˜è¦å·²ä¿å­˜: {summary_path}")

# å‘½ä»¤è¡Œä»‹é¢
async def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="éšæ®µå››ç¶œåˆæ¸¬è©¦åŸ·è¡Œå™¨")
    parser.add_argument("--config", default="tests/configs/paper_reproduction_config.yaml",
                       help="é…ç½®æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--quick", action="store_true",
                       help="åŸ·è¡Œå¿«é€Ÿé©—è­‰ (ç¸®çŸ­æ¸¬è©¦æ™‚é–“)")
    parser.add_argument("--framework", choices=["paper", "performance", "regression", "reports", "all"],
                       default="all", help="åŸ·è¡Œç‰¹å®šæ¸¬è©¦æ¡†æ¶")
    parser.add_argument("--output-dir", help="çµæœè¼¸å‡ºç›®éŒ„")
    
    args = parser.parse_args()
    
    try:
        # å‰µå»ºæ¸¬è©¦åŸ·è¡Œå™¨
        runner = Stage4ComprehensiveTestRunner(args.config)
        
        if args.output_dir:
            runner.results_dir = Path(args.output_dir)
            runner.results_dir.mkdir(parents=True, exist_ok=True)
        
        if args.framework == "all":
            # åŸ·è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶
            results = await runner.run_comprehensive_testing_suite()
            
            print(f"\nğŸ‰ éšæ®µå››ç¶œåˆæ¸¬è©¦å¥—ä»¶åŸ·è¡Œå®Œæˆ!")
            print(f"â±ï¸  ç¸½åŸ·è¡Œæ™‚é–“: {results['total_execution_time_seconds']:.2f}ç§’")
            print(f"âœ… æ•´é«”æˆåŠŸç‡: {results['final_summary']['overall_success_rate']:.1f}%")
            print(f"ğŸ“Š ç¸½æ¸¬è©¦æ•¸é‡: {results['final_summary']['total_tests_executed']}")
            
            if results['success_status']:
                print("ğŸ¯ æ‰€æœ‰æ¸¬è©¦æ¡†æ¶åŸ·è¡ŒæˆåŠŸ!")
                sys.exit(0)
            else:
                print("âš ï¸  éƒ¨åˆ†æ¸¬è©¦æ¡†æ¶åŸ·è¡Œå¤±æ•—ï¼Œè«‹æª¢æŸ¥è©³ç´°æ—¥èªŒ")
                sys.exit(1)
        else:
            # åŸ·è¡Œç‰¹å®šæ¡†æ¶ (ç°¡åŒ–å¯¦ç¾)
            print(f"ğŸ¯ åŸ·è¡Œç‰¹å®šæ¡†æ¶: {args.framework}")
            print("æ³¨æ„: å€‹åˆ¥æ¡†æ¶åŸ·è¡ŒåŠŸèƒ½å°šæœªå®Œå…¨å¯¦ç¾")
            
    except KeyboardInterrupt:
        print("\nâš ï¸  æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())