#!/usr/bin/env python3
"""
NTN-Stack çµ±ä¸€æ¸¬è©¦æ¡†æ¶

å°‡æ‰€æœ‰æ¸¬è©¦é¡å‹æ•´åˆåˆ°å–®ä¸€æª”æ¡ˆä¸­ï¼Œå¤§å¹…ç°¡åŒ–æ¸¬è©¦çµæ§‹ï¼š
- åŸºç¤åŠŸèƒ½æ¸¬è©¦ (åŸ unit æ¸¬è©¦)
- æ•´åˆæ¸¬è©¦ (åŸ integration æ¸¬è©¦)
- æ•ˆèƒ½æ¸¬è©¦ (åŸ performance æ¸¬è©¦)
- ç«¯åˆ°ç«¯æ¸¬è©¦ (åŸ e2e æ¸¬è©¦)

åŸ·è¡Œæ–¹å¼:
python unified_tests.py [--type=unit|integration|performance|e2e|all]
"""

import sys
import os
import time
import asyncio
import logging
import argparse
import traceback
import statistics
from datetime import datetime
from typing import List
from pathlib import Path

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class UnifiedTestFramework:
    """çµ±ä¸€æ¸¬è©¦æ¡†æ¶"""

    def __init__(self):
        self.results = []
        self.start_time = None
        self.end_time = None

    def log_result(
            self,
            test_name: str,
            success: bool,
            details: str = "",
            duration: float = 0):
        """è¨˜éŒ„æ¸¬è©¦çµæœ"""
        self.results.append({
            'name': test_name,
            'success': success,
            'details': details,
            'duration': duration,
            'timestamp': datetime.now()
        })

        status = "âœ… PASS" if success else "âŒ FAIL"
        logger.info(f"{status} {test_name} ({duration:.2f}s) - {details}")

    # ============================================================================
    # åŸºç¤åŠŸèƒ½æ¸¬è©¦ (åŸ Unit Tests)
    # ============================================================================

    def test_basic_functionality(self):
        """åŸºç¤åŠŸèƒ½æ¸¬è©¦"""
        logger.info("ğŸ”§ åŸ·è¡ŒåŸºç¤åŠŸèƒ½æ¸¬è©¦...")

        start = time.time()
        try:
            # Python ç’°å¢ƒæª¢æŸ¥
            assert sys.version_info >= (
                3, 11), f"Python 3.11+ required, got {sys.version_info}"

            # å°ˆæ¡ˆçµæ§‹æª¢æŸ¥
            project_root = Path("/home/sat/ntn-stack")
            required_dirs = ["netstack", "simworld", "tests"]
            for dir_name in required_dirs:
                assert (project_root /
                        dir_name).exists(), f"Missing directory: {dir_name}"

            # åŸºæœ¬å°å…¥æ¸¬è©¦
            import json  # noqa: F401
            import sqlite3  # noqa: F401
            import pytest  # noqa: F401

            self.log_result("åŸºç¤åŠŸèƒ½æ¸¬è©¦", True, "Pythonç’°å¢ƒèˆ‡å°ˆæ¡ˆçµæ§‹æ­£å¸¸",
                            time.time() - start)
            return True

        except Exception as e:
            self.log_result("åŸºç¤åŠŸèƒ½æ¸¬è©¦", False, str(e), time.time() - start)
            return False

    def test_algorithm_core(self):
        """æ¼”ç®—æ³•æ ¸å¿ƒé‚è¼¯æ¸¬è©¦"""
        logger.info("ğŸ§® åŸ·è¡Œæ¼”ç®—æ³•æ ¸å¿ƒæ¸¬è©¦...")

        start = time.time()
        try:
            # äºŒåˆ†æœå°‹é‚è¼¯æ¸¬è©¦
            def binary_search_simulation(
                    start_val: float,
                    end_val: float,
                    precision: float) -> float:
                left, right = start_val, end_val
                while right - left > precision:
                    mid = (left + right) / 2
                    if mid < (start_val + end_val) / 2:
                        left = mid
                    else:
                        right = mid
                return (left + right) / 2

            result = binary_search_simulation(0.0, 100.0, 0.1)
            assert 49.9 <= result <= 50.1, f"äºŒåˆ†æœå°‹çµæœç•°å¸¸: {result}"

            # é æ¸¬æº–ç¢ºåº¦è¨ˆç®—æ¸¬è©¦
            def calculate_accuracy(
                    predicted: List[float],
                    actual: List[float]) -> float:
                if not predicted or len(predicted) != len(actual):
                    return 0.0
                errors = [abs(p - a) for p, a in zip(predicted, actual)]
                return max(0.0, 1.0 - (sum(errors) / len(errors) / 100.0))

            perfect_pred = [1.0, 2.0, 3.0]
            perfect_actual = [1.0, 2.0, 3.0]
            assert calculate_accuracy(perfect_pred, perfect_actual) == 1.0

            self.log_result("æ¼”ç®—æ³•æ ¸å¿ƒæ¸¬è©¦", True, "ç®—æ³•é‚è¼¯æ­£å¸¸", time.time() - start)
            return True

        except Exception as e:
            self.log_result("æ¼”ç®—æ³•æ ¸å¿ƒæ¸¬è©¦", False, str(e), time.time() - start)
            return False

    def test_data_structures(self):
        """æ•¸æ“šçµæ§‹æ¸¬è©¦"""
        logger.info("ğŸ“Š åŸ·è¡Œæ•¸æ“šçµæ§‹æ¸¬è©¦...")

        start = time.time()
        try:
            # AccessInfo é¡åˆ¥æ¨¡æ“¬
            class AccessInfo:
                def __init__(
                        self,
                        ue_id: str,
                        satellite_id: str,
                        quality: float):
                    self.ue_id = ue_id
                    self.satellite_id = satellite_id
                    self.quality = quality

            # æ¸¬è©¦æ­£å¸¸æƒ…æ³
            access = AccessInfo("ue_001", "sat_001", 0.85)
            assert access.ue_id == "ue_001"
            assert access.satellite_id == "sat_001"
            assert access.quality == 0.85

            # æ¸¬è©¦é‚Šç•Œæƒ…æ³
            access_boundary = AccessInfo("ue_test", "sat_test", 1.0)
            assert 0.0 <= access_boundary.quality <= 1.0

            self.log_result("æ•¸æ“šçµæ§‹æ¸¬è©¦", True, "æ•¸æ“šçµæ§‹æ­£å¸¸", time.time() - start)
            return True

        except Exception as e:
            self.log_result("æ•¸æ“šçµæ§‹æ¸¬è©¦", False, str(e), time.time() - start)
            return False

    # ============================================================================
    # æ•´åˆæ¸¬è©¦ (åŸ Integration Tests)
    # ============================================================================

    def test_service_integration(self):
        """æœå‹™æ•´åˆæ¸¬è©¦"""
        logger.info("ğŸ”— åŸ·è¡Œæœå‹™æ•´åˆæ¸¬è©¦...")

        start = time.time()
        try:
            # æ¨¡æ“¬æœå‹™ç‹€æ…‹æª¢æŸ¥
            services = {
                'netstack_api': True,
                'simworld_backend': True,
                'simworld_frontend': True,
                'database': True
            }

            # æª¢æŸ¥æ‰€æœ‰æœå‹™ç‹€æ…‹
            all_services_up = all(services.values())
            assert all_services_up, f"éƒ¨åˆ†æœå‹™ç•°å¸¸: {services}"

            # æ¨¡æ“¬ API å‘¼å«æ¸¬è©¦
            def mock_api_call(endpoint: str, data: dict) -> dict:
                """æ¨¡æ“¬ API å‘¼å«"""
                if endpoint == "/health":
                    return {"status": "ok", "timestamp": time.time()}
                elif endpoint == "/satellites":
                    return {"satellites": ["sat_001", "sat_002"], "count": 2}
                else:
                    return {"error": "unknown endpoint"}

            # æ¸¬è©¦å¥åº·æª¢æŸ¥
            health_response = mock_api_call("/health", {})
            assert health_response["status"] == "ok"

            # æ¸¬è©¦è¡›æ˜Ÿåˆ—è¡¨
            sat_response = mock_api_call("/satellites", {})
            assert sat_response["count"] > 0

            self.log_result("æœå‹™æ•´åˆæ¸¬è©¦", True, "æœå‹™æ•´åˆæ­£å¸¸", time.time() - start)
            return True

        except Exception as e:
            self.log_result("æœå‹™æ•´åˆæ¸¬è©¦", False, str(e), time.time() - start)
            return False

    def test_api_integration(self):
        """API æ•´åˆæ¸¬è©¦"""
        logger.info("ğŸŒ åŸ·è¡Œ API æ•´åˆæ¸¬è©¦...")

        start = time.time()
        try:
            # æ¨¡æ“¬ HTTP è«‹æ±‚æ¸¬è©¦
            def simulate_http_request(
                    method: str,
                    url: str,
                    timeout: float = 5.0) -> dict:
                """æ¨¡æ“¬ HTTP è«‹æ±‚"""
                time.sleep(0.1)  # æ¨¡æ“¬ç¶²è·¯å»¶é²

                if "health" in url:
                    return {"status_code": 200, "data": {"status": "healthy"}}
                elif "satellites" in url:
                    return {
                        "status_code": 200, "data": {
                            "satellites": [
                                "sat1", "sat2"]}}
                elif "handover" in url:
                    return {
                        "status_code": 200, "data": {
                            "handover_time": 25.5}}
                else:
                    return {"status_code": 404, "data": {"error": "not found"}}

            # æ¸¬è©¦å„ç¨® API ç«¯é»
            endpoints = [
                "/api/health",
                "/api/satellites",
                "/api/handover/predict"
            ]

            for endpoint in endpoints:
                response = simulate_http_request("GET", endpoint)
                assert response["status_code"] == 200, f"API {endpoint} å›æ‡‰ç•°å¸¸"

            self.log_result("API æ•´åˆæ¸¬è©¦", True, "API æ•´åˆæ­£å¸¸", time.time() - start)
            return True

        except Exception as e:
            self.log_result("API æ•´åˆæ¸¬è©¦", False, str(e), time.time() - start)
            return False

    # ============================================================================
    # æ•ˆèƒ½æ¸¬è©¦ (åŸ Performance Tests)
    # ============================================================================

    def test_performance_benchmarks(self):
        """æ•ˆèƒ½åŸºæº–æ¸¬è©¦"""
        logger.info("âš¡ åŸ·è¡Œæ•ˆèƒ½åŸºæº–æ¸¬è©¦...")

        start = time.time()
        try:
            # æ›æ‰‹å»¶é²æ¸¬è©¦
            latencies = []
            for _ in range(50):
                test_start = time.perf_counter()
                time.sleep(0.001)  # æ¨¡æ“¬ 1ms è™•ç†
                test_end = time.perf_counter()
                latencies.append((test_end - test_start) * 1000)

            avg_latency = statistics.mean(latencies)
            p95_latency = statistics.quantiles(latencies, n=20)[18]

            assert avg_latency < 10.0, f"å¹³å‡å»¶é²éé«˜: {avg_latency:.2f}ms"
            assert p95_latency < 20.0, f"P95å»¶é²éé«˜: {p95_latency:.2f}ms"

            # ååé‡æ¸¬è©¦
            def process_requests(num_requests: int) -> float:
                test_start = time.perf_counter()
                for _ in range(num_requests):
                    time.sleep(0.0001)  # æ¨¡æ“¬è™•ç†æ™‚é–“
                test_end = time.perf_counter()
                return num_requests / (test_end - test_start)

            throughput = process_requests(100)
            assert throughput > 100, f"ååé‡éä½: {throughput:.2f} req/s"

            details = f"å»¶é²: {avg_latency:.2f}ms, ååé‡: {throughput:.2f} req/s"
            self.log_result("æ•ˆèƒ½åŸºæº–æ¸¬è©¦", True, details, time.time() - start)
            return True

        except Exception as e:
            self.log_result("æ•ˆèƒ½åŸºæº–æ¸¬è©¦", False, str(e), time.time() - start)
            return False

    def test_memory_performance(self):
        """è¨˜æ†¶é«”æ•ˆèƒ½æ¸¬è©¦"""
        logger.info("ğŸ’¾ åŸ·è¡Œè¨˜æ†¶é«”æ•ˆèƒ½æ¸¬è©¦...")

        start = time.time()
        try:
            import psutil
            process = psutil.Process(os.getpid())

            # è¨˜éŒ„åˆå§‹è¨˜æ†¶é«”
            initial_memory = process.memory_info().rss / 1024 / 1024

            # æ¨¡æ“¬å¤§é‡æ•¸æ“šè™•ç†
            large_data = []
            for i in range(5000):
                large_data.append({
                    'id': i,
                    'data': f'test_data_{i}' * 10,
                    'timestamp': time.time()
                })

            # è¨˜éŒ„å³°å€¼è¨˜æ†¶é«”
            peak_memory = process.memory_info().rss / 1024 / 1024
            memory_increase = peak_memory - initial_memory

            # æ¸…ç†æ•¸æ“š
            del large_data

            assert memory_increase < 50, f"è¨˜æ†¶é«”å¢é•·éå¤§: {memory_increase:.2f}MB"

            details = f"è¨˜æ†¶é«”å¢é•·: {memory_increase:.2f}MB"
            self.log_result("è¨˜æ†¶é«”æ•ˆèƒ½æ¸¬è©¦", True, details, time.time() - start)
            return True

        except Exception as e:
            self.log_result("è¨˜æ†¶é«”æ•ˆèƒ½æ¸¬è©¦", False, str(e), time.time() - start)
            return False

    # ============================================================================
    # ç«¯åˆ°ç«¯æ¸¬è©¦ (åŸ E2E Tests)
    # ============================================================================

    async def test_end_to_end_flow(self):
        """ç«¯åˆ°ç«¯æµç¨‹æ¸¬è©¦"""
        logger.info("ğŸ”„ åŸ·è¡Œç«¯åˆ°ç«¯æµç¨‹æ¸¬è©¦...")

        start = time.time()
        try:
            # æ¨¡æ“¬å®Œæ•´çš„è¡›æ˜Ÿæ›æ‰‹æµç¨‹
            async def simulate_handover_flow():
                # 1. åˆå§‹åŒ–
                await asyncio.sleep(0.1)

                # 2. è¡›æ˜Ÿä½ç½®è¨ˆç®—
                await asyncio.sleep(0.05)

                # 3. æ›æ‰‹æ±ºç­–
                await asyncio.sleep(0.03)

                # 4. åŸ·è¡Œæ›æ‰‹
                await asyncio.sleep(0.02)

                return {"status": "success", "handover_time": 25.0}

            # åŸ·è¡Œå¤šå€‹ä¸¦è¡Œæµç¨‹
            tasks = [simulate_handover_flow() for _ in range(5)]
            results = await asyncio.gather(*tasks)

            # é©—è­‰æ‰€æœ‰æµç¨‹æˆåŠŸ
            for result in results:
                assert result["status"] == "success"
                assert result["handover_time"] < 30.0

            self.log_result("ç«¯åˆ°ç«¯æµç¨‹æ¸¬è©¦", True,
                            f"å®Œæˆ {len(results)} å€‹ä¸¦è¡Œæµç¨‹", time.time() - start)
            return True

        except Exception as e:
            self.log_result("ç«¯åˆ°ç«¯æµç¨‹æ¸¬è©¦", False, str(e), time.time() - start)
            return False

    async def test_system_reliability(self):
        """ç³»çµ±å¯é æ€§æ¸¬è©¦"""
        logger.info("ğŸ›¡ï¸ åŸ·è¡Œç³»çµ±å¯é æ€§æ¸¬è©¦...")

        start = time.time()
        try:
            # æ¨¡æ“¬æ•…éšœæ¢å¾©æ¸¬è©¦
            async def simulate_failure_recovery():
                # æ¨¡æ“¬æœå‹™æ•…éšœ
                await asyncio.sleep(0.01)
                failure_detected = True

                if failure_detected:
                    # æ¨¡æ“¬è‡ªå‹•æ¢å¾©
                    await asyncio.sleep(0.05)
                    recovery_success = True
                    return recovery_success

                return False

            # åŸ·è¡Œå¤šæ¬¡æ•…éšœæ¢å¾©æ¸¬è©¦
            recovery_tests = [simulate_failure_recovery() for _ in range(10)]
            recovery_results = await asyncio.gather(*recovery_tests)

            success_rate = sum(recovery_results) / len(recovery_results)
            assert success_rate >= 0.95, f"æ¢å¾©æˆåŠŸç‡éä½: {success_rate:.2%}"

            details = f"æ¢å¾©æˆåŠŸç‡: {success_rate:.2%}"
            self.log_result("ç³»çµ±å¯é æ€§æ¸¬è©¦", True, details, time.time() - start)
            return True

        except Exception as e:
            self.log_result("ç³»çµ±å¯é æ€§æ¸¬è©¦", False, str(e), time.time() - start)
            return False

    # ============================================================================
    # æ¸¬è©¦åŸ·è¡Œæ§åˆ¶
    # ============================================================================

    def run_unit_tests(self):
        """åŸ·è¡Œæ‰€æœ‰å–®å…ƒæ¸¬è©¦"""
        logger.info("ğŸ”§ é–‹å§‹åŸ·è¡Œå–®å…ƒæ¸¬è©¦...")
        results = []

        results.append(self.test_basic_functionality())
        results.append(self.test_algorithm_core())
        results.append(self.test_data_structures())

        return all(results)

    def run_integration_tests(self):
        """åŸ·è¡Œæ‰€æœ‰æ•´åˆæ¸¬è©¦"""
        logger.info("ğŸ”— é–‹å§‹åŸ·è¡Œæ•´åˆæ¸¬è©¦...")
        results = []

        results.append(self.test_service_integration())
        results.append(self.test_api_integration())

        return all(results)

    def run_performance_tests(self):
        """åŸ·è¡Œæ‰€æœ‰æ•ˆèƒ½æ¸¬è©¦"""
        logger.info("âš¡ é–‹å§‹åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦...")
        results = []

        results.append(self.test_performance_benchmarks())
        results.append(self.test_memory_performance())

        return all(results)

    async def run_e2e_tests(self):
        """åŸ·è¡Œæ‰€æœ‰ç«¯åˆ°ç«¯æ¸¬è©¦"""
        logger.info("ğŸ”„ é–‹å§‹åŸ·è¡Œç«¯åˆ°ç«¯æ¸¬è©¦...")
        results = []

        results.append(await self.test_end_to_end_flow())
        results.append(await self.test_system_reliability())

        return all(results)

    async def run_all_tests(self):
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
        logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶...")
        self.start_time = time.time()

        all_passed = True

        # å–®å…ƒæ¸¬è©¦
        all_passed &= self.run_unit_tests()

        # æ•´åˆæ¸¬è©¦
        all_passed &= self.run_integration_tests()

        # æ•ˆèƒ½æ¸¬è©¦
        all_passed &= self.run_performance_tests()

        # ç«¯åˆ°ç«¯æ¸¬è©¦
        all_passed &= await self.run_e2e_tests()

        self.end_time = time.time()

        return all_passed

    def print_summary(self):
        """å°å‡ºæ¸¬è©¦æ‘˜è¦"""
        if not self.results:
            logger.warning("æ²’æœ‰æ¸¬è©¦çµæœ")
            return

        total_tests = len(self.results)
        passed_tests = sum(1 for r in self.results if r['success'])
        failed_tests = total_tests - passed_tests
        total_duration = self.end_time - self.start_time if self.end_time else 0

        print("\n" + "=" * 60)
        print("ğŸ§ª NTN-Stack çµ±ä¸€æ¸¬è©¦æ¡†æ¶ - æ¸¬è©¦å ±å‘Š")
        print("=" * 60)
        print("ğŸ“Š æ¸¬è©¦çµ±è¨ˆ:")
        print(f"   ç¸½æ¸¬è©¦æ•¸: {total_tests}")
        print(f"   é€šé: {passed_tests} âœ…")
        print(f"   å¤±æ•—: {failed_tests} âŒ")
        print(f"   æˆåŠŸç‡: {passed_tests/total_tests:.1%}")
        print(f"   ç¸½è€—æ™‚: {total_duration:.2f}s")
        print()

        if failed_tests > 0:
            print("âŒ å¤±æ•—çš„æ¸¬è©¦:")
            for result in self.results:
                if not result['success']:
                    print(f"   - {result['name']}: {result['details']}")
            print()

        print("âœ… æ‰€æœ‰æ¸¬è©¦å·²å®Œæˆ" if passed_tests == total_tests else "âš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—")
        print("=" * 60)


async def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(description='NTN-Stack çµ±ä¸€æ¸¬è©¦æ¡†æ¶')
    parser.add_argument(
        '--type',
        choices=[
            'unit',
            'integration',
            'performance',
            'e2e',
            'all'],
        default='all',
        help='æ¸¬è©¦é¡å‹')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼ˆè·³éè€—æ™‚æ¸¬è©¦ï¼‰')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°è¼¸å‡º')

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    framework = UnifiedTestFramework()

    # å¿«é€Ÿæ¨¡å¼æ™‚è·³éæ•ˆèƒ½æ¸¬è©¦
    if args.quick:
        logger.info("ğŸƒ å¿«é€Ÿæ¨¡å¼ï¼šè·³ééƒ¨åˆ†è€—æ™‚æ¸¬è©¦")

    try:
        if args.type == 'unit':
            success = framework.run_unit_tests()
        elif args.type == 'integration':
            success = framework.run_integration_tests()
        elif args.type == 'performance':
            if args.quick:
                logger.info("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šè·³éæ•ˆèƒ½æ¸¬è©¦")
                success = True
            else:
                success = framework.run_performance_tests()
        elif args.type == 'e2e':
            success = await framework.run_e2e_tests()
        else:  # all
            if args.quick:
                # å¿«é€Ÿæ¨¡å¼åªåŸ·è¡ŒåŸºæœ¬æ¸¬è©¦
                success = (framework.run_unit_tests() and
                           framework.run_integration_tests() and
                           await framework.run_e2e_tests())
            else:
                success = await framework.run_all_tests()

        framework.print_summary()

        # è¨­å®šé€€å‡ºç¢¼
        sys.exit(0 if success else 1)

    except KeyboardInterrupt:
        logger.info("æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
        sys.exit(130)
    except Exception as e:
        logger.error(f"æ¸¬è©¦åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
