#!/usr/bin/env python3
"""
Phase 3 å®Œæˆåº¦æ¸¬è©¦ - ç ”ç©¶æ•¸æ“šèˆ‡ RL æ•´åˆ
"""

import sys
import asyncio
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ è·¯å¾‘
sys.path.append('netstack/src')
sys.path.append('netstack')

async def test_phase3_completion():
    """æ¸¬è©¦ Phase 3 å®Œæˆåº¦"""
    print("ğŸ”¬ Phase 3 å®Œæˆåº¦æ¸¬è©¦ - ç ”ç©¶æ•¸æ“šèˆ‡ RL æ•´åˆ")
    print("=" * 60)
    
    results = {
        "phase3_features": {},
        "research_components": {},
        "integration_status": {},
        "overall_score": 0
    }
    
    # æ¸¬è©¦ 1: 45å¤©æ­·å²æ•¸æ“šæ”¶é›†è‡ªå‹•åŒ–
    print("\nğŸ“¡ 1. 45å¤©æ­·å²æ•¸æ“šæ”¶é›†è‡ªå‹•åŒ–")
    
    try:
        # æª¢æŸ¥ DailyTLECollector
        collector_path = Path("netstack/scripts/daily_tle_collector.py")
        if collector_path.exists():
            print("âœ… daily_tle_collector.py å­˜åœ¨")
            results["research_components"]["daily_tle_collector"] = True
            
            # æª¢æŸ¥åŠŸèƒ½å®Œæ•´æ€§
            with open(collector_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            required_methods = [
                "collect_daily_data",
                "validate_45day_completeness",
                "get_existing_data_status",
                "download_tle_data",
                "validate_tle_format"
            ]
            
            methods_found = 0
            for method in required_methods:
                if f"def {method}" in content:
                    methods_found += 1
                    print(f"  âœ… {method} æ–¹æ³•å­˜åœ¨")
                else:
                    print(f"  âŒ {method} æ–¹æ³•ç¼ºå¤±")
            
            results["phase3_features"]["tle_collection_automation"] = methods_found == len(required_methods)
            
        else:
            print("âŒ daily_tle_collector.py ä¸å­˜åœ¨")
            results["research_components"]["daily_tle_collector"] = False
            results["phase3_features"]["tle_collection_automation"] = False
            
    except Exception as e:
        print(f"âŒ TLE æ”¶é›†å™¨æ¸¬è©¦å¤±æ•—: {e}")
        results["research_components"]["daily_tle_collector"] = False
        results["phase3_features"]["tle_collection_automation"] = False
    
    # æ¸¬è©¦ 2: RL è¨“ç·´æ•¸æ“šé›†ç”Ÿæˆ
    print("\nğŸ¤– 2. RL è¨“ç·´æ•¸æ“šé›†ç”Ÿæˆ")
    
    try:
        # æª¢æŸ¥ RLDatasetGenerator
        rl_generator_path = Path("netstack/src/services/rl/rl_dataset_generator.py")
        if rl_generator_path.exists():
            print("âœ… rl_dataset_generator.py å­˜åœ¨")
            results["research_components"]["rl_dataset_generator"] = True
            
            # æª¢æŸ¥åŠŸèƒ½å®Œæ•´æ€§
            with open(rl_generator_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            required_methods = [
                "generate_handover_episodes",
                "export_ml_format",
                "build_state_vector",
                "calculate_reward",
                "export_pytorch_format",
                "export_csv_format"
            ]
            
            methods_found = 0
            for method in required_methods:
                if f"def {method}" in content:
                    methods_found += 1
                    print(f"  âœ… {method} æ–¹æ³•å­˜åœ¨")
                else:
                    print(f"  âŒ {method} æ–¹æ³•ç¼ºå¤±")
            
            results["phase3_features"]["rl_dataset_generation"] = methods_found == len(required_methods)
            
            # æª¢æŸ¥ ML æ¡†æ¶æ”¯æ´
            ml_formats = ["pytorch", "tensorflow", "csv", "json"]
            ml_support = []
            for fmt in ml_formats:
                if f"export_{fmt}_format" in content or f'format_type == "{fmt}"' in content:
                    ml_support.append(fmt)
                    print(f"  âœ… {fmt.upper()} æ ¼å¼æ”¯æ´")
            
            results["phase3_features"]["ml_framework_support"] = len(ml_support) >= 2
            
        else:
            print("âŒ rl_dataset_generator.py ä¸å­˜åœ¨")
            results["research_components"]["rl_dataset_generator"] = False
            results["phase3_features"]["rl_dataset_generation"] = False
            results["phase3_features"]["ml_framework_support"] = False
            
    except Exception as e:
        print(f"âŒ RL æ•¸æ“šé›†ç”Ÿæˆå™¨æ¸¬è©¦å¤±æ•—: {e}")
        results["research_components"]["rl_dataset_generator"] = False
        results["phase3_features"]["rl_dataset_generation"] = False
        results["phase3_features"]["ml_framework_support"] = False
    
    # æ¸¬è©¦ 3: 3GPP NTN æ¨™æº–äº‹ä»¶ç”Ÿæˆå™¨
    print("\nğŸ“‹ 3. 3GPP NTN æ¨™æº–äº‹ä»¶ç”Ÿæˆå™¨")
    
    try:
        # æª¢æŸ¥ ThreeGPPEventGenerator
        threegpp_path = Path("netstack/src/services/research/threegpp_event_generator.py")
        if threegpp_path.exists():
            print("âœ… threegpp_event_generator.py å­˜åœ¨")
            results["research_components"]["threegpp_event_generator"] = True
            
            # æª¢æŸ¥åŠŸèƒ½å®Œæ•´æ€§
            with open(threegpp_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æª¢æŸ¥ 3GPP äº‹ä»¶é¡å‹
            event_types = ["A1", "A2", "A3", "A4", "A5", "A6"]
            events_found = 0
            for event_type in event_types:
                if f"check_{event_type.lower()}_event" in content:
                    events_found += 1
                    print(f"  âœ… {event_type} äº‹ä»¶æ”¯æ´")
                else:
                    print(f"  âŒ {event_type} äº‹ä»¶ç¼ºå¤±")
            
            results["phase3_features"]["threegpp_events"] = events_found == len(event_types)
            
            # æª¢æŸ¥å­¸è¡“ç ”ç©¶åŠŸèƒ½
            academic_features = [
                "generate_academic_report",
                "analyze_signal_quality",
                "analyze_ntn_characteristics",
                "generate_academic_insights"
            ]
            
            academic_found = 0
            for feature in academic_features:
                if f"def {feature}" in content:
                    academic_found += 1
                    print(f"  âœ… {feature} åŠŸèƒ½å­˜åœ¨")
                else:
                    print(f"  âŒ {feature} åŠŸèƒ½ç¼ºå¤±")
            
            results["phase3_features"]["academic_research_support"] = academic_found == len(academic_features)
            
        else:
            print("âŒ threegpp_event_generator.py ä¸å­˜åœ¨")
            results["research_components"]["threegpp_event_generator"] = False
            results["phase3_features"]["threegpp_events"] = False
            results["phase3_features"]["academic_research_support"] = False
            
    except Exception as e:
        print(f"âŒ 3GPP äº‹ä»¶ç”Ÿæˆå™¨æ¸¬è©¦å¤±æ•—: {e}")
        results["research_components"]["threegpp_event_generator"] = False
        results["phase3_features"]["threegpp_events"] = False
        results["phase3_features"]["academic_research_support"] = False
    
    # æ¸¬è©¦ 4: åŠŸèƒ½æ•´åˆæ¸¬è©¦
    print("\nğŸ”— 4. åŠŸèƒ½æ•´åˆæ¸¬è©¦")
    
    try:
        # æ¸¬è©¦ TLE æ”¶é›†å™¨
        if results["research_components"]["daily_tle_collector"]:
            print("  ğŸ§ª æ¸¬è©¦ TLE æ”¶é›†å™¨å°å…¥")
            try:
                from netstack.scripts.daily_tle_collector import DailyTLECollector
                collector = DailyTLECollector(target_days=5)  # æ¸¬è©¦ç”¨å°æ•¸æ“šé›†
                print("  âœ… TLE æ”¶é›†å™¨å¯æ­£å¸¸å°å…¥å’Œå¯¦ä¾‹åŒ–")
                results["integration_status"]["tle_collector_import"] = True
            except Exception as e:
                print(f"  âŒ TLE æ”¶é›†å™¨å°å…¥å¤±æ•—: {e}")
                results["integration_status"]["tle_collector_import"] = False
        
        # æ¸¬è©¦ RL æ•¸æ“šé›†ç”Ÿæˆå™¨
        if results["research_components"]["rl_dataset_generator"]:
            print("  ğŸ§ª æ¸¬è©¦ RL æ•¸æ“šé›†ç”Ÿæˆå™¨å°å…¥")
            try:
                from netstack.src.services.rl.rl_dataset_generator import RLDatasetGenerator
                # å‰µå»ºæ¸¬è©¦æ•¸æ“š
                test_data = {
                    'observer_location': {'lat': 24.94417, 'lon': 121.37139},
                    'constellations': {
                        'starlink': {
                            'orbit_data': {
                                'test_sat': {
                                    'trajectory': {
                                        'timestamps': [0, 60, 120],
                                        'positions': [[100, 200, 300], [110, 210, 310], [120, 220, 320]],
                                        'elevations': [15, 25, 35]
                                    }
                                }
                            }
                        }
                    }
                }
                generator = RLDatasetGenerator(test_data)
                print("  âœ… RL æ•¸æ“šé›†ç”Ÿæˆå™¨å¯æ­£å¸¸å°å…¥å’Œå¯¦ä¾‹åŒ–")
                results["integration_status"]["rl_generator_import"] = True
            except Exception as e:
                print(f"  âŒ RL æ•¸æ“šé›†ç”Ÿæˆå™¨å°å…¥å¤±æ•—: {e}")
                results["integration_status"]["rl_generator_import"] = False
        
        # æ¸¬è©¦ 3GPP äº‹ä»¶ç”Ÿæˆå™¨
        if results["research_components"]["threegpp_event_generator"]:
            print("  ğŸ§ª æ¸¬è©¦ 3GPP äº‹ä»¶ç”Ÿæˆå™¨å°å…¥")
            try:
                from netstack.src.services.research.threegpp_event_generator import ThreeGPPEventGenerator
                generator = ThreeGPPEventGenerator()
                print("  âœ… 3GPP äº‹ä»¶ç”Ÿæˆå™¨å¯æ­£å¸¸å°å…¥å’Œå¯¦ä¾‹åŒ–")
                results["integration_status"]["threegpp_generator_import"] = True
            except Exception as e:
                print(f"  âŒ 3GPP äº‹ä»¶ç”Ÿæˆå™¨å°å…¥å¤±æ•—: {e}")
                results["integration_status"]["threegpp_generator_import"] = False
                
    except Exception as e:
        print(f"âŒ æ•´åˆæ¸¬è©¦å¤±æ•—: {e}")
        results["integration_status"]["tle_collector_import"] = False
        results["integration_status"]["rl_generator_import"] = False
        results["integration_status"]["threegpp_generator_import"] = False
    
    # æ¸¬è©¦ 5: å¤šæ˜Ÿåº§æ”¯æ´æª¢æŸ¥
    print("\nğŸ›°ï¸ 5. å¤šæ˜Ÿåº§æ”¯æ´æª¢æŸ¥")
    
    multi_constellation_support = True
    
    # æª¢æŸ¥ TLE æ”¶é›†å™¨çš„å¤šæ˜Ÿåº§æ”¯æ´
    if results["research_components"]["daily_tle_collector"]:
        with open("netstack/scripts/daily_tle_collector.py", 'r') as f:
            content = f.read()
        if "'starlink'" in content and "'oneweb'" in content:
            print("  âœ… TLE æ”¶é›†å™¨æ”¯æ´ Starlink å’Œ OneWeb")
        else:
            print("  âŒ TLE æ”¶é›†å™¨å¤šæ˜Ÿåº§æ”¯æ´ä¸å®Œæ•´")
            multi_constellation_support = False
    
    results["phase3_features"]["multi_constellation_support"] = multi_constellation_support
    
    # è¨ˆç®—ç¸½åˆ†
    all_features = {**results["phase3_features"], **results["research_components"], **results["integration_status"]}
    total_features = len(all_features)
    completed_features = sum(all_features.values())
    
    if total_features > 0:
        results["overall_score"] = (completed_features / total_features) * 100
    
    # è¼¸å‡ºçµæœæ‘˜è¦
    print(f"\nğŸ“Š Phase 3 å®Œæˆåº¦æ‘˜è¦")
    print(f"=" * 40)
    print(f"ç¸½é«”å®Œæˆåº¦: {results['overall_score']:.1f}%")
    print(f"å®ŒæˆåŠŸèƒ½: {completed_features}/{total_features}")
    
    print(f"\nğŸ¯ åŠŸèƒ½ç‹€æ…‹:")
    for category, features in results.items():
        if category == "overall_score":
            continue
        print(f"\n{category.upper()}:")
        for feature, status in features.items():
            status_icon = "âœ…" if status else "âŒ"
            print(f"  {status_icon} {feature}")
    
    # Phase 3 é©—æ”¶æ¨™æº–æª¢æŸ¥
    print(f"\nğŸ“‹ Phase 3 é©—æ”¶æ¨™æº–æª¢æŸ¥:")
    acceptance_criteria = {
        "45å¤©å®Œæ•´ TLE æ•¸æ“šæ”¶é›†æ©Ÿåˆ¶å»ºç«‹": results["phase3_features"]["tle_collection_automation"],
        "RL è¨“ç·´æ•¸æ“šé›†è‡ªå‹•ç”Ÿæˆ (æ”¯æ´ PyTorch/TensorFlow)": results["phase3_features"]["rl_dataset_generation"] and results["phase3_features"]["ml_framework_support"],
        "3GPP NTN æ¨™æº–äº‹ä»¶ç”Ÿæˆå™¨": results["phase3_features"]["threegpp_events"],
        "å­¸è¡“è«–æ–‡å“è³ªçš„æ•¸æ“šé©—è­‰å ±å‘Š": results["phase3_features"]["academic_research_support"],
        "æ”¯æ´å¤šæ˜Ÿåº§ (Starlink/OneWeb) å°æ¯”ç ”ç©¶": results["phase3_features"]["multi_constellation_support"]
    }
    
    for criterion, status in acceptance_criteria.items():
        status_icon = "âœ…" if status else "âŒ"
        print(f"  {status_icon} {criterion}")
    
    acceptance_score = sum(acceptance_criteria.values()) / len(acceptance_criteria) * 100
    print(f"\nğŸ¯ é©—æ”¶æ¨™æº–é”æˆç‡: {acceptance_score:.1f}%")
    
    # ä¿å­˜çµæœ
    with open('test_phase3_results.json', 'w', encoding='utf-8') as f:
        json.dump({
            **results,
            "acceptance_criteria": acceptance_criteria,
            "acceptance_score": acceptance_score,
            "test_timestamp": datetime.now().isoformat()
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ æ¸¬è©¦çµæœå·²ä¿å­˜è‡³: test_phase3_results.json")
    
    return results

if __name__ == "__main__":
    asyncio.run(test_phase3_completion())
