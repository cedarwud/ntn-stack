#!/usr/bin/env python3
"""
éšæ®µå››å¿«é€Ÿé©—è­‰æ¸¬è©¦ - ä¸ä¾è³´åœ–è¡¨åº«
æ¸¬è©¦æ ¸å¿ƒè«–æ–‡å¾©ç¾é‚è¼¯å’ŒAPIé€£æ¥
"""

import asyncio
import time
import json
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any
import sys
import os

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('/home/sat/ntn-stack')

def test_configuration_loading():
    """æ¸¬è©¦é…ç½®æª”æ¡ˆè¼‰å…¥"""
    print("ğŸ”§ æ¸¬è©¦é…ç½®æª”æ¡ˆè¼‰å…¥...")
    
    config_path = Path("configs/paper_reproduction_config.yaml")
    if not config_path.exists():
        print(f"âŒ é…ç½®æª”æ¡ˆä¸å­˜åœ¨: {config_path}")
        return False
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # æª¢æŸ¥é—œéµé…ç½®
        required_keys = [
            "paper_environments",
            "constellation_scenarios", 
            "handover_schemes_comparison",
            "acceptance_criteria"
        ]
        
        for key in required_keys:
            if key not in config:
                print(f"âŒ ç¼ºå°‘é…ç½®é …: {key}")
                return False
        
        print("âœ… é…ç½®æª”æ¡ˆè¼‰å…¥æˆåŠŸ")
        print(f"  ğŸ“Š æ˜Ÿåº§å ´æ™¯æ•¸é‡: {len(config['constellation_scenarios'])}")
        print(f"  ğŸ”„ æ›æ‰‹æ–¹æ¡ˆæ•¸é‡: {len(config['handover_schemes_comparison']['schemes'])}")
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®æª”æ¡ˆè¼‰å…¥å¤±æ•—: {e}")
        return False

async def test_api_connectivity():
    """æ¸¬è©¦APIé€£æ¥æ€§"""
    print("ğŸŒ æ¸¬è©¦APIé€£æ¥æ€§...")
    
    try:
        import aiohttp
        
        # NetStack APIæ¸¬è©¦
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get("http://localhost:8080/health") as response:
                    if response.status == 200:
                        print("âœ… NetStack API é€£æ¥æ­£å¸¸")
                        netstack_ok = True
                    else:
                        print(f"âš ï¸ NetStack API éŸ¿æ‡‰ç•°å¸¸: {response.status}")
                        netstack_ok = False
            except Exception as e:
                print(f"âŒ NetStack API é€£æ¥å¤±æ•—: {e}")
                netstack_ok = False
            
            # SimWorld APIæ¸¬è©¦  
            try:
                async with session.get("http://localhost:8888/") as response:
                    if response.status == 200:
                        print("âœ… SimWorld API é€£æ¥æ­£å¸¸")
                        simworld_ok = True
                    else:
                        print(f"âš ï¸ SimWorld API éŸ¿æ‡‰ç•°å¸¸: {response.status}")
                        simworld_ok = False
            except Exception as e:
                print(f"âŒ SimWorld API é€£æ¥å¤±æ•—: {e}")
                simworld_ok = False
                
        return netstack_ok and simworld_ok
        
    except ImportError:
        print("âŒ aiohttp å¥—ä»¶æœªå®‰è£")
        return False

def test_measurement_simulation():
    """æ¸¬è©¦æ¸¬é‡æ¨¡æ“¬é‚è¼¯"""
    print("ğŸ“Š æ¸¬è©¦æ¸¬é‡æ¨¡æ“¬é‚è¼¯...")
    
    try:
        import random
        
        # æ¨¡æ“¬å››ç¨®æ–¹æ¡ˆçš„åŸºç¤å»¶é²
        schemes = {
            "ntn_baseline": 250.0,
            "ntn_gs": 153.0,
            "ntn_smn": 158.5,
            "proposed": 25.0
        }
        
        measurements = {}
        
        for scheme_name, base_latency in schemes.items():
            # ç”Ÿæˆæ¸¬è©¦æ¸¬é‡æ•¸æ“š
            scheme_measurements = []
            for _ in range(100):
                # æ·»åŠ æ­£æ…‹åˆ†å¸ƒå™ªè²
                noise = random.gauss(0, base_latency * 0.1)
                actual_latency = max(base_latency + noise, 5.0)
                
                # è¨ˆç®—æˆåŠŸç‡ (åŸºæ–¼å»¶é²)
                success_probability = 0.99 if scheme_name == "proposed" else 0.95
                success = random.random() < success_probability
                
                measurement = {
                    "latency_ms": actual_latency,
                    "success": success,
                    "prediction_accuracy": random.uniform(0.9, 0.99) if scheme_name == "proposed" else random.uniform(0.7, 0.9)
                }
                scheme_measurements.append(measurement)
            
            measurements[scheme_name] = scheme_measurements
        
        # è¨ˆç®—çµ±è¨ˆæ‘˜è¦
        for scheme_name, data in measurements.items():
            latencies = [m["latency_ms"] for m in data]
            success_rates = [m["success"] for m in data]
            
            avg_latency = sum(latencies) / len(latencies)
            success_rate = sum(success_rates) / len(success_rates)
            
            print(f"  {scheme_name}: å¹³å‡å»¶é² {avg_latency:.1f}ms, æˆåŠŸç‡ {success_rate:.1%}")
        
        print("âœ… æ¸¬é‡æ¨¡æ“¬é‚è¼¯æ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬é‡æ¨¡æ“¬å¤±æ•—: {e}")
        return False

def test_file_system():
    """æ¸¬è©¦æª”æ¡ˆç³»çµ±çµæ§‹"""
    print("ğŸ“ æ¸¬è©¦æª”æ¡ˆç³»çµ±çµæ§‹...")
    
    # æª¢æŸ¥é—œéµæª”æ¡ˆå’Œç›®éŒ„
    paths_to_check = [
        "configs/paper_reproduction_config.yaml",
        "paper_reproduction_test_framework.py",
        "algorithm_regression_testing.py", 
        "enhanced_report_generator.py",
        "run_stage4_comprehensive_testing.py",
        "templates/"  # ç›®éŒ„
    ]
    
    missing_paths = []
    for path_str in paths_to_check:
        path = Path(path_str)
        if not path.exists():
            missing_paths.append(path_str)
        else:
            print(f"âœ… {path_str}")
    
    if missing_paths:
        print(f"âŒ ç¼ºå°‘æª”æ¡ˆæˆ–ç›®éŒ„: {missing_paths}")
        return False
    else:
        print("âœ… æª”æ¡ˆç³»çµ±çµæ§‹å®Œæ•´")
        return True

async def run_stage4_quick_verification():
    """åŸ·è¡Œéšæ®µå››å¿«é€Ÿé©—è­‰"""
    print("ğŸš€ é–‹å§‹éšæ®µå››å¿«é€Ÿé©—è­‰æ¸¬è©¦")
    print("=" * 50)
    
    start_time = time.time()
    test_results = {}
    
    # 1. é…ç½®æª”æ¡ˆæ¸¬è©¦
    test_results["configuration"] = test_configuration_loading()
    
    # 2. æª”æ¡ˆç³»çµ±æ¸¬è©¦
    test_results["file_system"] = test_file_system()
    
    # 3. API é€£æ¥æ¸¬è©¦
    test_results["api_connectivity"] = await test_api_connectivity()
    
    # 4. æ¸¬é‡é‚è¼¯æ¸¬è©¦
    test_results["measurement_logic"] = test_measurement_simulation()
    
    # çµæœæ‘˜è¦
    total_time = time.time() - start_time
    passed_tests = sum(test_results.values())
    total_tests = len(test_results)
    
    print("\n" + "=" * 50)
    print("ğŸ“Š éšæ®µå››å¿«é€Ÿé©—è­‰çµæœ")
    print("=" * 50)
    
    for test_name, result in test_results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{test_name:20} {status}")
    
    print(f"\nğŸ“ˆ æ¸¬è©¦é€šéç‡: {passed_tests}/{total_tests} ({passed_tests/total_tests:.1%})")
    print(f"â±ï¸ åŸ·è¡Œæ™‚é–“: {total_time:.2f}ç§’")
    
    # å„²å­˜çµæœ
    results_dir = Path("results/stage4_quick_verification")
    results_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = results_dir / f"quick_verification_{timestamp}.json"
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            "test_results": test_results,
            "summary": {
                "passed_tests": passed_tests,
                "total_tests": total_tests,
                "success_rate": passed_tests / total_tests,
                "execution_time": total_time
            },
            "timestamp": datetime.now().isoformat(),
            "next_steps": [
                "å®‰è£å®Œæ•´çš„Pythonåœ–è¡¨ä¾è³´ (matplotlib, seaborn)" if not test_results.get("api_connectivity") else "",
                "ä¿®å¾©APIé€£æ¥å•é¡Œ" if not test_results.get("api_connectivity") else "",
                "åŸ·è¡Œå®Œæ•´çš„éšæ®µå››æ¸¬è©¦å¥—ä»¶"
            ]
        }, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ çµæœå·²å„²å­˜: {result_file}")
    
    if passed_tests == total_tests:
        print("\nğŸ‰ éšæ®µå››å¿«é€Ÿé©—è­‰å®Œå…¨é€šé! å¯ä»¥é€²è¡Œå®Œæ•´æ¸¬è©¦")
        return True
    else:
        print(f"\nâš ï¸ éšæ®µå››é©—è­‰éƒ¨åˆ†å¤±æ•—ï¼Œéœ€è¦ä¿®å¾© {total_tests - passed_tests} å€‹å•é¡Œ")
        return False

if __name__ == "__main__":
    # è¨­å®šç•¶å‰å·¥ä½œç›®éŒ„
    os.chdir("/home/sat/ntn-stack/tests")
    
    # åŸ·è¡Œå¿«é€Ÿé©—è­‰
    success = asyncio.run(run_stage4_quick_verification())
    
    if success:
        sys.exit(0)
    else:
        sys.exit(1)