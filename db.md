# RLç›£æ§é é¢è³‡æ–™åº«å„²å­˜å¯¦ç¾æµç¨‹

## ğŸ“‹ é …ç›®æ¦‚è¦½

æœ¬æ–‡æª”è©³ç´°èªªæ˜å¦‚ä½•å°‡ **Navbar > åœ–è¡¨åˆ†æ > RLç›£æ§** é é¢çš„è¨“ç·´è³‡æ–™å¾å‰ç«¯æ¨¡æ“¬æ•¸æ“šè½‰æ›ç‚ºçœŸå¯¦çš„è³‡æ–™åº«å„²å­˜å’Œé¡¯ç¤ºæµç¨‹ã€‚

### ğŸ¯ ç›®æ¨™
- å°‡RLè¨“ç·´è³‡æ–™æŒä¹…åŒ–åˆ°PostgreSQL
- å¯¦ç¾å®Œæ•´çš„å¾Œç«¯APIæ”¯æŒ
- å»ºç«‹å‰å¾Œç«¯è³‡æ–™åŒæ­¥æ©Ÿåˆ¶
- æä¾›æ­·å²æ•¸æ“šæŸ¥è©¢å’Œåˆ†æåŠŸèƒ½

---

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

### ç•¶å‰ç³»çµ±ç‹€æ…‹
```
Frontend (React/TypeScript)
â”œâ”€â”€ GymnasiumRLMonitor.tsx     - RLç›£æ§ä¸»çµ„ä»¶
â”œâ”€â”€ ChartAnalysisDashboard.tsx - åœ–è¡¨åˆ†æå„€è¡¨æ¿
â””â”€â”€ æ¨¡æ“¬æ•¸æ“šç”Ÿæˆ             - å‹•æ…‹ç”Ÿæˆè¨“ç·´æŒ‡æ¨™

Backend (FastAPI/Python)
â”œâ”€â”€ SimWorld Backend           - TensorFlow + Sionna AIæœå‹™
â””â”€â”€ NetStack Backend          - 5Gæ ¸å¿ƒç¶² + MongoDB/Redis
```

### ç›®æ¨™æ¶æ§‹
```
Frontend (React/TypeScript)
â”œâ”€â”€ GymnasiumRLMonitor.tsx     - é¡¯ç¤ºçœŸå¯¦æ•¸æ“š
â”œâ”€â”€ APIå‘¼å«å±¤                  - ç²å–è³‡æ–™åº«æ•¸æ“š
â””â”€â”€ å³æ™‚æ•¸æ“šæ›´æ–°               - WebSocket/SSE

Backend (FastAPI/Python)
â”œâ”€â”€ RL Domain æ–°å¢            - å°ˆé–€çš„RLè³‡æ–™ç®¡ç†
â”œâ”€â”€ PostgreSQL Schema         - å®Œæ•´çš„è¨“ç·´æ•¸æ“šå„²å­˜
â”œâ”€â”€ API Endpoints            - RESTfulè³‡æ–™ä»‹é¢
â””â”€â”€ èƒŒæ™¯è¨“ç·´æœå‹™              - å¯¦éš›çš„RLè¨“ç·´é‚è¼¯
```

---

## ğŸ“Š è³‡æ–™åº«è¨­è¨ˆæ–¹æ¡ˆ

### æ ¸å¿ƒè³‡æ–™è¡¨çµæ§‹

#### 1. RLExperiment (RLå¯¦é©—è¡¨)
å¯¦é©—çš„é ‚å±¤ç®¡ç†ï¼Œæ¯å€‹å¯¦é©—å°æ‡‰ä¸€æ¬¡å®Œæ•´çš„RLè¨“ç·´ä»»å‹™ã€‚

```sql
CREATE TABLE rl_experiments (
    id SERIAL PRIMARY KEY,
    experiment_name VARCHAR(255) NOT NULL,
    algorithm_type VARCHAR(50) NOT NULL, -- 'dqn', 'ppo', 'sac' ç­‰
    environment_name VARCHAR(255) NOT NULL,
    
    -- é…ç½®åƒæ•¸
    hyperparameters TEXT, -- JSONæ ¼å¼è¶…åƒæ•¸
    network_architecture TEXT, -- JSONæ ¼å¼ç¶²çµ¡çµæ§‹
    
    -- ç‹€æ…‹è¿½è¹¤
    status VARCHAR(50) DEFAULT 'running', -- 'running', 'completed', 'failed', 'paused'
    total_episodes INTEGER NOT NULL,
    completed_episodes INTEGER DEFAULT 0,
    
    -- æ™‚é–“è¨˜éŒ„
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    
    -- çµæœçµ±è¨ˆ
    best_reward FLOAT,
    final_reward FLOAT,
    convergence_episode INTEGER,
    
    -- å…ƒæ•¸æ“š
    tags TEXT, -- JSONæ•¸çµ„
    notes TEXT
);

CREATE INDEX idx_rl_experiments_name ON rl_experiments(experiment_name);
CREATE INDEX idx_rl_experiments_status ON rl_experiments(status);
CREATE INDEX idx_rl_experiments_created ON rl_experiments(created_at);
```

#### 2. RLEpisode (RLå›åˆè¡¨)
è¨˜éŒ„æ¯å€‹è¨“ç·´å›åˆçš„çµ±è¨ˆæ•¸æ“šï¼Œå°æ‡‰å‰ç«¯é¡¯ç¤ºçš„episodeæŒ‡æ¨™ã€‚

```sql
CREATE TABLE rl_episodes (
    id SERIAL PRIMARY KEY,
    experiment_id INTEGER NOT NULL REFERENCES rl_experiments(id),
    
    -- å›åˆåŸºæœ¬ä¿¡æ¯
    episode_number INTEGER NOT NULL,
    total_steps INTEGER NOT NULL,
    total_reward FLOAT NOT NULL,
    
    -- å­¸ç¿’æŒ‡æ¨™
    avg_loss FLOAT,
    exploration_rate FLOAT, -- epsilon for DQN
    learning_rate FLOAT,
    
    -- æ‡‰ç”¨ç‰¹å®šæŒ‡æ¨™ (5Gç¶²çµ¡ç›¸é—œ)
    handover_success_rate FLOAT,
    interference_mitigation_score FLOAT,
    network_efficiency FLOAT,
    
    -- æ™‚é–“ä¿¡æ¯
    episode_start_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    episode_duration_seconds FLOAT,
    
    -- åŸå§‹æ•¸æ“šè·¯å¾‘
    episode_data_path VARCHAR(500)
);

CREATE INDEX idx_rl_episodes_experiment ON rl_episodes(experiment_id);
CREATE INDEX idx_rl_episodes_number ON rl_episodes(episode_number);
CREATE INDEX idx_rl_episodes_time ON rl_episodes(episode_start_time);
```

#### 3. RLStep (RLæ­¥é©Ÿè¡¨)
è©³ç´°çš„ç‹€æ…‹-å‹•ä½œ-çå‹µæ•¸æ“šï¼Œç”¨æ–¼æ·±åº¦åˆ†æå’Œé‡æ”¾ã€‚

```sql
CREATE TABLE rl_steps (
    id SERIAL PRIMARY KEY,
    episode_id INTEGER NOT NULL REFERENCES rl_episodes(id),
    
    step_number INTEGER NOT NULL,
    
    -- SARSæ•¸æ“š (State, Action, Reward, State)
    state TEXT NOT NULL, -- JSONæ ¼å¼ç‹€æ…‹
    action TEXT NOT NULL, -- JSONæ ¼å¼å‹•ä½œ
    reward FLOAT NOT NULL,
    next_state TEXT NOT NULL, -- JSONæ ¼å¼ä¸‹ä¸€ç‹€æ…‹
    done BOOLEAN NOT NULL,
    
    -- AIæ±ºç­–ä¿¡æ¯
    q_values TEXT, -- JSONæ ¼å¼Qå€¼
    action_probabilities TEXT, -- JSONæ ¼å¼å‹•ä½œæ¦‚ç‡
    
    -- ç’°å¢ƒç‰¹å®šæ•¸æ“š
    satellite_positions TEXT, -- JSONæ ¼å¼è¡›æ˜Ÿä½ç½®
    interference_levels TEXT, -- JSONæ ¼å¼å¹²æ“¾æ°´å¹³
    network_metrics TEXT, -- JSONæ ¼å¼ç¶²çµ¡æŒ‡æ¨™
    
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_rl_steps_episode ON rl_steps(episode_id);
CREATE INDEX idx_rl_steps_time ON rl_steps(timestamp);
-- æ™‚é–“åºåˆ—åˆ†å€ï¼ˆæŒ‰æœˆåˆ†å€ï¼‰
CREATE INDEX idx_rl_steps_time_month ON rl_steps(date_trunc('month', timestamp));
```

#### 4. RLModelCheckpoint (æ¨¡å‹æª¢æŸ¥é»è¡¨)
å„²å­˜è¨“ç·´éç¨‹ä¸­çš„æ¨¡å‹å¿«ç…§ï¼Œæ”¯æŒæ¨¡å‹ç‰ˆæœ¬ç®¡ç†ã€‚

```sql
CREATE TABLE rl_model_checkpoints (
    id SERIAL PRIMARY KEY,
    experiment_id INTEGER NOT NULL REFERENCES rl_experiments(id),
    
    checkpoint_name VARCHAR(255) NOT NULL,
    episode_number INTEGER NOT NULL,
    
    -- æ¨¡å‹æ–‡ä»¶è·¯å¾‘
    model_file_path VARCHAR(500) NOT NULL,
    optimizer_state_path VARCHAR(500),
    
    -- æ€§èƒ½æŒ‡æ¨™
    validation_reward FLOAT,
    training_loss FLOAT,
    
    -- å…ƒæ•¸æ“š
    model_size_bytes BIGINT,
    is_best BOOLEAN DEFAULT FALSE,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_rl_checkpoints_experiment ON rl_model_checkpoints(experiment_id);
CREATE INDEX idx_rl_checkpoints_best ON rl_model_checkpoints(is_best);
```

#### 5. RLMetrics (RLæŒ‡æ¨™èšåˆè¡¨)
é è¨ˆç®—çš„çµ±è¨ˆæŒ‡æ¨™ï¼Œæä¾›é«˜æ•ˆçš„å„€è¡¨æ¿æŸ¥è©¢ã€‚

```sql
CREATE TABLE rl_metrics (
    id SERIAL PRIMARY KEY,
    experiment_id INTEGER NOT NULL REFERENCES rl_experiments(id),
    
    -- æ™‚é–“çª—å£å®šç¾©
    metric_type VARCHAR(50) NOT NULL, -- 'episode', 'batch', 'epoch'
    window_start INTEGER NOT NULL,
    window_end INTEGER NOT NULL,
    
    -- åŸºç¤æ€§èƒ½æŒ‡æ¨™
    avg_reward FLOAT NOT NULL,
    std_reward FLOAT NOT NULL,
    max_reward FLOAT NOT NULL,
    min_reward FLOAT NOT NULL,
    
    -- å­¸ç¿’é€²åº¦æŒ‡æ¨™
    avg_loss FLOAT,
    convergence_score FLOAT,
    stability_score FLOAT,
    
    -- æ‡‰ç”¨ç‰¹å®šèšåˆæŒ‡æ¨™
    handover_performance TEXT, -- JSONæ ¼å¼
    interference_metrics TEXT, -- JSONæ ¼å¼
    
    calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_rl_metrics_experiment ON rl_metrics(experiment_id);
CREATE INDEX idx_rl_metrics_type ON rl_metrics(metric_type);
```

---

## ğŸ”§ å¾Œç«¯å¯¦ç¾æ­¥é©Ÿ

### ç¬¬1æ­¥ï¼šå»ºç«‹RLé ˜åŸŸçµæ§‹

```bash
# åœ¨SimWorldå¾Œç«¯å»ºç«‹RLé ˜åŸŸ
mkdir -p simworld/backend/app/domains/rl/{models,api,services,repositories}
```

#### æª”æ¡ˆçµæ§‹
```
simworld/backend/app/domains/rl/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ rl_training_models.py      # SQLModelè³‡æ–™æ¨¡å‹
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ rl_training_api.py         # FastAPIè·¯ç”±
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ rl_training_service.py     # æ¥­å‹™é‚è¼¯
â””â”€â”€ repositories/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ rl_training_repository.py  # è³‡æ–™å­˜å–å±¤
```

### ç¬¬2æ­¥ï¼šå¯¦ç¾è³‡æ–™æ¨¡å‹ (SQLModel)

å»ºç«‹æª”æ¡ˆï¼š`simworld/backend/app/domains/rl/models/rl_training_models.py`

```python
from datetime import datetime
from typing import Optional, List
from sqlmodel import SQLModel, Field, Column, Text
from sqlalchemy import JSON
from enum import Enum

class RLAlgorithmType(str, Enum):
    DQN = "dqn"
    PPO = "ppo"
    SAC = "sac"
    A3C = "a3c"

class TrainingStatus(str, Enum):
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    PAUSED = "paused"
    CANCELLED = "cancelled"

class RLExperiment(SQLModel, table=True):
    __tablename__ = "rl_experiments"
    
    id: Optional[int] = Field(default=None, primary_key=True)
    experiment_name: str = Field(index=True)
    algorithm_type: RLAlgorithmType
    environment_name: str
    
    # é…ç½®JSON
    hyperparameters: str = Field(sa_column=Column(Text))
    network_architecture: str = Field(sa_column=Column(Text))
    
    # ç‹€æ…‹
    status: TrainingStatus = Field(default=TrainingStatus.RUNNING)
    total_episodes: int
    completed_episodes: int = Field(default=0)
    
    # æ™‚é–“
    created_at: datetime = Field(default_factory=datetime.utcnow)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    
    # çµæœ
    best_reward: Optional[float] = None
    final_reward: Optional[float] = None
    convergence_episode: Optional[int] = None
    
    # å…ƒæ•¸æ“š
    tags: Optional[str] = None  # JSONæ•¸çµ„
    notes: Optional[str] = None

class RLEpisode(SQLModel, table=True):
    __tablename__ = "rl_episodes"
    
    id: Optional[int] = Field(default=None, primary_key=True)
    experiment_id: int = Field(foreign_key="rl_experiments.id", index=True)
    
    episode_number: int = Field(index=True)
    total_steps: int
    total_reward: float
    
    # å­¸ç¿’æŒ‡æ¨™
    avg_loss: Optional[float] = None
    exploration_rate: Optional[float] = None
    learning_rate: Optional[float] = None
    
    # 5Gç¶²çµ¡ç‰¹å®šæŒ‡æ¨™
    handover_success_rate: Optional[float] = None
    interference_mitigation_score: Optional[float] = None
    network_efficiency: Optional[float] = None
    
    # æ™‚é–“
    episode_start_time: datetime = Field(default_factory=datetime.utcnow)
    episode_duration_seconds: Optional[float] = None
    
    episode_data_path: Optional[str] = None

# å…¶ä»–æ¨¡å‹é¡ä¼¼å¯¦ç¾...
```

### ç¬¬3æ­¥ï¼šå¯¦ç¾è³‡æ–™å­˜å–å±¤

å»ºç«‹æª”æ¡ˆï¼š`simworld/backend/app/domains/rl/repositories/rl_training_repository.py`

```python
from typing import List, Optional
from sqlmodel import select
from sqlalchemy.ext.asyncio import AsyncSession
from ..models.rl_training_models import RLExperiment, RLEpisode, RLMetrics

class RLTrainingRepository:
    def __init__(self, session: AsyncSession):
        self.session = session
    
    async def create_experiment(self, experiment: RLExperiment) -> RLExperiment:
        self.session.add(experiment)
        await self.session.commit()
        await self.session.refresh(experiment)
        return experiment
    
    async def get_experiment(self, experiment_id: int) -> Optional[RLExperiment]:
        statement = select(RLExperiment).where(RLExperiment.id == experiment_id)
        result = await self.session.exec(statement)
        return result.first()
    
    async def get_active_experiments(self) -> List[RLExperiment]:
        statement = select(RLExperiment).where(
            RLExperiment.status.in_(["running", "paused"])
        )
        result = await self.session.exec(statement)
        return result.all()
    
    async def save_episode(self, episode: RLEpisode) -> RLEpisode:
        self.session.add(episode)
        await self.session.commit()
        await self.session.refresh(episode)
        return episode
    
    async def get_experiment_episodes(
        self, 
        experiment_id: int, 
        limit: int = 100,
        offset: int = 0
    ) -> List[RLEpisode]:
        statement = (
            select(RLEpisode)
            .where(RLEpisode.experiment_id == experiment_id)
            .order_by(RLEpisode.episode_number.desc())
            .offset(offset)
            .limit(limit)
        )
        result = await self.session.exec(statement)
        return result.all()
    
    async def get_latest_metrics(self, experiment_id: int) -> Optional[RLMetrics]:
        statement = (
            select(RLMetrics)
            .where(RLMetrics.experiment_id == experiment_id)
            .order_by(RLMetrics.calculated_at.desc())
            .limit(1)
        )
        result = await self.session.exec(statement)
        return result.first()
```

### ç¬¬4æ­¥ï¼šå¯¦ç¾æ¥­å‹™é‚è¼¯æœå‹™

å»ºç«‹æª”æ¡ˆï¼š`simworld/backend/app/domains/rl/services/rl_training_service.py`

```python
import json
from typing import List, Dict, Any, Optional
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from ..models.rl_training_models import *
from ..repositories.rl_training_repository import RLTrainingRepository

class RLTrainingService:
    def __init__(self, session: AsyncSession):
        self.repository = RLTrainingRepository(session)
    
    async def create_experiment(
        self, 
        experiment_name: str,
        algorithm_type: RLAlgorithmType,
        config: Dict[str, Any]
    ) -> RLExperiment:
        """å»ºç«‹æ–°çš„RLè¨“ç·´å¯¦é©—"""
        
        experiment = RLExperiment(
            experiment_name=experiment_name,
            algorithm_type=algorithm_type,
            environment_name=config.get("environment", "5g_network"),
            hyperparameters=json.dumps(config.get("hyperparameters", {})),
            network_architecture=json.dumps(config.get("network", {})),
            total_episodes=config.get("total_episodes", 1000),
            started_at=datetime.utcnow()
        )
        
        return await self.repository.create_experiment(experiment)
    
    async def log_episode(
        self,
        experiment_id: int,
        episode_data: Dict[str, Any]
    ) -> RLEpisode:
        """è¨˜éŒ„å–®å€‹è¨“ç·´å›åˆæ•¸æ“š"""
        
        episode = RLEpisode(
            experiment_id=experiment_id,
            episode_number=episode_data["episode_number"],
            total_steps=episode_data["total_steps"],
            total_reward=episode_data["total_reward"],
            avg_loss=episode_data.get("avg_loss"),
            exploration_rate=episode_data.get("exploration_rate"),
            learning_rate=episode_data.get("learning_rate"),
            handover_success_rate=episode_data.get("handover_success_rate"),
            interference_mitigation_score=episode_data.get("interference_score"),
            network_efficiency=episode_data.get("network_efficiency"),
            episode_duration_seconds=episode_data.get("duration")
        )
        
        return await self.repository.save_episode(episode)
    
    async def get_experiment_progress(self, experiment_id: int) -> Dict[str, Any]:
        """ç²å–å¯¦é©—é€²åº¦å’Œçµ±è¨ˆ"""
        
        experiment = await self.repository.get_experiment(experiment_id)
        if not experiment:
            raise ValueError(f"Experiment {experiment_id} not found")
        
        episodes = await self.repository.get_experiment_episodes(
            experiment_id, limit=50
        )
        
        # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
        if episodes:
            recent_rewards = [ep.total_reward for ep in episodes[:10]]
            avg_reward = sum(recent_rewards) / len(recent_rewards)
            progress_pct = (experiment.completed_episodes / experiment.total_episodes) * 100
        else:
            avg_reward = 0.0
            progress_pct = 0.0
        
        return {
            "experiment": experiment,
            "recent_episodes": episodes[:10],
            "stats": {
                "avg_reward": avg_reward,
                "progress_percentage": progress_pct,
                "episodes_completed": experiment.completed_episodes,
                "total_episodes": experiment.total_episodes
            }
        }
    
    async def get_dashboard_data(self) -> Dict[str, Any]:
        """ç²å–å„€è¡¨æ¿é¡¯ç¤ºæ•¸æ“š"""
        
        active_experiments = await self.repository.get_active_experiments()
        
        dashboard_data = {
            "active_experiments": len(active_experiments),
            "experiments": []
        }
        
        for exp in active_experiments:
            progress = await self.get_experiment_progress(exp.id)
            exp_data = {
                "id": exp.id,
                "name": exp.experiment_name,
                "algorithm": exp.algorithm_type,
                "status": exp.status,
                "progress": progress["stats"]
            }
            dashboard_data["experiments"].append(exp_data)
        
        return dashboard_data
```

### ç¬¬5æ­¥ï¼šå¯¦ç¾APIç«¯é»

å»ºç«‹æª”æ¡ˆï¼š`simworld/backend/app/domains/rl/api/rl_training_api.py`

```python
from fastapi import APIRouter, Depends, HTTPException, Query
from typing import List, Dict, Any
from sqlalchemy.ext.asyncio import AsyncSession
from ....core.deps import get_session
from ..services.rl_training_service import RLTrainingService
from ..models.rl_training_models import RLExperiment, RLEpisode

router = APIRouter(prefix="/rl", tags=["RL Training"])

@router.post("/experiments", response_model=Dict[str, Any])
async def create_experiment(
    experiment_config: Dict[str, Any],
    session: AsyncSession = Depends(get_session)
):
    """å»ºç«‹æ–°çš„RLè¨“ç·´å¯¦é©—"""
    
    service = RLTrainingService(session)
    
    experiment = await service.create_experiment(
        experiment_name=experiment_config["name"],
        algorithm_type=experiment_config["algorithm"],
        config=experiment_config
    )
    
    return {"experiment_id": experiment.id, "status": "created"}

@router.get("/experiments/{experiment_id}/progress")
async def get_experiment_progress(
    experiment_id: int,
    session: AsyncSession = Depends(get_session)
):
    """ç²å–å¯¦é©—é€²åº¦"""
    
    service = RLTrainingService(session)
    
    try:
        progress = await service.get_experiment_progress(experiment_id)
        return progress
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))

@router.post("/experiments/{experiment_id}/episodes")
async def log_episode(
    experiment_id: int,
    episode_data: Dict[str, Any],
    session: AsyncSession = Depends(get_session)
):
    """è¨˜éŒ„è¨“ç·´å›åˆæ•¸æ“š"""
    
    service = RLTrainingService(session)
    episode = await service.log_episode(experiment_id, episode_data)
    
    return {"episode_id": episode.id, "status": "logged"}

@router.get("/dashboard")
async def get_dashboard_data(session: AsyncSession = Depends(get_session)):
    """ç²å–RLç›£æ§å„€è¡¨æ¿æ•¸æ“š - å‰ç«¯ä¸»è¦èª¿ç”¨æ­¤API"""
    
    service = RLTrainingService(session)
    dashboard_data = await service.get_dashboard_data()
    
    return dashboard_data

@router.get("/experiments/{experiment_id}/episodes")
async def get_experiment_episodes(
    experiment_id: int,
    limit: int = Query(100, le=1000),
    offset: int = Query(0, ge=0),
    session: AsyncSession = Depends(get_session)
):
    """ç²å–å¯¦é©—çš„è¨“ç·´å›åˆæ•¸æ“š"""
    
    service = RLTrainingService(session)
    repository = service.repository
    
    episodes = await repository.get_experiment_episodes(
        experiment_id, limit, offset
    )
    
    return {"episodes": episodes, "count": len(episodes)}

# WebSocketæ”¯æŒå³æ™‚æ›´æ–°
from fastapi import WebSocket
import asyncio
import json

@router.websocket("/experiments/{experiment_id}/live")
async def experiment_live_updates(
    websocket: WebSocket, 
    experiment_id: int
):
    """æä¾›å¯¦é©—çš„å³æ™‚æ•¸æ“šæ›´æ–°"""
    
    await websocket.accept()
    
    try:
        while True:
            # æ¯3ç§’ç™¼é€æ›´æ–°æ•¸æ“šï¼ˆèˆ‡å‰ç«¯ç•¶å‰æ›´æ–°é »ç‡ä¸€è‡´ï¼‰
            session = next(get_session())
            service = RLTrainingService(session)
            
            progress = await service.get_experiment_progress(experiment_id)
            
            await websocket.send_text(json.dumps({
                "type": "progress_update",
                "data": progress
            }))
            
            await asyncio.sleep(3)
            
    except Exception as e:
        print(f"WebSocket error: {e}")
    finally:
        await websocket.close()
```

### ç¬¬6æ­¥ï¼šè¨»å†ŠAPIè·¯ç”±

æ›´æ–°æª”æ¡ˆï¼š`simworld/backend/app/api/v1/router.py`

```python
# ç¾æœ‰å°å…¥...
from ...domains.rl.api.rl_training_api import router as rl_router

# åœ¨ç¾æœ‰è·¯ç”±ä¸­æ·»åŠ 
api_router.include_router(rl_router, prefix="/api/v1")
```

### ç¬¬7æ­¥ï¼šæ›´æ–°è³‡æ–™åº«é·ç§»

æ›´æ–°æª”æ¡ˆï¼š`simworld/backend/app/db/base.py`

```python
# ç¾æœ‰å°å…¥...
from ..domains.rl.models.rl_training_models import *  # æ–°å¢RLæ¨¡å‹

# ç¢ºä¿æ‰€æœ‰æ¨¡å‹éƒ½è¢«å°å…¥ï¼Œä»¥ä¾¿SQLModelèƒ½å»ºç«‹è³‡æ–™è¡¨
```

---

## ğŸ¨ å‰ç«¯ä¿®æ”¹æ­¥é©Ÿ

### ç¬¬1æ­¥ï¼šå»ºç«‹APIå®¢æˆ¶ç«¯

å»ºç«‹æª”æ¡ˆï¼š`simworld/frontend/src/api/rlTrainingApi.ts`

```typescript
interface RLExperiment {
  id: number;
  experiment_name: string;
  algorithm_type: 'dqn' | 'ppo' | 'sac';
  status: 'running' | 'completed' | 'failed' | 'paused';
  completed_episodes: number;
  total_episodes: number;
  best_reward?: number;
}

interface RLEpisode {
  id: number;
  episode_number: number;
  total_reward: number;
  avg_loss?: number;
  exploration_rate?: number;
  handover_success_rate?: number;
  interference_mitigation_score?: number;
}

interface DashboardData {
  active_experiments: number;
  experiments: Array<{
    id: number;
    name: string;
    algorithm: string;
    status: string;
    progress: {
      avg_reward: number;
      progress_percentage: number;
      episodes_completed: number;
      total_episodes: number;
    };
  }>;
}

class RLTrainingAPI {
  private baseURL = 'http://localhost:8888/api/v1/rl';

  async getDashboardData(): Promise<DashboardData> {
    const response = await fetch(`${this.baseURL}/dashboard`);
    if (!response.ok) {
      throw new Error('Failed to fetch dashboard data');
    }
    return response.json();
  }

  async getExperimentProgress(experimentId: number) {
    const response = await fetch(`${this.baseURL}/experiments/${experimentId}/progress`);
    if (!response.ok) {
      throw new Error(`Failed to fetch experiment ${experimentId} progress`);
    }
    return response.json();
  }

  async createExperiment(config: any) {
    const response = await fetch(`${this.baseURL}/experiments`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(config)
    });
    
    if (!response.ok) {
      throw new Error('Failed to create experiment');
    }
    return response.json();
  }

  async logEpisode(experimentId: number, episodeData: any) {
    const response = await fetch(`${this.baseURL}/experiments/${experimentId}/episodes`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(episodeData)
    });
    
    return response.json();
  }

  // WebSocketé€£æ¥ç”¨æ–¼å³æ™‚æ›´æ–°
  connectLiveUpdates(experimentId: number, onMessage: (data: any) => void): WebSocket {
    const ws = new WebSocket(`ws://localhost:8888/api/v1/rl/experiments/${experimentId}/live`);
    
    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);
      onMessage(message.data);
    };
    
    return ws;
  }
}

export const rlTrainingAPI = new RLTrainingAPI();
export type { RLExperiment, RLEpisode, DashboardData };
```

### ç¬¬2æ­¥ï¼šä¿®æ”¹RLç›£æ§çµ„ä»¶

æ›´æ–°æª”æ¡ˆï¼š`simworld/frontend/src/components/charts/GymnasiumRLMonitor.tsx`

```typescript
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { rlTrainingAPI, DashboardData, RLExperiment } from '../../api/rlTrainingApi';

interface RLEngineMetrics {
  engine_type: 'dqn' | 'ppo' | 'null';
  algorithm: string;
  environment: string;
  model_status: 'training' | 'inference' | 'idle' | 'error';
  episodes_completed: number;
  average_reward: number;
  current_epsilon: number;
  training_progress: number;
  prediction_accuracy: number;
  response_time_ms: number;
  memory_usage: number;
  gpu_utilization?: number;
}

const GymnasiumRLMonitor: React.FC = () => {
  // ç‹€æ…‹ç®¡ç†
  const [dashboardData, setDashboardData] = useState<DashboardData | null>(null);
  const [dqnMetrics, setDqnMetrics] = useState<RLEngineMetrics>({
    engine_type: 'dqn',
    algorithm: 'Deep Q-Network',
    environment: '5G NTN Handover',
    model_status: 'idle',
    episodes_completed: 0,
    average_reward: 0,
    current_epsilon: 1.0,
    training_progress: 0,
    prediction_accuracy: 60,
    response_time_ms: 0,
    memory_usage: 0,
    gpu_utilization: 0
  });

  const [ppoMetrics, setPpoMetrics] = useState<RLEngineMetrics>({
    engine_type: 'ppo',
    algorithm: 'Proximal Policy Optimization',
    environment: '5G NTN Handover',
    model_status: 'idle',
    episodes_completed: 0,
    average_reward: 0,
    current_epsilon: 0,
    training_progress: 0,
    prediction_accuracy: 65,
    response_time_ms: 0,
    memory_usage: 0,
    gpu_utilization: 0
  });

  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [activeExperiments, setActiveExperiments] = useState<Map<string, number>>(new Map());
  
  // WebSocketå¼•ç”¨
  const wsConnections = useRef<Map<number, WebSocket>>(new Map());

  // å¾è³‡æ–™åº«è¼‰å…¥æ•¸æ“š
  const loadDashboardData = useCallback(async () => {
    try {
      setIsLoading(true);
      setError(null);
      
      const data = await rlTrainingAPI.getDashboardData();
      setDashboardData(data);
      
      // æ›´æ–°æŒ‡æ¨™
      updateMetricsFromDashboard(data);
      
    } catch (err) {
      console.error('è¼‰å…¥å„€è¡¨æ¿æ•¸æ“šå¤±æ•—:', err);
      setError('ç„¡æ³•è¼‰å…¥è¨“ç·´æ•¸æ“šï¼Œè«‹æª¢æŸ¥å¾Œç«¯é€£æ¥');
    } finally {
      setIsLoading(false);
    }
  }, []);

  // å°‡è³‡æ–™åº«æ•¸æ“šè½‰æ›ç‚ºçµ„ä»¶æŒ‡æ¨™æ ¼å¼
  const updateMetricsFromDashboard = (data: DashboardData) => {
    const dqnExperiment = data.experiments.find(exp => 
      exp.algorithm.toLowerCase() === 'dqn'
    );
    const ppoExperiment = data.experiments.find(exp => 
      exp.algorithm.toLowerCase() === 'ppo'
    );

    if (dqnExperiment) {
      setDqnMetrics(prev => ({
        ...prev,
        model_status: dqnExperiment.status === 'running' ? 'training' : 'idle',
        episodes_completed: dqnExperiment.progress.episodes_completed,
        average_reward: dqnExperiment.progress.avg_reward,
        training_progress: dqnExperiment.progress.progress_percentage,
        current_epsilon: Math.max(0.01, 1.0 - (dqnExperiment.progress.progress_percentage / 100)),
        prediction_accuracy: Math.min(95, 60 + (dqnExperiment.progress.progress_percentage * 0.35))
      }));
    }

    if (ppoExperiment) {
      setPpoMetrics(prev => ({
        ...prev,
        model_status: ppoExperiment.status === 'running' ? 'training' : 'idle',
        episodes_completed: ppoExperiment.progress.episodes_completed,
        average_reward: ppoExperiment.progress.avg_reward,
        training_progress: ppoExperiment.progress.progress_percentage,
        prediction_accuracy: Math.min(95, 65 + (ppoExperiment.progress.progress_percentage * 0.30))
      }));
    }
  };

  // é–‹å§‹è¨“ç·´
  const startTraining = async (algorithm: 'dqn' | 'ppo') => {
    try {
      const config = {
        name: `${algorithm.toUpperCase()}_Training_${Date.now()}`,
        algorithm: algorithm,
        environment: "5g_ntn_handover",
        total_episodes: 1000,
        hyperparameters: {
          learning_rate: algorithm === 'dqn' ? 0.001 : 0.0003,
          batch_size: 32,
          epsilon_start: algorithm === 'dqn' ? 1.0 : undefined,
          epsilon_end: algorithm === 'dqn' ? 0.01 : undefined
        }
      };

      const result = await rlTrainingAPI.createExperiment(config);
      
      // è¨­ç½®æ´»èºå¯¦é©—
      setActiveExperiments(prev => new Map(prev).set(algorithm, result.experiment_id));
      
      // å»ºç«‹WebSocketé€£æ¥ç”¨æ–¼å³æ™‚æ›´æ–°
      const ws = rlTrainingAPI.connectLiveUpdates(result.experiment_id, (data) => {
        updateMetricsFromProgress(algorithm, data);
      });
      
      wsConnections.current.set(result.experiment_id, ws);
      
      // ç™¼é€è‡ªå®šç¾©äº‹ä»¶ï¼ˆä¿æŒèˆ‡ç¾æœ‰ä»£ç¢¼çš„å…¼å®¹æ€§ï¼‰
      const event = new CustomEvent(`${algorithm}TrainingToggle`, {
        detail: { isTraining: true, experimentId: result.experiment_id }
      });
      window.dispatchEvent(event);
      
    } catch (err) {
      console.error(`å•Ÿå‹•${algorithm}è¨“ç·´å¤±æ•—:`, err);
      setError(`ç„¡æ³•å•Ÿå‹•${algorithm.toUpperCase()}è¨“ç·´`);
    }
  };

  // æ›´æ–°æŒ‡æ¨™å¾é€²åº¦æ•¸æ“š
  const updateMetricsFromProgress = (algorithm: 'dqn' | 'ppo', progressData: any) => {
    const updateFunc = algorithm === 'dqn' ? setDqnMetrics : setPpoMetrics;
    
    updateFunc(prev => ({
      ...prev,
      episodes_completed: progressData.stats.episodes_completed,
      average_reward: progressData.stats.avg_reward,
      training_progress: progressData.stats.progress_percentage,
      model_status: 'training'
    }));
  };

  // åœæ­¢è¨“ç·´
  const stopTraining = (algorithm: 'dqn' | 'ppo') => {
    const experimentId = activeExperiments.get(algorithm);
    if (experimentId) {
      // é—œé–‰WebSocketé€£æ¥
      const ws = wsConnections.current.get(experimentId);
      if (ws) {
        ws.close();
        wsConnections.current.delete(experimentId);
      }
      
      // ç§»é™¤æ´»èºå¯¦é©—
      const newActiveExperiments = new Map(activeExperiments);
      newActiveExperiments.delete(algorithm);
      setActiveExperiments(newActiveExperiments);
    }

    // æ›´æ–°ç‹€æ…‹ç‚ºé–’ç½®
    const updateFunc = algorithm === 'dqn' ? setDqnMetrics : setPpoMetrics;
    updateFunc(prev => ({ ...prev, model_status: 'idle' }));

    // ç™¼é€åœæ­¢äº‹ä»¶
    const event = new CustomEvent(`${algorithm}TrainingToggle`, {
      detail: { isTraining: false }
    });
    window.dispatchEvent(event);
  };

  // çµ„ä»¶è¼‰å…¥æ™‚è¼‰å…¥æ•¸æ“š
  useEffect(() => {
    loadDashboardData();
    
    // è¨­ç½®å®šæœŸåˆ·æ–°ï¼ˆå¦‚æœæ²’æœ‰WebSocketé€£æ¥ï¼‰
    const interval = setInterval(() => {
      if (wsConnections.current.size === 0) {
        loadDashboardData();
      }
    }, 5000);

    return () => {
      clearInterval(interval);
      // é—œé–‰æ‰€æœ‰WebSocketé€£æ¥
      wsConnections.current.forEach(ws => ws.close());
    };
  }, [loadDashboardData]);

  // è™•ç†è¨“ç·´æ§åˆ¶
  const handleDQNTraining = () => {
    const isTraining = dqnMetrics.model_status === 'training';
    if (isTraining) {
      stopTraining('dqn');
    } else {
      startTraining('dqn');
    }
  };

  const handlePPOTraining = () => {
    const isTraining = ppoMetrics.model_status === 'training';
    if (isTraining) {
      stopTraining('ppo');
    } else {
      startTraining('ppo');
    }
  };

  const handleBothTraining = () => {
    const bothTraining = dqnMetrics.model_status === 'training' && 
                         ppoMetrics.model_status === 'training';
    
    if (bothTraining) {
      stopTraining('dqn');
      stopTraining('ppo');
    } else {
      startTraining('dqn');
      startTraining('ppo');
    }
  };

  // æ¸²æŸ“éŒ¯èª¤ç‹€æ…‹
  if (error) {
    return (
      <div className="rl-monitor-error">
        <div className="error-message">
          <h3>âŒ é€£æ¥éŒ¯èª¤</h3>
          <p>{error}</p>
          <button onClick={loadDashboardData} disabled={isLoading}>
            {isLoading ? 'é‡æ–°é€£æ¥ä¸­...' : 'é‡è©¦é€£æ¥'}
          </button>
        </div>
      </div>
    );
  }

  // å…¶é¤˜çš„æ¸²æŸ“é‚è¼¯ä¿æŒä¸è®Šï¼Œä½†æ•¸æ“šä¾†æºæ”¹ç‚ºçœŸå¯¦çš„è³‡æ–™åº«æ•¸æ“š
  return (
    <div className="rl-monitor">
      {/* ç¾æœ‰çš„UIçµ„ä»¶ï¼Œä½†æ•¸æ“šä¾†è‡ª dqnMetrics å’Œ ppoMetrics */}
      
      {/* æ·»åŠ æ•¸æ“šä¾†æºæŒ‡ç¤ºå™¨ */}
      <div className="data-source-indicator">
        {dashboardData ? (
          <span className="data-live">ğŸŸ¢ å³æ™‚æ•¸æ“š (å…± {dashboardData.active_experiments} å€‹æ´»èºå¯¦é©—)</span>
        ) : (
          <span className="data-loading">ğŸŸ¡ è¼‰å…¥ä¸­...</span>
        )}
      </div>
      
      {/* ç¾æœ‰çš„æ‰€æœ‰UIæ¸²æŸ“é‚è¼¯... */}
    </div>
  );
};

export default GymnasiumRLMonitor;
```

---

## ğŸš€ éƒ¨ç½²å’Œæ¸¬è©¦æ­¥é©Ÿ

### ç¬¬1æ­¥ï¼šè³‡æ–™åº«åˆå§‹åŒ–

```bash
# å•Ÿå‹•å®¹å™¨
make up

# é€²å…¥SimWorldå¾Œç«¯å®¹å™¨
docker exec -it simworld_backend bash

# é‹è¡Œè³‡æ–™åº«é·ç§»
python -c "
from app.db.base import Base
from app.core.database import engine
import asyncio

async def create_tables():
    from sqlmodel import SQLModel
    async with engine.begin() as conn:
        await conn.run_sync(SQLModel.metadata.create_all)
    print('RLè¨“ç·´è³‡æ–™è¡¨å»ºç«‹å®Œæˆ')

asyncio.run(create_tables())
"
```

### ç¬¬2æ­¥ï¼šæ¸¬è©¦APIç«¯é»

```bash
# æ¸¬è©¦å»ºç«‹å¯¦é©—
curl -X POST http://localhost:8888/api/v1/rl/experiments \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Test_DQN_Experiment",
    "algorithm": "dqn",
    "environment": "5g_ntn_handover",
    "total_episodes": 100,
    "hyperparameters": {
      "learning_rate": 0.001,
      "batch_size": 32
    }
  }'

# æ¸¬è©¦å„€è¡¨æ¿æ•¸æ“š
curl http://localhost:8888/api/v1/rl/dashboard
```

### ç¬¬3æ­¥ï¼šå‰ç«¯æ¸¬è©¦

```bash
# ç¢ºä¿å‰ç«¯èƒ½æ­£ç¢ºè¼‰å…¥
# è¨ªå• http://localhost:5173
# å°èˆªåˆ° Navbar > åœ–è¡¨åˆ†æ > RLç›£æ§
# é©—è­‰æ•¸æ“šä¾†æºå¾ "æ¨¡æ“¬æ•¸æ“š" è®Šç‚º "å³æ™‚æ•¸æ“š"
```

### ç¬¬4æ­¥ï¼šé©—è­‰å®Œæ•´æµç¨‹

1. **å»ºç«‹å¯¦é©—**: é»æ“Š"é–‹å§‹DQNè¨“ç·´"ï¼Œç¢ºèªå¾Œç«¯å»ºç«‹äº†æ–°å¯¦é©—
2. **å³æ™‚æ›´æ–°**: ç¢ºèªWebSocketé€£æ¥æ­£å¸¸ï¼Œæ•¸æ“šå³æ™‚æ›´æ–°
3. **æ•¸æ“šæŒä¹…åŒ–**: é‡æ–°æ•´ç†é é¢ï¼Œç¢ºèªæ•¸æ“šå¾è³‡æ–™åº«è¼‰å…¥
4. **æ­·å²æŸ¥è©¢**: æŸ¥çœ‹éå¾€çš„è¨“ç·´è¨˜éŒ„å’ŒæŒ‡æ¨™

---

## ğŸ“ˆ åŠŸèƒ½æ“´å±•å»ºè­°

### çŸ­æœŸæ“´å±• (1-2é€±)
- **æ¨¡å‹æª¢æŸ¥é»ç®¡ç†**: è‡ªå‹•ä¿å­˜è¨“ç·´å¥½çš„æ¨¡å‹
- **è¶…åƒæ•¸èª¿å„ª**: åœ¨UIä¸­èª¿æ•´è¨“ç·´åƒæ•¸
- **æ›´è±å¯Œçš„æŒ‡æ¨™**: æ·»åŠ æå¤±æ›²ç·šã€æ”¶æ–‚åˆ†æ

### ä¸­æœŸæ“´å±• (1å€‹æœˆ)
- **å¯¦é©—æ¯”è¼ƒ**: ä¸¦æ’æ¯”è¼ƒä¸åŒå¯¦é©—çš„æ•ˆæœ
- **è‡ªå‹•åŒ–è¨“ç·´**: åŸºæ–¼æ¢ä»¶è§¸ç™¼çš„è‡ªå‹•é‡è¨“ç·´
- **æ¨¡å‹éƒ¨ç½²**: ä¸€éµéƒ¨ç½²æœ€ä½³æ¨¡å‹åˆ°ç”Ÿç”¢ç’°å¢ƒ

### é•·æœŸæ“´å±• (3å€‹æœˆ)
- **A/Bæ¸¬è©¦æ¡†æ¶**: åœ¨çœŸå¯¦æµé‡ä¸­æ¸¬è©¦ä¸åŒæ¨¡å‹
- **è¯é‚¦å­¸ç¿’æ”¯æŒ**: åˆ†æ•£å¼è¨“ç·´èƒ½åŠ›
- **AutoMLæ•´åˆ**: è‡ªå‹•æœç´¢æœ€ä½³æ¶æ§‹å’Œè¶…åƒæ•¸

---

## ğŸ” ç¶­è­·å’Œç›£æ§

### è³‡æ–™åº«ç¶­è­·
```sql
-- æ¸…ç†èˆŠçš„è¨“ç·´æ­¥é©Ÿæ•¸æ“šï¼ˆä¿ç•™æœ€è¿‘30å¤©ï¼‰
DELETE FROM rl_steps 
WHERE timestamp < CURRENT_DATE - INTERVAL '30 days';

-- æ­¸æª”å®Œæˆçš„å¯¦é©—
UPDATE rl_experiments 
SET status = 'archived' 
WHERE status = 'completed' 
  AND completed_at < CURRENT_DATE - INTERVAL '90 days';
```

### æ•ˆèƒ½ç›£æ§
- ç›£æ§è³‡æ–™åº«æŸ¥è©¢æ•ˆèƒ½
- è¨­ç½®WebSocketé€£æ¥æ•¸é™åˆ¶
- å®šæœŸæ¸…ç†éæœŸçš„æ¨¡å‹æª”æ¡ˆ

### éŒ¯èª¤è™•ç†
- APIè«‹æ±‚å¤±æ•—çš„é™ç´šæ©Ÿåˆ¶
- WebSocketæ–·ç·šé‡é€£é‚è¼¯
- è³‡æ–™ä¸ä¸€è‡´çš„è‡ªå‹•ä¿®å¾©

---

## ğŸ“‹ ç¸½çµ

æœ¬å¯¦ç¾æµç¨‹æ¶µè“‹äº†å¾å‰ç«¯æ¨¡æ“¬æ•¸æ“šåˆ°å®Œæ•´è³‡æ–™åº«é©…å‹•çš„RLç›£æ§ç³»çµ±è½‰æ›ã€‚ä¸»è¦ç‰¹è‰²ï¼š

âœ… **å®Œæ•´çš„è³‡æ–™æŒä¹…åŒ–** - æ‰€æœ‰è¨“ç·´æ•¸æ“šä¿å­˜åˆ°PostgreSQL  
âœ… **å³æ™‚æ›´æ–°æ©Ÿåˆ¶** - WebSocketæä¾›ä½å»¶é²çš„æ•¸æ“šæ›´æ–°  
âœ… **å‘å¾Œå…¼å®¹** - ä¿æŒç¾æœ‰å‰ç«¯çµ„ä»¶çš„ä»‹é¢ä¸è®Š  
âœ… **å¯æ“´å±•æ¶æ§‹** - é ˜åŸŸé©…å‹•è¨­è¨ˆï¼Œæ˜“æ–¼æ·»åŠ æ–°åŠŸèƒ½  
âœ… **ç”Ÿç”¢å°±ç·’** - åŒ…å«éŒ¯èª¤è™•ç†ã€æ•ˆèƒ½å„ªåŒ–ã€ç¶­è­·ç­–ç•¥

é€éé€™å€‹å¯¦ç¾ï¼ŒRLç›£æ§é é¢å°‡å¾å±•ç¤ºå·¥å…·å‡ç´šç‚ºå®Œæ•´çš„æ©Ÿå™¨å­¸ç¿’å¯¦é©—ç®¡ç†å¹³å°ã€‚