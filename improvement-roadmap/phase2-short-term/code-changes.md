# Phase 2: ç¨‹å¼ç¢¼ä¿®æ”¹æŒ‡å—

**ä¿®æ”¹ç¯„åœ**: æ¸¬è©¦æ¡†æ¶ã€ç›£æ§ç³»çµ±ã€é…ç½®ç®¡ç†
**å½±éŸ¿è©•ä¼°**: ä½-ä¸­ç­‰ - ä¸»è¦æ˜¯æ–°å¢åŠŸèƒ½ï¼Œä¸å½±éŸ¿æ ¸å¿ƒé‚è¼¯

## ğŸ§ª æ¸¬è©¦æ¡†æ¶æ“´å±•

### 1. æ“´å±•æ¸¬è©¦è¦†è“‹ç‡

#### æ–°å¢æª”æ¡ˆ: `/tests/unit/test_satellite_config_extended.py`
```python
"""
è¡›æ˜Ÿé…ç½®ç³»çµ±æ“´å±•æ¸¬è©¦
ç¢ºä¿é…ç½®åœ¨å„ç¨®é‚Šç•Œæ¢ä»¶ä¸‹çš„æ­£ç¢ºæ€§
"""

import pytest
from unittest.mock import patch, MagicMock
from config.satellite_config import SatelliteConfig, SATELLITE_CONFIG

class TestSatelliteConfigExtended:
    """è¡›æ˜Ÿé…ç½®æ“´å±•æ¸¬è©¦"""
    
    def test_config_boundary_values(self):
        """æ¸¬è©¦é…ç½®é‚Šç•Œå€¼"""
        # æ¸¬è©¦æœ€å¤§å€™é¸è¡›æ˜Ÿæ•¸é‚Šç•Œ
        assert SATELLITE_CONFIG.MAX_CANDIDATE_SATELLITES == 8
        
        # æ¸¬è©¦é è™•ç†è¡›æ˜Ÿæ•¸é‡åˆç†æ€§
        total_preprocess = sum(SATELLITE_CONFIG.PREPROCESS_SATELLITES.values())
        assert 50 <= total_preprocess <= 100
        
        # æ¸¬è©¦å»ºç½®æ™‚é–“é™åˆ¶
        assert SATELLITE_CONFIG.MAX_BUILD_TIME_MINUTES <= 15
    
    def test_config_validation_edge_cases(self):
        """æ¸¬è©¦é…ç½®é©—è­‰é‚Šç•Œæƒ…æ³"""
        # å‚™ä»½åŸå§‹é…ç½®
        original_max = SATELLITE_CONFIG.MAX_CANDIDATE_SATELLITES
        
        try:
            # æ¸¬è©¦è¶…å‡º SIB19 é™åˆ¶
            SATELLITE_CONFIG.MAX_CANDIDATE_SATELLITES = 10
            with pytest.raises(ValueError, match="ä¸å¾—è¶…é SIB19 è¦ç¯„"):
                SATELLITE_CONFIG.validate_configuration()
            
            # æ¸¬è©¦é è™•ç†è¡›æ˜Ÿæ•¸é‡éå¤š
            SATELLITE_CONFIG.PREPROCESS_SATELLITES = {'starlink': 80, 'oneweb': 50}
            with pytest.raises(ValueError, match="é è™•ç†è¡›æ˜Ÿç¸½æ•¸éå¤š"):
                SATELLITE_CONFIG.validate_configuration()
                
        finally:
            # æ¢å¾©åŸå§‹é…ç½®
            SATELLITE_CONFIG.MAX_CANDIDATE_SATELLITES = original_max
            SATELLITE_CONFIG.PREPROCESS_SATELLITES = {'starlink': 40, 'oneweb': 30}
    
    def test_configuration_immutability(self):
        """æ¸¬è©¦é…ç½®ä¸å¯è®Šæ€§"""
        original_config = SATELLITE_CONFIG.PREPROCESS_SATELLITES.copy()
        
        # å˜—è©¦ä¿®æ”¹é…ç½®
        SATELLITE_CONFIG.PREPROCESS_SATELLITES['starlink'] = 100
        
        # é©—è­‰é…ç½®æ‡‰è©²è¢«é‡ç½®æˆ–ä¿è­·
        # ï¼ˆé€™å€‹æ¸¬è©¦ç”¨æ–¼ç¢ºä¿é…ç½®ç®¡ç†çš„å¥å£¯æ€§ï¼‰
        assert SATELLITE_CONFIG.PREPROCESS_SATELLITES['starlink'] == 100
        
        # æ¢å¾©åŸå§‹é…ç½®
        SATELLITE_CONFIG.PREPROCESS_SATELLITES = original_config
    
    @patch('config.satellite_config.logger')
    def test_config_logging(self, mock_logger):
        """æ¸¬è©¦é…ç½®è®Šæ›´æ—¥èªŒè¨˜éŒ„"""
        # æ¨¡æ“¬é…ç½®è®Šæ›´
        SATELLITE_CONFIG.validate_configuration()
        
        # é©—è­‰æ˜¯å¦æœ‰é©ç•¶çš„æ—¥èªŒè¨˜éŒ„
        # é€™è£¡éœ€è¦å¯¦éš›çš„æ—¥èªŒè¨˜éŒ„æ©Ÿåˆ¶
        pass
```

#### æ–°å¢æª”æ¡ˆ: `/tests/integration/test_preprocessing_pipeline.py`
```python
"""
é è™•ç†ç®¡é“æ•´åˆæ¸¬è©¦
æ¸¬è©¦å¾ TLE æ•¸æ“šåˆ°æœ€çµ‚è¼¸å‡ºçš„å®Œæ•´æµç¨‹
"""

import pytest
import asyncio
import json
import tempfile
from pathlib import Path
from datetime import datetime, timezone

from simworld.backend.preprocess_120min_timeseries import TimeseriesPreprocessor
from config.satellite_config import SATELLITE_CONFIG

class TestPreprocessingPipeline:
    """é è™•ç†ç®¡é“æ•´åˆæ¸¬è©¦"""
    
    @pytest.fixture
    def temp_data_dir(self):
        """å‰µå»ºè‡¨æ™‚æ•¸æ“šç›®éŒ„"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield Path(temp_dir)
    
    @pytest.fixture
    def sample_tle_data(self):
        """æä¾›æ¸¬è©¦ç”¨ TLE æ•¸æ“š"""
        return [
            {
                "name": "STARLINK-1234",
                "norad_id": 12345,
                "line1": "1 12345U 20001A   21001.00000000  .00002182  00000-0  40917-4 0  9990",
                "line2": "2 12345  53.0000 339.2911 0002829  86.4002 273.8155 15.48919103260342",
                "INCLINATION": 53.0,
                "RA_OF_ASC_NODE": 339.2911
            },
            {
                "name": "STARLINK-5678", 
                "norad_id": 56789,
                "line1": "1 56789U 20002B   21001.00000000  .00001892  00000-0  35821-4 0  9991",
                "line2": "2 56789  53.1000 340.1234 0001234  87.5678 274.9876 15.49012345260343",
                "INCLINATION": 53.1,
                "RA_OF_ASC_NODE": 340.1234
            }
        ]
    
    @pytest.mark.asyncio
    async def test_full_preprocessing_pipeline(self, temp_data_dir, sample_tle_data):
        """æ¸¬è©¦å®Œæ•´çš„é è™•ç†ç®¡é“"""
        # è¨­ç½®æ¸¬è©¦ç’°å¢ƒ
        preprocessor = TimeseriesPreprocessor()
        preprocessor.data_output_path = temp_data_dir
        
        # æ¨¡æ“¬ TLE æ•¸æ“šè¼‰å…¥
        with patch.object(preprocessor, '_load_constellation_tle_data') as mock_load:
            mock_load.return_value = sample_tle_data
            
            # åŸ·è¡Œé è™•ç†
            result = await preprocessor._generate_constellation_timeseries("starlink")
            
            # é©—è­‰çµæœçµæ§‹
            assert result is not None
            assert "metadata" in result
            assert "satellites" in result
            assert "ue_trajectory" in result
            
            # é©—è­‰å…ƒæ•¸æ“š
            metadata = result["metadata"]
            assert metadata["constellation"] == "starlink"
            assert "calculation_method" in metadata
            assert "satellites_processed" in metadata
            
            # é©—è­‰è¡›æ˜Ÿæ•¸æ“š
            satellites = result["satellites"]
            assert len(satellites) <= SATELLITE_CONFIG.PREPROCESS_SATELLITES["starlink"]
            
            for sat in satellites:
                assert "norad_id" in sat
                assert "name" in sat
                assert "time_series" in sat
                assert "calculation_method" in sat
    
    @pytest.mark.asyncio 
    async def test_sgp4_fallback_mechanism(self, temp_data_dir, sample_tle_data):
        """æ¸¬è©¦ SGP4 å¤±æ•—æ™‚çš„å›é€€æ©Ÿåˆ¶"""
        preprocessor = TimeseriesPreprocessor()
        preprocessor.use_sgp4_in_build = True
        
        # æ¨¡æ“¬ SGP4 è¨ˆç®—å¤±æ•—
        with patch('simworld.backend.app.services.sgp4_calculator.SGP4Calculator') as mock_calculator:
            mock_instance = MagicMock()
            mock_instance.propagate_orbit.return_value = None  # æ¨¡æ“¬å¤±æ•—
            mock_calculator.return_value = mock_instance
            
            with patch.object(preprocessor, '_calculate_simplified_satellite_timeseries') as mock_simplified:
                mock_simplified.return_value = [{"test": "data"}]
                
                # åŸ·è¡Œæ¸¬è©¦
                result = await preprocessor._calculate_sgp4_satellite_timeseries(
                    sample_tle_data[0], datetime.now(timezone.utc)
                )
                
                # é©—è­‰å›é€€åˆ°ç°¡åŒ–æ¨¡å‹
                mock_simplified.assert_called_once()
                assert result == [{"test": "data"}]
    
    @pytest.mark.performance
    async def test_preprocessing_performance(self, sample_tle_data):
        """æ¸¬è©¦é è™•ç†æ€§èƒ½"""
        import time
        
        preprocessor = TimeseriesPreprocessor()
        
        start_time = time.time()
        
        # æ¸¬è©¦å°è¦æ¨¡è™•ç†ï¼ˆ3é¡†è¡›æ˜Ÿï¼‰
        with patch.object(preprocessor, '_load_constellation_tle_data') as mock_load:
            mock_load.return_value = sample_tle_data[:3]
            
            result = await preprocessor._generate_constellation_timeseries("starlink")
            
        processing_time = time.time() - start_time
        
        # é©—è­‰æ€§èƒ½åŸºæº–ï¼šæ¯é¡†è¡›æ˜Ÿè™•ç†æ™‚é–“ < 2ç§’
        satellites_count = len(result["satellites"]) if result else 0
        if satellites_count > 0:
            time_per_satellite = processing_time / satellites_count
            assert time_per_satellite < 2.0, f"è™•ç†æ™‚é–“éé•·: {time_per_satellite:.2f}s/è¡›æ˜Ÿ"
        
        # é©—è­‰ç¸½è™•ç†æ™‚é–“ < 10ç§’
        assert processing_time < 10.0, f"ç¸½è™•ç†æ™‚é–“éé•·: {processing_time:.2f}s"
```

### 2. æ€§èƒ½ç›£æ§æ¸¬è©¦

#### æ–°å¢æª”æ¡ˆ: `/tests/performance/test_system_performance.py`
```python
"""
ç³»çµ±æ€§èƒ½å›æ­¸æ¸¬è©¦
ç›£æ§é—œéµæ€§èƒ½æŒ‡æ¨™ï¼Œé˜²æ­¢æ€§èƒ½å›æ­¸
"""

import pytest
import time
import psutil
import requests
from contextlib import contextmanager

class TestSystemPerformance:
    """ç³»çµ±æ€§èƒ½æ¸¬è©¦"""
    
    @contextmanager
    def measure_time(self):
        """æ¸¬é‡åŸ·è¡Œæ™‚é–“çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        start_time = time.time()
        yield lambda: time.time() - start_time
        
    @contextmanager
    def measure_memory(self):
        """æ¸¬é‡è¨˜æ†¶é«”ä½¿ç”¨çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        process = psutil.Process()
        start_memory = process.memory_info().rss / 1024 / 1024  # MB
        yield lambda: process.memory_info().rss / 1024 / 1024 - start_memory
    
    @pytest.mark.performance
    def test_api_response_time(self):
        """æ¸¬è©¦ API éŸ¿æ‡‰æ™‚é–“"""
        endpoints = [
            "http://localhost:8080/health",
            "http://localhost:8080/api/v1/satellites/unified/health", 
            "http://localhost:8888/health"
        ]
        
        for endpoint in endpoints:
            with self.measure_time() as get_time:
                try:
                    response = requests.get(endpoint, timeout=5)
                    response.raise_for_status()
                except requests.exceptions.RequestException as e:
                    pytest.skip(f"æœå‹™ä¸å¯ç”¨: {endpoint} - {e}")
            
            response_time = get_time()
            assert response_time < 0.1, f"{endpoint} éŸ¿æ‡‰æ™‚é–“éé•·: {response_time:.3f}s"
    
    @pytest.mark.performance
    def test_docker_build_time(self):
        """æ¸¬è©¦ Docker å»ºç½®æ™‚é–“ï¼ˆåƒ…åœ¨ CI ç’°å¢ƒåŸ·è¡Œï¼‰"""
        import subprocess
        import os
        
        if not os.getenv('CI'):
            pytest.skip("åƒ…åœ¨ CI ç’°å¢ƒåŸ·è¡Œå»ºç½®æ™‚é–“æ¸¬è©¦")
        
        with self.measure_time() as get_time:
            try:
                result = subprocess.run(
                    ['docker', 'build', '-t', 'test-build', '.'],
                    capture_output=True,
                    timeout=1800  # 30åˆ†é˜è¶…æ™‚
                )
                assert result.returncode == 0, f"å»ºç½®å¤±æ•—: {result.stderr.decode()}"
            except subprocess.TimeoutExpired:
                pytest.fail("å»ºç½®è¶…æ™‚ï¼ˆ30åˆ†é˜ï¼‰")
        
        build_time = get_time()
        assert build_time < 900, f"å»ºç½®æ™‚é–“éé•·: {build_time:.1f}sï¼ˆç›®æ¨™: <15åˆ†é˜ï¼‰"
    
    @pytest.mark.performance  
    def test_memory_usage_baseline(self):
        """æ¸¬è©¦è¨˜æ†¶é«”ä½¿ç”¨åŸºæº–"""
        # é€™å€‹æ¸¬è©¦éœ€è¦åœ¨å®¹å™¨å…§åŸ·è¡Œæˆ–æ¨¡æ“¬å®¹å™¨ç’°å¢ƒ
        current_memory = psutil.virtual_memory().used / 1024 / 1024 / 1024  # GB
        
        # åŸºæº–ï¼šç³»çµ±ç¸½è¨˜æ†¶é«”ä½¿ç”¨ < 2GBï¼ˆé€™éœ€è¦æ ¹æ“šå¯¦éš›ç’°å¢ƒèª¿æ•´ï¼‰
        available_memory = psutil.virtual_memory().available / 1024 / 1024 / 1024
        
        # ç¢ºä¿æœ‰è¶³å¤ çš„å¯ç”¨è¨˜æ†¶é«”
        assert available_memory > 1.0, f"å¯ç”¨è¨˜æ†¶é«”ä¸è¶³: {available_memory:.2f}GB"
    
    @pytest.mark.performance
    def test_data_processing_throughput(self):
        """æ¸¬è©¦æ•¸æ“šè™•ç†ååé‡"""
        from simworld.backend.preprocess_120min_timeseries import TimeseriesPreprocessor
        
        # å‰µå»ºæ¸¬è©¦æ•¸æ“š
        test_satellites = [
            {"name": f"TEST-{i}", "norad_id": i, "line1": "test", "line2": "test"}
            for i in range(10)
        ]
        
        preprocessor = TimeseriesPreprocessor()
        
        with self.measure_time() as get_time:
            # æ¨¡æ“¬è™•ç†å¤šé¡†è¡›æ˜Ÿ
            processed_count = 0
            for sat in test_satellites:
                # é€™è£¡æ‡‰è©²èª¿ç”¨å¯¦éš›çš„è™•ç†é‚è¼¯
                # ç›®å‰ç°¡åŒ–ç‚ºè¨ˆæ•¸
                processed_count += 1
        
        processing_time = get_time()
        throughput = processed_count / processing_time  # è¡›æ˜Ÿ/ç§’
        
        # åŸºæº–ï¼šè™•ç†ååé‡ > 5 è¡›æ˜Ÿ/ç§’
        assert throughput > 5.0, f"è™•ç†ååé‡éä½: {throughput:.2f} è¡›æ˜Ÿ/ç§’"
```

## ğŸ“Š ç›£æ§ç³»çµ±å¯¦æ–½

### 3. æ€§èƒ½ç›£æ§å„€è¡¨æ¿

#### æ–°å¢æª”æ¡ˆ: `/monitoring/performance_monitor.py`
```python
"""
æ€§èƒ½ç›£æ§ç³»çµ±
å¯¦æ™‚ç›£æ§ç³»çµ±é—œéµæŒ‡æ¨™ä¸¦ç”Ÿæˆå ±å‘Š
"""

import time
import psutil
import logging
import json
from datetime import datetime, timezone
from typing import Dict, List, Any
from dataclasses import dataclass, asdict
from pathlib import Path

logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ¨™æ•¸æ“šçµæ§‹"""
    timestamp: str
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    disk_usage_percent: float
    api_response_times: Dict[str, float]
    active_connections: int
    error_count: int

class PerformanceMonitor:
    """æ€§èƒ½ç›£æ§å™¨"""
    
    def __init__(self, output_dir: Path = None):
        self.output_dir = output_dir or Path("./monitoring/data")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç›£æ§é…ç½®
        self.api_endpoints = [
            "http://localhost:8080/health",
            "http://localhost:8080/api/v1/satellites/unified/health",
            "http://localhost:8888/health"
        ]
        
        self.metrics_history: List[PerformanceMetrics] = []
        
    def collect_system_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†ç³»çµ±æ€§èƒ½æŒ‡æ¨™"""
        try:
            # CPU å’Œè¨˜æ†¶é«”
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            # API éŸ¿æ‡‰æ™‚é–“
            api_times = {}
            for endpoint in self.api_endpoints:
                try:
                    start_time = time.time()
                    import requests
                    response = requests.get(endpoint, timeout=5)
                    api_times[endpoint] = time.time() - start_time
                except Exception as e:
                    api_times[endpoint] = -1  # è¡¨ç¤ºå¤±æ•—
                    logger.warning(f"API ç›£æ§å¤±æ•— {endpoint}: {e}")
            
            # å‰µå»ºæŒ‡æ¨™å°è±¡
            metrics = PerformanceMetrics(
                timestamp=datetime.now(timezone.utc).isoformat(),
                cpu_percent=cpu_percent,
                memory_percent=memory.percent,
                memory_used_mb=memory.used / 1024 / 1024,
                disk_usage_percent=disk.percent,
                api_response_times=api_times,
                active_connections=len(psutil.net_connections()),
                error_count=0  # é€™éœ€è¦å¾æ—¥èªŒæˆ–å…¶ä»–ä¾†æºç²å–
            )
            
            self.metrics_history.append(metrics)
            
            return metrics
            
        except Exception as e:
            logger.error(f"æ”¶é›†æ€§èƒ½æŒ‡æ¨™å¤±æ•—: {e}")
            raise
    
    def save_metrics(self, metrics: PerformanceMetrics):
        """ä¿å­˜æ€§èƒ½æŒ‡æ¨™åˆ°æª”æ¡ˆ"""
        try:
            timestamp = datetime.fromisoformat(metrics.timestamp.replace('Z', '+00:00'))
            filename = f"metrics_{timestamp.strftime('%Y%m%d_%H%M%S')}.json"
            filepath = self.output_dir / filename
            
            with open(filepath, 'w') as f:
                json.dump(asdict(metrics), f, indent=2)
                
            logger.info(f"æ€§èƒ½æŒ‡æ¨™å·²ä¿å­˜: {filepath}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ€§èƒ½æŒ‡æ¨™å¤±æ•—: {e}")
    
    def generate_performance_report(self, hours: int = 24) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        if not self.metrics_history:
            return {"error": "ç„¡å¯ç”¨çš„æ€§èƒ½æ•¸æ“š"}
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        recent_metrics = self.metrics_history[-hours:] if len(self.metrics_history) >= hours else self.metrics_history
        
        cpu_values = [m.cpu_percent for m in recent_metrics]
        memory_values = [m.memory_percent for m in recent_metrics]
        
        # API éŸ¿æ‡‰æ™‚é–“çµ±è¨ˆ
        api_stats = {}
        for endpoint in self.api_endpoints:
            response_times = [
                m.api_response_times.get(endpoint, -1) 
                for m in recent_metrics 
                if m.api_response_times.get(endpoint, -1) > 0
            ]
            
            if response_times:
                api_stats[endpoint] = {
                    "average": sum(response_times) / len(response_times),
                    "max": max(response_times),
                    "min": min(response_times),
                    "success_rate": len(response_times) / len(recent_metrics)
                }
        
        report = {
            "report_time": datetime.now(timezone.utc).isoformat(),
            "time_range_hours": hours,
            "data_points": len(recent_metrics),
            "system_performance": {
                "cpu": {
                    "average": sum(cpu_values) / len(cpu_values),
                    "max": max(cpu_values),
                    "min": min(cpu_values)
                },
                "memory": {
                    "average": sum(memory_values) / len(memory_values),
                    "max": max(memory_values),
                    "min": min(memory_values)
                }
            },
            "api_performance": api_stats,
            "alerts": self._generate_alerts(recent_metrics)
        }
        
        return report
    
    def _generate_alerts(self, metrics: List[PerformanceMetrics]) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½å‘Šè­¦"""
        alerts = []
        
        if not metrics:
            return alerts
        
        latest = metrics[-1]
        
        # CPU å‘Šè­¦
        if latest.cpu_percent > 80:
            alerts.append(f"é«˜ CPU ä½¿ç”¨ç‡: {latest.cpu_percent:.1f}%")
        
        # è¨˜æ†¶é«”å‘Šè­¦
        if latest.memory_percent > 85:
            alerts.append(f"é«˜è¨˜æ†¶é«”ä½¿ç”¨ç‡: {latest.memory_percent:.1f}%")
        
        # API éŸ¿æ‡‰æ™‚é–“å‘Šè­¦
        for endpoint, response_time in latest.api_response_times.items():
            if response_time > 0.5:  # 500ms
                alerts.append(f"API éŸ¿æ‡‰ç·©æ…¢: {endpoint} ({response_time:.3f}s)")
            elif response_time == -1:
                alerts.append(f"API ç„¡éŸ¿æ‡‰: {endpoint}")
        
        return alerts
    
    def start_monitoring(self, interval_seconds: int = 60):
        """é–‹å§‹æŒçºŒç›£æ§"""
        logger.info(f"é–‹å§‹æ€§èƒ½ç›£æ§ï¼Œé–“éš” {interval_seconds} ç§’")
        
        try:
            while True:
                metrics = self.collect_system_metrics()
                self.save_metrics(metrics)
                
                # æª¢æŸ¥å‘Šè­¦
                alerts = self._generate_alerts([metrics])
                if alerts:
                    for alert in alerts:
                        logger.warning(f"æ€§èƒ½å‘Šè­¦: {alert}")
                
                time.sleep(interval_seconds)
                
        except KeyboardInterrupt:
            logger.info("æ€§èƒ½ç›£æ§å·²åœæ­¢")
        except Exception as e:
            logger.error(f"æ€§èƒ½ç›£æ§éŒ¯èª¤: {e}")
            raise

# CLI æ¥å£
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æ€§èƒ½ç›£æ§ç³»çµ±")
    parser.add_argument("--interval", type=int, default=60, help="ç›£æ§é–“éš”ï¼ˆç§’ï¼‰")
    parser.add_argument("--output-dir", type=Path, help="è¼¸å‡ºç›®éŒ„")
    parser.add_argument("--report", action="store_true", help="ç”Ÿæˆæ€§èƒ½å ±å‘Š")
    
    args = parser.parse_args()
    
    monitor = PerformanceMonitor(args.output_dir)
    
    if args.report:
        # è¼‰å…¥æ­·å²æ•¸æ“šä¸¦ç”Ÿæˆå ±å‘Š
        report = monitor.generate_performance_report()
        print(json.dumps(report, indent=2))
    else:
        # é–‹å§‹ç›£æ§
        monitor.start_monitoring(args.interval)
```

### 4. è‡ªå‹•åŒ–é…ç½®ç®¡ç†

#### æ–°å¢æª”æ¡ˆ: `/config/environment_config.py`
```python
"""
å¤šç’°å¢ƒé…ç½®ç®¡ç†
æ”¯æ´é–‹ç™¼ã€æ¸¬è©¦ã€é ç™¼ä½ˆã€ç”Ÿç”¢ç’°å¢ƒçš„é…ç½®åˆ†é›¢
"""

import os
import json
import logging
from enum import Enum
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass

logger = logging.getLogger(__name__)

class Environment(Enum):
    """ç’°å¢ƒé¡å‹æšèˆ‰"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

@dataclass
class DatabaseConfig:
    """æ•¸æ“šåº«é…ç½®"""
    host: str
    port: int
    database: str
    username: str
    password: str
    
@dataclass
class APIConfig:
    """API é…ç½®"""
    host: str
    port: int
    debug: bool
    timeout_seconds: int

@dataclass
class SatelliteConfig:
    """è¡›æ˜Ÿç³»çµ±é…ç½®"""
    max_candidates: int
    preprocess_counts: Dict[str, int]
    use_sgp4_in_build: bool
    build_timeout_minutes: int

class EnvironmentConfigManager:
    """ç’°å¢ƒé…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_dir: Path = None):
        self.config_dir = config_dir or Path("./config/environments")
        self.config_dir.mkdir(parents=True, exist_ok=True)
        
        # å¾ç’°å¢ƒè®Šæ•¸æˆ–é»˜èªå€¼ç¢ºå®šç•¶å‰ç’°å¢ƒ
        self.current_env = Environment(
            os.getenv("NTN_ENVIRONMENT", Environment.DEVELOPMENT.value)
        )
        
        logger.info(f"ç•¶å‰ç’°å¢ƒ: {self.current_env.value}")
        
    def load_environment_config(self, env: Environment = None) -> Dict[str, Any]:
        """è¼‰å…¥æŒ‡å®šç’°å¢ƒçš„é…ç½®"""
        env = env or self.current_env
        config_file = self.config_dir / f"{env.value}.json"
        
        if not config_file.exists():
            logger.warning(f"é…ç½®æª”æ¡ˆä¸å­˜åœ¨: {config_file}")
            return self._get_default_config(env)
        
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
                
            logger.info(f"å·²è¼‰å…¥ {env.value} ç’°å¢ƒé…ç½®")
            return config
            
        except Exception as e:
            logger.error(f"è¼‰å…¥é…ç½®å¤±æ•—: {e}")
            return self._get_default_config(env)
    
    def save_environment_config(self, config: Dict[str, Any], env: Environment = None):
        """ä¿å­˜ç’°å¢ƒé…ç½®"""
        env = env or self.current_env
        config_file = self.config_dir / f"{env.value}.json"
        
        try:
            with open(config_file, 'w') as f:
                json.dump(config, f, indent=2)
                
            logger.info(f"å·²ä¿å­˜ {env.value} ç’°å¢ƒé…ç½®")
            
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®å¤±æ•—: {e}")
            raise
    
    def _get_default_config(self, env: Environment) -> Dict[str, Any]:
        """ç²å–é»˜èªé…ç½®"""
        base_config = {
            "database": {
                "host": "localhost",
                "port": 5432,
                "database": "ntn_stack",
                "username": "postgres",
                "password": "password"
            },
            "api": {
                "host": "0.0.0.0",
                "port": 8080,
                "debug": False,
                "timeout_seconds": 30
            },
            "satellite": {
                "max_candidates": 8,
                "preprocess_counts": {
                    "starlink": 40,
                    "oneweb": 30
                },
                "use_sgp4_in_build": False,
                "build_timeout_minutes": 10
            }
        }
        
        # ç’°å¢ƒç‰¹å®šçš„é…ç½®è¦†è“‹
        if env == Environment.DEVELOPMENT:
            base_config["api"]["debug"] = True
            base_config["api"]["port"] = 8080
            
        elif env == Environment.TESTING:
            base_config["database"]["database"] = "ntn_stack_test"
            base_config["api"]["port"] = 8081
            base_config["satellite"]["preprocess_counts"] = {"starlink": 5, "oneweb": 3}
            
        elif env == Environment.STAGING:
            base_config["api"]["port"] = 8082
            base_config["satellite"]["use_sgp4_in_build"] = True
            
        elif env == Environment.PRODUCTION:
            base_config["api"]["debug"] = False
            base_config["api"]["timeout_seconds"] = 60
            base_config["satellite"]["build_timeout_minutes"] = 15
        
        return base_config
    
    def get_database_config(self) -> DatabaseConfig:
        """ç²å–æ•¸æ“šåº«é…ç½®"""
        config = self.load_environment_config()
        db_config = config.get("database", {})
        
        return DatabaseConfig(
            host=db_config.get("host", "localhost"),
            port=db_config.get("port", 5432),
            database=db_config.get("database", "ntn_stack"),
            username=db_config.get("username", "postgres"),
            password=db_config.get("password", "password")
        )
    
    def get_api_config(self) -> APIConfig:
        """ç²å– API é…ç½®"""
        config = self.load_environment_config()
        api_config = config.get("api", {})
        
        return APIConfig(
            host=api_config.get("host", "0.0.0.0"),
            port=api_config.get("port", 8080),
            debug=api_config.get("debug", False),
            timeout_seconds=api_config.get("timeout_seconds", 30)
        )
    
    def get_satellite_config(self) -> SatelliteConfig:
        """ç²å–è¡›æ˜Ÿç³»çµ±é…ç½®"""
        config = self.load_environment_config()
        sat_config = config.get("satellite", {})
        
        return SatelliteConfig(
            max_candidates=sat_config.get("max_candidates", 8),
            preprocess_counts=sat_config.get("preprocess_counts", {"starlink": 40, "oneweb": 30}),
            use_sgp4_in_build=sat_config.get("use_sgp4_in_build", False),
            build_timeout_minutes=sat_config.get("build_timeout_minutes", 10)
        )
    
    def validate_current_config(self) -> bool:
        """é©—è­‰ç•¶å‰ç’°å¢ƒé…ç½®"""
        try:
            config = self.load_environment_config()
            
            # åŸºæœ¬çµæ§‹é©—è­‰
            required_sections = ["database", "api", "satellite"]
            for section in required_sections:
                if section not in config:
                    logger.error(f"ç¼ºå°‘é…ç½®æ®µè½: {section}")
                    return False
            
            # è¡›æ˜Ÿé…ç½®é©—è­‰
            sat_config = self.get_satellite_config()
            if sat_config.max_candidates > 8:
                logger.error("å€™é¸è¡›æ˜Ÿæ•¸è¶…é SIB19 é™åˆ¶")
                return False
            
            total_preprocess = sum(sat_config.preprocess_counts.values())
            if total_preprocess > 100:
                logger.error("é è™•ç†è¡›æ˜Ÿç¸½æ•¸éå¤š")
                return False
            
            logger.info("é…ç½®é©—è­‰é€šé")
            return True
            
        except Exception as e:
            logger.error(f"é…ç½®é©—è­‰å¤±æ•—: {e}")
            return False

# å…¨å±€é…ç½®ç®¡ç†å™¨å¯¦ä¾‹
CONFIG_MANAGER = EnvironmentConfigManager()

# ä¾¿æ·å‡½æ•¸
def get_current_environment() -> Environment:
    """ç²å–ç•¶å‰ç’°å¢ƒ"""
    return CONFIG_MANAGER.current_env

def get_database_config() -> DatabaseConfig:
    """ç²å–æ•¸æ“šåº«é…ç½®"""
    return CONFIG_MANAGER.get_database_config()

def get_api_config() -> APIConfig:
    """ç²å– API é…ç½®"""
    return CONFIG_MANAGER.get_api_config()

def get_satellite_config() -> SatelliteConfig:
    """ç²å–è¡›æ˜Ÿé…ç½®"""
    return CONFIG_MANAGER.get_satellite_config()
```

## ğŸ“‹ ç¨‹å¼ç¢¼å¯©æŸ¥æª¢æŸ¥æ¸…å–®

### æ¸¬è©¦ä»£ç¢¼å“è³ª
- [ ] æ¸¬è©¦è¦†è“‹ç‡é”åˆ°ç›®æ¨™ (90%)
- [ ] æ¸¬è©¦æ¡ˆä¾‹æ¶µè“‹é‚Šç•Œæ¢ä»¶
- [ ] æ¸¬è©¦åŸ·è¡Œæ™‚é–“åˆç† (< 10åˆ†é˜)
- [ ] æ¸¬è©¦çµæœç©©å®šå¯é‡è¤‡

### ç›£æ§ç³»çµ±å¥å£¯æ€§
- [ ] ç›£æ§æŒ‡æ¨™å®šç¾©æ¸…æ™°
- [ ] å‘Šè­¦é–¾å€¼è¨­å®šåˆç†
- [ ] éŒ¯èª¤è™•ç†å®Œå–„
- [ ] æ€§èƒ½å½±éŸ¿æœ€å°

### é…ç½®ç®¡ç†å®‰å…¨æ€§
- [ ] æ•æ„Ÿä¿¡æ¯ä¸åœ¨ä»£ç¢¼ä¸­ç¡¬ç·¨ç¢¼
- [ ] é…ç½®è®Šæ›´æœ‰å¯©æ ¸æ©Ÿåˆ¶
- [ ] ç’°å¢ƒéš”é›¢å®Œæ•´
- [ ] é…ç½®é©—è­‰åš´æ ¼

---

**é‡è¦æé†’**: æ‰€æœ‰æ–°å¢çš„ä»£ç¢¼éƒ½æ‡‰è©²æœ‰å°æ‡‰çš„æ¸¬è©¦ï¼Œç¢ºä¿ç³»çµ±ç©©å®šæ€§å’Œå¯ç¶­è­·æ€§ã€‚