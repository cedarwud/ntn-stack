#!/usr/bin/env python3
"""
Phase 1 Docker æ•´åˆé…ç½®

åŠŸèƒ½:
1. è‡ªå‹•åŒ– Docker é…ç½®ç”Ÿæˆ
2. Phase 1 ç³»çµ±å®¹å™¨åŒ–æ•´åˆ
3. NetStack ä¸»ç³»çµ±æ•´åˆ
4. ä¾è³´ç®¡ç†å’Œå„ªåŒ–

ç¬¦åˆ CLAUDE.md åŸå‰‡:
- å®Œæ•´çš„ç”Ÿç”¢ç´šéƒ¨ç½²é…ç½®
- ç¢ºä¿ Phase 1 ç³»çµ±ç©©å®šé‹è¡Œ
- å„ªåŒ–å®¹å™¨è³‡æºä½¿ç”¨
"""

import os
import json
import yaml
import logging
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime, timezone

logger = logging.getLogger(__name__)

@dataclass
class DockerConfig:
    """Docker é…ç½®"""
    base_image: str
    python_version: str
    work_dir: str
    exposed_ports: List[int]
    environment_vars: Dict[str, str]
    volumes: List[str]
    health_check: Dict[str, Any]

@dataclass
class ServiceConfig:
    """æœå‹™é…ç½®"""
    name: str
    image: str
    ports: List[str]
    environment: Dict[str, str]
    volumes: List[str]
    depends_on: List[str]
    healthcheck: Dict[str, Any]
    restart: str = "unless-stopped"

class DockerIntegrator:
    """Docker æ•´åˆå™¨"""
    
    def __init__(self, project_root: Path):
        """
        åˆå§‹åŒ– Docker æ•´åˆå™¨
        
        Args:
            project_root: å°ˆæ¡ˆæ ¹ç›®éŒ„
        """
        self.project_root = project_root
        self.phase1_root = project_root / "phase1_refactor"
        self.netstack_root = project_root / "netstack"
        self.deployment_dir = self.phase1_root / "deployment"
        
        # ç¢ºä¿éƒ¨ç½²ç›®éŒ„å­˜åœ¨
        self.deployment_dir.mkdir(exist_ok=True)
        
        logger.info("Docker æ•´åˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def generate_dockerfile(self) -> str:
        """ç”Ÿæˆ Phase 1 å¢å¼·çš„ Dockerfile"""
        
        dockerfile_content = '''# Phase 1 å¢å¼· NetStack Dockerfile
FROM python:3.11-slim

# è¨­ç½®å·¥ä½œç›®éŒ„
WORKDIR /app

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y \\
    gcc \\
    g++ \\
    curl \\
    wget \\
    build-essential \\
    && rm -rf /var/lib/apt/lists/*

# è¤‡è£½ requirements æ–‡ä»¶
COPY requirements.txt /app/requirements.txt
COPY phase1_refactor/requirements.txt /app/phase1_requirements.txt

# å®‰è£ Python ä¾è³´
RUN pip install --no-cache-dir --upgrade pip
RUN pip install --no-cache-dir -r requirements.txt
RUN pip install --no-cache-dir -r phase1_requirements.txt

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼ä»£ç¢¼
COPY . /app/

# è¨­ç½® Python è·¯å¾‘
ENV PYTHONPATH="${PYTHONPATH}:/app:/app/phase1_refactor:/app/netstack"

# Phase 1 ç‰¹å®šç’°å¢ƒè®Šé‡
ENV PHASE1_TLE_DATA_PATH="/netstack/tle_data"
ENV PHASE1_OUTPUT_PATH="/app/data"
ENV PHASE1_LOG_LEVEL="INFO"
ENV PHASE1_CACHE_SIZE="2000"
ENV PHASE1_API_TIMEOUT="30"

# å‰µå»ºå¿…è¦ç›®éŒ„
RUN mkdir -p /netstack/tle_data/starlink/tle && \\
    mkdir -p /netstack/tle_data/oneweb/tle && \\
    mkdir -p /app/data && \\
    mkdir -p /app/logs

# è¨­ç½®æ¬Šé™
RUN chmod -R 755 /app/phase1_refactor && \\
    chmod +x /app/phase1_refactor/deployment/*.sh

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \\
    CMD curl -f http://localhost:8080/health || \\
        python -c "import sys; sys.path.append('/app/phase1_refactor/04_output_interface'); from phase1_api_enhanced import health_check; health_check()" || exit 1

# æš´éœ²ç«¯å£
EXPOSE 8080 8001

# å•Ÿå‹•å‘½ä»¤
CMD ["python", "-m", "uvicorn", "netstack_api.main:app", "--host", "0.0.0.0", "--port", "8080", "--reload"]
'''
        
        dockerfile_path = self.deployment_dir / "Dockerfile.phase1"
        dockerfile_path.write_text(dockerfile_content)
        
        logger.info(f"Dockerfile å·²ç”Ÿæˆ: {dockerfile_path}")
        return str(dockerfile_path)
    
    def generate_docker_compose(self) -> str:
        """ç”Ÿæˆ Phase 1 å¢å¼·çš„ docker-compose.yml"""
        
        compose_config = {
            "version": "3.8",
            "services": {
                "netstack-api-phase1": {
                    "build": {
                        "context": "../..",
                        "dockerfile": "phase1_refactor/deployment/Dockerfile.phase1"
                    },
                    "ports": [
                        "8080:8080",
                        "8001:8001"
                    ],
                    "environment": {
                        "PHASE1_TLE_DATA_PATH": "/netstack/tle_data",
                        "PHASE1_OUTPUT_PATH": "/app/data",
                        "PHASE1_LOG_LEVEL": "INFO",
                        "PHASE1_CACHE_SIZE": "2000",
                        "PHASE1_API_TIMEOUT": "30",
                        "PYTHONPATH": "/app:/app/phase1_refactor:/app/netstack"
                    },
                    "volumes": [
                        "./../../tle_data:/netstack/tle_data",
                        "./../../data:/app/data",
                        "./../../logs:/app/logs",
                        "./../../phase1_refactor:/app/phase1_refactor"
                    ],
                    "healthcheck": {
                        "test": [
                            "CMD-SHELL",
                            "curl -f http://localhost:8080/health || exit 1"
                        ],
                        "interval": "30s",
                        "timeout": "10s",
                        "retries": 3,
                        "start_period": "60s"
                    },
                    "restart": "unless-stopped",
                    "depends_on": ["netstack-rl-postgres"],
                    "networks": ["netstack-network"]
                },
                
                "netstack-rl-postgres": {
                    "image": "postgres:15-alpine",
                    "environment": {
                        "POSTGRES_DB": "rl_research",
                        "POSTGRES_USER": "rl_user",
                        "POSTGRES_PASSWORD": "rl_password"
                    },
                    "volumes": [
                        "postgres_data:/var/lib/postgresql/data"
                    ],
                    "ports": ["5432:5432"],
                    "healthcheck": {
                        "test": ["CMD-SHELL", "pg_isready -U rl_user -d rl_research"],
                        "interval": "10s",
                        "timeout": "5s",
                        "retries": 5
                    },
                    "restart": "unless-stopped",
                    "networks": ["netstack-network"]
                }
            },
            
            "volumes": {
                "postgres_data": None
            },
            
            "networks": {
                "netstack-network": {
                    "driver": "bridge"
                }
            }
        }
        
        compose_path = self.deployment_dir / "docker-compose.phase1.yml"
        with open(compose_path, 'w', encoding='utf-8') as f:
            yaml.dump(compose_config, f, default_flow_style=False, allow_unicode=True)
        
        logger.info(f"docker-compose.yml å·²ç”Ÿæˆ: {compose_path}")
        return str(compose_path)
    
    def generate_deployment_scripts(self) -> List[str]:
        """ç”Ÿæˆéƒ¨ç½²è…³æœ¬"""
        
        scripts = []
        
        # 1. éƒ¨ç½²æº–å‚™è…³æœ¬
        prepare_script = '''#!/bin/bash
# Phase 1 éƒ¨ç½²æº–å‚™è…³æœ¬

set -e

echo "ğŸš€ Phase 1 éƒ¨ç½²æº–å‚™é–‹å§‹..."

# æª¢æŸ¥ Docker å’Œ Docker Compose
echo "æª¢æŸ¥ Docker ç’°å¢ƒ..."
if ! command -v docker &> /dev/null; then
    echo "âŒ Docker æœªå®‰è£"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "âŒ Docker Compose æœªå®‰è£"
    exit 1
fi

echo "âœ… Docker ç’°å¢ƒæª¢æŸ¥é€šé"

# å‰µå»ºå¿…è¦ç›®éŒ„
echo "å‰µå»ºå¿…è¦ç›®éŒ„..."
mkdir -p ../../tle_data/starlink/tle
mkdir -p ../../tle_data/oneweb/tle
mkdir -p ../../data
mkdir -p ../../logs

echo "âœ… ç›®éŒ„å‰µå»ºå®Œæˆ"

# æª¢æŸ¥ TLE æ•¸æ“š
echo "æª¢æŸ¥ TLE æ•¸æ“š..."
if [ ! -f "../../tle_data/starlink/tle/starlink_20250805.tle" ]; then
    echo "âš ï¸  æœªæ‰¾åˆ° Starlink TLE æ•¸æ“šï¼Œå°‡å¾æ­·å²æ•¸æ“šç”Ÿæˆ..."
    python ../../phase1_refactor/01_data_source/generate_tle_from_historical.py
fi

if [ ! -f "../../tle_data/oneweb/tle/oneweb_20250805.tle" ]; then
    echo "âš ï¸  æœªæ‰¾åˆ° OneWeb TLE æ•¸æ“šï¼Œå°‡å¾æ­·å²æ•¸æ“šç”Ÿæˆ..."
    python ../../phase1_refactor/01_data_source/generate_tle_from_historical.py --constellation oneweb
fi

echo "âœ… TLE æ•¸æ“šæª¢æŸ¥å®Œæˆ"

# é©—è­‰ Phase 1 ç³»çµ±
echo "é©—è­‰ Phase 1 ç³»çµ±..."
cd ../../phase1_refactor
python validate_phase1_refactor.py

if [ $? -eq 0 ]; then
    echo "âœ… Phase 1 ç³»çµ±é©—è­‰é€šé"
else
    echo "âŒ Phase 1 ç³»çµ±é©—è­‰å¤±æ•—"
    exit 1
fi

cd deployment

echo "ğŸ¯ Phase 1 éƒ¨ç½²æº–å‚™å®Œæˆ"
'''
        
        prepare_script_path = self.deployment_dir / "prepare_deployment.sh"
        prepare_script_path.write_text(prepare_script)
        prepare_script_path.chmod(0o755)
        scripts.append(str(prepare_script_path))
        
        # 2. éƒ¨ç½²åŸ·è¡Œè…³æœ¬
        deploy_script = '''#!/bin/bash
# Phase 1 éƒ¨ç½²åŸ·è¡Œè…³æœ¬

set -e

echo "ğŸš€ Phase 1 éƒ¨ç½²åŸ·è¡Œé–‹å§‹..."

# åœæ­¢èˆŠæœå‹™
echo "åœæ­¢ç¾æœ‰æœå‹™..."
docker-compose -f docker-compose.phase1.yml down --remove-orphans || true

# æ¸…ç†èˆŠé¡åƒ
echo "æ¸…ç†èˆŠé¡åƒ..."
docker system prune -f

# å»ºæ§‹æ–°é¡åƒ
echo "å»ºæ§‹ Phase 1 å¢å¼·é¡åƒ..."
docker-compose -f docker-compose.phase1.yml build --no-cache

# å•Ÿå‹•æœå‹™
echo "å•Ÿå‹• Phase 1 æœå‹™..."
docker-compose -f docker-compose.phase1.yml up -d

# ç­‰å¾…æœå‹™å•Ÿå‹•
echo "ç­‰å¾…æœå‹™å•Ÿå‹•..."
sleep 30

# æª¢æŸ¥æœå‹™ç‹€æ…‹
echo "æª¢æŸ¥æœå‹™ç‹€æ…‹..."
docker-compose -f docker-compose.phase1.yml ps

# ç­‰å¾…å¥åº·æª¢æŸ¥
echo "ç­‰å¾…å¥åº·æª¢æŸ¥..."
for i in {1..30}; do
    if curl -f http://localhost:8080/health >/dev/null 2>&1; then
        echo "âœ… æœå‹™å¥åº·æª¢æŸ¥é€šé"
        break
    fi
    echo "ç­‰å¾…å¥åº·æª¢æŸ¥... ($i/30)"
    sleep 2
done

# åŸ·è¡Œéƒ¨ç½²å¾Œé©—è­‰
echo "åŸ·è¡Œéƒ¨ç½²å¾Œé©—è­‰..."
python ../05_integration/integration_test.py

if [ $? -eq 0 ]; then
    echo "âœ… éƒ¨ç½²å¾Œé©—è­‰é€šé"
else
    echo "âŒ éƒ¨ç½²å¾Œé©—è­‰å¤±æ•—"
    echo "å›æ»¾éƒ¨ç½²..."
    docker-compose -f docker-compose.phase1.yml down
    exit 1
fi

echo "ğŸ‰ Phase 1 éƒ¨ç½²å®Œæˆï¼"
echo "API ç«¯é»: http://localhost:8080"
echo "Phase 1 API: http://localhost:8001"
echo "å¥åº·æª¢æŸ¥: http://localhost:8080/health"
'''
        
        deploy_script_path = self.deployment_dir / "deploy.sh"
        deploy_script_path.write_text(deploy_script)
        deploy_script_path.chmod(0o755)
        scripts.append(str(deploy_script_path))
        
        # 3. å›æ»¾è…³æœ¬
        rollback_script = '''#!/bin/bash
# Phase 1 å›æ»¾è…³æœ¬

set -e

echo "ğŸ”„ Phase 1 å›æ»¾é–‹å§‹..."

# åœæ­¢ç•¶å‰æœå‹™
echo "åœæ­¢ç•¶å‰æœå‹™..."
docker-compose -f docker-compose.phase1.yml down

# å‚™ä»½ç•¶å‰æ•¸æ“š
echo "å‚™ä»½ç•¶å‰æ•¸æ“š..."
backup_dir="../../backup/rollback_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$backup_dir"
cp -r ../../data "$backup_dir/"
cp -r ../../logs "$backup_dir/"

# æ¢å¾©åˆ°åŸæœ‰é…ç½®
echo "æ¢å¾©åˆ°åŸæœ‰é…ç½®..."
if [ -d "../../backup/pre-phase1-integration/" ]; then
    cp -r ../../backup/pre-phase1-integration/* ../../
    echo "âœ… åŸæœ‰é…ç½®å·²æ¢å¾©"
else
    echo "âŒ æœªæ‰¾åˆ°åŸæœ‰é…ç½®å‚™ä»½"
    exit 1
fi

# é‡å•ŸåŸæœ‰æœå‹™
echo "é‡å•ŸåŸæœ‰æœå‹™..."
cd ../..
make up

echo "âœ… Phase 1 å›æ»¾å®Œæˆ"
'''
        
        rollback_script_path = self.deployment_dir / "rollback.sh"
        rollback_script_path.write_text(rollback_script)
        rollback_script_path.chmod(0o755)
        scripts.append(str(rollback_script_path))
        
        logger.info(f"éƒ¨ç½²è…³æœ¬å·²ç”Ÿæˆ: {len(scripts)} å€‹æ–‡ä»¶")
        return scripts
    
    def generate_ci_cd_config(self) -> str:
        """ç”Ÿæˆ CI/CD é…ç½®"""
        
        github_workflow = {
            "name": "Phase 1 Enhanced Deployment",
            "on": {
                "push": {
                    "branches": ["main"],
                    "paths": ["phase1_refactor/**", "netstack/**"]
                },
                "pull_request": {
                    "branches": ["main"],
                    "paths": ["phase1_refactor/**", "netstack/**"]
                }
            },
            
            "jobs": {
                "test": {
                    "runs-on": "ubuntu-latest",
                    "steps": [
                        {
                            "name": "Checkout code",
                            "uses": "actions/checkout@v3"
                        },
                        {
                            "name": "Set up Python 3.11",
                            "uses": "actions/setup-python@v4",
                            "with": {"python-version": "3.11"}
                        },
                        {
                            "name": "Install dependencies",
                            "run": "pip install -r phase1_refactor/requirements.txt"
                        },
                        {
                            "name": "Run Phase 1 tests",
                            "run": "cd phase1_refactor && python validate_phase1_refactor.py"
                        },
                        {
                            "name": "Run integration tests",
                            "run": "cd phase1_refactor/05_integration && python end_to_end_tests.py"
                        }
                    ]
                },
                
                "build": {
                    "runs-on": "ubuntu-latest",
                    "needs": "test",
                    "if": "github.ref == 'refs/heads/main'",
                    "steps": [
                        {
                            "name": "Checkout code",
                            "uses": "actions/checkout@v3"
                        },
                        {
                            "name": "Set up Docker Buildx",
                            "uses": "docker/setup-buildx-action@v2"
                        },
                        {
                            "name": "Build Phase 1 image",
                            "run": "docker build -f phase1_refactor/deployment/Dockerfile.phase1 -t netstack-phase1:latest ."
                        },
                        {
                            "name": "Test Docker image",
                            "run": "docker run --rm netstack-phase1:latest python -c 'import sys; print(f\"Python {sys.version}\"); from sgp4.api import Satrec; print(\"SGP4 OK\")'"
                        }
                    ]
                },
                
                "deploy": {
                    "runs-on": "ubuntu-latest",
                    "needs": ["test", "build"],
                    "if": "github.ref == 'refs/heads/main'",
                    "environment": "production",
                    "steps": [
                        {
                            "name": "Deploy to staging",
                            "run": "echo 'Deploy to staging environment'"
                        },
                        {
                            "name": "Run deployment verification",
                            "run": "echo 'Verify deployment'"
                        }
                    ]
                }
            }
        }
        
        workflow_dir = self.deployment_dir / ".github" / "workflows"
        workflow_dir.mkdir(parents=True, exist_ok=True)
        
        workflow_path = workflow_dir / "phase1-deploy.yml"
        with open(workflow_path, 'w', encoding='utf-8') as f:
            yaml.dump(github_workflow, f, default_flow_style=False, allow_unicode=True)
        
        logger.info(f"CI/CD é…ç½®å·²ç”Ÿæˆ: {workflow_path}")
        return str(workflow_path)
    
    def generate_monitoring_config(self) -> str:
        """ç”Ÿæˆç›£æ§é…ç½®"""
        
        monitoring_compose = '''version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: phase1-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    networks:
      - netstack-network

  grafana:
    image: grafana/grafana:latest
    container_name: phase1-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - netstack-network

  node_exporter:
    image: prom/node-exporter:latest
    container_name: phase1-node-exporter
    ports:
      - "9100:9100"
    networks:
      - netstack-network

volumes:
  grafana_data:

networks:
  netstack-network:
    external: true
'''
        
        monitoring_dir = self.deployment_dir / "monitoring"
        monitoring_dir.mkdir(exist_ok=True)
        
        monitoring_compose_path = monitoring_dir / "docker-compose.monitoring.yml"
        monitoring_compose_path.write_text(monitoring_compose)
        
        # Prometheus é…ç½®
        prometheus_config = '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'phase1-api'
    static_configs:
      - targets: ['netstack-api-phase1:8080']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node_exporter:9100']

  - job_name: 'postgres'
    static_configs:
      - targets: ['netstack-rl-postgres:5432']
'''
        
        prometheus_config_path = monitoring_dir / "prometheus.yml"
        prometheus_config_path.write_text(prometheus_config)
        
        logger.info(f"ç›£æ§é…ç½®å·²ç”Ÿæˆ: {monitoring_dir}")
        return str(monitoring_dir)
    
    def generate_production_config(self) -> str:
        """ç”Ÿæˆç”Ÿç”¢ç’°å¢ƒé…ç½®"""
        
        prod_config = {
            "phase1": {
                "api": {
                    "host": "0.0.0.0",
                    "port": 8080,
                    "workers": 4,
                    "timeout": 30,
                    "max_connections": 100
                },
                "data": {
                    "tle_data_path": "/netstack/tle_data",
                    "output_path": "/app/data",
                    "cache_size": 5000,
                    "cache_ttl": 3600
                },
                "performance": {
                    "sgp4_threads": 8,
                    "batch_size": 1000,
                    "memory_limit": "2GB",
                    "cpu_limit": "2.0"
                },
                "logging": {
                    "level": "INFO",
                    "format": "json",
                    "file": "/app/logs/phase1.log",
                    "max_size": "100MB",
                    "backup_count": 5
                },
                "security": {
                    "enable_cors": True,
                    "allowed_origins": ["*"],
                    "rate_limiting": {
                        "requests_per_minute": 100,
                        "requests_per_hour": 1000
                    }
                }
            },
            "deployment": {
                "strategy": "rolling_update",
                "health_check_timeout": 60,
                "readiness_probe_delay": 30,
                "liveness_probe_delay": 60,
                "resource_limits": {
                    "memory": "4GB",
                    "cpu": "2.0"
                },
                "resource_requests": {
                    "memory": "2GB",
                    "cpu": "1.0"
                }
            }
        }
        
        config_path = self.deployment_dir / "production.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(prod_config, f, default_flow_style=False, allow_unicode=True)
        
        logger.info(f"ç”Ÿç”¢ç’°å¢ƒé…ç½®å·²ç”Ÿæˆ: {config_path}")
        return str(config_path)
    
    def create_deployment_package(self) -> str:
        """å‰µå»ºå®Œæ•´éƒ¨ç½²åŒ…"""
        
        logger.info("å‰µå»ºå®Œæ•´éƒ¨ç½²åŒ…...")
        
        # ç”Ÿæˆæ‰€æœ‰é…ç½®æ–‡ä»¶
        dockerfile_path = self.generate_dockerfile()
        compose_path = self.generate_docker_compose()
        scripts = self.generate_deployment_scripts()
        cicd_path = self.generate_ci_cd_config()
        monitoring_path = self.generate_monitoring_config()
        production_path = self.generate_production_config()
        
        # å‰µå»ºéƒ¨ç½²æ–‡æª”
        deployment_doc = f'''# Phase 1 éƒ¨ç½²åŒ…

**ç”Ÿæˆæ™‚é–“**: {datetime.now(timezone.utc).isoformat()}
**ç‰ˆæœ¬**: 1.0.0

## ğŸ“ éƒ¨ç½²åŒ…å…§å®¹

### æ ¸å¿ƒé…ç½®
- `Dockerfile.phase1`: Phase 1 å¢å¼· Docker é¡åƒ
- `docker-compose.phase1.yml`: Docker Compose é…ç½®
- `production.yaml`: ç”Ÿç”¢ç’°å¢ƒé…ç½®

### éƒ¨ç½²è…³æœ¬
- `prepare_deployment.sh`: éƒ¨ç½²æº–å‚™è…³æœ¬
- `deploy.sh`: éƒ¨ç½²åŸ·è¡Œè…³æœ¬
- `rollback.sh`: å›æ»¾è…³æœ¬

### CI/CD é…ç½®
- `.github/workflows/phase1-deploy.yml`: GitHub Actions å·¥ä½œæµ

### ç›£æ§é…ç½®
- `monitoring/`: ç›£æ§ç³»çµ±é…ç½®ç›®éŒ„
  - `docker-compose.monitoring.yml`: ç›£æ§æœå‹™
  - `prometheus.yml`: Prometheus é…ç½®

## ğŸš€ éƒ¨ç½²æ­¥é©Ÿ

1. **æº–å‚™éšæ®µ**:
   ```bash
   cd phase1_refactor/deployment
   ./prepare_deployment.sh
   ```

2. **åŸ·è¡Œéƒ¨ç½²**:
   ```bash
   ./deploy.sh
   ```

3. **é©—è­‰éƒ¨ç½²**:
   ```bash
   curl http://localhost:8080/health
   curl http://localhost:8001/health
   ```

4. **å•Ÿå‹•ç›£æ§** (å¯é¸):
   ```bash
   docker-compose -f monitoring/docker-compose.monitoring.yml up -d
   ```

## ğŸ“Š éƒ¨ç½²å¾Œæª¢æŸ¥

### æœå‹™ç‹€æ…‹
- NetStack API: http://localhost:8080
- Phase 1 API: http://localhost:8001  
- å¥åº·æª¢æŸ¥: http://localhost:8080/health
- Prometheus: http://localhost:9090 (å¦‚å•Ÿç”¨ç›£æ§)
- Grafana: http://localhost:3000 (å¦‚å•Ÿç”¨ç›£æ§)

### æ€§èƒ½é©—è­‰
```bash
# åŸ·è¡Œæ€§èƒ½æ¸¬è©¦
cd ../05_integration
python performance_benchmark.py

# æŸ¥çœ‹æœå‹™ç‹€æ…‹
docker-compose -f ../deployment/docker-compose.phase1.yml ps
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ
1. **TLE æ•¸æ“šç¼ºå¤±**: åŸ·è¡Œ `prepare_deployment.sh`
2. **æœå‹™å•Ÿå‹•å¤±æ•—**: æª¢æŸ¥ Docker logs
3. **æ€§èƒ½ä¸ä½³**: èª¿æ•´ `production.yaml` ä¸­çš„é…ç½®

### å›æ»¾æ­¥é©Ÿ
```bash
./rollback.sh
```

## ğŸ“ æ”¯æ´è³‡è¨Š
- æŠ€è¡“æ–‡æª”: `../docs/`
- æ•´åˆæŒ‡å—: `../docs/integration_guide.md`
- API è¦ç¯„: `../docs/api_specification.md`
'''
        
        deployment_readme = self.deployment_dir / "README.md"
        deployment_readme.write_text(deployment_doc)
        
        # å‰µå»ºç‰ˆæœ¬ä¿¡æ¯
        version_info = {
            "package_version": "1.0.0",
            "created_at": datetime.now(timezone.utc).isoformat(),
            "components": {
                "dockerfile": dockerfile_path,
                "docker_compose": compose_path,
                "deployment_scripts": scripts,
                "cicd_config": cicd_path,
                "monitoring_config": monitoring_path,
                "production_config": production_path
            },
            "system_requirements": {
                "docker": ">=20.10",
                "docker_compose": ">=2.0",
                "python": "3.11",
                "memory": "4GB+",
                "cpu": "2 cores+",
                "disk": "10GB+"
            }
        }
        
        version_file = self.deployment_dir / "version.json"
        with open(version_file, 'w', encoding='utf-8') as f:
            json.dump(version_info, f, indent=2, ensure_ascii=False)
        
        logger.info("âœ… Phase 1 å®Œæ•´éƒ¨ç½²åŒ…å‰µå»ºå®Œæˆ")
        return str(self.deployment_dir)


class ProductionOptimizer:
    """ç”Ÿç”¢ç’°å¢ƒå„ªåŒ–å™¨"""
    
    def __init__(self, deployment_dir: Path):
        """
        åˆå§‹åŒ–ç”Ÿç”¢ç’°å¢ƒå„ªåŒ–å™¨
        
        Args:
            deployment_dir: éƒ¨ç½²é…ç½®ç›®éŒ„
        """
        self.deployment_dir = deployment_dir
        logger.info("ç”Ÿç”¢ç’°å¢ƒå„ªåŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def optimize_docker_image(self) -> Dict[str, Any]:
        """å„ªåŒ– Docker é¡åƒ"""
        
        optimizations = []
        
        # å¤šéšæ®µå»ºæ§‹å„ªåŒ–
        optimized_dockerfile = '''# Phase 1 å„ªåŒ– Dockerfile (å¤šéšæ®µå»ºæ§‹)

# ç¬¬ä¸€éšæ®µï¼šå»ºæ§‹ç’°å¢ƒ
FROM python:3.11-slim as builder

WORKDIR /app

# å®‰è£å»ºæ§‹ä¾è³´
RUN apt-get update && apt-get install -y \\
    gcc g++ build-essential \\
    && rm -rf /var/lib/apt/lists/*

# è¤‡è£½ä¸¦å®‰è£ Python ä¾è³´
COPY requirements.txt phase1_refactor/requirements.txt ./
RUN pip install --user --no-cache-dir -r requirements.txt && \\
    pip install --user --no-cache-dir -r phase1_refactor/requirements.txt

# ç¬¬äºŒéšæ®µï¼šé‹è¡Œç’°å¢ƒ
FROM python:3.11-slim as runtime

WORKDIR /app

# åªå®‰è£é‹è¡Œæ™‚ä¾è³´
RUN apt-get update && apt-get install -y \\
    curl \\
    && rm -rf /var/lib/apt/lists/* \\
    && apt-get clean

# è¤‡è£½å·²å®‰è£çš„ Python åŒ…
COPY --from=builder /root/.local /root/.local

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼ä»£ç¢¼
COPY . /app/

# è¨­ç½®ç’°å¢ƒè®Šé‡
ENV PYTHONPATH="${PYTHONPATH}:/app:/app/phase1_refactor:/app/netstack"
ENV PATH="/root/.local/bin:$PATH"

# Phase 1 å„ªåŒ–é…ç½®
ENV PHASE1_TLE_DATA_PATH="/netstack/tle_data"
ENV PHASE1_OUTPUT_PATH="/app/data"
ENV PHASE1_LOG_LEVEL="INFO"
ENV PHASE1_CACHE_SIZE="5000"
ENV PHASE1_API_TIMEOUT="30"
ENV PHASE1_WORKERS="4"

# å‰µå»ºå¿…è¦ç›®éŒ„ä¸¦è¨­ç½®æ¬Šé™
RUN mkdir -p /netstack/tle_data /app/data /app/logs && \\
    adduser --disabled-password --gecos '' appuser && \\
    chown -R appuser:appuser /app /netstack && \\
    chmod -R 755 /app/phase1_refactor/deployment

# åˆ‡æ›åˆ°é root ç”¨æˆ¶
USER appuser

# å¥åº·æª¢æŸ¥å„ªåŒ–
HEALTHCHECK --interval=30s --timeout=5s --start-period=60s --retries=3 \\
    CMD curl -f http://localhost:8080/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 8080

# ä½¿ç”¨ Gunicorn å•Ÿå‹•ï¼ˆç”Ÿç”¢ç´š WSGI æœå‹™å™¨ï¼‰
CMD ["gunicorn", "netstack_api.main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "--bind", "0.0.0.0:8080"]
'''
        
        optimized_dockerfile_path = self.deployment_dir / "Dockerfile.optimized"
        optimized_dockerfile_path.write_text(optimized_dockerfile)
        
        optimizations.append({
            "type": "docker_image",
            "description": "å¤šéšæ®µå»ºæ§‹ï¼Œæ¸›å°é¡åƒå¤§å°",
            "file": str(optimized_dockerfile_path)
        })
        
        return {"optimizations": optimizations, "status": "completed"}
    
    def generate_k8s_manifests(self) -> Dict[str, str]:
        """ç”Ÿæˆ Kubernetes éƒ¨ç½²æ¸…å–®"""
        
        k8s_dir = self.deployment_dir / "k8s"
        k8s_dir.mkdir(exist_ok=True)
        
        manifests = {}
        
        # Deployment æ¸…å–®
        deployment_manifest = '''apiVersion: apps/v1
kind: Deployment
metadata:
  name: netstack-phase1
  labels:
    app: netstack-phase1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: netstack-phase1
  template:
    metadata:
      labels:
        app: netstack-phase1
    spec:
      containers:
      - name: netstack-api
        image: netstack-phase1:latest
        ports:
        - containerPort: 8080
        env:
        - name: PHASE1_TLE_DATA_PATH
          value: "/netstack/tle_data"
        - name: PHASE1_OUTPUT_PATH
          value: "/app/data"
        - name: PHASE1_CACHE_SIZE
          value: "5000"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
        - name: tle-data
          mountPath: /netstack/tle_data
        - name: app-data
          mountPath: /app/data
      volumes:
      - name: tle-data
        persistentVolumeClaim:
          claimName: tle-data-pvc
      - name: app-data
        persistentVolumeClaim:
          claimName: app-data-pvc
'''
        
        deployment_path = k8s_dir / "deployment.yaml"
        deployment_path.write_text(deployment_manifest)
        manifests["deployment"] = str(deployment_path)
        
        # Service æ¸…å–®
        service_manifest = '''apiVersion: v1
kind: Service
metadata:
  name: netstack-phase1-service
spec:
  selector:
    app: netstack-phase1
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: LoadBalancer
'''
        
        service_path = k8s_dir / "service.yaml"
        service_path.write_text(service_manifest)
        manifests["service"] = str(service_path)
        
        # ConfigMap æ¸…å–®
        configmap_manifest = '''apiVersion: v1
kind: ConfigMap
metadata:
  name: netstack-phase1-config
data:
  PHASE1_LOG_LEVEL: "INFO"
  PHASE1_CACHE_SIZE: "5000"
  PHASE1_API_TIMEOUT: "30"
'''
        
        configmap_path = k8s_dir / "configmap.yaml"
        configmap_path.write_text(configmap_manifest)
        manifests["configmap"] = str(configmap_path)
        
        logger.info(f"Kubernetes æ¸…å–®å·²ç”Ÿæˆ: {len(manifests)} å€‹æ–‡ä»¶")
        return manifests


def create_deployment_package(project_root: str = "/home/sat/ntn-stack") -> Dict[str, Any]:
    """å‰µå»ºå®Œæ•´çš„ Phase 1 éƒ¨ç½²åŒ…"""
    
    project_path = Path(project_root)
    integrator = DockerIntegrator(project_path)
    
    # å‰µå»ºå®Œæ•´éƒ¨ç½²åŒ…
    deployment_dir = integrator.create_deployment_package()
    
    # ç”Ÿç”¢ç’°å¢ƒå„ªåŒ–
    optimizer = ProductionOptimizer(Path(deployment_dir))
    docker_optimizations = optimizer.optimize_docker_image()
    k8s_manifests = optimizer.generate_k8s_manifests()
    
    return {
        "deployment_package": deployment_dir,
        "docker_optimizations": docker_optimizations,
        "k8s_manifests": k8s_manifests,
        "status": "completed"
    }


if __name__ == "__main__":
    # åŸ·è¡Œéƒ¨ç½²åŒ…å‰µå»º
    logging.basicConfig(level=logging.INFO)
    
    try:
        print("ğŸš€ Phase 1 éƒ¨ç½²æµç¨‹å„ªåŒ–é–‹å§‹...")
        print("=" * 50)
        
        # å‰µå»ºéƒ¨ç½²åŒ…
        result = create_deployment_package()
        
        print("âœ… éƒ¨ç½²åŒ…å‰µå»ºå®Œæˆ:")
        print(f"   éƒ¨ç½²ç›®éŒ„: {result['deployment_package']}")
        print(f"   Docker å„ªåŒ–: {len(result['docker_optimizations']['optimizations'])} é …")
        print(f"   K8s æ¸…å–®: {len(result['k8s_manifests'])} å€‹æ–‡ä»¶")
        
        print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
        print("1. åŸ·è¡Œéƒ¨ç½²æº–å‚™: ./prepare_deployment.sh")
        print("2. åŸ·è¡Œéƒ¨ç½²: ./deploy.sh")
        print("3. é©—è­‰éƒ¨ç½²: curl http://localhost:8080/health")
        
        print("\nâœ… Stage 4.3: éƒ¨ç½²æµç¨‹å„ªåŒ–å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ éƒ¨ç½²æµç¨‹å„ªåŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()