#!/usr/bin/env python3
"""
Phase 1 ç«¯åˆ°ç«¯æµç¨‹æ¸¬è©¦

åŠŸèƒ½:
1. å®Œæ•´çš„ Phase 1 ç³»çµ±ç«¯åˆ°ç«¯æ¸¬è©¦
2. å¾ TLE è¼‰å…¥åˆ° API éŸ¿æ‡‰çš„å…¨æµç¨‹é©—è­‰
3. å¤šå ´æ™¯ã€å¤šè² è¼‰çš„ç¶œåˆæ¸¬è©¦
4. èˆ‡ç¾æœ‰ç³»çµ±çš„æ•´åˆå…¼å®¹æ€§æ¸¬è©¦

ç¬¦åˆ CLAUDE.md åŸå‰‡:
- ä½¿ç”¨çœŸå¯¦ TLE æ•¸æ“šé€²è¡Œå®Œæ•´æ¸¬è©¦
- é©—è­‰å®Œæ•´ SGP4 ç®—æ³•çš„ç«¯åˆ°ç«¯æ­£ç¢ºæ€§
- ç¢ºä¿å­¸è¡“ç ”ç©¶ç´šåˆ¥çš„æ•¸æ“šæº–ç¢ºæ€§
"""

import asyncio
import logging
import sys
import json
import time
import requests
import concurrent.futures
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
import numpy as np

# æ·»åŠ  Phase 1 æ¨¡çµ„è·¯å¾‘
PHASE1_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PHASE1_ROOT / "01_data_source"))
sys.path.insert(0, str(PHASE1_ROOT / "02_orbit_calculation"))
sys.path.insert(0, str(PHASE1_ROOT / "03_processing_pipeline"))
sys.path.insert(0, str(PHASE1_ROOT / "04_output_interface"))

logger = logging.getLogger(__name__)

@dataclass
class E2ETestResult:
    """ç«¯åˆ°ç«¯æ¸¬è©¦çµæœ"""
    test_name: str
    test_category: str
    start_time: datetime
    end_time: datetime
    duration_seconds: float
    success: bool
    error_message: Optional[str] = None
    performance_data: Optional[Dict[str, Any]] = None
    validation_data: Optional[Dict[str, Any]] = None

@dataclass
class E2ETestScenario:
    """æ¸¬è©¦å ´æ™¯å®šç¾©"""
    scenario_name: str
    description: str
    test_steps: List[str]
    expected_outcomes: Dict[str, Any]
    performance_requirements: Dict[str, float]
    data_requirements: Dict[str, Any]

class EndToEndTester:
    """ç«¯åˆ°ç«¯æ¸¬è©¦å™¨"""
    
    def __init__(self, api_base_url: str = None):
        """
        åˆå§‹åŒ–ç«¯åˆ°ç«¯æ¸¬è©¦å™¨
        
        Args:
            api_base_url: API åŸºç¤ URLï¼Œå¦‚æœæœªæä¾›å‰‡å¾é…ç½®ç³»çµ±ç²å–
        """
        # ä½¿ç”¨çµ±ä¸€é…ç½®è¼‰å…¥å™¨ç²å– API URL
        if api_base_url is None:
            try:
                import sys
                import os
                sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'config'))
                from config_loader import get_config_loader
                
                config_loader = get_config_loader()
                # ç²å– Phase 1 API URLï¼Œå›é€€åˆ°ç’°å¢ƒè®Šæ•¸æˆ–é è¨­å€¼
                api_base_url = os.getenv("PHASE1_API_URL", "http://localhost:8001")
                
            except ImportError as e:
                logger.warning(f"ç„¡æ³•è¼‰å…¥é…ç½®ç³»çµ±: {e}ï¼Œä½¿ç”¨é è¨­ URL")
                api_base_url = "http://localhost:8001"
        
        self.api_base_url = api_base_url
        self.test_results = []
        self.test_scenarios = self._define_test_scenarios()
        
        # æ¸¬è©¦çµ„ä»¶
        self.tle_loader = None
        self.sgp4_engine = None
        self.data_provider = None
        self.standard_interface = None
        
        logger.info(f"âœ… ç«¯åˆ°ç«¯æ¸¬è©¦å™¨åˆå§‹åŒ–å®Œæˆï¼ŒAPI URL: {self.api_base_url}")
    
    def _define_test_scenarios(self) -> List[E2ETestScenario]:
        """å®šç¾©æ¸¬è©¦å ´æ™¯"""
        scenarios = [
            E2ETestScenario(
                scenario_name="åŸºç¤æ•¸æ“šæµæ¸¬è©¦",
                description="å¾ TLE è¼‰å…¥åˆ° API éŸ¿æ‡‰çš„åŸºæœ¬æ•¸æ“šæµ",
                test_steps=[
                    "è¼‰å…¥ TLE æ•¸æ“š",
                    "å‰µå»º SGP4 è¡›æ˜Ÿå°è±¡",
                    "åŸ·è¡Œè»Œé“è¨ˆç®—",
                    "é€šéæ¨™æº–æ¥å£æŸ¥è©¢",
                    "é©—è­‰ API éŸ¿æ‡‰"
                ],
                expected_outcomes={
                    "tle_loaded": True,
                    "satellites_created": True,
                    "calculations_successful": True,
                    "api_response_valid": True,
                    "data_accuracy": True
                },
                performance_requirements={
                    "tle_load_time": 10.0,
                    "satellite_creation_time": 30.0,
                    "calculation_time": 5.0,
                    "api_response_time": 0.5
                },
                data_requirements={
                    "min_satellites": 1000,
                    "min_constellations": 2,
                    "position_accuracy_km": 0.1,
                    "velocity_accuracy_km_per_s": 1e-5
                }
            ),
            
            E2ETestScenario(
                scenario_name="é«˜è² è¼‰ä½µç™¼æ¸¬è©¦",
                description="å¤šç”¨æˆ¶ä½µç™¼è¨ªå•çš„é«˜è² è¼‰æ¸¬è©¦",
                test_steps=[
                    "å•Ÿå‹•å¤šå€‹ä½µç™¼å®¢æˆ¶ç«¯",
                    "åŸ·è¡Œå¤§é‡ API è«‹æ±‚",
                    "ç›£æ§ç³»çµ±æ€§èƒ½",
                    "é©—è­‰éŸ¿æ‡‰æº–ç¢ºæ€§",
                    "æª¢æŸ¥ç³»çµ±ç©©å®šæ€§"
                ],
                expected_outcomes={
                    "all_requests_successful": True,
                    "response_times_acceptable": True,
                    "data_consistency": True,
                    "no_memory_leaks": True,
                    "system_stable": True
                },
                performance_requirements={
                    "concurrent_users": 20,
                    "requests_per_user": 10,
                    "max_response_time": 2.0,
                    "success_rate": 0.95,
                    "max_memory_increase": 200
                },
                data_requirements={
                    "query_satellites": 100,
                    "time_range_hours": 2,
                    "data_consistency_check": True
                }
            ),
            
            E2ETestScenario(
                scenario_name="å¤§è¦æ¨¡æ•¸æ“šè™•ç†æ¸¬è©¦",
                description="å…¨é‡ 8,715 é¡†è¡›æ˜Ÿçš„å¤§è¦æ¨¡è™•ç†æ¸¬è©¦",
                test_steps=[
                    "è¼‰å…¥å…¨é‡ TLE æ•¸æ“š",
                    "å‰µå»ºæ‰€æœ‰è¡›æ˜Ÿå°è±¡",
                    "åŸ·è¡Œæ‰¹é‡è»Œé“è¨ˆç®—",
                    "æ¸¬è©¦å¤§é‡æ•¸æ“šæŸ¥è©¢",
                    "é©—è­‰ç³»çµ±æ“´å±•æ€§"
                ],
                expected_outcomes={
                    "full_data_loaded": True,
                    "all_satellites_active": True,
                    "batch_calculations_successful": True,
                    "large_queries_handled": True,
                    "scalability_maintained": True
                },
                performance_requirements={
                    "total_satellites": 8715,
                    "calculation_rate": 1000,
                    "large_query_time": 5.0,
                    "memory_efficiency": 0.5
                },
                data_requirements={
                    "starlink_satellites": 8000,
                    "oneweb_satellites": 600,
                    "calculation_accuracy": 0.99
                }
            ),
            
            E2ETestScenario(
                scenario_name="API å…¼å®¹æ€§æ¸¬è©¦",
                description="æ–°èˆŠ API æ¥å£çš„å…¼å®¹æ€§å’Œä¸€è‡´æ€§æ¸¬è©¦",
                test_steps=[
                    "æ¸¬è©¦æ–°æ¨™æº– API",
                    "æ¸¬è©¦å…¼å®¹ API",
                    "å°æ¯”éŸ¿æ‡‰æ•¸æ“š",
                    "é©—è­‰æ ¼å¼ä¸€è‡´æ€§",
                    "æª¢æŸ¥åŠŸèƒ½å®Œæ•´æ€§"
                ],
                expected_outcomes={
                    "new_api_functional": True,
                    "legacy_api_functional": True,
                    "data_consistency": True,
                    "format_compatibility": True,
                    "feature_parity": True
                },
                performance_requirements={
                    "api_response_time": 1.0,
                    "data_match_rate": 0.99
                },
                data_requirements={
                    "test_constellations": ["starlink", "oneweb"],
                    "sample_size": 50
                }
            ),
            
            E2ETestScenario(
                scenario_name="éŒ¯èª¤æ¢å¾©æ¸¬è©¦",
                description="ç³»çµ±éŒ¯èª¤è™•ç†å’Œæ¢å¾©èƒ½åŠ›æ¸¬è©¦",
                test_steps=[
                    "æ¨¡æ“¬ TLE æ•¸æ“šéŒ¯èª¤",
                    "æ¸¬è©¦ç„¡æ•ˆè«‹æ±‚è™•ç†",
                    "æ¨¡æ“¬ç³»çµ±éè¼‰",
                    "æ¸¬è©¦éŒ¯èª¤æ¢å¾©",
                    "é©—è­‰ç³»çµ±é­¯æ£’æ€§"
                ],
                expected_outcomes={
                    "error_handling_correct": True,
                    "graceful_degradation": True,
                    "recovery_successful": True,
                    "no_data_corruption": True,
                    "system_resilient": True
                },
                performance_requirements={
                    "error_response_time": 1.0,
                    "recovery_time": 30.0
                },
                data_requirements={
                    "error_scenarios": 5,
                    "recovery_validation": True
                }
            )
        ]
        
        logger.info(f"å®šç¾©äº† {len(scenarios)} å€‹æ¸¬è©¦å ´æ™¯")
        return scenarios
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ‰€æœ‰ç«¯åˆ°ç«¯æ¸¬è©¦"""
        logger.info("ğŸš€ é–‹å§‹ç«¯åˆ°ç«¯æ¸¬è©¦...")
        
        overall_start = datetime.now(timezone.utc)
        test_summary = {
            "test_start_time": overall_start.isoformat(),
            "total_scenarios": len(self.test_scenarios),
            "scenario_results": {},
            "overall_success": False,
            "summary_stats": {}
        }
        
        try:
            # åˆå§‹åŒ–æ¸¬è©¦çµ„ä»¶
            await self._initialize_test_components()
            
            # åŸ·è¡Œæ¯å€‹æ¸¬è©¦å ´æ™¯
            for scenario in self.test_scenarios:
                logger.info(f"ğŸ“‹ åŸ·è¡Œæ¸¬è©¦å ´æ™¯: {scenario.scenario_name}")
                
                scenario_result = await self._execute_test_scenario(scenario)
                test_summary["scenario_results"][scenario.scenario_name] = scenario_result
                
                status = "âœ… é€šé" if scenario_result["success"] else "âŒ å¤±æ•—"
                logger.info(f"{status}: {scenario.scenario_name}")
            
            # è¨ˆç®—ç¸½é«”çµæœ
            overall_end = datetime.now(timezone.utc)
            test_summary["test_end_time"] = overall_end.isoformat()
            test_summary["total_duration"] = (overall_end - overall_start).total_seconds()
            
            # çµ±è¨ˆæˆåŠŸç‡
            successful_scenarios = sum(1 for result in test_summary["scenario_results"].values() if result["success"])
            test_summary["success_rate"] = (successful_scenarios / len(self.test_scenarios)) * 100
            test_summary["overall_success"] = successful_scenarios == len(self.test_scenarios)
            
            # æ€§èƒ½çµ±è¨ˆ
            test_summary["summary_stats"] = self._calculate_summary_stats()
            
            logger.info(f"ğŸ¯ ç«¯åˆ°ç«¯æ¸¬è©¦å®Œæˆ: {successful_scenarios}/{len(self.test_scenarios)} å ´æ™¯é€šé")
            return test_summary
            
        except Exception as e:
            logger.error(f"ç«¯åˆ°ç«¯æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
            test_summary["error"] = str(e)
            test_summary["overall_success"] = False
            return test_summary
    
    async def _initialize_test_components(self):
        """åˆå§‹åŒ–æ¸¬è©¦çµ„ä»¶"""
        try:
            # åˆå§‹åŒ– TLE è¼‰å…¥å™¨
            from tle_loader import create_tle_loader
            # ä½¿ç”¨çµ±ä¸€é…ç½®è¼‰å…¥å™¨
            self.tle_loader = create_tle_loader()
            
            # åˆå§‹åŒ– SGP4 å¼•æ“
            from sgp4_engine import create_sgp4_engine, validate_sgp4_availability
            
            if not validate_sgp4_availability():
                raise RuntimeError("SGP4 åº«ä¸å¯ç”¨")
            
            self.sgp4_engine = create_sgp4_engine()
            
            # åˆå§‹åŒ–æ•¸æ“šæä¾›è€…å’Œæ¨™æº–æ¥å£
            from phase1_data_provider import create_sgp4_data_provider
            from phase2_interface import create_standard_interface
            
            # ä½¿ç”¨çµ±ä¸€é…ç½®ï¼Œç„¡éœ€æŒ‡å®šè·¯å¾‘
            self.data_provider = create_sgp4_data_provider()
            self.standard_interface = create_standard_interface(self.data_provider)
            
            logger.info("âœ… æ¸¬è©¦çµ„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¸¬è©¦çµ„ä»¶åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def _execute_test_scenario(self, scenario: E2ETestScenario) -> Dict[str, Any]:
        """åŸ·è¡Œå–®å€‹æ¸¬è©¦å ´æ™¯"""
        start_time = datetime.now(timezone.utc)
        
        scenario_result = {
            "scenario_name": scenario.scenario_name,
            "description": scenario.description,
            "start_time": start_time.isoformat(),
            "success": False,
            "test_steps_results": {},
            "performance_metrics": {},
            "validation_results": {},
            "error_message": None
        }
        
        try:
            # æ ¹æ“šå ´æ™¯é¡å‹é¸æ“‡æ¸¬è©¦æ–¹æ³•
            if scenario.scenario_name == "åŸºç¤æ•¸æ“šæµæ¸¬è©¦":
                result = await self._test_basic_data_flow(scenario)
            elif scenario.scenario_name == "é«˜è² è¼‰ä½µç™¼æ¸¬è©¦":
                result = await self._test_high_load_concurrent(scenario)
            elif scenario.scenario_name == "å¤§è¦æ¨¡æ•¸æ“šè™•ç†æ¸¬è©¦":
                result = await self._test_large_scale_processing(scenario)
            elif scenario.scenario_name == "API å…¼å®¹æ€§æ¸¬è©¦":
                result = await self._test_api_compatibility(scenario)
            elif scenario.scenario_name == "éŒ¯èª¤æ¢å¾©æ¸¬è©¦":
                result = await self._test_error_recovery(scenario)
            else:
                raise ValueError(f"æœªçŸ¥æ¸¬è©¦å ´æ™¯: {scenario.scenario_name}")
            
            scenario_result.update(result)
            
        except Exception as e:
            logger.error(f"æ¸¬è©¦å ´æ™¯åŸ·è¡Œå¤±æ•— {scenario.scenario_name}: {e}")
            scenario_result["error_message"] = str(e)
        
        end_time = datetime.now(timezone.utc)
        scenario_result["end_time"] = end_time.isoformat()
        scenario_result["duration_seconds"] = (end_time - start_time).total_seconds()
        
        return scenario_result
    
    async def _test_basic_data_flow(self, scenario: E2ETestScenario) -> Dict[str, Any]:
        """æ¸¬è©¦åŸºç¤æ•¸æ“šæµ"""
        logger.info("åŸ·è¡ŒåŸºç¤æ•¸æ“šæµæ¸¬è©¦...")
        
        results = {
            "test_steps_results": {},
            "performance_metrics": {},
            "validation_results": {},
            "success": False
        }
        
        try:
            # Step 1: è¼‰å…¥ TLE æ•¸æ“š
            step1_start = time.time()
            tle_result = self.tle_loader.load_all_tle_data()
            step1_time = time.time() - step1_start
            
            step1_success = tle_result.total_records > scenario.data_requirements["min_satellites"]
            results["test_steps_results"]["è¼‰å…¥ TLE æ•¸æ“š"] = {
                "success": step1_success,
                "duration": step1_time,
                "records_loaded": tle_result.total_records
            }
            
            if not step1_success:
                results["error_message"] = f"TLE æ•¸æ“šä¸è¶³: {tle_result.total_records}"
                return results
            
            # Step 2: å‰µå»º SGP4 è¡›æ˜Ÿå°è±¡
            step2_start = time.time()
            created_satellites = 0
            
            test_satellites = tle_result.records[:100]  # æ¸¬è©¦å‰100é¡†
            for record in test_satellites:
                if self.sgp4_engine.create_satellite(record.satellite_id, record.line1, record.line2):
                    created_satellites += 1
            
            step2_time = time.time() - step2_start
            step2_success = created_satellites >= len(test_satellites) * 0.9
            
            results["test_steps_results"]["å‰µå»º SGP4 è¡›æ˜Ÿå°è±¡"] = {
                "success": step2_success,
                "duration": step2_time,
                "satellites_created": created_satellites,
                "total_attempted": len(test_satellites)
            }
            
            # Step 3: åŸ·è¡Œè»Œé“è¨ˆç®—
            step3_start = time.time()
            test_time = datetime.now(timezone.utc)
            successful_calculations = 0
            
            for record in test_satellites[:50]:
                result = self.sgp4_engine.calculate_position(record.satellite_id, test_time)
                if result and result.success:
                    successful_calculations += 1
            
            step3_time = time.time() - step3_start
            step3_success = successful_calculations >= 45  # 90% æˆåŠŸç‡
            
            results["test_steps_results"]["åŸ·è¡Œè»Œé“è¨ˆç®—"] = {
                "success": step3_success,
                "duration": step3_time,
                "successful_calculations": successful_calculations,
                "calculation_rate": successful_calculations / step3_time
            }
            
            # Step 4: é€šéæ¨™æº–æ¥å£æŸ¥è©¢
            step4_start = time.time()
            
            query_request = self.standard_interface.create_query_request(
                constellations=["starlink"],
                max_records=10
            )
            
            query_response = self.standard_interface.execute_query(query_request)
            step4_time = time.time() - step4_start
            step4_success = query_response.success and query_response.returned_records > 0
            
            results["test_steps_results"]["é€šéæ¨™æº–æ¥å£æŸ¥è©¢"] = {
                "success": step4_success,
                "duration": step4_time,
                "returned_records": query_response.returned_records
            }
            
            # Step 5: é©—è­‰ API éŸ¿æ‡‰
            step5_start = time.time()
            
            try:
                # æ¸¬è©¦å¥åº·æª¢æŸ¥
                health_response = requests.get(f"{self.api_base_url}/health", timeout=10)
                health_ok = health_response.status_code == 200
                
                # æ¸¬è©¦è¡›æ˜Ÿåˆ—è¡¨
                satellites_response = requests.get(f"{self.api_base_url}/satellites?limit=10", timeout=10)
                satellites_ok = satellites_response.status_code == 200
                
                step5_time = time.time() - step5_start
                step5_success = health_ok and satellites_ok
                
            except Exception as api_error:
                step5_time = time.time() - step5_start
                step5_success = False
                logger.warning(f"API æ¸¬è©¦å¤±æ•—: {api_error}")
            
            results["test_steps_results"]["é©—è­‰ API éŸ¿æ‡‰"] = {
                "success": step5_success,
                "duration": step5_time,
                "health_check": health_ok if 'health_ok' in locals() else False,
                "satellites_api": satellites_ok if 'satellites_ok' in locals() else False
            }
            
            # è¨ˆç®—æ€§èƒ½æŒ‡æ¨™
            results["performance_metrics"] = {
                "tle_load_time": step1_time,
                "satellite_creation_time": step2_time,
                "calculation_time": step3_time,
                "query_time": step4_time,
                "api_response_time": step5_time
            }
            
            # é©—è­‰æ€§èƒ½è¦æ±‚
            perf_requirements = scenario.performance_requirements
            results["validation_results"] = {
                "tle_load_performance": step1_time <= perf_requirements["tle_load_time"],
                "satellite_creation_performance": step2_time <= perf_requirements["satellite_creation_time"],
                "calculation_performance": step3_time <= perf_requirements["calculation_time"],
                "api_performance": step5_time <= perf_requirements["api_response_time"]
            }
            
            # åˆ¤æ–·æ•´é«”æˆåŠŸ
            all_steps_success = all(step["success"] for step in results["test_steps_results"].values())
            all_perf_ok = all(results["validation_results"].values())
            results["success"] = all_steps_success and all_perf_ok
            
            return results
            
        except Exception as e:
            logger.error(f"åŸºç¤æ•¸æ“šæµæ¸¬è©¦å¤±æ•—: {e}")
            results["error_message"] = str(e)
            return results
    
    async def _test_high_load_concurrent(self, scenario: E2ETestScenario) -> Dict[str, Any]:
        """æ¸¬è©¦é«˜è² è¼‰ä½µç™¼"""
        logger.info("åŸ·è¡Œé«˜è² è¼‰ä½µç™¼æ¸¬è©¦...")
        
        results = {
            "test_steps_results": {},
            "performance_metrics": {},
            "validation_results": {},
            "success": False
        }
        
        try:
            concurrent_users = scenario.performance_requirements["concurrent_users"]
            requests_per_user = scenario.performance_requirements["requests_per_user"]
            max_response_time = scenario.performance_requirements["max_response_time"]
            
            # æº–å‚™ä½µç™¼æ¸¬è©¦å‡½æ•¸
            def make_api_request(user_id: int, request_id: int) -> Dict[str, Any]:
                try:
                    start_time = time.time()
                    
                    # éš¨æ©Ÿé¸æ“‡ API ç«¯é»
                    endpoints = [
                        f"{self.api_base_url}/satellites?limit=10",
                        f"{self.api_base_url}/api/v1/phase1/satellite_orbits?constellation=starlink&count=5",
                        f"{self.api_base_url}/health"
                    ]
                    
                    import random
                    endpoint = random.choice(endpoints)
                    response = requests.get(endpoint, timeout=30)
                    
                    end_time = time.time()
                    response_time = end_time - start_time
                    
                    return {
                        "user_id": user_id,
                        "request_id": request_id,
                        "success": response.status_code == 200,
                        "response_time": response_time,
                        "endpoint": endpoint,
                        "status_code": response.status_code
                    }
                    
                except Exception as e:
                    return {
                        "user_id": user_id,
                        "request_id": request_id,
                        "success": False,
                        "response_time": max_response_time + 1,
                        "error": str(e)
                    }
            
            # åŸ·è¡Œä½µç™¼æ¸¬è©¦
            concurrent_start = time.time()
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_users) as executor:
                # æäº¤æ‰€æœ‰è«‹æ±‚
                futures = []
                for user_id in range(concurrent_users):
                    for request_id in range(requests_per_user):
                        future = executor.submit(make_api_request, user_id, request_id)
                        futures.append(future)
                
                # æ”¶é›†çµæœ
                request_results = []
                for future in concurrent.futures.as_completed(futures):
                    result = future.result()
                    request_results.append(result)
            
            concurrent_end = time.time()
            total_duration = concurrent_end - concurrent_start
            
            # åˆ†æçµæœ
            successful_requests = sum(1 for r in request_results if r["success"])
            total_requests = len(request_results)
            success_rate = successful_requests / total_requests if total_requests > 0 else 0
            
            response_times = [r["response_time"] for r in request_results if r["success"]]
            avg_response_time = np.mean(response_times) if response_times else 0
            max_actual_response_time = np.max(response_times) if response_times else 0
            
            # è¨˜éŒ„æ¸¬è©¦çµæœ
            results["test_steps_results"]["ä½µç™¼è«‹æ±‚åŸ·è¡Œ"] = {
                "success": success_rate >= scenario.performance_requirements["success_rate"],
                "duration": total_duration,
                "total_requests": total_requests,
                "successful_requests": successful_requests,
                "success_rate": success_rate
            }
            
            results["performance_metrics"] = {
                "concurrent_users": concurrent_users,
                "requests_per_user": requests_per_user,
                "total_requests": total_requests,
                "successful_requests": successful_requests,
                "success_rate": success_rate,
                "total_duration": total_duration,
                "requests_per_second": total_requests / total_duration,
                "average_response_time": avg_response_time,
                "max_response_time": max_actual_response_time
            }
            
            # é©—è­‰æ€§èƒ½è¦æ±‚
            results["validation_results"] = {
                "success_rate_ok": success_rate >= scenario.performance_requirements["success_rate"],
                "response_time_ok": max_actual_response_time <= max_response_time,
                "concurrency_handled": True
            }
            
            results["success"] = all(results["validation_results"].values())
            
            return results
            
        except Exception as e:
            logger.error(f"é«˜è² è¼‰ä½µç™¼æ¸¬è©¦å¤±æ•—: {e}")
            results["error_message"] = str(e)
            return results
    
    async def _test_large_scale_processing(self, scenario: E2ETestScenario) -> Dict[str, Any]:
        """æ¸¬è©¦å¤§è¦æ¨¡æ•¸æ“šè™•ç†"""
        logger.info("åŸ·è¡Œå¤§è¦æ¨¡æ•¸æ“šè™•ç†æ¸¬è©¦...")
        
        results = {
            "test_steps_results": {},
            "performance_metrics": {},
            "validation_results": {},
            "success": False
        }
        
        try:
            # ç²å–æ•¸æ“šè¦†è“‹ä¿¡æ¯
            coverage = self.data_provider.get_data_coverage()
            total_satellites = coverage.get("total_satellites", 0)
            
            results["test_steps_results"]["æ•¸æ“šè¦æ¨¡æª¢æŸ¥"] = {
                "success": total_satellites >= scenario.performance_requirements["total_satellites"],
                "total_satellites": total_satellites,
                "target_satellites": scenario.performance_requirements["total_satellites"]
            }
            
            # æ¸¬è©¦å¤§é‡æ•¸æ“šæŸ¥è©¢
            large_query_start = time.time()
            
            query_request = self.standard_interface.create_query_request(
                max_records=1000
            )
            
            query_response = self.standard_interface.execute_query(query_request)
            
            large_query_time = time.time() - large_query_start
            
            results["test_steps_results"]["å¤§é‡æ•¸æ“šæŸ¥è©¢"] = {
                "success": query_response.success and query_response.returned_records >= 500,
                "duration": large_query_time,
                "returned_records": query_response.returned_records,
                "total_matches": query_response.total_matches
            }
            
            # æ€§èƒ½æŒ‡æ¨™
            results["performance_metrics"] = {
                "total_satellites": total_satellites,
                "large_query_time": large_query_time,
                "query_records": query_response.returned_records,
                "records_per_second": query_response.returned_records / large_query_time if large_query_time > 0 else 0
            }
            
            # é©—è­‰è¦æ±‚
            results["validation_results"] = {
                "scale_requirement": total_satellites >= scenario.performance_requirements["total_satellites"],
                "query_performance": large_query_time <= scenario.performance_requirements["large_query_time"],
                "data_availability": query_response.returned_records > 0
            }
            
            results["success"] = all(results["validation_results"].values())
            
            return results
            
        except Exception as e:
            logger.error(f"å¤§è¦æ¨¡æ•¸æ“šè™•ç†æ¸¬è©¦å¤±æ•—: {e}")
            results["error_message"] = str(e)
            return results
    
    async def _test_api_compatibility(self, scenario: E2ETestScenario) -> Dict[str, Any]:
        """æ¸¬è©¦ API å…¼å®¹æ€§"""
        logger.info("åŸ·è¡Œ API å…¼å®¹æ€§æ¸¬è©¦...")
        
        results = {
            "test_steps_results": {},
            "performance_metrics": {},
            "validation_results": {},
            "success": False
        }
        
        try:
            # æ¸¬è©¦æ–°æ¨™æº– API
            new_api_start = time.time()
            
            try:
                new_response = requests.get(
                    f"{self.api_base_url}/satellites?constellation=starlink&limit=10",
                    timeout=10
                )
                new_api_success = new_response.status_code == 200
                new_data = new_response.json() if new_api_success else None
            except Exception as e:
                new_api_success = False
                new_data = None
                logger.warning(f"æ–° API æ¸¬è©¦å¤±æ•—: {e}")
            
            new_api_time = time.time() - new_api_start
            
            # æ¸¬è©¦å…¼å®¹ API
            legacy_api_start = time.time()
            
            try:
                legacy_response = requests.get(
                    f"{self.api_base_url}/api/v1/phase1/satellite_orbits?constellation=starlink&count=10",
                    timeout=10
                )
                legacy_api_success = legacy_response.status_code == 200
                legacy_data = legacy_response.json() if legacy_api_success else None
            except Exception as e:
                legacy_api_success = False
                legacy_data = None
                logger.warning(f"å…¼å®¹ API æ¸¬è©¦å¤±æ•—: {e}")
            
            legacy_api_time = time.time() - legacy_api_start
            
            # è¨˜éŒ„æ¸¬è©¦çµæœ
            results["test_steps_results"]["æ–°æ¨™æº– API"] = {
                "success": new_api_success,
                "duration": new_api_time,
                "data_received": new_data is not None
            }
            
            results["test_steps_results"]["å…¼å®¹ API"] = {
                "success": legacy_api_success,
                "duration": legacy_api_time,
                "data_received": legacy_data is not None
            }
            
            # æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥ï¼ˆå¦‚æœå…©å€‹ API éƒ½æˆåŠŸï¼‰
            data_consistency = False
            if new_api_success and legacy_api_success and new_data and legacy_data:
                # æª¢æŸ¥æ•¸æ“šæ ¼å¼å’Œå…§å®¹ï¼ˆç°¡åŒ–æª¢æŸ¥ï¼‰
                try:
                    new_count = len(new_data.get("satellites", [])) if isinstance(new_data, dict) else len(new_data)
                    legacy_count = len(legacy_data) if isinstance(legacy_data, list) else 0
                    
                    data_consistency = abs(new_count - legacy_count) <= 2  # å…è¨±å°å¹…å·®ç•°
                except Exception:
                    data_consistency = False
            
            results["test_steps_results"]["æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥"] = {
                "success": data_consistency,
                "new_api_data": bool(new_data),
                "legacy_api_data": bool(legacy_data)
            }
            
            # æ€§èƒ½æŒ‡æ¨™
            results["performance_metrics"] = {
                "new_api_response_time": new_api_time,
                "legacy_api_response_time": legacy_api_time,
                "response_time_ratio": legacy_api_time / new_api_time if new_api_time > 0 else 0
            }
            
            # é©—è­‰è¦æ±‚
            results["validation_results"] = {
                "new_api_functional": new_api_success,
                "legacy_api_functional": legacy_api_success,
                "data_consistency": data_consistency,
                "performance_acceptable": new_api_time <= scenario.performance_requirements["api_response_time"]
            }
            
            results["success"] = all(results["validation_results"].values())
            
            return results
            
        except Exception as e:
            logger.error(f"API å…¼å®¹æ€§æ¸¬è©¦å¤±æ•—: {e}")
            results["error_message"] = str(e)
            return results
    
    async def _test_error_recovery(self, scenario: E2ETestScenario) -> Dict[str, Any]:
        """æ¸¬è©¦éŒ¯èª¤æ¢å¾©"""
        logger.info("åŸ·è¡ŒéŒ¯èª¤æ¢å¾©æ¸¬è©¦...")
        
        results = {
            "test_steps_results": {},
            "performance_metrics": {},
            "validation_results": {},
            "success": False
        }
        
        try:
            # æ¸¬è©¦ç„¡æ•ˆè«‹æ±‚è™•ç†
            error_tests = [
                {
                    "name": "ç„¡æ•ˆæ˜Ÿåº§åç¨±",
                    "url": f"{self.api_base_url}/satellites?constellation=invalid_constellation",
                    "expected_status": [400, 404]
                },
                {
                    "name": "è¶…å¤§æŸ¥è©¢é™åˆ¶",
                    "url": f"{self.api_base_url}/satellites?limit=999999",
                    "expected_status": [400, 413]
                },
                {
                    "name": "ç„¡æ•ˆ API è·¯å¾‘",
                    "url": f"{self.api_base_url}/invalid_endpoint",
                    "expected_status": [404]
                }
            ]
            
            error_handling_results = {}
            
            for test in error_tests:
                try:
                    error_start = time.time()
                    response = requests.get(test["url"], timeout=10)
                    error_time = time.time() - error_start
                    
                    correct_error_handling = response.status_code in test["expected_status"]
                    
                    error_handling_results[test["name"]] = {
                        "success": correct_error_handling,
                        "duration": error_time,
                        "status_code": response.status_code,
                        "expected_status": test["expected_status"]
                    }
                    
                except Exception as e:
                    error_handling_results[test["name"]] = {
                        "success": False,
                        "error": str(e)
                    }
            
            results["test_steps_results"]["éŒ¯èª¤è™•ç†æ¸¬è©¦"] = error_handling_results
            
            # æ¸¬è©¦ç³»çµ±æ¢å¾©ï¼ˆæ¸¬è©¦å¥åº·æª¢æŸ¥ï¼‰
            recovery_start = time.time()
            
            try:
                health_response = requests.get(f"{self.api_base_url}/health", timeout=10)
                system_recovered = health_response.status_code == 200
                
                if system_recovered:
                    health_data = health_response.json()
                    system_healthy = health_data.get("service") in ["healthy", "degraded"]
                else:
                    system_healthy = False
                    
            except Exception as e:
                system_recovered = False
                system_healthy = False
                logger.warning(f"ç³»çµ±æ¢å¾©æ¸¬è©¦å¤±æ•—: {e}")
            
            recovery_time = time.time() - recovery_start
            
            results["test_steps_results"]["ç³»çµ±æ¢å¾©æ¸¬è©¦"] = {
                "success": system_recovered and system_healthy,
                "duration": recovery_time,
                "system_responded": system_recovered,
                "system_healthy": system_healthy
            }
            
            # æ€§èƒ½æŒ‡æ¨™
            avg_error_response_time = np.mean([
                r.get("duration", 0) for r in error_handling_results.values() 
                if "duration" in r
            ])
            
            results["performance_metrics"] = {
                "average_error_response_time": avg_error_response_time,
                "recovery_time": recovery_time,
                "error_tests_count": len(error_tests)
            }
            
            # é©—è­‰è¦æ±‚
            error_handling_success = all(
                r["success"] for r in error_handling_results.values()
            )
            
            results["validation_results"] = {
                "error_handling_correct": error_handling_success,
                "recovery_successful": system_recovered and system_healthy,
                "error_response_time_ok": avg_error_response_time <= scenario.performance_requirements["error_response_time"]
            }
            
            results["success"] = all(results["validation_results"].values())
            
            return results
            
        except Exception as e:
            logger.error(f"éŒ¯èª¤æ¢å¾©æ¸¬è©¦å¤±æ•—: {e}")
            results["error_message"] = str(e)
            return results
    
    def _calculate_summary_stats(self) -> Dict[str, Any]:
        """è¨ˆç®—ç¸½çµçµ±è¨ˆ"""
        try:
            all_durations = []
            all_performance_metrics = {}
            
            for result in self.test_results:
                if hasattr(result, 'duration_seconds'):
                    all_durations.append(result.duration_seconds)
                
                if hasattr(result, 'performance_data') and result.performance_data:
                    for key, value in result.performance_data.items():
                        if key not in all_performance_metrics:
                            all_performance_metrics[key] = []
                        all_performance_metrics[key].append(value)
            
            summary = {
                "total_test_time": sum(all_durations) if all_durations else 0,
                "average_test_time": np.mean(all_durations) if all_durations else 0,
                "performance_aggregates": {}
            }
            
            for metric, values in all_performance_metrics.items():
                summary["performance_aggregates"][metric] = {
                    "average": np.mean(values),
                    "min": np.min(values),
                    "max": np.max(values)
                }
            
            return summary
            
        except Exception as e:
            logger.error(f"è¨ˆç®—ç¸½çµçµ±è¨ˆå¤±æ•—: {e}")
            return {"error": str(e)}
    
    def export_test_results(self, output_path: str):
        """å°å‡ºæ¸¬è©¦çµæœ"""
        try:
            # æº–å‚™å°å‡ºæ•¸æ“š
            export_data = {
                "test_metadata": {
                    "export_timestamp": datetime.now(timezone.utc).isoformat(),
                    "api_base_url": self.api_base_url,
                    "total_scenarios": len(self.test_scenarios)
                },
                "test_scenarios": [asdict(scenario) for scenario in self.test_scenarios],
                "test_results": [asdict(result) for result in self.test_results]
            }
            
            # å¯«å…¥æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"æ¸¬è©¦çµæœå·²å°å‡ºåˆ°: {output_path}")
            
        except Exception as e:
            logger.error(f"å°å‡ºæ¸¬è©¦çµæœå¤±æ•—: {e}")

# ä¾¿åˆ©å‡½æ•¸
def create_e2e_tester(api_base_url: str = None) -> EndToEndTester:
    """å‰µå»ºç«¯åˆ°ç«¯æ¸¬è©¦å™¨ï¼Œè‡ªå‹•å¾é…ç½®ç³»çµ±ç²å– API URL"""
    return EndToEndTester(api_base_url)

async def main():
    """ä¸»å‡½æ•¸"""
    logging.basicConfig(level=logging.INFO)
    
    try:
        print("ğŸš€ Phase 1 ç«¯åˆ°ç«¯æ¸¬è©¦")
        print("=" * 50)
        
        # å‰µå»ºæ¸¬è©¦å™¨
        tester = create_e2e_tester()
        
        # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
        test_summary = await tester.run_all_tests()
        
        # é¡¯ç¤ºçµæœ
        print(f"\nğŸ“Š æ¸¬è©¦ç¸½çµ:")
        print(f"åŸ·è¡Œå ´æ™¯: {test_summary['total_scenarios']}")
        print(f"æˆåŠŸç‡: {test_summary['success_rate']:.1f}%")
        print(f"ç¸½è€—æ™‚: {test_summary['total_duration']:.1f}s")
        print(f"æ•´é«”çµæœ: {'âœ… é€šé' if test_summary['overall_success'] else 'âŒ å¤±æ•—'}")
        
        # å°å‡ºçµæœ
        output_path = PHASE1_ROOT / "05_integration" / "e2e_test_results.json"
        tester.export_test_results(str(output_path))
        print(f"è©³ç´°çµæœå·²ä¿å­˜: {output_path}")
        
        return 0 if test_summary['overall_success'] else 1
        
    except Exception as e:
        logger.error(f"ç«¯åˆ°ç«¯æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        return 1

if __name__ == "__main__":
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)