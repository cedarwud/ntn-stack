"""
è»Œé“æ•¸æ“šè¼‰å…¥å™¨ - Stage 2æ¨¡çµ„åŒ–çµ„ä»¶

è·è²¬ï¼š
1. å¾Stage 1è¼‰å…¥è»Œé“è¨ˆç®—çµæœ
2. è§£æå’Œé©—è­‰è»Œé“æ•¸æ“šæ ¼å¼
3. æŒ‰æ˜Ÿåº§åˆ†çµ„è™•ç†æ•¸æ“š
4. æä¾›çµ±ä¸€çš„æ•¸æ“šè¨ªå•æ¥å£
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class OrbitalDataLoader:
    """è»Œé“æ•¸æ“šè¼‰å…¥å™¨ - å°ˆé–€è™•ç†Stage 1çš„è¼¸å‡º"""
    
    def __init__(self, input_dir: str = None):
        self.logger = logging.getLogger(f"{__name__}.OrbitalDataLoader")
        
        # è‡ªå‹•æª¢æ¸¬ç’°å¢ƒä¸¦è¨­ç½®è¼¸å…¥ç›®éŒ„
        if input_dir is None:
            if os.path.exists("/satellite-processing") or Path(".").exists():
                input_dir = "data/stage1_outputs"  # å®¹å™¨ç’°å¢ƒ
            else:
                input_dir = "/tmp/ntn-stack-dev/stage1_outputs"  # é–‹ç™¼ç’°å¢ƒ
        
        self.input_dir = Path(input_dir)
        
        # è¼‰å…¥çµ±è¨ˆ
        self.load_statistics = {
            "files_found": 0,
            "satellites_loaded": 0,
            "constellations_found": 0,
            "load_errors": 0
        }
    
    def load_stage1_output(self) -> Dict[str, Any]:
        """
        è¼‰å…¥Stage 1çš„è»Œé“è¨ˆç®—è¼¸å‡º
        
        Returns:
            Stage 1çš„è»Œé“æ•¸æ“š
        """
        self.logger.info("ğŸ“¥ è¼‰å…¥Stage 1è»Œé“è¨ˆç®—è¼¸å‡º...")
        
        # æŸ¥æ‰¾Stage 1è¼¸å‡ºæ–‡ä»¶
        possible_files = [
            "orbital_calculation_output.json",
            "tle_calculation_outputs.json", 
            "stage1_output.json"
        ]
        
        stage1_data = None
        
        for filename in possible_files:
            # ğŸš¨ v6.0ä¿®å¾©: ä½¿ç”¨os.path.joiné€²è¡Œè·¯å¾‘æ‹¼æ¥ï¼Œé¿å…str / stréŒ¯èª¤
            import os
            input_file = os.path.join(str(self.input_dir), filename)
            if os.path.exists(input_file):
                self.logger.info(f"æ‰¾åˆ°Stage 1è¼¸å‡ºæ–‡ä»¶: {input_file}")
                try:
                    with open(input_file, 'r', encoding='utf-8') as f:
                        stage1_data = json.load(f)
                    
                    self.load_statistics["files_found"] = 1
                    break
                    
                except Exception as e:
                    self.logger.error(f"è¼‰å…¥Stage 1è¼¸å‡ºå¤±æ•—: {e}")
                    self.load_statistics["load_errors"] += 1
                    continue
        
        if stage1_data is None:
            self.logger.error(f"æœªæ‰¾åˆ°Stage 1è¼¸å‡ºæ–‡ä»¶æ–¼: {self.input_dir}")
            raise FileNotFoundError(f"Stage 1è¼¸å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {self.input_dir}")
        
        # é©—è­‰æ•¸æ“šæ ¼å¼
        validated_data = self._validate_and_normalize_stage1_data(stage1_data)

        # ğŸš¨ v6.0 é‡æ§‹ï¼šæå–Stage 1æ™‚é–“åŸºæº–
        stage1_time_base = self._extract_stage1_time_base(stage1_data)
        validated_data["inherited_time_base"] = stage1_time_base

        self.logger.info(f"âœ… Stage 1æ•¸æ“šè¼‰å…¥æˆåŠŸ: {self.load_statistics['satellites_loaded']} é¡†è¡›æ˜Ÿ")
        self.logger.info(f"ğŸ¯ ç¹¼æ‰¿Stage 1æ™‚é–“åŸºæº–: {stage1_time_base}")
        return validated_data
    
    def _validate_and_normalize_stage1_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """é©—è­‰ä¸¦æ¨™æº–åŒ–Stage 1æ•¸æ“šæ ¼å¼"""
        
        if not isinstance(data, dict):
            raise ValueError("Stage 1æ•¸æ“šæ ¼å¼éŒ¯èª¤: å¿…é ˆæ˜¯å­—å…¸æ ¼å¼")
        
        # æª¢æŸ¥å¿…è¦çš„æ•¸æ“šçµæ§‹
        if "data" not in data:
            raise ValueError("Stage 1æ•¸æ“šç¼ºå°‘ 'data' æ¬„ä½")
        
        data_section = data["data"]
        all_satellites = []
        
        # è™•ç†æ–°æ ¼å¼ï¼šæŒ‰æ˜Ÿåº§çµ„ç¹”çš„æ•¸æ“š
        if "constellations" in data_section:
            self.logger.info("æª¢æ¸¬åˆ°æ–°æ ¼å¼: æŒ‰æ˜Ÿåº§çµ„ç¹”çš„æ•¸æ“š")
            
            for constellation_name, constellation_data in data_section["constellations"].items():
                satellites = constellation_data.get("satellites", {})
                
                for sat_id, sat_data in satellites.items():
                    # æ¨™æº–åŒ–è¡›æ˜Ÿæ•¸æ“š
                    normalized_sat = self._normalize_satellite_data(sat_data, constellation_name, sat_id)
                    if normalized_sat:
                        all_satellites.append(normalized_sat)
                        
                self.load_statistics["constellations_found"] += 1
        
        # è™•ç†èˆŠæ ¼å¼ï¼šç›´æ¥çš„è¡›æ˜Ÿæ•¸çµ„
        elif "satellites" in data_section:
            self.logger.info("æª¢æ¸¬åˆ°èˆŠæ ¼å¼: ç›´æ¥çš„è¡›æ˜Ÿæ•¸çµ„")
            
            satellites = data_section["satellites"]
            
            if isinstance(satellites, dict):
                # å­—å…¸æ ¼å¼çš„è¡›æ˜Ÿæ•¸æ“š
                for sat_id, sat_data in satellites.items():
                    normalized_sat = self._normalize_satellite_data(
                        sat_data, 
                        sat_data.get('constellation', 'unknown'), 
                        sat_id
                    )
                    if normalized_sat:
                        all_satellites.append(normalized_sat)
            
            elif isinstance(satellites, list):
                # åˆ—è¡¨æ ¼å¼çš„è¡›æ˜Ÿæ•¸æ“š
                for sat_data in satellites:
                    normalized_sat = self._normalize_satellite_data(
                        sat_data,
                        sat_data.get('constellation', 'unknown'),
                        sat_data.get('satellite_id', 'unknown')
                    )
                    if normalized_sat:
                        all_satellites.append(normalized_sat)
        
        else:
            raise ValueError("Stage 1æ•¸æ“šæ ¼å¼éŒ¯èª¤: ç¼ºå°‘ 'constellations' æˆ– 'satellites' æ¬„ä½")
        
        self.load_statistics["satellites_loaded"] = len(all_satellites)
        
        # è¿”å›æ¨™æº–åŒ–çš„æ•¸æ“šçµæ§‹
        return {
            "satellites": all_satellites,
            "metadata": data.get("metadata", {}),
            "load_statistics": self.load_statistics.copy()
        }
    
    def _normalize_satellite_data(self, sat_data: Dict[str, Any], 
                                 constellation: str, sat_id: str) -> Optional[Dict[str, Any]]:
        """æ¨™æº–åŒ–å–®é¡†è¡›æ˜Ÿçš„æ•¸æ“šæ ¼å¼"""
        
        try:
            # æª¢æŸ¥å¿…è¦çš„è»Œé“ä½ç½®æ•¸æ“š
            orbital_positions = sat_data.get("orbital_positions", [])
            
            if not orbital_positions:
                self.logger.warning(f"è¡›æ˜Ÿ {sat_id} ç¼ºå°‘è»Œé“ä½ç½®æ•¸æ“š")
                return None
            
            # æå–è¡›æ˜ŸåŸºæœ¬ä¿¡æ¯
            satellite_info = sat_data.get("satellite_info", {})
            
            normalized_satellite = {
                "satellite_id": sat_id,
                "name": satellite_info.get("name", sat_id),
                "constellation": constellation.lower(),
                "norad_id": satellite_info.get("norad_id", sat_id),
                
                # è»Œé“æ•¸æ“š
                "orbital_positions": orbital_positions,
                "orbital_elements": sat_data.get("orbital_elements", {}),
                
                # æ™‚é–“åºåˆ—æ•¸æ“šï¼ˆç”¨æ–¼å¯è¦‹æ€§è¨ˆç®—ï¼‰
                "position_timeseries": self._convert_to_position_timeseries(orbital_positions),
                
                # åŸå§‹æ•¸æ“šï¼ˆä¿ç•™ç”¨æ–¼é«˜ç´šè¨ˆç®—ï¼‰
                "tle_data": {
                    "line1": satellite_info.get("tle_line1"),
                    "line2": satellite_info.get("tle_line2")
                },
                
                # Stage 1å…ƒæ•¸æ“š
                "stage1_metadata": sat_data.get("calculation_metadata", {})
            }
            
            return normalized_satellite
            
        except Exception as e:
            self.logger.error(f"æ¨™æº–åŒ–è¡›æ˜Ÿæ•¸æ“šå¤±æ•— {sat_id}: {e}")
            return None
    
    def _convert_to_position_timeseries(self, orbital_positions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å°‡è»Œé“ä½ç½®è½‰æ›ç‚ºå¯è¦‹æ€§è¨ˆç®—æ‰€éœ€çš„æ™‚é–“åºåˆ—æ ¼å¼"""
        
        timeseries = []
        
        for i, pos in enumerate(orbital_positions):
            try:
                # åŸºæœ¬ä½ç½®ä¿¡æ¯
                timeseries_point = {
                    "timestamp": pos.get("timestamp", f"point_{i}"),
                    "latitude": pos.get("latitude", 0.0),
                    "longitude": pos.get("longitude", 0.0),
                    "altitude_km": pos.get("altitude_km", 0.0),
                    "velocity_kmps": pos.get("velocity_kmps", 0.0)
                }
                
                # å¦‚æœæœ‰ECIåæ¨™ï¼Œæ·»åŠ å®ƒå€‘
                if "eci" in pos:
                    timeseries_point["eci"] = pos["eci"]
                
                # å¦‚æœå·²ç¶“æœ‰ç›¸å°æ–¼è§€æ¸¬è€…çš„æ•¸æ“šï¼Œä¿ç•™å®ƒå€‘
                if "relative_to_observer" in pos:
                    timeseries_point["relative_to_observer"] = pos["relative_to_observer"]
                elif "elevation" in pos:
                    # è½‰æ›èˆŠæ ¼å¼çš„ä»°è§’æ•¸æ“š
                    timeseries_point["relative_to_observer"] = {
                        "elevation_deg": pos.get("elevation", 0.0),
                        "azimuth_deg": pos.get("azimuth", 0.0),
                        "range_km": pos.get("range_km", 0.0)
                    }
                
                timeseries.append(timeseries_point)
                
            except Exception as e:
                self.logger.warning(f"è½‰æ›ä½ç½®é» {i} æ™‚å‡ºéŒ¯: {e}")
                continue
        
        return timeseries
    
    def get_satellites_by_constellation(self, data: Dict[str, Any]) -> Dict[str, List[Dict[str, Any]]]:
        """æŒ‰æ˜Ÿåº§åˆ†çµ„è¡›æ˜Ÿæ•¸æ“š"""
        
        constellation_groups = {}
        
        for sat in data.get("satellites", []):
            constellation = sat.get("constellation", "unknown").lower()
            
            if constellation not in constellation_groups:
                constellation_groups[constellation] = []
            
            constellation_groups[constellation].append(sat)
        
        return constellation_groups
    
    def get_load_statistics(self) -> Dict[str, Any]:
        """ç²å–è¼‰å…¥çµ±è¨ˆä¿¡æ¯"""
        return self.load_statistics.copy()
    
    def validate_orbital_data_completeness(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """é©—è­‰è»Œé“æ•¸æ“šçš„å®Œæ•´æ€§"""
        
        validation_result = {
            "overall_valid": True,
            "total_satellites": len(data.get("satellites", [])),
            "validation_checks": {},
            "issues": []
        }
        
        satellites = data.get("satellites", [])
        
        if not satellites:
            validation_result["overall_valid"] = False
            validation_result["issues"].append("ç„¡è¡›æ˜Ÿæ•¸æ“š")
            return validation_result
        
        # æª¢æŸ¥è»Œé“ä½ç½®æ•¸æ“šå®Œæ•´æ€§
        satellites_with_positions = 0
        satellites_with_sufficient_positions = 0
        
        for sat in satellites:
            positions = sat.get("orbital_positions", [])
            
            if positions:
                satellites_with_positions += 1
                
                if len(positions) >= 100:  # è‡³å°‘100å€‹ä½ç½®é»
                    satellites_with_sufficient_positions += 1
        
        validation_result["validation_checks"]["position_data_check"] = {
            "satellites_with_positions": satellites_with_positions,
            "satellites_with_sufficient_positions": satellites_with_sufficient_positions,
            "passed": satellites_with_positions == len(satellites)
        }
        
        if satellites_with_positions < len(satellites):
            validation_result["overall_valid"] = False
            validation_result["issues"].append(f"{len(satellites) - satellites_with_positions} é¡†è¡›æ˜Ÿç¼ºå°‘ä½ç½®æ•¸æ“š")
        
        # æª¢æŸ¥æ™‚é–“åºåˆ—é€£çºŒæ€§
        time_continuity_issues = 0
        
        for sat in satellites:
            timeseries = sat.get("position_timeseries", [])
            if len(timeseries) > 1:
                # ç°¡å–®æª¢æŸ¥å‰å¹¾å€‹æ™‚é–“é»
                for i in range(1, min(5, len(timeseries))):
                    prev_ts = timeseries[i-1].get("timestamp", "")
                    curr_ts = timeseries[i].get("timestamp", "")
                    
                    if curr_ts <= prev_ts:
                        time_continuity_issues += 1
                        break
        
        validation_result["validation_checks"]["time_continuity_check"] = {
            "satellites_with_issues": time_continuity_issues,
            "passed": time_continuity_issues == 0
        }
        
        if time_continuity_issues > 0:
            validation_result["overall_valid"] = False
            validation_result["issues"].append(f"{time_continuity_issues} é¡†è¡›æ˜Ÿæ™‚é–“åºåˆ—ä¸é€£çºŒ")

        return validation_result

    def _extract_stage1_time_base(self, stage1_data: Dict[str, Any]) -> str:
        """
        å¾Stage 1 metadataæå–è¨ˆç®—åŸºæº–æ™‚é–“

        v6.0 é‡æ§‹ï¼šç¢ºä¿Stage 2æ­£ç¢ºç¹¼æ‰¿Stage 1çš„æ™‚é–“åŸºæº–
        """
        try:
            metadata = stage1_data.get("metadata", {})

            # å„ªå…ˆä½¿ç”¨TLE epochæ™‚é–“
            tle_epoch_time = metadata.get("tle_epoch_time")
            calculation_base_time = metadata.get("calculation_base_time")

            if tle_epoch_time:
                self.logger.info(f"ğŸ¯ ä½¿ç”¨Stage 1 TLE epochæ™‚é–“: {tle_epoch_time}")
                return tle_epoch_time
            elif calculation_base_time:
                self.logger.info(f"ğŸ¯ ä½¿ç”¨Stage 1è¨ˆç®—åŸºæº–æ™‚é–“: {calculation_base_time}")
                return calculation_base_time
            else:
                # æª¢æŸ¥data sectionä¸­çš„metadata
                data_section = stage1_data.get("data", {})
                if isinstance(data_section, dict) and "metadata" in data_section:
                    data_metadata = data_section["metadata"]
                    tle_epoch_time = data_metadata.get("tle_epoch_time")
                    calculation_base_time = data_metadata.get("calculation_base_time")

                    if tle_epoch_time:
                        self.logger.info(f"ğŸ¯ å¾data sectionä½¿ç”¨TLE epochæ™‚é–“: {tle_epoch_time}")
                        return tle_epoch_time
                    elif calculation_base_time:
                        self.logger.info(f"ğŸ¯ å¾data sectionä½¿ç”¨è¨ˆç®—åŸºæº–æ™‚é–“: {calculation_base_time}")
                        return calculation_base_time

                # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œé€™æ˜¯ä¸€å€‹åš´é‡å•é¡Œ
                self.logger.error("âŒ Stage 1 metadataç¼ºå¤±æ™‚é–“åŸºæº–ä¿¡æ¯")
                self.logger.error(f"å¯ç”¨metadataæ¬„ä½: {list(metadata.keys())}")
                if isinstance(data_section, dict) and "metadata" in data_section:
                    self.logger.error(f"data.metadataæ¬„ä½: {list(data_section['metadata'].keys())}")

                raise ValueError("Stage 1 metadataç¼ºå¤±æ™‚é–“åŸºæº–ä¿¡æ¯ï¼Œç„¡æ³•åŸ·è¡Œæ™‚é–“åŸºæº–ç¹¼æ‰¿")

        except Exception as e:
            self.logger.error(f"âŒ æå–Stage 1æ™‚é–“åŸºæº–å¤±æ•—: {e}")
            raise