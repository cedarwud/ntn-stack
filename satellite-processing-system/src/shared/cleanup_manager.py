"""
çµ±ä¸€æ¸…ç†ç®¡ç†å™¨ - æ”¯æ´é›™æ¨¡å¼æ¸…ç†ç­–ç•¥
Author: Claude Code Assistant  
Date: 2025-09-07
"""

import os
import logging
from pathlib import Path
from typing import Dict, List, Optional, Literal
from dataclasses import dataclass
import inspect

logger = logging.getLogger(__name__)

@dataclass
class CleanupTarget:
    """æ¸…ç†ç›®æ¨™å®šç¾©"""
    stage: int
    output_files: List[str]
    validation_file: str
    directories: List[str] = None

class UnifiedCleanupManager:
    """çµ±ä¸€æ¸…ç†ç®¡ç†å™¨ - æ™ºèƒ½é›™æ¨¡å¼æ¸…ç†"""
    
    # å®šç¾©æ‰€æœ‰éšæ®µçš„æ¸…ç†ç›®æ¨™ï¼ˆåŸºæ–¼å¯¦éš›è™•ç†å™¨åˆ†æï¼‰
    STAGE_CLEANUP_TARGETS = {
        # éšæ®µä¸€ï¼šTLEè¼‰å…¥èˆ‡SGP4è»Œé“è¨ˆç®—
        1: CleanupTarget(
            stage=1,
            output_files=[
                "data/tle_orbital_calculation_output.json"  # 1.4GBï¼Œ8791é¡†è¡›æ˜Ÿè»Œé“è¨ˆç®—çµæœ
            ],
            validation_file="data/validation_snapshots/stage1_validation.json",
            directories=[
                "data/tle_calculation_outputs",  # æ¸…ç†éšæ®µä¸€å°ˆç”¨ç›®éŒ„
                "data/detailed_track_data"       # æ¸…ç†è©³ç´°è»Œé“è¿½è¹¤æ•¸æ“šç›®éŒ„
            ]
        ),
        
        # éšæ®µäºŒï¼šæ™ºèƒ½è¡›æ˜Ÿç¯©é¸  
        2: CleanupTarget(
            stage=2,
            output_files=[
                "data/satellite_visibility_filtered_output.json"  # 1.1GBï¼Œ3101é¡†å¯è¦‹è¡›æ˜Ÿç¯©é¸çµæœ
            ],
            validation_file="data/validation_snapshots/stage2_validation.json",
            directories=[
                "data/intelligent_filtering_outputs"  # æ¸…ç†éšæ®µäºŒå°ˆç”¨ç›®éŒ„
            ]
        ),
        
        # éšæ®µä¸‰ï¼šä¿¡è™Ÿå“è³ªåˆ†æ
        3: CleanupTarget(
            stage=3,
            output_files=[
                "data/signal_quality_analysis_output.json"  # 1.1GBï¼Œ3GPPäº‹ä»¶åˆ†æçµæœ
            ],
            validation_file="data/validation_snapshots/stage3_validation.json",
            directories=[
                "data/signal_analysis_outputs"  # æ¸…ç†éšæ®µä¸‰å°ˆç”¨ç›®éŒ„
            ]
        ),
        
        # éšæ®µå››ï¼šæ™‚é–“åºåˆ—é è™•ç†
        4: CleanupTarget(
            stage=4,
            output_files=[
                "data/timeseries_preprocessing_outputs/animation_enhanced_starlink.json",  # 192MB
                "data/timeseries_preprocessing_outputs/animation_enhanced_oneweb.json",    # 14MB  
                "data/timeseries_preprocessing_outputs/conversion_statistics.json"         # 90 bytes
            ],
            validation_file="data/validation_snapshots/stage4_validation.json",
            directories=[
                "data/timeseries_preprocessing_outputs"  # æ¸…ç†æ•´å€‹éšæ®µå››ç›®éŒ„
            ]
        ),
        
        # éšæ®µäº”ï¼šè³‡æ–™æ•´åˆ
        5: CleanupTarget(
            stage=5,
            output_files=[
                "data/data_integration_outputs/data_integration_output.json"
            ],
            validation_file="data/validation_snapshots/stage5_validation.json",
            directories=[
                "data/data_integration_outputs"  # æ¸…ç†éšæ®µäº”å°ˆç”¨ç›®éŒ„
            ]
        ),
        
        # éšæ®µå…­ï¼šå‹•æ…‹æ± è¦åŠƒ
        6: CleanupTarget(
            stage=6,
            output_files=[
                "data/dynamic_pool_planning_outputs/enhanced_dynamic_pools_output.json"
            ],
            validation_file="data/validation_snapshots/stage6_validation.json",
            directories=[
                "data/dynamic_pool_planning_outputs"  # æ¸…ç†éšæ®µå…­å°ˆç”¨ç›®éŒ„
            ]
        )
    }
    
    def __init__(self):
        self.logger = logger
    
    def detect_execution_mode(self) -> Literal["full_pipeline", "single_stage"]:
        """
        æ™ºèƒ½æª¢æ¸¬åŸ·è¡Œæ¨¡å¼
        
        Returns:
            "full_pipeline": å®Œæ•´ç®¡é“åŸ·è¡Œ
            "single_stage": å–®ä¸€éšæ®µæ¸¬è©¦
        """
        
        # æ–¹æ¡ˆ1: æª¢æŸ¥ç’°å¢ƒè®Šé‡
        pipeline_mode = os.getenv('PIPELINE_MODE', '').lower()
        if pipeline_mode == 'full':
            self.logger.info("ğŸ” æª¢æ¸¬åˆ°ç’°å¢ƒè®Šé‡: PIPELINE_MODE=full")
            return "full_pipeline"
        elif pipeline_mode == 'single':
            self.logger.info("ğŸ” æª¢æ¸¬åˆ°ç’°å¢ƒè®Šé‡: PIPELINE_MODE=single") 
            return "single_stage"
        
        # æ–¹æ¡ˆ2: æª¢æŸ¥èª¿ç”¨å †æ£§
        try:
            # ç²å–èª¿ç”¨å †æ£§
            frame_info = inspect.stack()
            
            # æª¢æŸ¥æ˜¯å¦å¾ç®¡é“è…³æœ¬èª¿ç”¨
            for frame in frame_info:
                filename = frame.filename
                if 'run_six_stages' in filename or 'pipeline' in filename:
                    self.logger.info(f"ğŸ” æª¢æ¸¬åˆ°ç®¡é“è…³æœ¬èª¿ç”¨: {Path(filename).name}")
                    return "full_pipeline"
                    
        except Exception as e:
            self.logger.warning(f"èª¿ç”¨å †æ£§æª¢æ¸¬å¤±æ•—: {e}")
        
        # é è¨­ç‚ºå–®ä¸€éšæ®µæ¨¡å¼
        self.logger.info("ğŸ” é è¨­æª¢æ¸¬çµæœ: single_stageæ¨¡å¼")
        return "single_stage"
    
    def cleanup_full_pipeline(self) -> Dict[str, int]:
        """
        æ–¹æ¡ˆä¸€ï¼šå®Œæ•´ç®¡é“æ¸…ç†
        æ¸…ç†æ‰€æœ‰éšæ®µçš„è¼¸å‡ºæª”æ¡ˆå’Œé©—è­‰å¿«ç…§
        """
        self.logger.info("ğŸ—‘ï¸ åŸ·è¡Œå®Œæ•´ç®¡é“æ¸…ç†ï¼ˆæ–¹æ¡ˆä¸€ï¼‰")
        self.logger.info("=" * 50)
        
        total_cleaned = {"files": 0, "directories": 0}
        
        for stage_num in range(1, 7):
            stage_cleaned = self._cleanup_stage_files(stage_num, include_validation=True)
            total_cleaned["files"] += stage_cleaned["files"]
            total_cleaned["directories"] += stage_cleaned["directories"]
        
        self.logger.info("=" * 50)
        self.logger.info(f"ğŸ—‘ï¸ å®Œæ•´ç®¡é“æ¸…ç†å®Œæˆ: {total_cleaned['files']} æª”æ¡ˆ, {total_cleaned['directories']} ç›®éŒ„")
        
        return total_cleaned
    
    def cleanup_single_stage(self, stage_number: int) -> Dict[str, int]:
        """
        æ–¹æ¡ˆäºŒï¼šå–®ä¸€éšæ®µæ¸…ç†
        åªæ¸…ç†æŒ‡å®šéšæ®µçš„ç›¸é—œæª”æ¡ˆ
        """
        self.logger.info(f"ğŸ—‘ï¸ åŸ·è¡Œéšæ®µ {stage_number} æ¸…ç†ï¼ˆæ–¹æ¡ˆäºŒï¼‰")
        
        cleaned = self._cleanup_stage_files(stage_number, include_validation=True)
        
        self.logger.info(f"ğŸ—‘ï¸ éšæ®µ {stage_number} æ¸…ç†å®Œæˆ: {cleaned['files']} æª”æ¡ˆ, {cleaned['directories']} ç›®éŒ„")
        
        return cleaned
    
    def auto_cleanup(self, current_stage: Optional[int] = None) -> Dict[str, int]:
        """
        è‡ªå‹•æ¸…ç† - æ ¹æ“šåŸ·è¡Œæ¨¡å¼é¸æ“‡æ¸…ç†ç­–ç•¥
        
        Args:
            current_stage: ç•¶å‰åŸ·è¡Œçš„éšæ®µè™Ÿç¢¼ï¼ˆç”¨æ–¼å–®ä¸€éšæ®µæ¨¡å¼ï¼‰
        """
        mode = self.detect_execution_mode()
        
        if mode == "full_pipeline":
            # ğŸ”§ ä¿®å¾©æ™‚åºå•é¡Œï¼šåªåœ¨ç¬¬ä¸€éšæ®µæ¸…ç†ä¸€æ¬¡ï¼Œé¿å…èª¤åˆªä¾è³´æª”æ¡ˆ
            if current_stage == 1:  # åªåœ¨ç¬¬ä¸€éšæ®µæ¸…ç†
                self.logger.info("ğŸ”§ å®Œæ•´ç®¡é“æ¨¡å¼ï¼šåœ¨éšæ®µä¸€åŸ·è¡Œçµ±ä¸€æ¸…ç†")
                return self.cleanup_full_pipeline()
            else:
                self.logger.info(f"ğŸ”§ å®Œæ•´ç®¡é“æ¨¡å¼ï¼šéšæ®µ {current_stage} è·³éæ¸…ç†ï¼Œä¿è­·ä¾è³´æª”æ¡ˆ")
                return {"files": 0, "directories": 0}  # å…¶ä»–éšæ®µè·³éæ¸…ç†
        else:
            # å–®ä¸€éšæ®µæ¨¡å¼ä¿æŒä¸è®Š
            if current_stage is None:
                # å˜—è©¦å¾èª¿ç”¨å †æ£§æ¨æ–·éšæ®µè™Ÿç¢¼
                current_stage = self._infer_current_stage()
            
            if current_stage:
                return self.cleanup_single_stage(current_stage)
            else:
                self.logger.warning("âš ï¸ å–®ä¸€éšæ®µæ¨¡å¼ä½†ç„¡æ³•ç¢ºå®šéšæ®µè™Ÿç¢¼ï¼Œè·³éæ¸…ç†")
                return {"files": 0, "directories": 0}
    
    def _cleanup_stage_files(self, stage_number: int, include_validation: bool = True) -> Dict[str, int]:
        """æ¸…ç†æŒ‡å®šéšæ®µçš„æª”æ¡ˆ"""
        if stage_number not in self.STAGE_CLEANUP_TARGETS:
            self.logger.warning(f"âš ï¸ éšæ®µ {stage_number} æ²’æœ‰å®šç¾©æ¸…ç†ç›®æ¨™")
            return {"files": 0, "directories": 0}
        
        target = self.STAGE_CLEANUP_TARGETS[stage_number]
        cleaned_files = 0
        cleaned_dirs = 0
        
        # æ¸…ç†è¼¸å‡ºæª”æ¡ˆ
        for file_path in target.output_files:
            if self._remove_file(file_path):
                cleaned_files += 1
        
        # æ¸…ç†é©—è­‰æª”æ¡ˆ
        if include_validation:
            if self._remove_file(target.validation_file):
                cleaned_files += 1
        
        # æ¸…ç†ç›®éŒ„
        if target.directories:
            for dir_path in target.directories:
                if self._remove_directory(dir_path):
                    cleaned_dirs += 1
        
        return {"files": cleaned_files, "directories": cleaned_dirs}
    
    def _remove_file(self, file_path: str) -> bool:
        """ç§»é™¤æª”æ¡ˆ"""
        try:
            path = Path(file_path)
            if path.exists():
                file_size_mb = path.stat().st_size / (1024 * 1024)
                path.unlink()
                self.logger.info(f"  âœ… å·²åˆªé™¤: {file_path} ({file_size_mb:.1f} MB)")
                return True
        except Exception as e:
            self.logger.warning(f"  âš ï¸ åˆªé™¤å¤±æ•— {file_path}: {e}")
        return False
    
    def _remove_directory(self, dir_path: str) -> bool:
        """ç§»é™¤ç›®éŒ„ï¼ˆåŒ…å«ç©ºç›®éŒ„ï¼‰"""
        try:
            import shutil
            path = Path(dir_path)
            if path.exists() and path.is_dir():
                file_count = len(list(path.rglob("*")))
                shutil.rmtree(path)
                if file_count > 0:
                    self.logger.info(f"  ğŸ—‚ï¸ å·²ç§»é™¤ç›®éŒ„: {dir_path} ({file_count} å€‹æª”æ¡ˆ)")
                else:
                    self.logger.info(f"  ğŸ—‚ï¸ å·²ç§»é™¤ç©ºç›®éŒ„: {dir_path}")
                return True
        except Exception as e:
            self.logger.warning(f"  âš ï¸ ç›®éŒ„ç§»é™¤å¤±æ•— {dir_path}: {e}")
        return False
    
    def _infer_current_stage(self) -> Optional[int]:
        """å¾èª¿ç”¨å †æ£§æ¨æ–·ç•¶å‰éšæ®µ"""
        try:
            frame_info = inspect.stack()
            
            for frame in frame_info:
                filename = frame.filename
                
                # æ ¹æ“šæª”æ¡ˆåæ¨æ–·éšæ®µ
                if 'orbital_calculation' in filename:
                    return 1
                elif 'visibility_filter' in filename or 'satellite_filter' in filename:
                    return 2
                elif 'signal_analysis' in filename:
                    return 3
                elif 'timeseries_preprocessing' in filename:
                    return 4
                elif 'data_integration' in filename:
                    return 5
                elif 'dynamic_pool' in filename:
                    return 6
                    
        except Exception as e:
            self.logger.warning(f"éšæ®µæ¨æ–·å¤±æ•—: {e}")
        
        return None

# å…¨å±€å¯¦ä¾‹
_cleanup_manager = None

def get_cleanup_manager() -> UnifiedCleanupManager:
    """ç²å–æ¸…ç†ç®¡ç†å™¨å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰"""
    global _cleanup_manager
    if _cleanup_manager is None:
        _cleanup_manager = UnifiedCleanupManager()
    return _cleanup_manager

def auto_cleanup(current_stage: Optional[int] = None) -> Dict[str, int]:
    """è‡ªå‹•æ¸…ç†ä¾¿æ·å‡½æ•¸"""
    return get_cleanup_manager().auto_cleanup(current_stage)

def cleanup_all_stages() -> Dict[str, int]:
    """æ¸…ç†æ‰€æœ‰éšæ®µä¾¿æ·å‡½æ•¸"""
    return get_cleanup_manager().cleanup_full_pipeline()