#!/usr/bin/env python3
"""
Stage 1: æ•¸æ“šè¼‰å…¥å±¤è™•ç†å™¨ (é‡æ§‹ç‰ˆæœ¬)

é‡æ§‹åŸå‰‡ï¼š
- å°ˆæ³¨æ•¸æ“šè¼‰å…¥å’Œé©—è­‰ï¼Œç§»é™¤SGP4è¨ˆç®—åŠŸèƒ½
- ä½¿ç”¨å…±äº«çš„é©—è­‰æ¡†æ¶å’Œå·¥å…·æ¨¡çµ„
- å¯¦ç¾çµ±ä¸€çš„è™•ç†å™¨æ¥å£
- æä¾›æ¸…æ½”çš„TLEæ•¸æ“šè¼¸å‡ºä¾›Stage 2ä½¿ç”¨

åŠŸèƒ½è®ŠåŒ–ï¼š
- âœ… ä¿ç•™: TLEæ•¸æ“šè¼‰å…¥ã€æ•¸æ“šé©—è­‰
- âŒ ç§»é™¤: SGP4è»Œé“è¨ˆç®—ï¼ˆç§»è‡³Stage 2ï¼‰
- âœ… æ–°å¢: æ™‚é–“åŸºæº–æ¨™æº–åŒ–ã€æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥
"""

import logging
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, List, Optional
from pathlib import Path

# å…±äº«æ¨¡çµ„å°å…¥
from shared.interfaces import BaseProcessor, ProcessingStatus, ProcessingResult, create_processing_result
from shared.validation_framework import ValidationEngine
from shared.utils import TimeUtils, FileUtils
from shared.constants import SystemConstantsManager
from shared.testing import TestAssertion

# Stage 1å°ˆç”¨æ¨¡çµ„
from .tle_data_loader import TLEDataLoader

logger = logging.getLogger(__name__)


class Stage1DataLoadingProcessor(BaseProcessor):
    """
    Stage 1: æ•¸æ“šè¼‰å…¥å±¤è™•ç†å™¨ (é‡æ§‹ç‰ˆæœ¬)

    å°ˆè·è²¬ä»»ï¼š
    1. TLEæ•¸æ“šè¼‰å…¥å’Œè§£æ
    2. æ•¸æ“šæ ¼å¼é©—è­‰å’Œå®Œæ•´æ€§æª¢æŸ¥
    3. æ™‚é–“åŸºæº–æ¨™æº–åŒ–
    4. ç‚ºStage 2æä¾›æ¸…æ½”çš„æ•¸æ“šè¼¸å‡º
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__("Stage1DataLoadingProcessor", config or {})

        # é…ç½®åƒæ•¸
        self.sample_mode = self.config.get('sample_mode', False)
        self.sample_size = self.config.get('sample_size', 100)
        self.validate_tle_epoch = self.config.get('validate_tle_epoch', True)

        # åˆå§‹åŒ–çµ„ä»¶
        self.tle_loader = TLEDataLoader()
        self.validation_engine = ValidationEngine('stage1')
        self.system_constants = SystemConstantsManager()

        # è™•ç†çµ±è¨ˆ
        self.processing_stats = {
            'total_files_scanned': 0,
            'total_satellites_loaded': 0,
            'validation_failures': 0,
            'time_reference_issues': 0
        }

        self.logger.info("Stage 1 æ•¸æ“šè¼‰å…¥è™•ç†å™¨å·²åˆå§‹åŒ–")

    def process(self, input_data: Any) -> ProcessingResult:
        """
        ä¸»è¦è™•ç†æ–¹æ³•

        Args:
            input_data: è¼¸å…¥æ•¸æ“šï¼ˆå¯é¸çš„TLEæ•¸æ“šæˆ–é…ç½®ï¼‰

        Returns:
            è™•ç†çµæœï¼ŒåŒ…å«è¼‰å…¥çš„TLEæ•¸æ“š
        """
        start_time = datetime.now(timezone.utc)
        self.logger.info("ğŸš€ é–‹å§‹Stage 1æ•¸æ“šè¼‰å…¥è™•ç†...")

        try:
            # æª¢æŸ¥è¼¸å…¥æ•¸æ“šé¡å‹
            if input_data and isinstance(input_data, dict) and 'tle_data' in input_data:
                # ä½¿ç”¨æä¾›çš„TLEæ•¸æ“š
                self.logger.info("ğŸ“‹ ä½¿ç”¨è¼¸å…¥çš„TLEæ•¸æ“š...")
                tle_data_list = input_data['tle_data']
                loaded_data = self._process_input_tle_data(tle_data_list)
            else:
                # å¾æ–‡ä»¶è¼‰å…¥TLEæ•¸æ“š
                self.logger.info("ğŸ“ å¾æ–‡ä»¶è¼‰å…¥TLEæ•¸æ“š...")
                loaded_data = self._load_tle_data_from_files()

            # æ•¸æ“šé©—è­‰
            validation_result = self._validate_loaded_data(loaded_data)

            # æª¢æŸ¥é©—è­‰çµæœ
            if hasattr(validation_result, 'overall_status'):
                validation_status = validation_result.overall_status
                is_valid = validation_status == 'PASS' or (validation_status == 'PENDING' and len(loaded_data) > 0)
                # è½‰æ›ç‚ºå­—å…¸ç²å–è©³ç´°ä¿¡æ¯
                validation_dict = validation_result.to_dict()
                errors = [check['message'] for check in validation_dict['detailed_results']
                         if check['status'] == 'FAILURE']
                metrics = {'validation_summary': validation_dict}

                # å¦‚æœæ˜¯PENDINGç‹€æ…‹ä½†æœ‰æ•¸æ“šï¼Œæ·»åŠ åŸºæœ¬æª¢æŸ¥
                if validation_status == 'PENDING' and len(loaded_data) > 0:
                    validation_result.add_success(
                        "data_loaded",
                        f"æˆåŠŸè¼‰å…¥ {len(loaded_data)} é¡†è¡›æ˜Ÿæ•¸æ“š",
                        {'satellite_count': len(loaded_data)}
                    )
                    validation_result.finalize()
                    is_valid = True
            else:
                # å¦‚æœæ˜¯å­—å…¸æ ¼å¼
                is_valid = validation_result.get('is_valid', False)
                errors = validation_result.get('errors', [])
                metrics = validation_result.get('metrics', {})

            if not is_valid:
                return create_processing_result(
                    status=ProcessingStatus.VALIDATION_FAILED,
                    data={},
                    message=f"æ•¸æ“šé©—è­‰å¤±æ•—: {errors}"
                )

            # æ™‚é–“åŸºæº–æ¨™æº–åŒ–
            standardized_data = self._standardize_time_reference(loaded_data)

            # æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥
            completeness_check = self._check_data_completeness(standardized_data)

            # æ§‹å»ºè¼¸å‡ºçµæœ
            processing_time = datetime.now(timezone.utc) - start_time
            result_data = {
                'stage': 'stage1_data_loading',
                'tle_data': standardized_data,
                'metadata': {
                    'processing_start_time': start_time.isoformat(),
                    'processing_end_time': datetime.now(timezone.utc).isoformat(),
                    'processing_duration_seconds': processing_time.total_seconds(),
                    'total_satellites_loaded': len(standardized_data),
                    'time_reference_standard': 'tle_epoch',
                    'validation_passed': True,
                    'completeness_score': completeness_check['score']
                },
                'processing_stats': self.processing_stats,
                'quality_metrics': metrics,
                'next_stage_ready': True
            }

            self.logger.info(f"âœ… Stage 1æ•¸æ“šè¼‰å…¥å®Œæˆï¼Œè¼‰å…¥{len(standardized_data)}é¡†è¡›æ˜Ÿæ•¸æ“š")

            return create_processing_result(
                status=ProcessingStatus.SUCCESS,
                data=result_data,
                message=f"æˆåŠŸè¼‰å…¥{len(standardized_data)}é¡†è¡›æ˜Ÿçš„TLEæ•¸æ“š"
            )

        except Exception as e:
            self.logger.error(f"âŒ Stage 1æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return create_processing_result(
                status=ProcessingStatus.ERROR,
                data={},
                message=f"æ•¸æ“šè¼‰å…¥éŒ¯èª¤: {str(e)}"
            )

    def _process_input_tle_data(self, tle_data_list: List[Dict]) -> List[Dict]:
        """è™•ç†è¼¸å…¥çš„TLEæ•¸æ“š"""
        if not tle_data_list:
            self.logger.warning("è¼¸å…¥çš„TLEæ•¸æ“šç‚ºç©º")
            return []

        processed_data = []
        for tle_data in tle_data_list:
            # åŸºæœ¬æ ¼å¼æª¢æŸ¥
            if self._validate_tle_format(tle_data):
                processed_data.append(tle_data)
            else:
                self.processing_stats['validation_failures'] += 1

        self.processing_stats['total_satellites_loaded'] = len(processed_data)
        return processed_data

    def _load_tle_data_from_files(self) -> List[Dict]:
        """å¾æ–‡ä»¶è¼‰å…¥TLEæ•¸æ“š"""
        try:
            # æƒæTLEæ–‡ä»¶
            tle_files = self.tle_loader.scan_tle_data()
            self.processing_stats['total_files_scanned'] = len(tle_files)

            if not tle_files:
                self.logger.warning("æœªæ‰¾åˆ°TLEæ–‡ä»¶")
                return []

            # è¼‰å…¥æ‰€æœ‰TLEæ•¸æ“š
            all_tle_data = []
            for tle_file in tle_files:
                tle_data = self.tle_loader.load_satellite_data(tle_files)
                if tle_data:
                    all_tle_data.extend(tle_data)
                break  # load_satellite_data handles all files at once

            # æ¨£æœ¬æ¨¡å¼è™•ç†
            if self.sample_mode and len(all_tle_data) > self.sample_size:
                self.logger.info(f"æ¨£æœ¬æ¨¡å¼ï¼šå¾{len(all_tle_data)}é¡†è¡›æ˜Ÿä¸­é¸å–{self.sample_size}é¡†")
                all_tle_data = all_tle_data[:self.sample_size]

            self.processing_stats['total_satellites_loaded'] = len(all_tle_data)
            return all_tle_data

        except Exception as e:
            self.logger.error(f"è¼‰å…¥TLEæ–‡ä»¶å¤±æ•—: {e}")
            raise

    def _validate_tle_format(self, tle_data: Dict) -> bool:
        """é©—è­‰TLEæ•¸æ“šæ ¼å¼"""
        required_fields = ['satellite_id', 'line1', 'line2', 'name']

        for field in required_fields:
            if field not in tle_data:
                self.logger.warning(f"TLEæ•¸æ“šç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                return False

        # æª¢æŸ¥TLEè¡Œæ ¼å¼
        line1 = tle_data['line1']
        line2 = tle_data['line2']

        if len(line1) != 69 or len(line2) != 69:
            self.logger.warning("TLEè¡Œé•·åº¦ä¸æ­£ç¢º")
            return False

        if line1[0] != '1' or line2[0] != '2':
            self.logger.warning("TLEè¡Œæ¨™è­˜ç¬¦ä¸æ­£ç¢º")
            return False

        return True

    def _validate_loaded_data(self, loaded_data: List[Dict]) -> Dict[str, Any]:
        """ä½¿ç”¨å…±äº«é©—è­‰æ¡†æ¶é©—è­‰è¼‰å…¥çš„æ•¸æ“š"""
        try:
            # æ§‹å»ºé©—è­‰è¦å‰‡
            validation_rules = {
                'min_satellites': 1,
                'required_fields': ['satellite_id', 'line1', 'line2', 'name'],
                'tle_format_check': True,
                'academic_compliance': True
            }

            # åŸ·è¡Œé©—è­‰
            validation_result = self.validation_engine.validate(loaded_data, validation_rules)

            # é¡å¤–çš„TLEç‰¹å®šæª¢æŸ¥
            if hasattr(validation_result, 'overall_status') and validation_result.overall_status == 'PASS':
                tle_specific_checks = self._perform_tle_specific_validation(loaded_data)
                # åœ¨ValidationResultä¸­æ·»åŠ é¡å¤–æª¢æŸ¥
                for check_name, value in tle_specific_checks.items():
                    validation_result.add_success(
                        f"tle_specific_{check_name}",
                        f"{check_name}: {value}",
                        {'value': value}
                    )
            elif isinstance(validation_result, dict) and validation_result.get('is_valid'):
                tle_specific_checks = self._perform_tle_specific_validation(loaded_data)
                validation_result['metrics'].update(tle_specific_checks)

            return validation_result

        except Exception as e:
            self.logger.error(f"æ•¸æ“šé©—è­‰å¤±æ•—: {e}")
            return {
                'is_valid': False,
                'errors': [str(e)],
                'metrics': {}
            }

    def _perform_tle_specific_validation(self, data: List[Dict]) -> Dict[str, Any]:
        """åŸ·è¡ŒTLEç‰¹å®šçš„é©—è­‰æª¢æŸ¥"""
        metrics = {
            'unique_satellites': 0,
            'epoch_time_range_days': 0,
            'constellation_coverage': 0,
            'data_freshness_score': 0
        }

        if not data:
            return metrics

        # æª¢æŸ¥è¡›æ˜ŸIDå”¯ä¸€æ€§
        satellite_ids = set()
        epochs = []
        constellations = set()

        for tle in data:
            satellite_ids.add(tle['satellite_id'])

            # è§£æTLEæ™‚é–“
            try:
                line1 = tle['line1']
                epoch_year = int(line1[18:20])
                epoch_day = float(line1[20:32])

                # è½‰æ›ç‚ºå®Œæ•´å¹´ä»½
                if epoch_year < 57:
                    full_year = 2000 + epoch_year
                else:
                    full_year = 1900 + epoch_year

                epoch_time = TimeUtils.parse_tle_epoch(full_year, epoch_day)
                epochs.append(epoch_time)

            except Exception as e:
                self.logger.warning(f"TLEæ™‚é–“è§£æå¤±æ•—: {e}")
                self.processing_stats['time_reference_issues'] += 1

        metrics['unique_satellites'] = len(satellite_ids)

        if epochs:
            time_range = max(epochs) - min(epochs)
            metrics['epoch_time_range_days'] = time_range.days

            # æ•¸æ“šæ–°é®®åº¦è©•åˆ†
            latest_epoch = max(epochs)
            age_days = (datetime.now(timezone.utc) - latest_epoch).days
            metrics['data_freshness_score'] = max(0, 100 - age_days)

        return metrics

    def _standardize_time_reference(self, loaded_data: List[Dict]) -> List[Dict]:
        """æ¨™æº–åŒ–æ™‚é–“åŸºæº–"""
        standardized_data = []

        for tle_data in loaded_data:
            try:
                # è§£æTLE epochæ™‚é–“
                line1 = tle_data['line1']
                epoch_year = int(line1[18:20])
                epoch_day = float(line1[20:32])

                # è½‰æ›ç‚ºå®Œæ•´å¹´ä»½
                if epoch_year < 57:
                    full_year = 2000 + epoch_year
                else:
                    full_year = 1900 + epoch_year

                # æ¨™æº–åŒ–æ™‚é–“ä¿¡æ¯
                epoch_time = TimeUtils.parse_tle_epoch(full_year, epoch_day)

                # æ·»åŠ æ¨™æº–åŒ–æ™‚é–“å­—æ®µ
                enhanced_tle = tle_data.copy()
                enhanced_tle.update({
                    'epoch_datetime': epoch_time.isoformat(),
                    'epoch_year_full': full_year,
                    'epoch_day_decimal': epoch_day,
                    'time_reference_standard': 'tle_epoch'
                })

                standardized_data.append(enhanced_tle)

            except Exception as e:
                self.logger.error(f"æ™‚é–“æ¨™æº–åŒ–å¤±æ•— {tle_data.get('satellite_id', 'unknown')}: {e}")
                # ä¿ç•™åŸæ•¸æ“šä½†æ¨™è¨˜å•é¡Œ
                enhanced_tle = tle_data.copy()
                enhanced_tle['time_reference_error'] = str(e)
                standardized_data.append(enhanced_tle)
                self.processing_stats['time_reference_issues'] += 1

        return standardized_data

    def _check_data_completeness(self, data: List[Dict]) -> Dict[str, Any]:
        """æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§"""
        if not data:
            return {'score': 0, 'issues': ['ç„¡æ•¸æ“š']}

        total_satellites = len(data)
        complete_records = 0
        issues = []

        for tle in data:
            completeness_checks = [
                'satellite_id' in tle and tle['satellite_id'],
                'name' in tle and tle['name'],
                'line1' in tle and len(tle['line1']) == 69,
                'line2' in tle and len(tle['line2']) == 69,
                'epoch_datetime' in tle,
                'time_reference_error' not in tle
            ]

            if all(completeness_checks):
                complete_records += 1
            else:
                missing_fields = []
                if not completeness_checks[0]:
                    missing_fields.append('satellite_id')
                if not completeness_checks[1]:
                    missing_fields.append('name')
                if not completeness_checks[2]:
                    missing_fields.append('line1_format')
                if not completeness_checks[3]:
                    missing_fields.append('line2_format')
                if not completeness_checks[4]:
                    missing_fields.append('epoch_time')
                if not completeness_checks[5]:
                    missing_fields.append('time_parsing')

                if missing_fields:
                    issues.append(f"è¡›æ˜Ÿ {tle.get('satellite_id', 'unknown')}: {', '.join(missing_fields)}")

        completeness_score = (complete_records / total_satellites) * 100

        return {
            'score': completeness_score,
            'complete_records': complete_records,
            'total_records': total_satellites,
            'issues': issues[:10]  # é™åˆ¶å ±å‘Šå‰10å€‹å•é¡Œ
        }

    def validate_input(self, input_data: Any) -> Dict[str, Any]:
        """é©—è­‰è¼¸å…¥æ•¸æ“š"""
        errors = []
        warnings = []

        if input_data is None:
            # å…è¨±ç„¡è¼¸å…¥ï¼Œå°‡å¾æ–‡ä»¶è¼‰å…¥
            return {'valid': True, 'errors': errors, 'warnings': warnings}

        if isinstance(input_data, dict):
            if 'tle_data' in input_data:
                tle_data = input_data['tle_data']
                if not isinstance(tle_data, list):
                    errors.append("tle_dataå¿…é ˆæ˜¯åˆ—è¡¨æ ¼å¼")
                elif len(tle_data) == 0:
                    warnings.append("tle_dataç‚ºç©ºåˆ—è¡¨")
            return {'valid': len(errors) == 0, 'errors': errors, 'warnings': warnings}

        errors.append("è¼¸å…¥æ•¸æ“šæ ¼å¼ä¸æ­£ç¢º")
        return {'valid': False, 'errors': errors, 'warnings': warnings}

    def validate_output(self, output_data: Any) -> Dict[str, Any]:
        """é©—è­‰è¼¸å‡ºæ•¸æ“š"""
        errors = []
        warnings = []

        if not isinstance(output_data, dict):
            errors.append("è¼¸å‡ºæ•¸æ“šå¿…é ˆæ˜¯å­—å…¸æ ¼å¼")
            return {'valid': False, 'errors': errors, 'warnings': warnings}

        required_fields = ['stage', 'tle_data', 'metadata']
        for field in required_fields:
            if field not in output_data:
                errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")

        if output_data.get('stage') != 'stage1_data_loading':
            errors.append("éšæ®µæ¨™è­˜éŒ¯èª¤")

        # æª¢æŸ¥ TLE æ•¸æ“š
        tle_data = output_data.get('tle_data', {})
        if not isinstance(tle_data, list):
            errors.append("TLEæ•¸æ“šæ ¼å¼éŒ¯èª¤")
        elif len(tle_data) == 0:
            warnings.append("TLEæ•¸æ“šç‚ºç©º")

        return {
            'valid': len(errors) == 0,
            'errors': errors,
            'warnings': warnings
        }

    def extract_key_metrics(self) -> Dict[str, Any]:
        """æå–é—œéµæŒ‡æ¨™"""
        return {
            'stage': 'stage1_data_loading',
            'satellites_loaded': self.processing_stats['total_satellites_loaded'],
            'files_scanned': self.processing_stats['total_files_scanned'],
            'validation_failures': self.processing_stats['validation_failures'],
            'time_reference_issues': self.processing_stats['time_reference_issues'],
            'success_rate': (
                (self.processing_stats['total_satellites_loaded'] - self.processing_stats['validation_failures'])
                / max(1, self.processing_stats['total_satellites_loaded'])
            ) * 100
        }


def create_stage1_processor(config: Optional[Dict[str, Any]] = None) -> Stage1DataLoadingProcessor:
    """
    å‰µå»ºStage 1æ•¸æ“šè¼‰å…¥è™•ç†å™¨å¯¦ä¾‹

    Args:
        config: å¯é¸é…ç½®åƒæ•¸

    Returns:
        Stage 1è™•ç†å™¨å¯¦ä¾‹
    """
    return Stage1DataLoadingProcessor(config)