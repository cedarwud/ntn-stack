"""
ç°¡åŒ–éšŽæ®µäºŒè™•ç†å™¨ï¼šåŸºæœ¬åœ°ç†å¯è¦‹æ€§éŽæ¿¾
éµå¾ªæ–¹æ¡ˆä¸€ï¼šåªè² è²¬ ECIâ†’åœ°å¹³åº§æ¨™è½‰æ›å’Œä»°è§’é–€æª»éŽæ¿¾
"""

import os
import json
import gzip
import logging
from datetime import datetime, timezone
from typing import Dict, Any
from pathlib import Path

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from shared.base_processor import BaseStageProcessor
from .simple_geographic_filter import SimpleGeographicFilter


class SimpleStage2Processor(BaseStageProcessor):
    """ç°¡åŒ–éšŽæ®µäºŒè™•ç†å™¨ - åªè™•ç†åŸºæœ¬åœ°ç†å¯è¦‹æ€§éŽæ¿¾"""

    def __init__(self, debug_mode: bool = False):
        super().__init__(stage_number=2, stage_name="simplified_visibility_filter")
        self.debug_mode = debug_mode
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–æ ¸å¿ƒéŽæ¿¾å™¨
        self.geographic_filter = SimpleGeographicFilter()

        self.logger.info("ðŸŽ¯ åˆå§‹åŒ–ç°¡åŒ–éšŽæ®µäºŒè™•ç†å™¨")

    def execute(self) -> Dict[str, Any]:
        """
        åŸ·è¡Œç°¡åŒ–éšŽæ®µäºŒï¼šåŸºæœ¬åœ°ç†å¯è¦‹æ€§éŽæ¿¾

        Returns:
            éŽæ¿¾çµæžœå­—å…¸
        """
        start_time = datetime.now(timezone.utc)
        self.logger.info("ðŸš€ é–‹å§‹åŸ·è¡Œç°¡åŒ–éšŽæ®µäºŒï¼šåŸºæœ¬åœ°ç†å¯è¦‹æ€§éŽæ¿¾")

        try:
            # 1. è¼‰å…¥ Stage 1 æ•¸æ“š
            self.logger.info("ðŸ“¥ è¼‰å…¥éšŽæ®µä¸€è»Œé“è¨ˆç®—çµæžœ...")
            stage1_data = self._load_stage1_data()

            # 2. åŸ·è¡Œåœ°ç†å¯è¦‹æ€§éŽæ¿¾
            self.logger.info("ðŸ” åŸ·è¡Œåœ°ç†å¯è¦‹æ€§éŽæ¿¾...")
            filtered_results = self.geographic_filter.filter_visible_satellites(stage1_data)

            # 3. ä¿å­˜çµæžœ
            self.logger.info("ðŸ’¾ ä¿å­˜éŽæ¿¾çµæžœ...")
            self._save_results(filtered_results)

            # 4. è¨ˆç®—åŸ·è¡Œçµ±è¨ˆ
            execution_time = (datetime.now(timezone.utc) - start_time).total_seconds()

            # 5. æ›´æ–°å…ƒæ•¸æ“š
            filtered_results['metadata']['total_execution_time'] = execution_time
            filtered_results['metadata']['stage2_simplified'] = True
            filtered_results['metadata']['bypassed_features'] = [
                'signal_analysis',  # ç§»è‡³ Stage 3
                'handover_decisions',  # ç§»è‡³ Stage 3
                'coverage_planning',  # ç§»è‡³ Stage 6
                'academic_validation'  # ç³»çµ±ç´šåŠŸèƒ½
            ]

            self.logger.info(f"âœ… ç°¡åŒ–éšŽæ®µäºŒåŸ·è¡Œå®Œæˆ (è€—æ™‚: {execution_time:.2f}s)")
            return filtered_results

        except Exception as e:
            self.logger.error(f"âŒ ç°¡åŒ–éšŽæ®µäºŒåŸ·è¡Œå¤±æ•—: {str(e)}")
            raise

    def _load_stage1_data(self) -> Dict[str, Any]:
        """è¼‰å…¥ Stage 1 è»Œé“è¨ˆç®—çµæžœ"""
        try:
            # æœç´¢å¤šå€‹å¯èƒ½çš„ Stage 1 è¼¸å‡ºä½ç½®
            possible_dirs = [
                Path("/satellite-processing/data/outputs/stage1"),
                Path("/satellite-processing/data/stage1_outputs"),
                Path("/satellite-processing/data/tle_calculation_outputs")
            ]

            json_files = []
            for output_dir in possible_dirs:
                if output_dir.exists():
                    # æŸ¥æ‰¾å£“ç¸®çš„çµæžœæ–‡ä»¶
                    json_files.extend(output_dir.glob("*.json.gz"))
                    # æŸ¥æ‰¾æœªå£“ç¸®æ–‡ä»¶
                    json_files.extend(output_dir.glob("*.json"))

            if not json_files:
                raise FileNotFoundError("æœªæ‰¾åˆ° Stage 1 è¼¸å‡ºæ–‡ä»¶")

            # ä½¿ç”¨æœ€æ–°æ–‡ä»¶ (orbital_calculation_output.json.gz å„ªå…ˆ)
            orbital_files = [f for f in json_files if 'orbital_calculation_output' in f.name]
            if orbital_files:
                latest_file = max(orbital_files, key=lambda f: f.stat().st_mtime)
            else:
                latest_file = max(json_files, key=lambda f: f.stat().st_mtime)

            self.logger.info(f"ðŸ“‚ è¼‰å…¥æ–‡ä»¶: {latest_file}")

            # è®€å–æ•¸æ“š
            if latest_file.suffix == '.gz':
                with gzip.open(latest_file, 'rt', encoding='utf-8') as f:
                    data = json.load(f)
            else:
                with open(latest_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

            # é©—è­‰æ•¸æ“šçµæ§‹
            if 'data' not in data:
                raise ValueError("Stage 1 æ•¸æ“šæ ¼å¼ç„¡æ•ˆ: ç¼ºå°‘ 'data' å­—æ®µ")

            # é©é…æ–°çš„æ•¸æ“šæ ¼å¼ (data.satellites è€Œä¸æ˜¯åˆ†åˆ¥çš„ starlink_satellites/oneweb_satellites)
            satellites_data = data['data']
            
            if 'satellites' in satellites_data:
                # æ–°æ ¼å¼: æ‰€æœ‰è¡›æ˜Ÿåœ¨ satellites å­—å…¸ä¸­ï¼ŒæŒ‰ norad_id åˆ†çµ„
                all_satellites = satellites_data['satellites']
                starlink_count = 0
                oneweb_count = 0
                
                for sat_id, sat_info in all_satellites.items():
                    constellation = sat_info.get('satellite_info', {}).get('constellation', '').lower()
                    if constellation == 'starlink':
                        starlink_count += 1
                    elif constellation == 'oneweb':
                        oneweb_count += 1
                        
                self.logger.info(f"ðŸ“Š è¼‰å…¥å®Œæˆ: {starlink_count} Starlink + {oneweb_count} OneWeb (æ–°æ ¼å¼)")
                
            elif 'starlink_satellites' in satellites_data and 'oneweb_satellites' in satellites_data:
                # èˆŠæ ¼å¼: åˆ†åˆ¥çš„ starlink_satellites å’Œ oneweb_satellites åˆ—è¡¨
                starlink_count = len(satellites_data.get('starlink_satellites', []))
                oneweb_count = len(satellites_data.get('oneweb_satellites', []))
                self.logger.info(f"ðŸ“Š è¼‰å…¥å®Œæˆ: {starlink_count} Starlink + {oneweb_count} OneWeb (èˆŠæ ¼å¼)")
                
            else:
                raise ValueError("Stage 1 æ•¸æ“šæ ¼å¼ç„¡æ•ˆ: æ‰¾ä¸åˆ°è¡›æ˜Ÿæ•¸æ“š")

            return data

        except Exception as e:
            self.logger.error(f"âŒ Stage 1 æ•¸æ“šè¼‰å…¥å¤±æ•—: {str(e)}")
            raise

    def _save_results(self, results: Dict[str, Any]) -> None:
        """ä¿å­˜éŽæ¿¾çµæžœåˆ°æ–‡ä»¶"""
        try:
            # å‰µå»ºè¼¸å‡ºç›®éŒ„
            output_dir = Path("/satellite-processing/data/intelligent_filtering_outputs")
            output_dir.mkdir(parents=True, exist_ok=True)

            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
            filename = f"stage2_simple_visibility_filter_{timestamp}.json.gz"
            output_path = output_dir / filename

            # ä¿å­˜ç‚ºå£“ç¸® JSON
            with gzip.open(output_path, 'wt', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)

            self.logger.info(f"ðŸ’¾ çµæžœå·²ä¿å­˜: {output_path}")

            # å‰µå»ºç¬¦è™ŸéˆæŽ¥æŒ‡å‘æœ€æ–°æ–‡ä»¶
            latest_link = output_dir / "latest_stage2_results.json.gz"
            if latest_link.exists():
                latest_link.unlink()
            latest_link.symlink_to(filename)

        except Exception as e:
            self.logger.error(f"âŒ çµæžœä¿å­˜å¤±æ•—: {str(e)}")
            raise

    def validate_input(self, input_data: Any) -> bool:
        """é©—è­‰è¼¸å…¥æ•¸æ“š (ç°¡åŒ–ç‰ˆæœ¬)"""
        return True  # Stage 1 æ•¸æ“šå·²ç”± Stage 1 é©—è­‰

    def process(self, input_data: Any) -> Any:
        """è™•ç†æ•¸æ“š (ç¬¦åˆ BaseStageProcessor æŽ¥å£)"""
        return self.execute()

    def validate_output(self, output_data: Any) -> bool:
        """é©—è­‰è¼¸å‡ºæ•¸æ“š"""
        if not isinstance(output_data, dict):
            return False

        required_keys = ['metadata', 'data']
        return all(key in output_data for key in required_keys)

    def save_results(self, results: Any) -> None:
        """ä¿å­˜çµæžœ (ç¬¦åˆ BaseStageProcessor æŽ¥å£)"""
        self._save_results(results)

    def extract_key_metrics(self) -> Dict[str, Any]:
        """æå–é—œéµæŒ‡æ¨™"""
        return {
            'stage': 'stage2_simplified',
            'processor_type': 'SimpleStage2Processor',
            'features': ['geographic_visibility_filtering'],
            'bypassed_features': [
                'signal_analysis',
                'handover_decisions',
                'coverage_planning',
                'academic_validation'
            ]
        }

    def run_validation_checks(self) -> Dict[str, Any]:
        """åŸ·è¡Œé©—è­‰æª¢æŸ¥ (ç°¡åŒ–ç‰ˆæœ¬)"""
        return {
            'validation_status': 'passed',
            'checks_performed': [
                'basic_data_structure_validation',
                'geographic_filtering_logic_verification'
            ],
            'bypassed_checks': [
                'signal_quality_validation',
                'handover_logic_validation',
                'coverage_planning_validation'
            ],
            'timestamp': datetime.now(timezone.utc).isoformat()
        }