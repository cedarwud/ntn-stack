#!/usr/bin/env python3
"""
æ¸¬è©¦æœ¬åœ° TLE æ•¸æ“šåŠ è¼‰å™¨ - Phase 0
"""

import sys
import json
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LocalTLELoader:
    """æœ¬åœ° TLE æ•¸æ“šåŠ è¼‰å™¨ - Phase 0 å¢å¼·ç‰ˆæœ¬ï¼Œæ”¯æ´å¯¦éš›æ—¥æœŸå‘½å"""
    
    def __init__(self, tle_data_dir: str = "/home/sat/ntn-stack/tle_data"):
        """
        åˆå§‹åŒ–æœ¬åœ° TLE æ•¸æ“šåŠ è¼‰å™¨
        
        Args:
            tle_data_dir: TLE æ•¸æ“šæ ¹ç›®éŒ„ï¼Œé è¨­ç‚º /home/sat/ntn-stack/tle_data
        """
        self.tle_data_dir = Path(tle_data_dir)
        logger.info(f"LocalTLELoader åˆå§‹åŒ–ï¼Œæ•¸æ“šç›®éŒ„: {self.tle_data_dir}")
        
        # Phase 0 æ”¯æ´çš„æ˜Ÿåº§
        self.supported_constellations = ['starlink', 'oneweb']
    
    def scan_available_dates(self, constellation: str) -> List[str]:
        """æƒææŒ‡å®šæ˜Ÿåº§çš„å¯ç”¨æ—¥æœŸ"""
        if constellation not in self.supported_constellations:
            logger.error(f"ä¸æ”¯æ´çš„æ˜Ÿåº§: {constellation}")
            return []
            
        tle_dir = self.tle_data_dir / constellation / "tle"
        if not tle_dir.exists():
            logger.warning(f"TLE ç›®éŒ„ä¸å­˜åœ¨: {tle_dir}")
            return []
            
        available_dates = []
        pattern = f"{constellation}_*.tle"
        
        import glob
        import re
        
        for tle_file in glob.glob(str(tle_dir / pattern)):
            # æå–æ—¥æœŸ (YYYYMMDD)
            match = re.search(r'(\d{8})\.tle$', tle_file)
            if match:
                date_str = match.group(1)
                # é©—è­‰æ–‡ä»¶å­˜åœ¨ä¸”éç©º
                if Path(tle_file).stat().st_size > 0:
                    available_dates.append(date_str)
                    
        available_dates.sort()
        logger.info(f"{constellation} å¯ç”¨æ—¥æœŸ: {len(available_dates)} å¤©ï¼Œç¯„åœ: {available_dates[0] if available_dates else 'N/A'} - {available_dates[-1] if available_dates else 'N/A'}")
        return available_dates
    
    def parse_tle_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """è§£æ TLE æ–‡ä»¶"""
        satellites = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.strip().split('\n')
            lines = [line.strip() for line in lines if line.strip()]
            
            i = 0
            while i < len(lines):
                if i + 2 < len(lines):
                    name_line = lines[i].strip()
                    line1 = lines[i + 1].strip()
                    line2 = lines[i + 2].strip()
                    
                    # é©—è­‰ TLE æ ¼å¼
                    if (line1.startswith('1 ') and 
                        line2.startswith('2 ') and 
                        len(line1) >= 69 and 
                        len(line2) >= 69):
                        
                        try:
                            norad_id = int(line1[2:7].strip())
                            
                            satellite_data = {
                                'name': name_line,
                                'norad_id': norad_id,
                                'line1': line1,
                                'line2': line2,
                                'data_source': 'local_collection'
                            }
                            
                            satellites.append(satellite_data)
                            
                        except ValueError as e:
                            logger.warning(f"ç„¡æ³•è§£æ NORAD ID: {line1[:10]} - {e}")
                    
                    i += 3
                else:
                    i += 1
                    
        except Exception as e:
            logger.error(f"è§£æ TLE æ–‡ä»¶å¤±æ•— {file_path}: {e}")
            
        logger.debug(f"å¾ {file_path} è§£æå‡º {len(satellites)} é¡†è¡›æ˜Ÿ")
        return satellites
    
    def parse_json_file(self, file_path: Path) -> Optional[List[Dict[str, Any]]]:
        """è§£æ JSON æ–‡ä»¶"""
        try:
            import json
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list):
                logger.debug(f"å¾ {file_path} è§£æå‡º {len(data)} ç­† JSON è¨˜éŒ„")
                return data
            else:
                logger.warning(f"JSON æ–‡ä»¶æ ¼å¼ä¸æ­£ç¢º: {file_path}")
                return None
                
        except Exception as e:
            logger.error(f"è§£æ JSON æ–‡ä»¶å¤±æ•— {file_path}: {e}")
            return None
    
    def load_collected_data(self, constellation: str = "starlink", 
                           start_date: str = None, end_date: str = None) -> Dict[str, Any]:
        """è¼‰å…¥æ‰‹å‹•æ”¶é›†çš„TLEæ­·å²æ•¸æ“š"""
        if constellation not in self.supported_constellations:
            return {'error': f'ä¸æ”¯æ´çš„æ˜Ÿåº§: {constellation}'}
            
        tle_dir = self.tle_data_dir / constellation / "tle"
        json_dir = self.tle_data_dir / constellation / "json"
        
        if not tle_dir.exists():
            return {'error': f'TLE ç›®éŒ„ä¸å­˜åœ¨: {tle_dir}'}
            
        collected_data = []
        available_dates = []
        
        import glob
        import re
        
        # æƒææ‰€æœ‰å¯ç”¨çš„ TLE æª”æ¡ˆ
        tle_pattern = str(tle_dir / f"{constellation}_*.tle")
        tle_files = glob.glob(tle_pattern)
        
        for tle_file in tle_files:
            # æå–å¯¦éš›æ—¥æœŸ (YYYYMMDD)
            match = re.search(r'(\d{8})\.tle$', tle_file)
            if match:
                date_str = match.group(1)
                
                # æ—¥æœŸç¯„åœéæ¿¾
                if start_date and date_str < start_date:
                    continue
                if end_date and date_str > end_date:
                    continue
                
                tle_path = Path(tle_file)
                json_path = json_dir / f"{constellation}_{date_str}.json"
                
                if tle_path.exists() and tle_path.stat().st_size > 0:
                    # è§£æ TLE æ•¸æ“š
                    daily_tle_data = self.parse_tle_file(tle_path)
                    daily_json_data = None
                    
                    # å˜—è©¦è®€å–å°æ‡‰çš„ JSON æ•¸æ“š
                    if json_path.exists() and json_path.stat().st_size > 0:
                        daily_json_data = self.parse_json_file(json_path)
                    
                    if daily_tle_data:
                        collected_data.append({
                            'date': date_str,
                            'tle_file': str(tle_path),
                            'json_file': str(json_path) if daily_json_data else None,
                            'satellites': daily_tle_data[:3],  # åªä¿ç•™å‰3å€‹ä½œç‚ºæ¨£æœ¬
                            'satellite_count': len(daily_tle_data),
                            'json_metadata': daily_json_data[:3] if daily_json_data else None,  # åªä¿ç•™å‰3å€‹ä½œç‚ºæ¨£æœ¬
                            'has_dual_format': daily_json_data is not None
                        })
                        available_dates.append(date_str)
        
        # æŒ‰æ—¥æœŸæ’åº
        collected_data.sort(key=lambda x: x['date'])
        available_dates.sort()
        
        return {
            'constellation': constellation,
            'total_days_collected': len(collected_data),
            'date_range': {
                'start': available_dates[0] if available_dates else None,
                'end': available_dates[-1] if available_dates else None,
                'available_dates': available_dates
            },
            'dual_format_coverage': sum(1 for d in collected_data if d['has_dual_format']),
            'coverage_percentage': len(collected_data) / len(available_dates) * 100 if available_dates else 0,
            'daily_data': collected_data
        }
    
    def get_data_coverage_status(self) -> Dict[str, Any]:
        """æª¢æŸ¥æ‰‹å‹•æ”¶é›†æ•¸æ“šçš„ç‹€æ…‹å’Œè¦†è“‹ç‡"""
        status = {'starlink': {}, 'oneweb': {}, 'overall': {}}
        
        # ç²å–å…©å€‹æ˜Ÿåº§çš„æ•¸æ“š
        starlink_data = self.load_collected_data('starlink')
        oneweb_data = self.load_collected_data('oneweb')
        
        # è¨ˆç®—æ—¥æœŸè¦†è“‹ç¯„åœ
        all_dates = set()
        starlink_dates = set()
        oneweb_dates = set()
        
        if 'date_range' in starlink_data and starlink_data['date_range']['available_dates']:
            starlink_dates = set(starlink_data['date_range']['available_dates'])
            all_dates.update(starlink_dates)
        
        if 'date_range' in oneweb_data and oneweb_data['date_range']['available_dates']:
            oneweb_dates = set(oneweb_data['date_range']['available_dates'])
            all_dates.update(oneweb_dates)
        
        status['starlink'] = {
            'days_collected': starlink_data.get('total_days_collected', 0),
            'dates': sorted(list(starlink_dates)),
            'dual_format_count': starlink_data.get('dual_format_coverage', 0),
            'dual_format_percentage': (starlink_data.get('dual_format_coverage', 0) / 
                                     starlink_data.get('total_days_collected', 1) * 100) if starlink_data.get('total_days_collected', 0) > 0 else 0
        }
        
        status['oneweb'] = {
            'days_collected': oneweb_data.get('total_days_collected', 0),
            'dates': sorted(list(oneweb_dates)),
            'dual_format_count': oneweb_data.get('dual_format_coverage', 0),
            'dual_format_percentage': (oneweb_data.get('dual_format_coverage', 0) / 
                                     oneweb_data.get('total_days_collected', 1) * 100) if oneweb_data.get('total_days_collected', 0) > 0 else 0
        }
        
        status['overall'] = {
            'total_unique_dates': len(all_dates),
            'date_range': {
                'start': min(all_dates) if all_dates else None,
                'end': max(all_dates) if all_dates else None
            },
            'common_dates': len(starlink_dates & oneweb_dates),
            'coverage_days': len(all_dates)
        }
        
        return status
    
    def validate_daily_data_quality(self, constellation: str, date_str: str) -> Dict[str, Any]:
        """é©—è­‰ç‰¹å®šæ—¥æœŸæ•¸æ“šå“è³ª"""
        tle_path = self.tle_data_dir / constellation / "tle" / f"{constellation}_{date_str}.tle"
        json_path = self.tle_data_dir / constellation / "json" / f"{constellation}_{date_str}.json"
        
        if not tle_path.exists():
            return {'valid': False, 'error': 'TLE file not found', 'date': date_str}
            
        # è§£æ TLE æ•¸æ“š
        satellites = self.parse_tle_file(tle_path)
        
        # å˜—è©¦è§£æ JSON æ•¸æ“š
        json_data = None
        has_json = json_path.exists() and json_path.stat().st_size > 0
        if has_json:
            json_data = self.parse_json_file(json_path)
        
        validation_result = {
            'valid': True,
            'date': date_str,
            'satellite_count': len(satellites),
            'has_dual_format': has_json,
            'json_satellite_count': len(json_data) if json_data else 0,
            'format_errors': [],
            'orbit_warnings': [],
            'data_quality_score': 0
        }
        
        # åŸºç¤é©—è­‰
        format_errors = 0
        orbit_warnings = 0
        
        for sat in satellites:
            # ç°¡å–®æ ¼å¼æª¢æŸ¥
            if len(sat.get('line1', '')) < 69 or len(sat.get('line2', '')) < 69:
                format_errors += 1
                validation_result['format_errors'].append(f"Invalid TLE length: {sat.get('name', 'Unknown')}")
            
            # åŸºæœ¬è»Œé“åƒæ•¸æª¢æŸ¥
            try:
                if not (1 <= sat.get('norad_id', 0) <= 99999):
                    orbit_warnings += 1
                    validation_result['orbit_warnings'].append(f"Suspicious NORAD ID: {sat.get('name', 'Unknown')}")
            except:
                orbit_warnings += 1
        
        # è¨ˆç®—å“è³ªåˆ†æ•¸
        total_sats = len(satellites)
        if total_sats > 0:
            validation_result['data_quality_score'] = max(0, 
                100 - (format_errors * 10) - (orbit_warnings * 2))
        
        validation_result['valid'] = (format_errors == 0 and total_sats > 0)
        
        return validation_result

def main():
    """æ¸¬è©¦ä¸»ç¨‹åº"""
    print("ğŸš€ Phase 0 æœ¬åœ° TLE æ•¸æ“šåŠ è¼‰å™¨æ¸¬è©¦")
    print("=" * 60)
    
    # åˆå§‹åŒ–åŠ è¼‰å™¨
    loader = LocalTLELoader()
    
    # 1. æª¢æŸ¥æ•¸æ“šè¦†è“‹ç‹€æ…‹
    print("\nğŸ“Š æ•¸æ“šè¦†è“‹ç‹€æ…‹æª¢æŸ¥")
    print("-" * 30)
    status = loader.get_data_coverage_status()
    print(json.dumps(status, indent=2, ensure_ascii=False))
    
    # 2. è¼‰å…¥ Starlink æ•¸æ“š
    print("\nğŸ›°ï¸ Starlink æ•¸æ“šè¼‰å…¥æ¸¬è©¦")
    print("-" * 30)
    starlink_data = loader.load_collected_data('starlink')
    if 'error' not in starlink_data:
        print(f"âœ… ç¸½å¤©æ•¸: {starlink_data.get('total_days_collected', 0)}")
        print(f"âœ… æ—¥æœŸç¯„åœ: {starlink_data.get('date_range', {}).get('start', 'N/A')} - {starlink_data.get('date_range', {}).get('end', 'N/A')}")
        print(f"âœ… é›™æ ¼å¼è¦†è“‹: {starlink_data.get('dual_format_coverage', 0)} / {starlink_data.get('total_days_collected', 0)}")
        
        # é¡¯ç¤ºæ¨£æœ¬æ•¸æ“š
        if starlink_data.get('daily_data'):
            sample_day = starlink_data['daily_data'][0]
            print(f"âœ… æ¨£æœ¬æ—¥æœŸ: {sample_day['date']}")
            print(f"âœ… è¡›æ˜Ÿæ•¸é‡: {sample_day['satellite_count']}")
            print(f"âœ… é›™æ ¼å¼æ”¯æ´: {sample_day['has_dual_format']}")
    else:
        print(f"âŒ éŒ¯èª¤: {starlink_data['error']}")
    
    # 3. è¼‰å…¥ OneWeb æ•¸æ“š
    print("\nğŸŒ OneWeb æ•¸æ“šè¼‰å…¥æ¸¬è©¦")
    print("-" * 30)
    oneweb_data = loader.load_collected_data('oneweb')
    if 'error' not in oneweb_data:
        print(f"âœ… ç¸½å¤©æ•¸: {oneweb_data.get('total_days_collected', 0)}")
        print(f"âœ… æ—¥æœŸç¯„åœ: {oneweb_data.get('date_range', {}).get('start', 'N/A')} - {oneweb_data.get('date_range', {}).get('end', 'N/A')}")
        print(f"âœ… é›™æ ¼å¼è¦†è“‹: {oneweb_data.get('dual_format_coverage', 0)} / {oneweb_data.get('total_days_collected', 0)}")
        
        # é¡¯ç¤ºæ¨£æœ¬æ•¸æ“š
        if oneweb_data.get('daily_data'):
            sample_day = oneweb_data['daily_data'][0]
            print(f"âœ… æ¨£æœ¬æ—¥æœŸ: {sample_day['date']}")
            print(f"âœ… è¡›æ˜Ÿæ•¸é‡: {sample_day['satellite_count']}")
            print(f"âœ… é›™æ ¼å¼æ”¯æ´: {sample_day['has_dual_format']}")
    else:
        print(f"âŒ éŒ¯èª¤: {oneweb_data['error']}")
    
    # 4. æ•¸æ“šå“è³ªæª¢æŸ¥æ¸¬è©¦
    print("\nğŸ” æ•¸æ“šå“è³ªæª¢æŸ¥æ¸¬è©¦")
    print("-" * 30)
    if starlink_data.get('daily_data'):
        test_date = starlink_data['daily_data'][0]['date']
        validation_result = loader.validate_daily_data_quality('starlink', test_date)
        print(f"âœ… æ¸¬è©¦æ—¥æœŸ: {test_date}")
        print(f"âœ… æ•¸æ“šæœ‰æ•ˆ: {validation_result['valid']}")
        print(f"âœ… è¡›æ˜Ÿæ•¸é‡: {validation_result['satellite_count']}")
        print(f"âœ… å“è³ªåˆ†æ•¸: {validation_result['data_quality_score']}")
    
    print("\nğŸ‰ Phase 0 æœ¬åœ° TLE æ•¸æ“šåŠ è¼‰å™¨æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    main()