"""
ğŸ§  é…ç½®é©…å‹•çš„ç®—æ³•ç®¡ç†å™¨

åŸºæ–¼é…ç½®æ–‡ä»¶çš„ç®—æ³•ç®¡ç†ï¼Œæ”¯æ´ï¼š
- YAML/JSON é…ç½®é©…å‹•
- å‹•æ…‹ç®—æ³•åŠ è¼‰
- ç†±é‡è¼‰é…ç½®
- ç’°å¢ƒéš”é›¢
"""

import os
import logging
import yaml
import json
from typing import Dict, Any, List, Optional, Union
from pathlib import Path
from dataclasses import dataclass
from datetime import datetime
import asyncio
import hashlib

from ..interfaces.rl_algorithm import IRLAlgorithm, ScenarioType
from .algorithm_factory import get_algorithm
from .di_container import DIContainer

logger = logging.getLogger(__name__)


@dataclass
class AlgorithmConfig:
    """ç®—æ³•é…ç½®"""
    name: str
    algorithm_type: str
    enabled: bool = True
    scenarios: List[str] = None
    hyperparameters: Dict[str, Any] = None
    training_config: Dict[str, Any] = None
    deployment_config: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.scenarios is None:
            self.scenarios = ["urban"]
        if self.hyperparameters is None:
            self.hyperparameters = {}
        if self.training_config is None:
            self.training_config = {}
        if self.deployment_config is None:
            self.deployment_config = {}


@dataclass
class SystemConfig:
    """ç³»çµ±é…ç½®"""
    environment: str = "development"
    log_level: str = "INFO"
    database_url: str = ""
    redis_url: str = ""
    model_storage_path: str = "./models"
    enable_monitoring: bool = True
    enable_web_ui: bool = True
    api_rate_limit: int = 1000
    max_concurrent_training: int = 3


class ConfigDrivenAlgorithmManager:
    """é…ç½®é©…å‹•çš„ç®—æ³•ç®¡ç†å™¨
    
    è² è²¬æ ¹æ“šé…ç½®æ–‡ä»¶è‡ªå‹•åŒ–ç®¡ç†ç®—æ³•çš„åŠ è¼‰ã€é…ç½®å’Œç”Ÿå‘½é€±æœŸã€‚
    æ”¯æ´å¤šç’°å¢ƒé…ç½®å’Œç†±é‡è¼‰åŠŸèƒ½ã€‚
    """
    
    def __init__(self, config_path: Union[str, Path], container: Optional[DIContainer] = None):
        self.config_path = Path(config_path)
        self.container = container or DIContainer()
        self.config: Dict[str, Any] = {}
        self.algorithms: Dict[str, IRLAlgorithm] = {}
        self.system_config: Optional[SystemConfig] = None
        self.algorithm_configs: Dict[str, AlgorithmConfig] = {}
        self._config_hash: Optional[str] = None
        self._file_watchers: List[asyncio.Task] = []
        self._initialized = False
        
        logger.info(f"é…ç½®é©…å‹•ç®—æ³•ç®¡ç†å™¨åˆå§‹åŒ–ï¼Œé…ç½®æ–‡ä»¶: {config_path}")
    
    async def initialize(self) -> None:
        """åˆå§‹åŒ–ç®—æ³•ç®¡ç†å™¨"""
        if self._initialized:
            logger.warning("ç®—æ³•ç®¡ç†å™¨å·²åˆå§‹åŒ–")
            return
        
        try:
            # åŠ è¼‰é…ç½®
            await self._load_config()
            
            # è§£æé…ç½®
            await self._parse_config()
            
            # å‹•æ…‹åŠ è¼‰ç®—æ³•æ’ä»¶
            await self._load_algorithm_plugins()
            
            # è¨­ç½®æ–‡ä»¶ç›£æ§ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if self.system_config and self.system_config.environment != "production":
                await self._setup_file_watcher()
            
            self._initialized = True
            logger.info("é…ç½®é©…å‹•ç®—æ³•ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–ç®—æ³•ç®¡ç†å™¨å¤±æ•—: {e}")
            raise
    
    async def _load_config(self) -> None:
        """åŠ è¼‰é…ç½®æ–‡ä»¶"""
        if not self.config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
        
        try:
            config_content = self.config_path.read_text(encoding='utf-8')
            
            # è¨ˆç®—é…ç½®æ–‡ä»¶å“ˆå¸Œå€¼
            current_hash = hashlib.md5(config_content.encode()).hexdigest()
            
            # å¦‚æœé…ç½®æ²’æœ‰è®ŠåŒ–ï¼Œè·³éé‡è¼‰
            if self._config_hash == current_hash:
                logger.debug("é…ç½®æ–‡ä»¶æœªè®ŠåŒ–ï¼Œè·³éé‡è¼‰")
                return
            
            # æ ¹æ“šæ–‡ä»¶æ“´å±•åè§£æé…ç½®
            if self.config_path.suffix.lower() in ['.yml', '.yaml']:
                self.config = yaml.safe_load(config_content)
            elif self.config_path.suffix.lower() == '.json':
                self.config = json.loads(config_content)
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„é…ç½®æ–‡ä»¶æ ¼å¼: {self.config_path.suffix}")
            
            self._config_hash = current_hash
            logger.info(f"æˆåŠŸåŠ è¼‰é…ç½®æ–‡ä»¶: {self.config_path}")
            
        except Exception as e:
            logger.error(f"åŠ è¼‰é…ç½®æ–‡ä»¶å¤±æ•—: {e}")
            raise
    
    async def _parse_config(self) -> None:
        """è§£æé…ç½®å…§å®¹"""
        try:
            # è§£æç³»çµ±é…ç½®
            system_config_data = self.config.get('system', {})
            self.system_config = SystemConfig(
                environment=system_config_data.get('environment', 'development'),
                log_level=system_config_data.get('log_level', 'INFO'),
                database_url=system_config_data.get('database_url', ''),
                redis_url=system_config_data.get('redis_url', ''),
                model_storage_path=system_config_data.get('model_storage_path', './models'),
                enable_monitoring=system_config_data.get('enable_monitoring', True),
                enable_web_ui=system_config_data.get('enable_web_ui', True),
                api_rate_limit=system_config_data.get('api_rate_limit', 1000),
                max_concurrent_training=system_config_data.get('max_concurrent_training', 3)
            )
            
            # è§£æç®—æ³•é…ç½®
            rl_algorithms = self.config.get('handover_algorithms', {}).get('reinforcement_learning', {})
            self.algorithm_configs.clear()
            
            for algo_name, algo_config in rl_algorithms.items():
                config_obj = AlgorithmConfig(
                    name=algo_name,
                    algorithm_type=algo_config.get('algorithm_type', algo_name.upper()),
                    enabled=algo_config.get('enabled', True),
                    scenarios=algo_config.get('scenarios', ['urban']),
                    hyperparameters=algo_config.get('hyperparameters', {}),
                    training_config=algo_config.get('training', {}),
                    deployment_config=algo_config.get('deployment', {})
                )
                self.algorithm_configs[algo_name] = config_obj
            
            logger.info(f"è§£æåˆ° {len(self.algorithm_configs)} å€‹ç®—æ³•é…ç½®")
            
        except Exception as e:
            logger.error(f"è§£æé…ç½®å¤±æ•—: {e}")
            raise
    
    async def _load_algorithm_plugins(self) -> None:
        """å‹•æ…‹åŠ è¼‰ç®—æ³•æ’ä»¶"""
        try:
            loaded_count = 0
            
            for algo_name, algo_config in self.algorithm_configs.items():
                if not algo_config.enabled:
                    logger.info(f"ç®—æ³• {algo_name} å·²ç¦ç”¨ï¼Œè·³éåŠ è¼‰")
                    continue
                
                try:
                    # å˜—è©¦å‰µå»ºç®—æ³•å¯¦ä¾‹
                    scenario_types = [ScenarioType(s) for s in algo_config.scenarios]
                    
                    # ç‚ºæ¯å€‹å ´æ™¯å‰µå»ºç®—æ³•å¯¦ä¾‹
                    for scenario_type in scenario_types:
                        algorithm = get_algorithm(
                            name=algo_config.algorithm_type.lower(),
                            env_name="CartPole-v1",  # ä½¿ç”¨æ¨™æº– Gymnasium ç’°å¢ƒ
                            config=algo_config.hyperparameters,
                            scenario_type=scenario_type,
                            use_singleton=True
                        )
                        
                        instance_key = f"{algo_name}_{scenario_type.value}"
                        self.algorithms[instance_key] = algorithm
                        
                        logger.info(f"æˆåŠŸåŠ è¼‰ç®—æ³•: {algo_name} (é¡å‹: {algo_config.algorithm_type}, å ´æ™¯: {scenario_type.value})")
                    
                    loaded_count += 1
                    
                except Exception as e:
                    logger.error(f"åŠ è¼‰ç®—æ³• {algo_name} å¤±æ•—: {e}")
            
            logger.info(f"æˆåŠŸåŠ è¼‰ {loaded_count} å€‹ç®—æ³•")
            
        except Exception as e:
            logger.error(f"åŠ è¼‰ç®—æ³•æ’ä»¶å¤±æ•—: {e}")
            raise
    
    async def _setup_file_watcher(self) -> None:
        """è¨­ç½®é…ç½®æ–‡ä»¶ç›£æ§"""
        async def watch_config_file():
            """ç›£æ§é…ç½®æ–‡ä»¶è®ŠåŒ–"""
            last_modified = None
            
            while True:
                try:
                    current_modified = self.config_path.stat().st_mtime
                    
                    if last_modified is None:
                        last_modified = current_modified
                    elif current_modified != last_modified:
                        logger.info("æª¢æ¸¬åˆ°é…ç½®æ–‡ä»¶è®ŠåŒ–ï¼Œé‡æ–°åŠ è¼‰...")
                        await self._reload_config()
                        last_modified = current_modified
                    
                    await asyncio.sleep(5)  # æ¯5ç§’æª¢æŸ¥ä¸€æ¬¡
                    
                except Exception as e:
                    logger.error(f"ç›£æ§é…ç½®æ–‡ä»¶å¤±æ•—: {e}")
                    await asyncio.sleep(10)  # å‡ºéŒ¯æ™‚ç­‰å¾…æ›´é•·æ™‚é–“
        
        # å•Ÿå‹•ç›£æ§ä»»å‹™
        task = asyncio.create_task(watch_config_file())
        self._file_watchers.append(task)
        logger.info("å·²å•Ÿå‹•é…ç½®æ–‡ä»¶ç›£æ§")
    
    async def _reload_config(self) -> None:
        """é‡æ–°åŠ è¼‰é…ç½®"""
        try:
            # é‡æ–°åŠ è¼‰é…ç½®æ–‡ä»¶
            await self._load_config()
            await self._parse_config()
            
            # é‡æ–°åŠ è¼‰ç®—æ³•
            old_algorithms = self.algorithms.copy()
            self.algorithms.clear()
            await self._load_algorithm_plugins()
            
            # æ¸…ç†èˆŠçš„ç®—æ³•å¯¦ä¾‹
            for old_algorithm in old_algorithms.values():
                try:
                    # å¦‚æœç®—æ³•æœ‰æ¸…ç†æ–¹æ³•ï¼Œèª¿ç”¨å®ƒ
                    if hasattr(old_algorithm, 'cleanup'):
                        await old_algorithm.cleanup()
                except Exception as e:
                    logger.warning(f"æ¸…ç†èˆŠç®—æ³•å¯¦ä¾‹å¤±æ•—: {e}")
            
            logger.info("é…ç½®é‡æ–°åŠ è¼‰å®Œæˆ")
            
        except Exception as e:
            logger.error(f"é‡æ–°åŠ è¼‰é…ç½®å¤±æ•—: {e}")
    
    async def get_algorithm(self, name: str, scenario_type: ScenarioType = ScenarioType.URBAN) -> IRLAlgorithm:
        """ç²å–ç®—æ³•å¯¦ä¾‹
        
        Args:
            name: ç®—æ³•åç¨±
            scenario_type: å ´æ™¯é¡å‹
            
        Returns:
            IRLAlgorithm: ç®—æ³•å¯¦ä¾‹
            
        Raises:
            ValueError: ç®—æ³•ä¸å­˜åœ¨æˆ–æœªå•Ÿç”¨
        """
        if not self._initialized:
            await self.initialize()
        
        instance_key = f"{name}_{scenario_type.value}"
        
        if instance_key not in self.algorithms:
            raise ValueError(f"ç®—æ³• {name} (å ´æ™¯: {scenario_type.value}) ä¸å­˜åœ¨æˆ–æœªå•Ÿç”¨")
        
        return self.algorithms[instance_key]
    
    def get_available_algorithms(self) -> List[str]:
        """ç²å–å¯ç”¨ç®—æ³•åˆ—è¡¨
        
        Returns:
            List[str]: ç®—æ³•åç¨±åˆ—è¡¨
        """
        return [
            config.name 
            for config in self.algorithm_configs.values() 
            if config.enabled
        ]
    
    def get_algorithm_config(self, name: str) -> Optional[AlgorithmConfig]:
        """ç²å–ç®—æ³•é…ç½®
        
        Args:
            name: ç®—æ³•åç¨±
            
        Returns:
            Optional[AlgorithmConfig]: ç®—æ³•é…ç½®
        """
        return self.algorithm_configs.get(name)
    
    def get_system_config(self) -> SystemConfig:
        """ç²å–ç³»çµ±é…ç½®
        
        Returns:
            SystemConfig: ç³»çµ±é…ç½®
        """
        return self.system_config
    
    async def update_algorithm_config(self, name: str, updates: Dict[str, Any]) -> bool:
        """æ›´æ–°ç®—æ³•é…ç½®
        
        Args:
            name: ç®—æ³•åç¨±
            updates: æ›´æ–°å…§å®¹
            
        Returns:
            bool: æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            if name not in self.algorithm_configs:
                logger.error(f"ç®—æ³• {name} ä¸å­˜åœ¨")
                return False
            
            # æ›´æ–°å…§å­˜ä¸­çš„é…ç½®
            config = self.algorithm_configs[name]
            for key, value in updates.items():
                if hasattr(config, key):
                    setattr(config, key, value)
            
            # æ›´æ–°é…ç½®æ–‡ä»¶ï¼ˆå¯é¸ï¼‰
            # é€™è£¡å¯ä»¥å¯¦ç¾é…ç½®æ–‡ä»¶çš„è‡ªå‹•æ›´æ–°
            
            logger.info(f"æˆåŠŸæ›´æ–°ç®—æ³• {name} çš„é…ç½®")
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–°ç®—æ³•é…ç½®å¤±æ•—: {e}")
            return False
    
    async def enable_algorithm(self, name: str) -> bool:
        """å•Ÿç”¨ç®—æ³•
        
        Args:
            name: ç®—æ³•åç¨±
            
        Returns:
            bool: æ˜¯å¦å•Ÿç”¨æˆåŠŸ
        """
        return await self.update_algorithm_config(name, {"enabled": True})
    
    async def disable_algorithm(self, name: str) -> bool:
        """ç¦ç”¨ç®—æ³•
        
        Args:
            name: ç®—æ³•åç¨±
            
        Returns:
            bool: æ˜¯å¦ç¦ç”¨æˆåŠŸ
        """
        return await self.update_algorithm_config(name, {"enabled": False})
    
    def get_manager_stats(self) -> Dict[str, Any]:
        """ç²å–ç®¡ç†å™¨çµ±è¨ˆè³‡è¨Š
        
        Returns:
            Dict[str, Any]: çµ±è¨ˆè³‡è¨Š
        """
        enabled_algorithms = sum(1 for config in self.algorithm_configs.values() if config.enabled)
        
        return {
            "initialized": self._initialized,
            "config_path": str(self.config_path),
            "config_hash": self._config_hash,
            "total_algorithms": len(self.algorithm_configs),
            "enabled_algorithms": enabled_algorithms,
            "loaded_instances": len(self.algorithms),
            "system_config": {
                "environment": self.system_config.environment if self.system_config else "unknown",
                "monitoring_enabled": self.system_config.enable_monitoring if self.system_config else False
            },
            "file_watchers_active": len(self._file_watchers)
        }
    
    async def shutdown(self) -> None:
        """é—œé–‰ç®¡ç†å™¨"""
        try:
            # åœæ­¢æ–‡ä»¶ç›£æ§
            for task in self._file_watchers:
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass
            
            # æ¸…ç†ç®—æ³•å¯¦ä¾‹
            for algorithm in self.algorithms.values():
                try:
                    if hasattr(algorithm, 'cleanup'):
                        await algorithm.cleanup()
                except Exception as e:
                    logger.warning(f"æ¸…ç†ç®—æ³•å¯¦ä¾‹å¤±æ•—: {e}")
            
            self.algorithms.clear()
            self._initialized = False
            
            logger.info("é…ç½®é©…å‹•ç®—æ³•ç®¡ç†å™¨å·²é—œé–‰")
            
        except Exception as e:
            logger.error(f"é—œé–‰ç®—æ³•ç®¡ç†å™¨å¤±æ•—: {e}")


# å·¥å…·å‡½æ•¸
def create_default_config(config_path: Union[str, Path]) -> None:
    """å‰µå»ºé è¨­é…ç½®æ–‡ä»¶
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾‘
    """
    default_config = {
        "system": {
            "environment": "development",
            "log_level": "INFO",
            "database_url": "postgresql://postgres:password@localhost:5432/rl_system",
            "redis_url": "redis://localhost:6379/0",
            "model_storage_path": "./models",
            "enable_monitoring": True,
            "enable_web_ui": True,
            "api_rate_limit": 1000,
            "max_concurrent_training": 3
        },
        "handover_algorithms": {
            "reinforcement_learning": {
                "dqn": {
                    "algorithm_type": "DQN",
                    "enabled": True,
                    "scenarios": ["urban", "suburban"],
                    "hyperparameters": {
                        "learning_rate": 0.001,
                        "batch_size": 32,
                        "epsilon": 0.1,
                        "gamma": 0.99
                    },
                    "training": {
                        "max_episodes": 1000,
                        "max_steps_per_episode": 500
                    },
                    "deployment": {
                        "auto_deploy": False,
                        "validation_required": True
                    }
                },
                "ppo": {
                    "algorithm_type": "PPO",
                    "enabled": True,
                    "scenarios": ["urban", "low_latency"],
                    "hyperparameters": {
                        "learning_rate": 0.0003,
                        "batch_size": 64,
                        "gamma": 0.99,
                        "clip_epsilon": 0.2
                    }
                },
                "sac": {
                    "algorithm_type": "SAC",
                    "enabled": False,
                    "scenarios": ["suburban", "high_mobility"],
                    "hyperparameters": {
                        "learning_rate": 0.0001,
                        "batch_size": 128,
                        "tau": 0.005
                    }
                }
            }
        }
    }
    
    config_path = Path(config_path)
    config_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(default_config, f, default_flow_style=False, allow_unicode=True)
    
    logger.info(f"å·²å‰µå»ºé è¨­é…ç½®æ–‡ä»¶: {config_path}")


# ç•°å¸¸å®šç¾©
class ConfigManagerError(Exception):
    """é…ç½®ç®¡ç†å™¨åŸºç¤ç•°å¸¸"""
    pass


class ConfigFileError(ConfigManagerError):
    """é…ç½®æ–‡ä»¶ç•°å¸¸"""
    pass


class AlgorithmLoadError(ConfigManagerError):
    """ç®—æ³•åŠ è¼‰ç•°å¸¸"""
    pass