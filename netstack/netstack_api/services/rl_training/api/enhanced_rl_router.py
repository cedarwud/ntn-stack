"""
ğŸ§  å¢å¼·ç‰ˆ RL API è·¯ç”±å™¨

æ•´åˆæ–°çš„ SOLID æ¶æ§‹å’Œç¾æœ‰ FastAPI è·¯ç”±å™¨ï¼Œ
æä¾›ä¸–ç•Œç´šçš„ RL ç³»çµ± API æ¥å£ã€‚
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Union
from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends, Query, Path
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel, Field
import asyncio
import json

from ..core.service_locator import ServiceLocator
from ..core.algorithm_factory import AlgorithmFactory
from ..interfaces.rl_algorithm import ScenarioType, TrainingConfig, PredictionContext
from ..interfaces.training_scheduler import TrainingJob, TrainingPriority
from ..interfaces.performance_monitor import MetricType
from ..interfaces.model_manager import ModelMetadata

logger = logging.getLogger(__name__)

# å‰µå»ºè·¯ç”±å™¨
router = APIRouter(prefix="/api/v1/rl", tags=["å¼·åŒ–å­¸ç¿’ç³»çµ±"])


# ===== è«‹æ±‚/éŸ¿æ‡‰æ¨¡å‹ =====

class SystemStatusResponse(BaseModel):
    """ç³»çµ±ç‹€æ…‹éŸ¿æ‡‰"""
    status: str = Field(description="ç³»çµ±ç‹€æ…‹")
    version: str = Field(description="ç³»çµ±ç‰ˆæœ¬")
    uptime_seconds: float = Field(description="é‹è¡Œæ™‚é–“")
    available_algorithms: List[str] = Field(description="å¯ç”¨ç®—æ³•åˆ—è¡¨")
    active_training_jobs: int = Field(description="æ´»èºè¨“ç·´ä»»å‹™æ•¸")
    total_models: int = Field(description="æ¨¡å‹ç¸½æ•¸")
    system_health: Dict[str, Any] = Field(description="ç³»çµ±å¥åº·ç‹€æ…‹")


class AlgorithmInfoResponse(BaseModel):
    """ç®—æ³•è³‡è¨ŠéŸ¿æ‡‰"""
    name: str = Field(description="ç®—æ³•åç¨±")
    version: str = Field(description="ç‰ˆæœ¬è™Ÿ")
    supported_scenarios: List[str] = Field(description="æ”¯æ´å ´æ™¯")
    description: str = Field(description="ç®—æ³•æè¿°")
    author: str = Field(description="ä½œè€…")
    hyperparameters: Dict[str, Any] = Field(description="è¶…åƒæ•¸")
    training_metrics: Dict[str, Any] = Field(description="è¨“ç·´æŒ‡æ¨™")


class TrainingRequest(BaseModel):
    """è¨“ç·´è«‹æ±‚"""
    algorithm_name: str = Field(description="ç®—æ³•åç¨±")
    scenario_type: str = Field(default="urban", description="å ´æ™¯é¡å‹")
    episodes: int = Field(default=1000, ge=1, le=10000, description="è¨“ç·´å›åˆæ•¸")
    max_steps_per_episode: int = Field(default=1000, ge=1, description="æ¯å›åˆæœ€å¤§æ­¥æ•¸")
    custom_config: Optional[Dict[str, Any]] = Field(None, description="è‡ªå®šç¾©é…ç½®")
    priority: str = Field(default="normal", description="è¨“ç·´å„ªå…ˆç´š")
    experiment_name: Optional[str] = Field(None, description="è¨“ç·´åç¨±")


class PredictionRequest(BaseModel):
    """é æ¸¬è«‹æ±‚"""
    algorithm_name: str = Field(description="ç®—æ³•åç¨±")
    scenario_type: str = Field(default="urban", description="å ´æ™¯é¡å‹")
    ue_position: Dict[str, float] = Field(description="ç”¨æˆ¶è¨­å‚™ä½ç½®")
    satellite_positions: List[Dict[str, Any]] = Field(description="è¡›æ˜Ÿä½ç½®åˆ—è¡¨")
    network_conditions: Dict[str, Any] = Field(description="ç¶²è·¯ç‹€æ³")
    current_serving_satellite: int = Field(description="ç•¶å‰æœå‹™è¡›æ˜ŸID")
    candidate_satellites: List[int] = Field(description="å€™é¸è¡›æ˜Ÿåˆ—è¡¨")


class TrainingJobResponse(BaseModel):
    """è¨“ç·´ä»»å‹™éŸ¿æ‡‰"""
    job_id: str = Field(description="ä»»å‹™ID")
    algorithm_name: str = Field(description="ç®—æ³•åç¨±")
    status: str = Field(description="ä»»å‹™ç‹€æ…‹")
    progress_percent: float = Field(description="å®Œæˆé€²åº¦")
    episodes_completed: int = Field(description="å·²å®Œæˆå›åˆæ•¸")
    total_episodes: int = Field(description="ç¸½å›åˆæ•¸")
    current_score: float = Field(description="ç•¶å‰åˆ†æ•¸")
    estimated_completion: Optional[str] = Field(None, description="é ä¼°å®Œæˆæ™‚é–“")
    created_at: str = Field(description="å‰µå»ºæ™‚é–“")


class PerformanceMetricsResponse(BaseModel):
    """æ€§èƒ½æŒ‡æ¨™éŸ¿æ‡‰"""
    algorithm_name: str = Field(description="ç®—æ³•åç¨±")
    scenario_type: str = Field(description="å ´æ™¯é¡å‹")
    metrics: Dict[str, Any] = Field(description="æ€§èƒ½æŒ‡æ¨™")
    time_range: Dict[str, str] = Field(description="æ™‚é–“ç¯„åœ")
    statistical_summary: Dict[str, Any] = Field(description="çµ±è¨ˆæ‘˜è¦")


# ===== ä¾è³´æ³¨å…¥ =====

async def get_algorithm_manager():
    """ç²å–ç®—æ³•ç®¡ç†å™¨ä¾è³´"""
    try:
        # é€™è£¡æ‡‰è©²å¾é…ç½®ç®¡ç†å™¨ç²å–ï¼Œæš«æ™‚ä½¿ç”¨å·¥å» æ¨¡å¼
        return AlgorithmFactory
    except Exception as e:
        logger.error(f"ç²å–ç®—æ³•ç®¡ç†å™¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="ç®—æ³•ç®¡ç†å™¨ä¸å¯ç”¨")


async def get_training_scheduler():
    """ç²å–è¨“ç·´èª¿åº¦å™¨ä¾è³´"""
    try:
        return ServiceLocator.get_training_scheduler()
    except Exception as e:
        logger.error(f"ç²å–è¨“ç·´èª¿åº¦å™¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="è¨“ç·´èª¿åº¦å™¨ä¸å¯ç”¨")


async def get_performance_monitor():
    """ç²å–æ€§èƒ½ç›£æ§å™¨ä¾è³´"""
    try:
        return ServiceLocator.get_performance_monitor()
    except Exception as e:
        logger.error(f"ç²å–æ€§èƒ½ç›£æ§å™¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="æ€§èƒ½ç›£æ§å™¨ä¸å¯ç”¨")


async def get_model_manager():
    """ç²å–æ¨¡å‹ç®¡ç†å™¨ä¾è³´"""
    try:
        return ServiceLocator.get_model_manager()
    except Exception as e:
        logger.error(f"ç²å–æ¨¡å‹ç®¡ç†å™¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="æ¨¡å‹ç®¡ç†å™¨ä¸å¯ç”¨")


# ===== API ç«¯é» =====

@router.get("/status", response_model=SystemStatusResponse, summary="ç²å–ç³»çµ±ç‹€æ…‹")
async def get_system_status():
    """
    ç²å– RL ç³»çµ±çš„æ•´é«”ç‹€æ…‹å’Œå¥åº·è³‡è¨Š
    
    è¿”å›ç³»çµ±é‹è¡Œç‹€æ…‹ã€å¯ç”¨ç®—æ³•ã€æ´»èºä»»å‹™ç­‰è³‡è¨Š
    """
    try:
        # ç²å–ç®—æ³•è³‡è¨Š
        available_algorithms = AlgorithmFactory.get_available_algorithms()
        registry_stats = AlgorithmFactory.get_registry_stats()
        
        # ç²å–æœå‹™å¥åº·ç‹€æ…‹
        health_status = ServiceLocator.get_health_status()
        
        # ç²å–è¨“ç·´ä»»å‹™ç‹€æ…‹
        try:
            scheduler = await get_training_scheduler()
            scheduler_status = await scheduler.get_scheduler_status()
            active_jobs = scheduler_status.active_jobs
        except:
            active_jobs = 0
        
        # ç²å–æ¨¡å‹çµ±è¨ˆ
        try:
            model_manager = await get_model_manager()
            models = await model_manager.list_models()
            total_models = len(models)
        except:
            total_models = 0
        
        return SystemStatusResponse(
            status="healthy" if health_status["status"] == "healthy" else "degraded",
            version="2.0.0",
            uptime_seconds=0.0,  # è¨ˆç®—å¯¦éš›é‹è¡Œæ™‚é–“
            available_algorithms=available_algorithms,
            active_training_jobs=active_jobs,
            total_models=total_models,
            system_health=health_status
        )
        
    except Exception as e:
        logger.error(f"ç²å–ç³»çµ±ç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–ç³»çµ±ç‹€æ…‹å¤±æ•—: {str(e)}")


@router.get("/algorithms", response_model=List[str], summary="ç²å–å¯ç”¨ç®—æ³•åˆ—è¡¨")
async def get_available_algorithms():
    """
    ç²å–æ‰€æœ‰å·²è¨»å†Šçš„ RL ç®—æ³•åˆ—è¡¨
    """
    try:
        algorithms = AlgorithmFactory.get_available_algorithms()
        return algorithms
    except Exception as e:
        logger.error(f"ç²å–ç®—æ³•åˆ—è¡¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–ç®—æ³•åˆ—è¡¨å¤±æ•—: {str(e)}")


@router.get("/algorithms/{algorithm_name}", response_model=AlgorithmInfoResponse, summary="ç²å–ç®—æ³•è©³ç´°è³‡è¨Š")
async def get_algorithm_info(algorithm_name: str = Path(description="ç®—æ³•åç¨±")):
    """
    ç²å–æŒ‡å®šç®—æ³•çš„è©³ç´°è³‡è¨Šï¼ŒåŒ…æ‹¬ç‰ˆæœ¬ã€æ”¯æ´å ´æ™¯ã€è¶…åƒæ•¸ç­‰
    """
    try:
        algorithm_info = AlgorithmFactory.get_algorithm_info(algorithm_name)
        if not algorithm_info:
            raise HTTPException(status_code=404, detail=f"ç®—æ³• {algorithm_name} ä¸å­˜åœ¨")
        
        # å˜—è©¦å‰µå»ºç®—æ³•å¯¦ä¾‹ä»¥ç²å–é‹è¡Œæ™‚è³‡è¨Š
        try:
            algorithm = AlgorithmFactory.create_algorithm(algorithm_name, scenario_type=ScenarioType.URBAN)
            hyperparameters = algorithm.get_hyperparameters()
            training_metrics = algorithm.get_training_metrics()
        except:
            hyperparameters = algorithm_info.default_config
            training_metrics = {}
        
        return AlgorithmInfoResponse(
            name=algorithm_info.name,
            version=algorithm_info.version,
            supported_scenarios=[s.value for s in algorithm_info.supported_scenarios],
            description=algorithm_info.description,
            author=algorithm_info.author,
            hyperparameters=hyperparameters,
            training_metrics=training_metrics
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç²å–ç®—æ³•è³‡è¨Šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–ç®—æ³•è³‡è¨Šå¤±æ•—: {str(e)}")


@router.get("/algorithms/by-scenario/{scenario_type}", response_model=List[str], summary="æ ¹æ“šå ´æ™¯ç²å–ç®—æ³•")
async def get_algorithms_by_scenario(scenario_type: str = Path(description="å ´æ™¯é¡å‹")):
    """
    ç²å–æ”¯æ´æŒ‡å®šå ´æ™¯çš„ç®—æ³•åˆ—è¡¨
    """
    try:
        scenario = ScenarioType(scenario_type)
        algorithms = AlgorithmFactory.get_algorithms_by_scenario(scenario)
        return algorithms
    except ValueError:
        raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆçš„å ´æ™¯é¡å‹: {scenario_type}")
    except Exception as e:
        logger.error(f"æ ¹æ“šå ´æ™¯ç²å–ç®—æ³•å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–ç®—æ³•å¤±æ•—: {str(e)}")


@router.post("/training/start", response_model=Dict[str, Any], summary="é–‹å§‹è¨“ç·´")
async def start_training(
    request: TrainingRequest,
    background_tasks: BackgroundTasks,
    scheduler = Depends(get_training_scheduler)
):
    """
    å•Ÿå‹• RL ç®—æ³•è¨“ç·´ä»»å‹™
    
    æ”¯æ´å¾Œå°åŸ·è¡Œï¼Œè¿”å›ä»»å‹™IDç”¨æ–¼è¿½è¹¤é€²åº¦
    """
    try:
        # é©—è­‰ç®—æ³•æ˜¯å¦å­˜åœ¨
        if request.algorithm_name not in AlgorithmFactory.get_available_algorithms():
            raise HTTPException(status_code=400, detail=f"ç®—æ³• {request.algorithm_name} ä¸å­˜åœ¨")
        
        # é©—è­‰å ´æ™¯é¡å‹
        try:
            scenario_type = ScenarioType(request.scenario_type)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆçš„å ´æ™¯é¡å‹: {request.scenario_type}")
        
        # å‰µå»ºè¨“ç·´é…ç½®
        training_config = TrainingConfig(
            episodes=request.episodes,
            batch_size=request.custom_config.get('batch_size', 32) if request.custom_config else 32,
            learning_rate=request.custom_config.get('learning_rate', 0.001) if request.custom_config else 0.001,
            max_steps_per_episode=request.max_steps_per_episode,
            scenario_type=scenario_type,
            custom_params=request.custom_config or {}
        )
        
        # å‰µå»ºè¨“ç·´ä»»å‹™
        training_job = TrainingJob(
            job_id=f"train_{request.algorithm_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            algorithm_name=request.algorithm_name,
            config=training_config,
            priority=TrainingPriority(request.priority.upper()),
            estimated_duration_minutes=request.episodes // 10,  # ç²—ç•¥ä¼°ç®—
        )
        
        # æäº¤ä»»å‹™åˆ°èª¿åº¦å™¨
        job_id = await scheduler.submit_training_job(training_job)
        
        logger.info(f"è¨“ç·´ä»»å‹™å·²æäº¤: {job_id}")
        
        return {
            "job_id": job_id,
            "algorithm_name": request.algorithm_name,
            "scenario_type": request.scenario_type,
            "status": "queued",
            "message": "è¨“ç·´ä»»å‹™å·²æäº¤åˆ°éšŠåˆ—",
            "config": {
                "episodes": request.episodes,
                "max_steps_per_episode": request.max_steps_per_episode,
                "scenario_type": request.scenario_type
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é–‹å§‹è¨“ç·´å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"é–‹å§‹è¨“ç·´å¤±æ•—: {str(e)}")


@router.get("/training/jobs", response_model=List[TrainingJobResponse], summary="ç²å–è¨“ç·´ä»»å‹™åˆ—è¡¨")
async def get_training_jobs(
    status: Optional[str] = Query(None, description="ä»»å‹™ç‹€æ…‹éæ¿¾"),
    algorithm: Optional[str] = Query(None, description="ç®—æ³•åç¨±éæ¿¾"),
    limit: int = Query(10, ge=1, le=100, description="è¿”å›æ•¸é‡é™åˆ¶"),
    scheduler = Depends(get_training_scheduler)
):
    """
    ç²å–è¨“ç·´ä»»å‹™åˆ—è¡¨ï¼Œæ”¯æ´ç‹€æ…‹å’Œç®—æ³•éæ¿¾
    """
    try:
        # ç²å–è¨“ç·´éšŠåˆ—
        training_queue = await scheduler.get_training_queue()
        
        # æ‡‰ç”¨éæ¿¾å™¨
        filtered_jobs = training_queue
        if status:
            filtered_jobs = [job for job in filtered_jobs if job.status == status]
        if algorithm:
            filtered_jobs = [job for job in filtered_jobs if job.algorithm_name == algorithm]
        
        # é™åˆ¶æ•¸é‡
        filtered_jobs = filtered_jobs[:limit]
        
        # è½‰æ›ç‚ºéŸ¿æ‡‰æ ¼å¼
        job_responses = []
        for job in filtered_jobs:
            # ç²å–ä»»å‹™è©³ç´°ç‹€æ…‹
            job_status = await scheduler.get_job_status(job.job_id)
            
            job_responses.append(TrainingJobResponse(
                job_id=job.job_id,
                algorithm_name=job.algorithm_name,
                status=job_status.get("status", "unknown"),
                progress_percent=job_status.get("progress", 0.0),
                episodes_completed=job_status.get("episodes_completed", 0),
                total_episodes=job.config.episodes,
                current_score=job_status.get("current_score", 0.0),
                estimated_completion=job_status.get("estimated_completion"),
                created_at=job.created_at.isoformat() if job.created_at else ""
            ))
        
        return job_responses
        
    except Exception as e:
        logger.error(f"ç²å–è¨“ç·´ä»»å‹™åˆ—è¡¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–ä»»å‹™åˆ—è¡¨å¤±æ•—: {str(e)}")


@router.get("/training/jobs/{job_id}", response_model=TrainingJobResponse, summary="ç²å–è¨“ç·´ä»»å‹™è©³æƒ…")
async def get_training_job(
    job_id: str = Path(description="ä»»å‹™ID"),
    scheduler = Depends(get_training_scheduler)
):
    """
    ç²å–æŒ‡å®šè¨“ç·´ä»»å‹™çš„è©³ç´°ç‹€æ…‹å’Œé€²åº¦
    """
    try:
        job_status = await scheduler.get_job_status(job_id)
        if not job_status:
            raise HTTPException(status_code=404, detail=f"ä»»å‹™ {job_id} ä¸å­˜åœ¨")
        
        return TrainingJobResponse(
            job_id=job_id,
            algorithm_name=job_status.get("algorithm_name", "unknown"),
            status=job_status.get("status", "unknown"),
            progress_percent=job_status.get("progress", 0.0),
            episodes_completed=job_status.get("episodes_completed", 0),
            total_episodes=job_status.get("total_episodes", 0),
            current_score=job_status.get("current_score", 0.0),
            estimated_completion=job_status.get("estimated_completion"),
            created_at=job_status.get("created_at", "")
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç²å–è¨“ç·´ä»»å‹™è©³æƒ…å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–ä»»å‹™è©³æƒ…å¤±æ•—: {str(e)}")


@router.delete("/training/jobs/{job_id}", summary="å–æ¶ˆè¨“ç·´ä»»å‹™")
async def cancel_training_job(
    job_id: str = Path(description="ä»»å‹™ID"),
    scheduler = Depends(get_training_scheduler)
):
    """
    å–æ¶ˆæŒ‡å®šçš„è¨“ç·´ä»»å‹™
    """
    try:
        success = await scheduler.cancel_training_job(job_id)
        if not success:
            raise HTTPException(status_code=404, detail=f"ä»»å‹™ {job_id} ä¸å­˜åœ¨æˆ–ç„¡æ³•å–æ¶ˆ")
        
        return {"message": f"ä»»å‹™ {job_id} å·²å–æ¶ˆ"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å–æ¶ˆè¨“ç·´ä»»å‹™å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"å–æ¶ˆä»»å‹™å¤±æ•—: {str(e)}")


@router.post("/prediction", response_model=Dict[str, Any], summary="åŸ·è¡Œæ›æ‰‹æ±ºç­–é æ¸¬")
async def predict_handover(request: PredictionRequest):
    """
    åŸ·è¡Œ LEO è¡›æ˜Ÿæ›æ‰‹æ±ºç­–é æ¸¬
    
    æ ¹æ“šç•¶å‰ç¶²è·¯ç‹€æ³å’Œè¡›æ˜Ÿä½ç½®ï¼Œé æ¸¬æœ€ä½³çš„æ›æ‰‹ç›®æ¨™è¡›æ˜Ÿ
    """
    try:
        # é©—è­‰ç®—æ³•
        if request.algorithm_name not in AlgorithmFactory.get_available_algorithms():
            raise HTTPException(status_code=400, detail=f"ç®—æ³• {request.algorithm_name} ä¸å­˜åœ¨")
        
        # é©—è­‰å ´æ™¯é¡å‹
        try:
            scenario_type = ScenarioType(request.scenario_type)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆçš„å ´æ™¯é¡å‹: {request.scenario_type}")
        
        # å‰µå»ºç®—æ³•å¯¦ä¾‹
        algorithm = AlgorithmFactory.create_algorithm(
            request.algorithm_name,
            scenario_type=scenario_type
        )
        
        # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²è¨“ç·´
        if not algorithm.is_trained():
            logger.warning(f"ç®—æ³• {request.algorithm_name} å°šæœªè¨“ç·´ï¼Œä½¿ç”¨é è¨­æ¨¡å‹")
        
        # å‰µå»ºé æ¸¬ä¸Šä¸‹æ–‡
        context = PredictionContext(
            satellite_positions=request.satellite_positions,
            ue_position=request.ue_position,
            network_conditions=request.network_conditions,
            current_serving_satellite=request.current_serving_satellite,
            candidate_satellites=request.candidate_satellites,
            timestamp=datetime.now()
        )
        
        # åŸ·è¡Œé æ¸¬
        decision = await algorithm.predict(context)
        
        # è¨˜éŒ„é æ¸¬çµæœï¼ˆç”¨æ–¼ç›£æ§å’Œåˆ†æï¼‰
        try:
            performance_monitor = await get_performance_monitor()
            # å¯ä»¥åœ¨é€™è£¡è¨˜éŒ„é æ¸¬æŒ‡æ¨™
        except:
            pass
        
        return {
            "algorithm_name": request.algorithm_name,
            "scenario_type": request.scenario_type,
            "prediction": {
                "target_satellite_id": decision.target_satellite_id,
                "confidence_score": decision.confidence_score,
                "estimated_latency_ms": decision.estimated_latency_ms,
                "predicted_throughput_mbps": decision.predicted_throughput_mbps,
                "execution_priority": decision.execution_priority,
                "reasoning": decision.decision_reasoning
            },
            "context": {
                "current_serving_satellite": request.current_serving_satellite,
                "candidate_satellites": request.candidate_satellites,
                "ue_position": request.ue_position
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é æ¸¬å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"é æ¸¬å¤±æ•—: {str(e)}")


@router.get("/performance/{algorithm_name}", response_model=PerformanceMetricsResponse, summary="ç²å–ç®—æ³•æ€§èƒ½æŒ‡æ¨™")
async def get_algorithm_performance(
    algorithm_name: str = Path(description="ç®—æ³•åç¨±"),
    scenario_type: Optional[str] = Query(None, description="å ´æ™¯é¡å‹"),
    time_range_hours: int = Query(24, ge=1, le=168, description="æ™‚é–“ç¯„åœï¼ˆå°æ™‚ï¼‰"),
    performance_monitor = Depends(get_performance_monitor)
):
    """
    ç²å–æŒ‡å®šç®—æ³•çš„æ€§èƒ½æŒ‡æ¨™å’Œçµ±è¨ˆè³‡è¨Š
    """
    try:
        # é©—è­‰ç®—æ³•
        if algorithm_name not in AlgorithmFactory.get_available_algorithms():
            raise HTTPException(status_code=400, detail=f"ç®—æ³• {algorithm_name} ä¸å­˜åœ¨")
        
        # è¨­ç½®æ™‚é–“ç¯„åœ
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=time_range_hours)
        
        # è½‰æ›å ´æ™¯é¡å‹
        scenario = None
        if scenario_type:
            try:
                scenario = ScenarioType(scenario_type)
            except ValueError:
                raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆçš„å ´æ™¯é¡å‹: {scenario_type}")
        
        # ç²å–æ€§èƒ½æ‘˜è¦
        metric_types = [MetricType.REWARD, MetricType.LATENCY, MetricType.THROUGHPUT, MetricType.SUCCESS_RATE]
        performance_summary = await performance_monitor.get_performance_summary(
            algorithm_name=algorithm_name,
            metric_types=metric_types,
            scenario_type=scenario,
            time_range=(start_time, end_time)
        )
        
        # è½‰æ›ç‚ºéŸ¿æ‡‰æ ¼å¼
        metrics = {}
        statistical_summary = {}
        
        for metric_type, summary in performance_summary.items():
            metrics[metric_type.value] = {
                "count": summary.count,
                "mean": summary.mean,
                "current_value": summary.mean  # ç°¡åŒ–è™•ç†
            }
            statistical_summary[metric_type.value] = {
                "std": summary.std,
                "min": summary.min_value,
                "max": summary.max_value,
                "median": summary.percentile_50,
                "p95": summary.percentile_95
            }
        
        return PerformanceMetricsResponse(
            algorithm_name=algorithm_name,
            scenario_type=scenario_type or "all",
            metrics=metrics,
            time_range={
                "start": start_time.isoformat(),
                "end": end_time.isoformat(),
                "hours": time_range_hours
            },
            statistical_summary=statistical_summary
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç²å–æ€§èƒ½æŒ‡æ¨™å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æ€§èƒ½æŒ‡æ¨™å¤±æ•—: {str(e)}")


@router.get("/performance/compare", summary="æ¯”è¼ƒç®—æ³•æ€§èƒ½")
async def compare_algorithms(
    algorithms: str = Query(description="ç®—æ³•åç¨±åˆ—è¡¨ï¼Œé€—è™Ÿåˆ†éš”"),
    scenario_type: Optional[str] = Query(None, description="å ´æ™¯é¡å‹"),
    metric_types: str = Query("reward,latency,success_rate", description="æ¯”è¼ƒæŒ‡æ¨™ï¼Œé€—è™Ÿåˆ†éš”"),
    performance_monitor = Depends(get_performance_monitor)
):
    """
    æ¯”è¼ƒå¤šå€‹ç®—æ³•çš„æ€§èƒ½æŒ‡æ¨™
    """
    try:
        # è§£æåƒæ•¸
        algorithm_names = [name.strip() for name in algorithms.split(",")]
        metric_type_list = []
        
        for metric_name in metric_types.split(","):
            try:
                metric_type_list.append(MetricType(metric_name.strip()))
            except ValueError:
                raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆçš„æŒ‡æ¨™é¡å‹: {metric_name}")
        
        # é©—è­‰ç®—æ³•
        available_algorithms = AlgorithmFactory.get_available_algorithms()
        for algorithm_name in algorithm_names:
            if algorithm_name not in available_algorithms:
                raise HTTPException(status_code=400, detail=f"ç®—æ³• {algorithm_name} ä¸å­˜åœ¨")
        
        # è½‰æ›å ´æ™¯é¡å‹
        scenario = None
        if scenario_type:
            try:
                scenario = ScenarioType(scenario_type)
            except ValueError:
                raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆçš„å ´æ™¯é¡å‹: {scenario_type}")
        
        # æ¯”è¼ƒç®—æ³•
        comparison_results = await performance_monitor.compare_algorithms(
            algorithm_names=algorithm_names,
            metric_types=metric_type_list,
            scenario_type=scenario
        )
        
        return {
            "algorithms": algorithm_names,
            "scenario_type": scenario_type or "all",
            "metrics": [mt.value for mt in metric_type_list],
            "comparison_results": comparison_results,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç®—æ³•æ¯”è¼ƒå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç®—æ³•æ¯”è¼ƒå¤±æ•—: {str(e)}")


@router.get("/models", summary="ç²å–æ¨¡å‹åˆ—è¡¨")
async def get_models(
    algorithm_type: Optional[str] = Query(None, description="ç®—æ³•é¡å‹éæ¿¾"),
    limit: int = Query(10, ge=1, le=100, description="è¿”å›æ•¸é‡é™åˆ¶"),
    model_manager = Depends(get_model_manager)
):
    """
    ç²å–å·²è¨»å†Šçš„æ¨¡å‹åˆ—è¡¨
    """
    try:
        models = await model_manager.list_models(
            algorithm_name=algorithm_type,
            limit=limit
        )
        
        return {
            "models": [
                {
                    "model_id": model.model_id,
                    "algorithm_name": model.algorithm_name,
                    "version": model.version,
                    "validation_score": model.validation_metrics.get("score", 0.0),
                    "created_at": model.created_at.isoformat(),
                    "tags": model.tags
                }
                for model in models
            ],
            "total": len(models),
            "algorithm_filter": algorithm_type
        }
        
    except Exception as e:
        logger.error(f"ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—: {str(e)}")


@router.get("/health", summary="å¥åº·æª¢æŸ¥")
async def health_check():
    """
    ç³»çµ±å¥åº·æª¢æŸ¥ç«¯é»
    """
    try:
        health_status = ServiceLocator.get_health_status()
        
        return {
            "status": health_status["status"],
            "timestamp": datetime.now().isoformat(),
            "version": "2.0.0",
            "components": health_status.get("core_services", {}),
            "uptime": health_status.get("container", {}).get("initialization_time")
        }
        
    except Exception as e:
        logger.error(f"å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
        return JSONResponse(
            status_code=503,
            content={
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
        )