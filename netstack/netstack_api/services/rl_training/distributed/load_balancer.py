"""
è² è¼‰å‡è¡¡å™¨ - Phase 4 æ ¸å¿ƒçµ„ä»¶

å¯¦ç¾åˆ†ä½ˆå¼è¨“ç·´ç’°å¢ƒä¸­çš„æ™ºèƒ½è² è¼‰å‡è¡¡ï¼š
- å‹•æ…‹è² è¼‰ç›£æ§
- æ™ºèƒ½ä»»å‹™åˆ†é…
- è³‡æºä½¿ç”¨å„ªåŒ–
- æ€§èƒ½é æ¸¬å’Œèª¿åº¦

Features:
- åŸºæ–¼è² è¼‰å’Œæ€§èƒ½çš„æ™ºèƒ½èª¿åº¦
- æ”¯æ´å¤šç¨®è² è¼‰å‡è¡¡ç®—æ³•
- å¯¦æ™‚æ€§èƒ½ç›£æ§å’Œèª¿æ•´
- é æ¸¬å¼è³‡æºåˆ†é…
"""

import asyncio
import logging
import time
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import numpy as np
from collections import defaultdict, deque

from .node_coordinator import NodeInfo, NodeStatus, NodeType, TrainingTask

logger = logging.getLogger(__name__)


class LoadBalancingStrategy(Enum):
    """è² è¼‰å‡è¡¡ç­–ç•¥"""
    ROUND_ROBIN = "round_robin"        # è¼ªè©¢
    LEAST_LOADED = "least_loaded"      # æœ€å°‘è² è¼‰
    WEIGHTED_ROUND_ROBIN = "weighted_round_robin"  # åŠ æ¬Šè¼ªè©¢
    PREDICTIVE = "predictive"          # é æ¸¬å¼
    ADAPTIVE = "adaptive"              # è‡ªé©æ‡‰


@dataclass
class LoadMetrics:
    """è² è¼‰æŒ‡æ¨™"""
    cpu_usage: float = 0.0
    memory_usage: float = 0.0
    gpu_usage: float = 0.0
    network_io: float = 0.0
    disk_io: float = 0.0
    active_tasks: int = 0
    queue_length: int = 0
    response_time: float = 0.0
    throughput: float = 0.0
    
    def get_composite_load(self) -> float:
        """è¨ˆç®—è¤‡åˆè² è¼‰åˆ†æ•¸"""
        weights = {
            'cpu': 0.3,
            'memory': 0.2,
            'gpu': 0.3,
            'network': 0.1,
            'disk': 0.1
        }
        
        return (
            weights['cpu'] * self.cpu_usage +
            weights['memory'] * self.memory_usage +
            weights['gpu'] * self.gpu_usage +
            weights['network'] * self.network_io +
            weights['disk'] * self.disk_io
        )


@dataclass
class NodePerformanceHistory:
    """ç¯€é»æ€§èƒ½æ­·å²"""
    node_id: str
    load_history: deque = field(default_factory=lambda: deque(maxlen=100))
    response_times: deque = field(default_factory=lambda: deque(maxlen=50))
    throughput_history: deque = field(default_factory=lambda: deque(maxlen=50))
    task_completion_times: deque = field(default_factory=lambda: deque(maxlen=30))
    last_updated: datetime = field(default_factory=datetime.now)
    
    def add_load_sample(self, load: float):
        """æ·»åŠ è² è¼‰æ¨£æœ¬"""
        self.load_history.append((datetime.now(), load))
        self.last_updated = datetime.now()
    
    def add_response_time(self, response_time: float):
        """æ·»åŠ éŸ¿æ‡‰æ™‚é–“æ¨£æœ¬"""
        self.response_times.append(response_time)
        self.last_updated = datetime.now()
    
    def add_throughput(self, throughput: float):
        """æ·»åŠ ååé‡æ¨£æœ¬"""
        self.throughput_history.append(throughput)
        self.last_updated = datetime.now()
    
    def add_task_completion_time(self, completion_time: float):
        """æ·»åŠ ä»»å‹™å®Œæˆæ™‚é–“æ¨£æœ¬"""
        self.task_completion_times.append(completion_time)
        self.last_updated = datetime.now()
    
    def get_average_load(self, window_minutes: int = 5) -> float:
        """ç²å–å¹³å‡è² è¼‰"""
        if not self.load_history:
            return 0.0
        
        cutoff_time = datetime.now() - timedelta(minutes=window_minutes)
        recent_loads = [load for timestamp, load in self.load_history 
                       if timestamp >= cutoff_time]
        
        return np.mean(recent_loads) if recent_loads else 0.0
    
    def get_average_response_time(self) -> float:
        """ç²å–å¹³å‡éŸ¿æ‡‰æ™‚é–“"""
        return np.mean(self.response_times) if self.response_times else 0.0
    
    def get_average_throughput(self) -> float:
        """ç²å–å¹³å‡ååé‡"""
        return np.mean(self.throughput_history) if self.throughput_history else 0.0
    
    def predict_completion_time(self, task_complexity: float = 1.0) -> float:
        """é æ¸¬ä»»å‹™å®Œæˆæ™‚é–“"""
        if not self.task_completion_times:
            return 300.0  # é»˜èª 5 åˆ†é˜
        
        avg_completion_time = np.mean(self.task_completion_times)
        std_completion_time = np.std(self.task_completion_times)
        
        # æ ¹æ“šä»»å‹™è¤‡é›œåº¦èª¿æ•´
        predicted_time = avg_completion_time * task_complexity
        
        # æ·»åŠ ä¸ç¢ºå®šæ€§
        uncertainty = std_completion_time * 0.5
        
        return predicted_time + uncertainty


class LoadBalancer:
    """
    è² è¼‰å‡è¡¡å™¨
    
    å¯¦ç¾åˆ†ä½ˆå¼è¨“ç·´ç’°å¢ƒä¸­çš„æ™ºèƒ½è² è¼‰å‡è¡¡ï¼Œ
    æ”¯æŒå¤šç¨®è² è¼‰å‡è¡¡ç­–ç•¥å’Œå‹•æ…‹èª¿æ•´ã€‚
    """
    
    def __init__(self,
                 strategy: LoadBalancingStrategy = LoadBalancingStrategy.ADAPTIVE,
                 monitoring_interval: int = 30,
                 prediction_window: int = 300):
        """
        åˆå§‹åŒ–è² è¼‰å‡è¡¡å™¨
        
        Args:
            strategy: è² è¼‰å‡è¡¡ç­–ç•¥
            monitoring_interval: ç›£æ§é–“éš”ï¼ˆç§’ï¼‰
            prediction_window: é æ¸¬æ™‚é–“çª—å£ï¼ˆç§’ï¼‰
        """
        self.strategy = strategy
        self.monitoring_interval = monitoring_interval
        self.prediction_window = prediction_window
        
        # æ€§èƒ½æ•¸æ“š
        self.node_metrics: Dict[str, LoadMetrics] = {}
        self.performance_history: Dict[str, NodePerformanceHistory] = {}
        
        # è² è¼‰å‡è¡¡ç‹€æ…‹
        self.round_robin_counter = 0
        self.last_assignments: Dict[str, datetime] = {}
        
        # é‹è¡Œç‹€æ…‹
        self.nodes: Dict[str, Any] = {}
        self.is_running = False
        self.start_time = datetime.now()
        self.last_selection_time = None
        
        # çµ±è¨ˆä¿¡æ¯
        self.stats = {
            LoadBalancingStrategy.ROUND_ROBIN: 0,
            LoadBalancingStrategy.LEAST_LOADED: 0,
            LoadBalancingStrategy.PREDICTIVE: 0,
            LoadBalancingStrategy.ADAPTIVE: 0
        }
        
        # è©³ç´°çµ±è¨ˆä¿¡æ¯
        self.assignment_stats = {
            "total_assignments": 0,
            "successful_assignments": 0,
            "failed_assignments": 0,
            "strategy_switches": 0,
            "average_response_time": 0.0,
            "last_optimization": datetime.now()
        }
        
        # é‹è¡Œç‹€æ…‹
        self.is_running = False
        self.monitoring_task = None
        
        self.logger = logger
        
    async def start(self):
        """å•Ÿå‹•è² è¼‰å‡è¡¡å™¨"""
        try:
            self.logger.info("ğŸš€ å•Ÿå‹•è² è¼‰å‡è¡¡å™¨...")
            
            # å•Ÿå‹•ç›£æ§ä»»å‹™
            self.monitoring_task = asyncio.create_task(self._monitoring_loop())
            
            self.is_running = True
            
            self.logger.info(f"âœ… è² è¼‰å‡è¡¡å™¨å•Ÿå‹•æˆåŠŸ (ç­–ç•¥: {self.strategy.value})")
            
        except Exception as e:
            self.logger.error(f"âŒ è² è¼‰å‡è¡¡å™¨å•Ÿå‹•å¤±æ•—: {e}")
            raise
    
    async def stop(self):
        """åœæ­¢è² è¼‰å‡è¡¡å™¨"""
        try:
            self.logger.info("ğŸ›‘ åœæ­¢è² è¼‰å‡è¡¡å™¨...")
            
            self.is_running = False
            
            # åœæ­¢ç›£æ§ä»»å‹™
            if self.monitoring_task:
                self.monitoring_task.cancel()
                try:
                    await self.monitoring_task
                except asyncio.CancelledError:
                    pass
            
            self.logger.info("âœ… è² è¼‰å‡è¡¡å™¨å·²åœæ­¢")
            
        except Exception as e:
            self.logger.error(f"âŒ åœæ­¢è² è¼‰å‡è¡¡å™¨å¤±æ•—: {e}")
    
    async def select_node(self, 
                         available_nodes: List[NodeInfo],
                         task: TrainingTask) -> Optional[NodeInfo]:
        """
        é¸æ“‡æœ€é©åˆçš„ç¯€é»
        
        Args:
            available_nodes: å¯ç”¨ç¯€é»åˆ—è¡¨
            task: è¨“ç·´ä»»å‹™
            
        Returns:
            é¸ä¸­çš„ç¯€é»ï¼Œå¦‚æœæ²’æœ‰å¯ç”¨ç¯€é»å‰‡è¿”å› None
        """
        if not available_nodes:
            return None
        
        try:
            # æ ¹æ“šç­–ç•¥é¸æ“‡ç¯€é»
            if self.strategy == LoadBalancingStrategy.ROUND_ROBIN:
                return await self._round_robin_selection(available_nodes)
            elif self.strategy == LoadBalancingStrategy.LEAST_LOADED:
                return await self._least_loaded_selection(available_nodes)
            elif self.strategy == LoadBalancingStrategy.WEIGHTED_ROUND_ROBIN:
                return await self._weighted_round_robin_selection(available_nodes)
            elif self.strategy == LoadBalancingStrategy.PREDICTIVE:
                return await self._predictive_selection(available_nodes, task)
            elif self.strategy == LoadBalancingStrategy.ADAPTIVE:
                return await self._adaptive_selection(available_nodes, task)
            else:
                # é»˜èªä½¿ç”¨æœ€å°‘è² è¼‰ç­–ç•¥
                return await self._least_loaded_selection(available_nodes)
                
        except Exception as e:
            self.logger.error(f"âŒ ç¯€é»é¸æ“‡å¤±æ•—: {e}")
            # å¤±æ•—æ™‚ä½¿ç”¨ç°¡å–®è¼ªè©¢
            return available_nodes[self.round_robin_counter % len(available_nodes)]
    
    async def _round_robin_selection(self, nodes: List[NodeInfo]) -> NodeInfo:
        """è¼ªè©¢é¸æ“‡"""
        selected_node = nodes[self.round_robin_counter % len(nodes)]
        self.round_robin_counter += 1
        
        self.logger.debug(f"ğŸ”„ è¼ªè©¢é¸æ“‡ç¯€é»: {selected_node.node_id}")
        
        return selected_node
    
    async def _least_loaded_selection(self, nodes: List[NodeInfo]) -> NodeInfo:
        """æœ€å°‘è² è¼‰é¸æ“‡"""
        # è¨ˆç®—æ¯å€‹ç¯€é»çš„è² è¼‰åˆ†æ•¸
        node_loads = []
        for node in nodes:
            metrics = self.node_metrics.get(node.node_id, LoadMetrics())
            load_score = metrics.get_composite_load()
            node_loads.append((node, load_score))
        
        # é¸æ“‡è² è¼‰æœ€ä½çš„ç¯€é»
        selected_node = min(node_loads, key=lambda x: x[1])[0]
        
        self.logger.debug(f"âš–ï¸ æœ€å°‘è² è¼‰é¸æ“‡ç¯€é»: {selected_node.node_id}")
        
        return selected_node
    
    async def _weighted_round_robin_selection(self, nodes: List[NodeInfo]) -> NodeInfo:
        """åŠ æ¬Šè¼ªè©¢é¸æ“‡"""
        # æ ¹æ“šç¯€é»èƒ½åŠ›è¨ˆç®—æ¬Šé‡
        weights = []
        for node in nodes:
            # åŸºç¤æ¬Šé‡
            weight = 1.0
            
            # æ ¹æ“š CPU æ ¸å¿ƒæ•¸èª¿æ•´
            cpu_cores = node.capabilities.get('cpu_cores', 1)
            weight *= cpu_cores
            
            # æ ¹æ“š GPU æ•¸é‡èª¿æ•´
            gpu_count = node.capabilities.get('gpu_count', 0)
            weight *= (1 + gpu_count * 0.5)
            
            # æ ¹æ“šå…§å­˜å¤§å°èª¿æ•´
            memory_gb = node.capabilities.get('memory_gb', 8)
            weight *= (memory_gb / 8)
            
            weights.append(weight)
        
        # åŠ æ¬Šéš¨æ©Ÿé¸æ“‡
        total_weight = sum(weights)
        if total_weight == 0:
            return nodes[0]
        
        probabilities = [w / total_weight for w in weights]
        selected_index = np.random.choice(len(nodes), p=probabilities)
        
        selected_node = nodes[selected_index]
        
        self.logger.debug(f"âš–ï¸ åŠ æ¬Šè¼ªè©¢é¸æ“‡ç¯€é»: {selected_node.node_id}")
        
        return selected_node
    
    async def _predictive_selection(self, nodes: List[NodeInfo], task: TrainingTask) -> NodeInfo:
        """é æ¸¬å¼é¸æ“‡"""
        # é æ¸¬æ¯å€‹ç¯€é»çš„æ€§èƒ½
        node_predictions = []
        
        for node in nodes:
            history = self.performance_history.get(node.node_id)
            if history:
                # æ ¹æ“šä»»å‹™ç®—æ³•ä¼°ç®—è¤‡é›œåº¦
                task_complexity = self._estimate_task_complexity(task)
                
                # é æ¸¬å®Œæˆæ™‚é–“
                predicted_time = history.predict_completion_time(task_complexity)
                
                # è€ƒæ…®ç•¶å‰è² è¼‰
                current_load = self.node_metrics.get(node.node_id, LoadMetrics()).get_composite_load()
                
                # ç¶œåˆè©•åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
                score = predicted_time * (1 + current_load)
                
                node_predictions.append((node, score))
            else:
                # æ²’æœ‰æ­·å²æ•¸æ“šï¼Œä½¿ç”¨é»˜èªåˆ†æ•¸
                node_predictions.append((node, 1000.0))
        
        # é¸æ“‡é æ¸¬æ€§èƒ½æœ€å¥½çš„ç¯€é»
        selected_node = min(node_predictions, key=lambda x: x[1])[0]
        
        self.logger.debug(f"ğŸ”® é æ¸¬å¼é¸æ“‡ç¯€é»: {selected_node.node_id}")
        
        return selected_node
    
    async def _adaptive_selection(self, nodes: List[NodeInfo], task: TrainingTask) -> NodeInfo:
        """è‡ªé©æ‡‰é¸æ“‡"""
        # æ ¹æ“šç•¶å‰ç³»çµ±ç‹€æ…‹é¸æ“‡æœ€é©åˆçš„ç­–ç•¥
        
        # åˆ†æç³»çµ±ç‹€æ…‹
        total_nodes = len(nodes)
        avg_load = np.mean([
            self.node_metrics.get(node.node_id, LoadMetrics()).get_composite_load()
            for node in nodes
        ])
        
        load_variance = np.var([
            self.node_metrics.get(node.node_id, LoadMetrics()).get_composite_load()
            for node in nodes
        ])
        
        # é¸æ“‡ç­–ç•¥
        if total_nodes <= 2:
            # ç¯€é»å°‘ï¼Œä½¿ç”¨è¼ªè©¢
            return await self._round_robin_selection(nodes)
        elif avg_load > 0.8:
            # ç³»çµ±è² è¼‰é«˜ï¼Œä½¿ç”¨æœ€å°‘è² è¼‰ç­–ç•¥
            return await self._least_loaded_selection(nodes)
        elif load_variance > 0.3:
            # è² è¼‰å·®ç•°å¤§ï¼Œä½¿ç”¨é æ¸¬å¼ç­–ç•¥
            return await self._predictive_selection(nodes, task)
        else:
            # ç³»çµ±ç©©å®šï¼Œä½¿ç”¨åŠ æ¬Šè¼ªè©¢
            return await self._weighted_round_robin_selection(nodes)
    
    def _estimate_task_complexity(self, task: TrainingTask) -> float:
        """ä¼°ç®—ä»»å‹™è¤‡é›œåº¦"""
        complexity = 1.0
        
        # æ ¹æ“šç®—æ³•é¡å‹èª¿æ•´
        algorithm_complexity = {
            'dqn': 1.0,
            'ppo': 1.2,
            'sac': 1.5,
            'a3c': 1.8
        }
        
        complexity *= algorithm_complexity.get(task.algorithm, 1.0)
        
        # æ ¹æ“šåƒæ•¸èª¿æ•´
        if task.parameters:
            episodes = task.parameters.get('episodes', 100)
            complexity *= (episodes / 100)
            
            batch_size = task.parameters.get('batch_size', 32)
            complexity *= (batch_size / 32)
        
        return complexity
    
    async def update_node_metrics(self, node_id: str, metrics: LoadMetrics):
        """æ›´æ–°ç¯€é»æŒ‡æ¨™"""
        self.node_metrics[node_id] = metrics
        
        # æ›´æ–°æ€§èƒ½æ­·å²
        if node_id not in self.performance_history:
            self.performance_history[node_id] = NodePerformanceHistory(node_id)
        
        history = self.performance_history[node_id]
        history.add_load_sample(metrics.get_composite_load())
        
        if metrics.response_time > 0:
            history.add_response_time(metrics.response_time)
        
        if metrics.throughput > 0:
            history.add_throughput(metrics.throughput)
    
    async def record_task_completion(self, node_id: str, completion_time: float):
        """è¨˜éŒ„ä»»å‹™å®Œæˆæ™‚é–“"""
        if node_id in self.performance_history:
            self.performance_history[node_id].add_task_completion_time(completion_time)
    
    async def _monitoring_loop(self):
        """ç›£æ§å¾ªç’°"""
        while self.is_running:
            try:
                # ç›£æ§ç¯€é»æ€§èƒ½
                await self._monitor_node_performance()
                
                # å„ªåŒ–è² è¼‰å‡è¡¡ç­–ç•¥
                await self._optimize_strategy()
                
                # æ¸…ç†éæœŸæ•¸æ“š
                await self._cleanup_old_data()
                
                await asyncio.sleep(self.monitoring_interval)
                
            except Exception as e:
                self.logger.error(f"âŒ ç›£æ§å¾ªç’°éŒ¯èª¤: {e}")
                await asyncio.sleep(5)
    
    async def _monitor_node_performance(self):
        """ç›£æ§ç¯€é»æ€§èƒ½"""
        try:
            # è¨ˆç®—å¹³å‡éŸ¿æ‡‰æ™‚é–“
            response_times = []
            for history in self.performance_history.values():
                if history.response_times:
                    response_times.extend(history.response_times)
            
            if response_times:
                self.assignment_stats["average_response_time"] = np.mean(response_times)
            
            # æª¢æ¸¬ç•°å¸¸ç¯€é»
            await self._detect_anomalous_nodes()
            
        except Exception as e:
            self.logger.error(f"âŒ ç¯€é»æ€§èƒ½ç›£æ§å¤±æ•—: {e}")
    
    async def _detect_anomalous_nodes(self):
        """æª¢æ¸¬ç•°å¸¸ç¯€é»"""
        try:
            for node_id, history in self.performance_history.items():
                if len(history.response_times) < 5:
                    continue
                
                # æª¢æ¸¬éŸ¿æ‡‰æ™‚é–“ç•°å¸¸
                recent_times = list(history.response_times)[-5:]
                avg_time = np.mean(recent_times)
                
                # å¦‚æœéŸ¿æ‡‰æ™‚é–“è¶…éå¹³å‡å€¼çš„ 2 å€ï¼Œæ¨™è¨˜ç‚ºç•°å¸¸
                if avg_time > self.assignment_stats["average_response_time"] * 2:
                    self.logger.warning(f"âš ï¸ æª¢æ¸¬åˆ°ç•°å¸¸ç¯€é»: {node_id} (éŸ¿æ‡‰æ™‚é–“: {avg_time:.2f}s)")
                    
        except Exception as e:
            self.logger.error(f"âŒ ç•°å¸¸ç¯€é»æª¢æ¸¬å¤±æ•—: {e}")
    
    async def _optimize_strategy(self):
        """å„ªåŒ–è² è¼‰å‡è¡¡ç­–ç•¥"""
        try:
            # å¦‚æœä½¿ç”¨è‡ªé©æ‡‰ç­–ç•¥ï¼Œä¸éœ€è¦å„ªåŒ–
            if self.strategy == LoadBalancingStrategy.ADAPTIVE:
                return
            
            # åˆ†æç•¶å‰ç­–ç•¥çš„æ•ˆæœ
            current_time = datetime.now()
            
            # è¨ˆç®—æœ€è¿‘çš„å¹³å‡æ€§èƒ½
            recent_performance = self._calculate_recent_performance()
            
            # å¦‚æœæ€§èƒ½ä¸‹é™ï¼Œè€ƒæ…®åˆ‡æ›ç­–ç•¥
            if recent_performance < 0.7:  # 70% é–¾å€¼
                await self._switch_strategy()
                
        except Exception as e:
            self.logger.error(f"âŒ ç­–ç•¥å„ªåŒ–å¤±æ•—: {e}")
    
    def _calculate_recent_performance(self) -> float:
        """è¨ˆç®—æœ€è¿‘çš„æ€§èƒ½åˆ†æ•¸"""
        try:
            # è¨ˆç®—æˆåŠŸç‡
            total_assignments = self.assignment_stats["total_assignments"]
            successful_assignments = self.assignment_stats["successful_assignments"]
            
            if total_assignments == 0:
                return 1.0
            
            success_rate = successful_assignments / total_assignments
            
            # è¨ˆç®—éŸ¿æ‡‰æ™‚é–“æ€§èƒ½
            avg_response_time = self.assignment_stats["average_response_time"]
            response_performance = max(0.0, 1.0 - (avg_response_time / 10.0))  # 10ç§’ä½œç‚ºåŸºæº–
            
            # ç¶œåˆæ€§èƒ½åˆ†æ•¸
            performance_score = (success_rate * 0.7 + response_performance * 0.3)
            
            return performance_score
            
        except Exception as e:
            self.logger.error(f"âŒ æ€§èƒ½è¨ˆç®—å¤±æ•—: {e}")
            return 1.0
    
    async def _switch_strategy(self):
        """åˆ‡æ›è² è¼‰å‡è¡¡ç­–ç•¥"""
        try:
            # ç­–ç•¥åˆ‡æ›é †åº
            strategy_order = [
                LoadBalancingStrategy.LEAST_LOADED,
                LoadBalancingStrategy.PREDICTIVE,
                LoadBalancingStrategy.WEIGHTED_ROUND_ROBIN,
                LoadBalancingStrategy.ROUND_ROBIN
            ]
            
            # æ‰¾åˆ°ç•¶å‰ç­–ç•¥çš„ç´¢å¼•
            current_index = strategy_order.index(self.strategy)
            
            # åˆ‡æ›åˆ°ä¸‹ä¸€å€‹ç­–ç•¥
            next_index = (current_index + 1) % len(strategy_order)
            new_strategy = strategy_order[next_index]
            
            self.logger.info(f"ğŸ”„ åˆ‡æ›è² è¼‰å‡è¡¡ç­–ç•¥: {self.strategy.value} -> {new_strategy.value}")
            
            self.strategy = new_strategy
            self.assignment_stats["strategy_switches"] += 1
            
        except Exception as e:
            self.logger.error(f"âŒ ç­–ç•¥åˆ‡æ›å¤±æ•—: {e}")
    
    async def _cleanup_old_data(self):
        """æ¸…ç†éæœŸæ•¸æ“š"""
        try:
            # æ¸…ç†è¶…é 1 å°æ™‚çš„åˆ†é…è¨˜éŒ„
            cutoff_time = datetime.now() - timedelta(hours=1)
            
            expired_assignments = [
                node_id for node_id, timestamp in self.last_assignments.items()
                if timestamp < cutoff_time
            ]
            
            for node_id in expired_assignments:
                del self.last_assignments[node_id]
                
        except Exception as e:
            self.logger.error(f"âŒ æ•¸æ“šæ¸…ç†å¤±æ•—: {e}")
    
    def get_load_balancer_stats(self) -> Dict[str, Any]:
        """ç²å–è² è¼‰å‡è¡¡å™¨çµ±è¨ˆä¿¡æ¯"""
        return {
            "strategy": self.strategy.value,
            "total_nodes": len(self.node_metrics),
            "assignment_stats": self.assignment_stats,
            "average_loads": {
                node_id: metrics.get_composite_load()
                for node_id, metrics in self.node_metrics.items()
            },
            "performance_summary": {
                node_id: {
                    "avg_load": history.get_average_load(),
                    "avg_response_time": history.get_average_response_time(),
                    "avg_throughput": history.get_average_throughput()
                }
                for node_id, history in self.performance_history.items()
            }
        }
    
    def get_node_metrics(self, node_id: str) -> Optional[LoadMetrics]:
        """ç²å–ç¯€é»æŒ‡æ¨™"""
        return self.node_metrics.get(node_id)
    
    def get_node_performance_history(self, node_id: str) -> Optional[NodePerformanceHistory]:
        """ç²å–ç¯€é»æ€§èƒ½æ­·å²"""
        return self.performance_history.get(node_id)
    
    async def set_strategy(self, strategy: LoadBalancingStrategy):
        """è¨­ç½®è² è¼‰å‡è¡¡ç­–ç•¥"""
        if strategy != self.strategy:
            self.logger.info(f"ğŸ”„ è¨­ç½®è² è¼‰å‡è¡¡ç­–ç•¥: {strategy.value}")
            self.strategy = strategy
            self.assignment_stats["strategy_switches"] += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–è² è¼‰å‡è¡¡çµ±è¨ˆä¿¡æ¯"""
        try:
            total_requests = sum(self.stats.values())
            uptime = (datetime.now() - self.start_time).total_seconds() if hasattr(self, 'start_time') else 0
            
            return {
                "total_requests": total_requests,
                "requests_per_strategy": dict(self.stats),
                "current_strategy": self.strategy.value,
                "managed_nodes": len(self.nodes),
                "uptime_seconds": uptime,
                "last_selection_time": self.last_selection_time.isoformat() if hasattr(self, 'last_selection_time') else None,
                "performance_history_size": sum(len(history.response_times) for history in self.performance_history.values()),
                "is_running": self.is_running
            }
        except Exception as e:
            return {
                "error": str(e),
                "total_requests": 0,
                "is_running": self.is_running
            }
