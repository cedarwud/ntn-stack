#!/usr/bin/env python3
"""
æ­·å²æ•¸æ“šé è¼‰å™¨ - å¯¦ç¾ docs/architecture.md ä¸­çš„æ­£ç¢ºæ¶æ§‹
å„ªå…ˆç´š: PostgreSQL é è¼‰æ•¸æ“š > Docker æ­·å²æ•¸æ“š > å¤–éƒ¨ä¸‹è¼‰ > Redis æ¨¡æ“¬æ•¸æ“š

æ ¸å¿ƒåŠŸèƒ½:
1. è¼‰å…¥ Docker æ˜ åƒå…§å»ºçš„æ­·å² TLE æ•¸æ“šåˆ° PostgreSQL
2. é ç®— 45 å¤©çš„è»Œé“æ•¸æ“š (~518,400 æ¢è¨˜éŒ„)
3. å»ºç«‹æ™‚é–“åºåˆ—ç·©å­˜ï¼Œå¯¦ç¾å¿«é€ŸæŸ¥è©¢
"""

import asyncio
import asyncpg
import structlog
import sys
import os
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any, Optional

logger = structlog.get_logger(__name__)

# å°å…¥ NetStack çš„æ­·å²æ•¸æ“š
try:
    from ..data.historical_tle_data import (
        get_historical_tle_data, 
        get_data_source_info,
        ALL_HISTORICAL_TLE_DATA
    )
    HISTORICAL_DATA_AVAILABLE = True
    logger.info("âœ… æˆåŠŸå°å…¥ NetStack æ­·å²æ•¸æ“šæ¨¡çµ„")
except ImportError as e:
    HISTORICAL_DATA_AVAILABLE = False
    logger.error(f"âš ï¸ ç„¡æ³•å°å…¥ NetStack æ­·å²æ•¸æ“šæ¨¡çµ„: {e}")

from .orbit_calculation_engine import OrbitCalculationEngine, TLEData, TimeRange

class HistoricalDataPreloader:
    """æ­·å²æ•¸æ“šé è¼‰å™¨ - å¯¦ç¾æ­£ç¢ºçš„æ¶æ§‹è¨­è¨ˆ"""
    
    def __init__(self, db_url: str):
        self.db_url = db_url
        self.orbit_engine = OrbitCalculationEngine()
        self.db_pool: Optional[asyncpg.Pool] = None
        
    async def initialize(self):
        """åˆå§‹åŒ–æ•¸æ“šåº«é€£æ¥æ± """
        try:
            self.db_pool = await asyncpg.create_pool(
                self.db_url, min_size=2, max_size=10, command_timeout=60
            )
            logger.info("ğŸ›°ï¸ æ­·å²æ•¸æ“šé è¼‰å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ æ­·å²æ•¸æ“šé è¼‰å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def preload_all_historical_data(self) -> Dict[str, Any]:
        """
        å®Œæ•´çš„æ­·å²æ•¸æ“šé è¼‰æµç¨‹
        æŒ‰ç…§ docs/architecture.md è¨­è¨ˆå¯¦ç¾
        """
        logger.info("ğŸš€ é–‹å§‹å®Œæ•´æ­·å²æ•¸æ“šé è¼‰æµç¨‹...")
        
        start_time = datetime.now(timezone.utc)
        stats = {
            "start_time": start_time,
            "tle_records_loaded": 0,
            "orbital_records_precomputed": 0,
            "preload_jobs_created": 0,
            "errors": []
        }
        
        try:
            # Step 1: è¼‰å…¥æ­·å² TLE æ•¸æ“šåˆ° PostgreSQL
            tle_stats = await self._load_historical_tle_data()
            stats["tle_records_loaded"] = tle_stats["records_loaded"]
            stats["errors"].extend(tle_stats.get("errors", []))
            
            if stats["tle_records_loaded"] == 0:
                stats["errors"].append("æ²’æœ‰æˆåŠŸè¼‰å…¥ä»»ä½• TLE æ•¸æ“š")
                return stats
            
            # Step 2: é è¨ˆç®— 45 å¤©è»Œé“æ•¸æ“š
            orbital_stats = await self._precompute_orbital_data()
            stats["orbital_records_precomputed"] = orbital_stats["records_computed"]
            stats["errors"].extend(orbital_stats.get("errors", []))
            
            # Step 3: è¨˜éŒ„é è¼‰ä½œæ¥­
            job_stats = await self._create_preload_job_record(stats)
            stats["preload_jobs_created"] = job_stats["jobs_created"]
            
            end_time = datetime.now(timezone.utc)
            stats["end_time"] = end_time
            stats["duration_seconds"] = (end_time - start_time).total_seconds()
            
            logger.info(
                f"âœ… æ­·å²æ•¸æ“šé è¼‰å®Œæˆ: "
                f"TLE {stats['tle_records_loaded']} æ¢, "
                f"è»Œé“ {stats['orbital_records_precomputed']} æ¢, "
                f"è€—æ™‚ {stats['duration_seconds']:.1f} ç§’"
            )
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ æ­·å²æ•¸æ“šé è¼‰å¤±æ•—: {e}")
            stats["errors"].append(str(e))
            return stats
    
    async def _load_historical_tle_data(self) -> Dict[str, Any]:
        """è¼‰å…¥æ­·å² TLE æ•¸æ“šåˆ° PostgreSQL"""
        logger.info("ğŸ“¡ è¼‰å…¥æ­·å² TLE æ•¸æ“šåˆ° PostgreSQL...")
        
        stats = {"records_loaded": 0, "errors": []}
        
        if not HISTORICAL_DATA_AVAILABLE:
            stats["errors"].append("æ­·å²æ•¸æ“šæ¨¡çµ„ä¸å¯ç”¨")
            return stats
        
        try:
            # æ¸…ç©ºç¾æœ‰ TLE æ•¸æ“šä»¥ç¢ºä¿ä¹¾æ·¨çš„é–‹å§‹
            async with self.db_pool.acquire() as conn:
                await conn.execute("TRUNCATE TABLE satellite_tle_data CASCADE")
                logger.info("ğŸ§¹ å·²æ¸…ç©ºç¾æœ‰ TLE æ•¸æ“šè¡¨")
            
            # è¼‰å…¥æ‰€æœ‰æ˜Ÿåº§çš„æ­·å²æ•¸æ“š
            for constellation, tle_list in ALL_HISTORICAL_TLE_DATA.items():
                constellation_count = 0
                
                async with self.db_pool.acquire() as conn:
                    async with conn.transaction():
                        for tle_entry in tle_list:
                            try:
                                # è§£æ epoch æ™‚é–“
                                line1 = tle_entry["line1"]
                                epoch_year = int(line1[18:20])
                                epoch_day = float(line1[20:32])
                                
                                # è½‰æ›ç‚ºå®Œæ•´å¹´ä»½
                                if epoch_year < 57:
                                    full_year = 2000 + epoch_year
                                else:
                                    full_year = 1900 + epoch_year
                                
                                # è¨ˆç®— epoch æ™‚é–“
                                epoch = datetime(full_year, 1, 1, tzinfo=timezone.utc) + timedelta(
                                    days=epoch_day - 1
                                )
                                
                                # è¨ˆç®—è»Œé“åƒæ•¸ - å¾ TLE line2 æå–å¹³å‡é‹å‹•
                                line2 = tle_entry["line2"]
                                try:
                                    # TLE line2 format: mean motion is in columns 52-63
                                    mean_motion = float(line2[52:63].strip())
                                except (ValueError, IndexError):
                                    # å›é€€å€¼
                                    mean_motion = 15.0
                                    
                                orbital_period = 1440.0 / mean_motion if mean_motion > 0 else 90.0
                                
                                # æ’å…¥æ•¸æ“š
                                await conn.execute(
                                    """
                                    INSERT INTO satellite_tle_data (
                                        satellite_id, norad_id, satellite_name, constellation,
                                        line1, line2, epoch, mean_motion, orbital_period,
                                        is_active, last_updated
                                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
                                    ON CONFLICT (norad_id) DO UPDATE SET
                                        satellite_name = EXCLUDED.satellite_name,
                                        line1 = EXCLUDED.line1,
                                        line2 = EXCLUDED.line2,
                                        epoch = EXCLUDED.epoch,
                                        last_updated = EXCLUDED.last_updated
                                    """,
                                    f"{constellation}_{tle_entry['norad_id']}",
                                    tle_entry["norad_id"],
                                    tle_entry["name"],
                                    constellation,
                                    tle_entry["line1"],
                                    tle_entry["line2"],
                                    epoch,
                                    mean_motion,
                                    orbital_period,
                                    True,
                                    datetime.now(timezone.utc)
                                )
                                
                                constellation_count += 1
                                stats["records_loaded"] += 1
                                
                            except Exception as e:
                                error_msg = f"è¼‰å…¥ {constellation} è¡›æ˜Ÿ {tle_entry.get('name', 'Unknown')} å¤±æ•—: {e}"
                                logger.warning(error_msg)
                                stats["errors"].append(error_msg)
                
                logger.info(f"âœ… {constellation}: è¼‰å…¥ {constellation_count} é¡†è¡›æ˜Ÿ")
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ æ­·å² TLE æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            stats["errors"].append(str(e))
            return stats
    
    async def _precompute_orbital_data(self) -> Dict[str, Any]:
        """é è¨ˆç®— 45 å¤©è»Œé“æ•¸æ“š - å¯¦ç¾ ~518,400 æ¢è¨˜éŒ„"""
        logger.info("ğŸŒ é–‹å§‹é è¨ˆç®— 45 å¤©è»Œé“æ•¸æ“š...")
        
        stats = {"records_computed": 0, "errors": []}
        
        try:
            # æ¸…ç©ºç¾æœ‰è»Œé“ç·©å­˜
            async with self.db_pool.acquire() as conn:
                await conn.execute("TRUNCATE TABLE satellite_orbital_cache")
                logger.info("ğŸ§¹ å·²æ¸…ç©ºç¾æœ‰è»Œé“ç·©å­˜")
            
            # ç²å–æ‰€æœ‰ TLE æ•¸æ“š
            async with self.db_pool.acquire() as conn:
                tle_records = await conn.fetch(
                    """
                    SELECT satellite_id, norad_id, satellite_name, constellation,
                           line1, line2, epoch
                    FROM satellite_tle_data 
                    WHERE is_active = TRUE
                    ORDER BY constellation, norad_id
                    """
                )
            
            if not tle_records:
                stats["errors"].append("æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„ TLE æ•¸æ“š")
                return stats
            
            logger.info(f"ğŸ“Š å°‡ç‚º {len(tle_records)} é¡†è¡›æ˜Ÿé è¨ˆç®—è»Œé“æ•¸æ“š")
            
            # è¨ˆç®—æ™‚é–“ç¯„åœ: 45 å¤©
            start_time = datetime.now(timezone.utc)
            end_time = start_time + timedelta(days=45)
            time_range = TimeRange(start=start_time, end=end_time)
            
            # æ™‚é–“è§£æåº¦: 30 ç§’ (ç¬¦åˆ docs/overview.md)
            sample_interval_minutes = 0.5  # 30ç§’ = 0.5åˆ†é˜
            
            for tle_record in tle_records:
                try:
                    # æº–å‚™ TLE æ•¸æ“š
                    tle_data = TLEData(
                        satellite_id=str(tle_record["norad_id"]),
                        satellite_name=tle_record["satellite_name"],
                        line1=tle_record["line1"],
                        line2=tle_record["line2"],
                        epoch=tle_record["epoch"]
                    )
                    
                    # æ·»åŠ åˆ°è»Œé“å¼•æ“
                    self.orbit_engine.add_tle_data(tle_data)
                    
                    # è¨ˆç®—è»Œé“è·¯å¾‘
                    orbit_path = self.orbit_engine.predict_orbit_path(
                        str(tle_record["norad_id"]), time_range, sample_interval_minutes
                    )
                    
                    if not orbit_path or not orbit_path.positions:
                        logger.warning(f"âš ï¸ è¡›æ˜Ÿ {tle_record['satellite_name']} è»Œé“è¨ˆç®—å¤±æ•—")
                        continue
                    
                    # å°ç£è§€æ¸¬è€…ä½ç½® (ç¬¦åˆ docs/overview.md)
                    observer_lat = 24.9564  # 24Â°56'39"N
                    observer_lon = 121.3717  # 121Â°22'17"E
                    observer_alt = 0.1  # 100m
                    
                    # æ‰¹é‡æ’å…¥è»Œé“æ•¸æ“š
                    records_for_this_satellite = 0
                    async with self.db_pool.acquire() as conn:
                        async with conn.transaction():
                            for position in orbit_path.positions:
                                # è¨ˆç®—è§€æ¸¬è€…è¦–è§’
                                elevation, azimuth, range_km = self._calculate_observer_view(
                                    observer_lat, observer_lon, observer_alt,
                                    position.latitude, position.longitude, position.altitude
                                )
                                
                                await conn.execute(
                                    """
                                    INSERT INTO satellite_orbital_cache (
                                        satellite_id, norad_id, constellation, timestamp,
                                        position_x, position_y, position_z,
                                        latitude, longitude, altitude,
                                        velocity_x, velocity_y, velocity_z,
                                        orbital_period, elevation_angle, azimuth_angle, range_rate,
                                        calculation_method, data_quality, created_at
                                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20)
                                    """,
                                    tle_record["satellite_id"],
                                    tle_record["norad_id"],  # æ·»åŠ  norad_id
                                    tle_record["constellation"],
                                    position.timestamp,
                                    position.x,
                                    position.y,
                                    position.z,
                                    position.latitude,
                                    position.longitude,
                                    position.altitude,
                                    position.velocity_x,
                                    position.velocity_y,
                                    position.velocity_z,
                                    position.orbital_period,
                                    elevation,
                                    azimuth,
                                    0.0,  # range_rate (æš«æ™‚è¨­ç‚º0)
                                    'SGP4',
                                    1.0,
                                    datetime.now(timezone.utc)
                                )
                                
                                records_for_this_satellite += 1
                                stats["records_computed"] += 1
                    
                    logger.info(
                        f"âœ… {tle_record['satellite_name']} ({tle_record['constellation']}): "
                        f"{records_for_this_satellite} æ¢è»Œé“è¨˜éŒ„"
                    )
                    
                except Exception as e:
                    error_msg = f"è¡›æ˜Ÿ {tle_record['satellite_name']} è»Œé“é è¨ˆç®—å¤±æ•—: {e}"
                    logger.error(error_msg)
                    stats["errors"].append(error_msg)
            
            logger.info(f"ğŸ‰ è»Œé“æ•¸æ“šé è¨ˆç®—å®Œæˆ: ç¸½å…± {stats['records_computed']} æ¢è¨˜éŒ„")
            return stats
            
        except Exception as e:
            logger.error(f"âŒ è»Œé“æ•¸æ“šé è¨ˆç®—å¤±æ•—: {e}")
            stats["errors"].append(str(e))
            return stats
    
    def _calculate_observer_view(self, obs_lat, obs_lon, obs_alt, sat_lat, sat_lon, sat_alt):
        """è¨ˆç®—è§€æ¸¬è€…è¦–è§’ (ä»°è§’ã€æ–¹ä½è§’ã€è·é›¢)"""
        import math
        
        # åœ°çƒåŠå¾‘ (km)
        R = 6371.0
        
        # è½‰æ›ç‚ºå¼§åº¦
        obs_lat_rad = math.radians(obs_lat)
        obs_lon_rad = math.radians(obs_lon)
        sat_lat_rad = math.radians(sat_lat)
        sat_lon_rad = math.radians(sat_lon)
        
        # è¡›æ˜Ÿèˆ‡è§€æ¸¬è€…çš„ ECEF åº§æ¨™
        obs_x = (R + obs_alt) * math.cos(obs_lat_rad) * math.cos(obs_lon_rad)
        obs_y = (R + obs_alt) * math.cos(obs_lat_rad) * math.sin(obs_lon_rad)
        obs_z = (R + obs_alt) * math.sin(obs_lat_rad)
        
        sat_x = (R + sat_alt) * math.cos(sat_lat_rad) * math.cos(sat_lon_rad)
        sat_y = (R + sat_alt) * math.cos(sat_lat_rad) * math.sin(sat_lon_rad)
        sat_z = (R + sat_alt) * math.sin(sat_lat_rad)
        
        # ç›¸å°ä½ç½®å‘é‡
        dx = sat_x - obs_x
        dy = sat_y - obs_y
        dz = sat_z - obs_z
        
        # è·é›¢
        range_km = math.sqrt(dx*dx + dy*dy + dz*dz)
        
        # è½‰æ›åˆ° ENU åº§æ¨™ç³»
        # ç°¡åŒ–è¨ˆç®—ï¼Œè¿”å›è¿‘ä¼¼å€¼
        elevation = math.degrees(math.asin(dz / range_km)) if range_km > 0 else -90
        azimuth = math.degrees(math.atan2(dy, dx)) % 360
        
        return elevation, azimuth, range_km
    
    async def _create_preload_job_record(self, stats: Dict[str, Any]) -> Dict[str, Any]:
        """å‰µå»ºé è¼‰ä½œæ¥­è¨˜éŒ„ - åŒ¹é…ç¾æœ‰è¡¨çµæ§‹"""
        try:
            duration_ms = stats.get("duration_seconds", 0) * 1000
            total_records = stats["tle_records_loaded"] + stats["orbital_records_precomputed"]
            
            async with self.db_pool.acquire() as conn:
                await conn.execute(
                    """
                    INSERT INTO satellite_data_preload_jobs (
                        job_name, job_type, constellation, status,
                        started_at, completed_at, created_at,
                        satellites_processed, total_satellites, records_created,
                        execution_time_ms, created_by
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
                    """,
                    "historical_data_preload",
                    "full_preload",
                    "all_constellations", 
                    "completed" if not stats.get("errors") else "completed_with_errors",
                    stats["start_time"],
                    stats.get("end_time", datetime.now(timezone.utc)),
                    datetime.now(timezone.utc),
                    len(ALL_HISTORICAL_TLE_DATA) if HISTORICAL_DATA_AVAILABLE else 0,
                    len(ALL_HISTORICAL_TLE_DATA) if HISTORICAL_DATA_AVAILABLE else 0,
                    total_records,
                    int(duration_ms),
                    "historical_data_preloader"
                )
            
            logger.info("ğŸ“‹ é è¼‰ä½œæ¥­è¨˜éŒ„å·²å‰µå»º")
            return {"jobs_created": 1}
            
        except Exception as e:
            logger.error(f"âš ï¸ å‰µå»ºé è¼‰ä½œæ¥­è¨˜éŒ„å¤±æ•—: {e}")
            return {"jobs_created": 0}
    
    async def check_preload_status(self) -> Dict[str, Any]:
        """æª¢æŸ¥é è¼‰ç‹€æ…‹ - åŒ¹é…ç¾æœ‰è¡¨çµæ§‹"""
        try:
            async with self.db_pool.acquire() as conn:
                # æª¢æŸ¥ TLE æ•¸æ“š
                tle_count = await conn.fetchval("SELECT COUNT(*) FROM satellite_tle_data WHERE is_active = TRUE")
                
                # æª¢æŸ¥è»Œé“ç·©å­˜
                orbital_count = await conn.fetchval("SELECT COUNT(*) FROM satellite_orbital_cache")
                
                # æª¢æŸ¥æœ€æ–°é è¼‰ä½œæ¥­
                latest_job = await conn.fetchrow(
                    """
                    SELECT job_name, status, completed_at, records_created, satellites_processed
                    FROM satellite_data_preload_jobs
                    ORDER BY created_at DESC
                    LIMIT 1
                    """
                )
                
                return {
                    "tle_records": tle_count,
                    "orbital_records": orbital_count,
                    "latest_job": dict(latest_job) if latest_job else None,
                    "is_fully_preloaded": tle_count > 10 and orbital_count > 1000,
                    "expected_orbital_records": 518400  # 45å¤© Ã— 24å°æ™‚ Ã— 120æ™‚é–“é» Ã— å¹³å‡8é¡†è¡›æ˜Ÿ
                }
                
        except Exception as e:
            logger.error(f"âŒ æª¢æŸ¥é è¼‰ç‹€æ…‹å¤±æ•—: {e}")
            return {"error": str(e)}
    
    async def close(self):
        """é—œé–‰æ•¸æ“šåº«é€£æ¥æ± """
        if self.db_pool:
            await self.db_pool.close()
            logger.info("ğŸ›°ï¸ æ­·å²æ•¸æ“šé è¼‰å™¨å·²é—œé–‰")


async def preload_historical_data(db_url: str) -> Dict[str, Any]:
    """
    ä¸»è¦æ¥å£å‡½æ•¸ - åŸ·è¡Œå®Œæ•´çš„æ­·å²æ•¸æ“šé è¼‰
    ä¾› NetStack å•Ÿå‹•æ™‚èª¿ç”¨
    """
    preloader = HistoricalDataPreloader(db_url)
    
    try:
        await preloader.initialize()
        
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“é è¼‰
        status = await preloader.check_preload_status()
        
        if status.get("is_fully_preloaded", False):
            logger.info(f"âœ… æ•¸æ“šå·²é è¼‰: TLE {status['tle_records']} æ¢, è»Œé“ {status['orbital_records']} æ¢")
            return {"status": "already_preloaded", "details": status}
        
        # åŸ·è¡Œå®Œæ•´é è¼‰
        logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œæ­·å²æ•¸æ“šé è¼‰...")
        result = await preloader.preload_all_historical_data()
        
        return {"status": "preloaded", "details": result}
        
    finally:
        await preloader.close()


if __name__ == "__main__":
    """ç›´æ¥åŸ·è¡Œæ¸¬è©¦"""
    import os
    
    db_url = os.getenv("RL_DATABASE_URL", "postgresql://rl_user:rl_password@localhost:5432/rl_research")
    
    async def test_preload():
        result = await preload_historical_data(db_url)
        print(f"é è¼‰çµæœ: {result}")
    
    asyncio.run(test_preload())