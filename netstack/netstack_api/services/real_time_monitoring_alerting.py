#!/usr/bin/env python3
"""
å³æ™‚æ€§èƒ½ç›£æ§å’Œå‘Šè­¦ç³»çµ±
å¯¦ç¾éšæ®µä¸ƒè¦æ±‚çš„å³æ™‚æ€§èƒ½ç›£æ§ã€å‘Šè­¦å’Œè‡ªå‹•éŸ¿æ‡‰æ©Ÿåˆ¶

åŠŸèƒ½ï¼š
1. å³æ™‚æ€§èƒ½ç›£æ§
2. æ™ºèƒ½å‘Šè­¦ç³»çµ±
3. å‘Šè­¦è¦å‰‡å¼•æ“
4. è‡ªå‹•éŸ¿æ‡‰æ©Ÿåˆ¶
5. å‘Šè­¦èšåˆå’Œå»é‡
6. å‘Šè­¦å‡ç´šç­–ç•¥
7. æ€§èƒ½ç•°å¸¸æª¢æ¸¬
8. ç›£æ§å„€è¡¨æ¿æ•¸æ“šæº
"""

import asyncio
import time
import statistics
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
import structlog
import aiohttp
import numpy as np
from collections import defaultdict, deque
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

from .unified_metrics_collector import UnifiedMetricsCollector, MetricValue
from .enhanced_performance_optimizer import EnhancedPerformanceOptimizer

logger = structlog.get_logger(__name__)


class AlertSeverity(Enum):
    """å‘Šè­¦åš´é‡ç´šåˆ¥"""
    CRITICAL = "critical"
    HIGH = "high" 
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


class AlertStatus(Enum):
    """å‘Šè­¦ç‹€æ…‹"""
    ACTIVE = "active"
    ACKNOWLEDGED = "acknowledged"
    RESOLVED = "resolved"
    SUPPRESSED = "suppressed"


class MonitoringStatus(Enum):
    """ç›£æ§ç‹€æ…‹"""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"


@dataclass
class AlertRule:
    """å‘Šè­¦è¦å‰‡"""
    rule_id: str
    name: str
    description: str
    metric_name: str
    condition: str  # >, <, >=, <=, ==, !=
    threshold: float
    severity: AlertSeverity
    duration_seconds: int = 60  # æŒçºŒæ™‚é–“é–¾å€¼
    evaluation_interval: int = 30  # è©•ä¼°é–“éš”(ç§’)
    enabled: bool = True
    tags: Dict[str, str] = field(default_factory=dict)
    suppression_rules: List[str] = field(default_factory=list)


@dataclass
class Alert:
    """å‘Šè­¦"""
    alert_id: str
    rule_id: str
    metric_name: str
    current_value: float
    threshold: float
    severity: AlertSeverity
    status: AlertStatus
    message: str
    timestamp: datetime
    acknowledged_by: Optional[str] = None
    acknowledged_at: Optional[datetime] = None
    resolved_at: Optional[datetime] = None
    labels: Dict[str, str] = field(default_factory=dict)
    annotations: Dict[str, str] = field(default_factory=dict)


@dataclass
class MonitoringDashboard:
    """ç›£æ§å„€è¡¨æ¿æ•¸æ“š"""
    timestamp: datetime
    overall_status: MonitoringStatus
    active_alerts_count: int
    critical_alerts_count: int
    high_alerts_count: int
    services_status: Dict[str, MonitoringStatus]
    key_metrics: Dict[str, float]
    performance_trends: Dict[str, List[float]]
    system_health_score: float


class AnomalyDetector:
    """ç•°å¸¸æª¢æ¸¬å™¨"""
    
    def __init__(self):
        self.metric_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=100))
        self.baseline_stats: Dict[str, Dict[str, float]] = {}
        
    def add_metric_value(self, metric_name: str, value: float, timestamp: float):
        """æ·»åŠ æŒ‡æ¨™å€¼"""
        self.metric_history[metric_name].append((timestamp, value))
        
        # æ›´æ–°åŸºç·šçµ±è¨ˆ
        if len(self.metric_history[metric_name]) >= 10:
            values = [v for _, v in self.metric_history[metric_name]]
            self.baseline_stats[metric_name] = {
                'mean': statistics.mean(values),
                'std': statistics.stdev(values) if len(values) > 1 else 0,
                'min': min(values),
                'max': max(values),
                'median': statistics.median(values)
            }
    
    def detect_anomaly(self, metric_name: str, value: float) -> Dict[str, Any]:
        """æª¢æ¸¬ç•°å¸¸"""
        if metric_name not in self.baseline_stats:
            return {"is_anomaly": False, "confidence": 0.0, "reason": "insufficient_data"}
        
        stats = self.baseline_stats[metric_name]
        
        # Z-score ç•°å¸¸æª¢æ¸¬
        if stats['std'] > 0:
            z_score = abs(value - stats['mean']) / stats['std']
            is_anomaly = z_score > 3.0  # 3-sigmaè¦å‰‡
            confidence = min(z_score / 3.0, 1.0)
        else:
            z_score = 0
            is_anomaly = False
            confidence = 0.0
        
        # ç¯„åœç•°å¸¸æª¢æ¸¬
        iqr_factor = 1.5
        q1_approx = stats['mean'] - 0.675 * stats['std']
        q3_approx = stats['mean'] + 0.675 * stats['std']
        iqr = q3_approx - q1_approx
        lower_bound = q1_approx - iqr_factor * iqr
        upper_bound = q3_approx + iqr_factor * iqr
        
        range_anomaly = value < lower_bound or value > upper_bound
        
        final_anomaly = is_anomaly or range_anomaly
        reason = []
        if z_score > 3.0:
            reason.append(f"z_score_{z_score:.2f}")
        if range_anomaly:
            reason.append("out_of_range")
        
        return {
            "is_anomaly": final_anomaly,
            "confidence": confidence,
            "z_score": z_score,
            "reason": "_".join(reason) if reason else "normal",
            "baseline_mean": stats['mean'],
            "baseline_std": stats['std']
        }


class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self):
        self.rules: Dict[str, AlertRule] = {}
        self.active_alerts: Dict[str, Alert] = {}
        self.alert_history: List[Alert] = []
        self.rule_states: Dict[str, Dict] = {}  # è¦å‰‡ç‹€æ…‹è¿½è¸ª
        self.notification_channels: List[Callable] = []
        self.suppression_groups: Dict[str, List[str]] = {}
        
    def add_rule(self, rule: AlertRule):
        """æ·»åŠ å‘Šè­¦è¦å‰‡"""
        self.rules[rule.rule_id] = rule
        self.rule_states[rule.rule_id] = {
            'last_evaluation': 0,
            'trigger_start': None,
            'consecutive_violations': 0
        }
        logger.info(f"æ·»åŠ å‘Šè­¦è¦å‰‡: {rule.name}")
    
    def remove_rule(self, rule_id: str):
        """ç§»é™¤å‘Šè­¦è¦å‰‡"""
        if rule_id in self.rules:
            del self.rules[rule_id]
            if rule_id in self.rule_states:
                del self.rule_states[rule_id]
            logger.info(f"ç§»é™¤å‘Šè­¦è¦å‰‡: {rule_id}")
    
    def evaluate_rules(self, metrics: List[MetricValue]) -> List[Alert]:
        """è©•ä¼°å‘Šè­¦è¦å‰‡"""
        new_alerts = []
        current_time = time.time()
        
        # æŒ‰æŒ‡æ¨™åç¨±çµ„ç¹”æŒ‡æ¨™å€¼
        metrics_by_name = defaultdict(list)
        for metric in metrics:
            metrics_by_name[metric.metric_name].append(metric)
        
        for rule_id, rule in self.rules.items():
            if not rule.enabled:
                continue
                
            # æª¢æŸ¥è©•ä¼°é–“éš”
            state = self.rule_states[rule_id]
            if current_time - state['last_evaluation'] < rule.evaluation_interval:
                continue
                
            state['last_evaluation'] = current_time
            
            # ç²å–ç›¸é—œæŒ‡æ¨™
            relevant_metrics = metrics_by_name.get(rule.metric_name, [])
            if not relevant_metrics:
                continue
            
            # ä½¿ç”¨æœ€æ–°å€¼é€²è¡Œè©•ä¼°
            latest_metric = max(relevant_metrics, key=lambda m: m.timestamp)
            current_value = latest_metric.value
            
            # è©•ä¼°æ¢ä»¶
            violation = self._evaluate_condition(current_value, rule.condition, rule.threshold)
            
            if violation:
                state['consecutive_violations'] += 1
                if state['trigger_start'] is None:
                    state['trigger_start'] = current_time
                
                # æª¢æŸ¥æŒçºŒæ™‚é–“
                if current_time - state['trigger_start'] >= rule.duration_seconds:
                    # ç”Ÿæˆå‘Šè­¦
                    alert = self._create_alert(rule, latest_metric, current_value)
                    if alert and not self._is_suppressed(alert):
                        new_alerts.append(alert)
                        self.active_alerts[alert.alert_id] = alert
                        
            else:
                # é‡ç½®ç‹€æ…‹
                state['consecutive_violations'] = 0
                state['trigger_start'] = None
                
                # è§£æ±ºç›¸é—œçš„æ´»èºå‘Šè­¦
                self._resolve_alerts_for_rule(rule_id)
        
        return new_alerts
    
    def _evaluate_condition(self, value: float, condition: str, threshold: float) -> bool:
        """è©•ä¼°æ¢ä»¶"""
        if condition == ">":
            return value > threshold
        elif condition == ">=":
            return value >= threshold
        elif condition == "<":
            return value < threshold
        elif condition == "<=":
            return value <= threshold
        elif condition == "==":
            return abs(value - threshold) < 0.001
        elif condition == "!=":
            return abs(value - threshold) >= 0.001
        else:
            return False
    
    def _create_alert(self, rule: AlertRule, metric: MetricValue, current_value: float) -> Optional[Alert]:
        """å‰µå»ºå‘Šè­¦"""
        alert_id = f"{rule.rule_id}_{int(time.time())}"
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå‘Šè­¦
        for alert in self.active_alerts.values():
            if (alert.rule_id == rule.rule_id and 
                alert.metric_name == rule.metric_name and
                alert.status == AlertStatus.ACTIVE):
                return None  # é¿å…é‡è¤‡å‘Šè­¦
        
        message = (f"{rule.name}: {rule.metric_name} is {current_value:.2f} "
                  f"(threshold: {rule.condition} {rule.threshold})")
        
        alert = Alert(
            alert_id=alert_id,
            rule_id=rule.rule_id,
            metric_name=rule.metric_name,
            current_value=current_value,
            threshold=rule.threshold,
            severity=rule.severity,
            status=AlertStatus.ACTIVE,
            message=message,
            timestamp=datetime.now(),
            labels=metric.labels.copy(),
            annotations={
                "rule_name": rule.name,
                "description": rule.description,
                "source_service": metric.source_service
            }
        )
        
        return alert
    
    def _is_suppressed(self, alert: Alert) -> bool:
        """æª¢æŸ¥å‘Šè­¦æ˜¯å¦è¢«æŠ‘åˆ¶"""
        rule = self.rules.get(alert.rule_id)
        if not rule or not rule.suppression_rules:
            return False
        
        # æª¢æŸ¥æŠ‘åˆ¶è¦å‰‡
        for suppression_rule in rule.suppression_rules:
            if self._check_suppression_condition(alert, suppression_rule):
                return True
        
        return False
    
    def _check_suppression_condition(self, alert: Alert, suppression_rule: str) -> bool:
        """æª¢æŸ¥æŠ‘åˆ¶æ¢ä»¶"""
        # ç°¡å–®çš„æŠ‘åˆ¶é‚è¼¯ï¼Œå¯ä»¥æ ¹æ“šéœ€è¦æ“´å±•
        if suppression_rule.startswith("higher_severity_exists"):
            higher_severities = []
            if alert.severity == AlertSeverity.HIGH:
                higher_severities = [AlertSeverity.CRITICAL]
            elif alert.severity == AlertSeverity.MEDIUM:
                higher_severities = [AlertSeverity.CRITICAL, AlertSeverity.HIGH]
            elif alert.severity == AlertSeverity.LOW:
                higher_severities = [AlertSeverity.CRITICAL, AlertSeverity.HIGH, AlertSeverity.MEDIUM]
            
            for active_alert in self.active_alerts.values():
                if (active_alert.severity in higher_severities and 
                    active_alert.status == AlertStatus.ACTIVE):
                    return True
        
        return False
    
    def _resolve_alerts_for_rule(self, rule_id: str):
        """è§£æ±ºè¦å‰‡ç›¸é—œçš„å‘Šè­¦"""
        current_time = datetime.now()
        for alert in list(self.active_alerts.values()):
            if alert.rule_id == rule_id and alert.status == AlertStatus.ACTIVE:
                alert.status = AlertStatus.RESOLVED
                alert.resolved_at = current_time
                self.alert_history.append(alert)
                del self.active_alerts[alert.alert_id]
    
    def acknowledge_alert(self, alert_id: str, acknowledged_by: str):
        """ç¢ºèªå‘Šè­¦"""
        if alert_id in self.active_alerts:
            alert = self.active_alerts[alert_id]
            alert.status = AlertStatus.ACKNOWLEDGED
            alert.acknowledged_by = acknowledged_by
            alert.acknowledged_at = datetime.now()
            logger.info(f"å‘Šè­¦å·²ç¢ºèª: {alert_id} by {acknowledged_by}")
    
    def resolve_alert(self, alert_id: str):
        """æ‰‹å‹•è§£æ±ºå‘Šè­¦"""
        if alert_id in self.active_alerts:
            alert = self.active_alerts[alert_id]
            alert.status = AlertStatus.RESOLVED
            alert.resolved_at = datetime.now()
            self.alert_history.append(alert)
            del self.active_alerts[alert_id]
            logger.info(f"å‘Šè­¦å·²è§£æ±º: {alert_id}")
    
    def add_notification_channel(self, channel: Callable):
        """æ·»åŠ é€šçŸ¥æ¸ é“"""
        self.notification_channels.append(channel)
    
    async def send_notifications(self, alerts: List[Alert]):
        """ç™¼é€é€šçŸ¥"""
        for alert in alerts:
            for channel in self.notification_channels:
                try:
                    await channel(alert)
                except Exception as e:
                    logger.error(f"ç™¼é€é€šçŸ¥å¤±æ•—: {e}")


class RealTimeMonitoringAlerting:
    """å³æ™‚æ€§èƒ½ç›£æ§å’Œå‘Šè­¦ç³»çµ±"""
    
    def __init__(self, metrics_collector: UnifiedMetricsCollector, 
                 performance_optimizer: EnhancedPerformanceOptimizer):
        self.logger = structlog.get_logger(__name__)
        
        # ä¾è³´æœå‹™
        self.metrics_collector = metrics_collector
        self.performance_optimizer = performance_optimizer
        
        # æ ¸å¿ƒçµ„ä»¶
        self.alert_manager = AlertManager()
        self.anomaly_detector = AnomalyDetector()
        
        # ç›£æ§ç‹€æ…‹
        self.monitoring_active = False
        self.monitoring_task: Optional[asyncio.Task] = None
        
        # ç›£æ§é…ç½®
        self.monitoring_interval = 10.0  # 10ç§’ç›£æ§é–“éš”
        self.dashboard_update_interval = 30.0  # 30ç§’å„€è¡¨æ¿æ›´æ–°é–“éš”
        
        # æ€§èƒ½æ•¸æ“š
        self.recent_metrics: deque = deque(maxlen=1000)
        self.dashboard_data: Optional[MonitoringDashboard] = None
        
        # è‡ªå‹•éŸ¿æ‡‰é–‹é—œ
        self.auto_response_enabled = True
        
        # çµ±è¨ˆä¿¡æ¯
        self.monitoring_stats = {
            "total_evaluations": 0,
            "alerts_generated": 0,
            "alerts_resolved": 0,
            "anomalies_detected": 0,
            "auto_responses_triggered": 0
        }
        
        # åˆå§‹åŒ–é è¨­å‘Šè­¦è¦å‰‡
        self._initialize_default_rules()
        
        # åˆå§‹åŒ–é€šçŸ¥æ¸ é“
        self._initialize_notification_channels()
    
    def _initialize_default_rules(self):
        """åˆå§‹åŒ–é è¨­å‘Šè­¦è¦å‰‡"""
        default_rules = [
            AlertRule(
                rule_id="e2e_latency_critical",
                name="E2Eå»¶é²è‡¨ç•Œå‘Šè­¦",
                description="ç«¯åˆ°ç«¯å»¶é²è¶…éè‡¨ç•Œé–¾å€¼",
                metric_name="ntn_kpi_e2e_latency_ms",
                condition=">",
                threshold=100.0,
                severity=AlertSeverity.CRITICAL,
                duration_seconds=30
            ),
            AlertRule(
                rule_id="e2e_latency_high",
                name="E2Eå»¶é²é«˜å‘Šè­¦",
                description="ç«¯åˆ°ç«¯å»¶é²è¶…éç›®æ¨™å€¼",
                metric_name="ntn_kpi_e2e_latency_ms",
                condition=">",
                threshold=50.0,
                severity=AlertSeverity.HIGH,
                duration_seconds=60
            ),
            AlertRule(
                rule_id="transmission_rate_low",
                name="å‚³è¼¸é€Ÿç‡ä½å‘Šè­¦",
                description="å‚³è¼¸é€Ÿç‡ä½æ–¼ç›®æ¨™å€¼",
                metric_name="ntn_kpi_transmission_rate_mbps",
                condition="<",
                threshold=65.0,
                severity=AlertSeverity.MEDIUM,
                duration_seconds=90
            ),
            AlertRule(
                rule_id="coverage_low",
                name="è¦†è“‹ç‡ä½å‘Šè­¦",
                description="ç³»çµ±è¦†è“‹ç‡ä½æ–¼ç›®æ¨™å€¼",
                metric_name="ntn_kpi_coverage_percent",
                condition="<",
                threshold=75.0,
                severity=AlertSeverity.HIGH,
                duration_seconds=120
            ),
            AlertRule(
                rule_id="cpu_utilization_high",
                name="CPUä½¿ç”¨ç‡é«˜å‘Šè­¦",
                description="CPUä½¿ç”¨ç‡éé«˜",
                metric_name="system_resource_cpu_usage_percent",
                condition=">",
                threshold=90.0,
                severity=AlertSeverity.HIGH,
                duration_seconds=60
            ),
            AlertRule(
                rule_id="memory_utilization_critical",
                name="è¨˜æ†¶é«”ä½¿ç”¨ç‡è‡¨ç•Œå‘Šè­¦",
                description="è¨˜æ†¶é«”ä½¿ç”¨ç‡è‡¨ç•Œ",
                metric_name="system_resource_memory_usage_mb",
                condition=">",
                threshold=95.0,
                severity=AlertSeverity.CRITICAL,
                duration_seconds=30
            ),
            AlertRule(
                rule_id="handover_success_rate_low",
                name="æ›æ‰‹æˆåŠŸç‡ä½å‘Šè­¦",
                description="è¡›æ˜Ÿæ›æ‰‹æˆåŠŸç‡éä½",
                metric_name="ntn_kpi_handover_success_rate_percent",
                condition="<",
                threshold=95.0,
                severity=AlertSeverity.HIGH,
                duration_seconds=120
            ),
            AlertRule(
                rule_id="ai_interference_detection_low",
                name="AIå¹²æ“¾æª¢æ¸¬æº–ç¢ºç‡ä½å‘Šè­¦",
                description="AIå¹²æ“¾æª¢æ¸¬æº–ç¢ºç‡éä½",
                metric_name="ntn_kpi_ai_interference_detection_accuracy_percent",
                condition="<",
                threshold=85.0,
                severity=AlertSeverity.MEDIUM,
                duration_seconds=300
            )
        ]
        
        for rule in default_rules:
            self.alert_manager.add_rule(rule)
    
    def _initialize_notification_channels(self):
        """åˆå§‹åŒ–é€šçŸ¥æ¸ é“"""
        # æ·»åŠ æ—¥èªŒé€šçŸ¥æ¸ é“
        self.alert_manager.add_notification_channel(self._log_notification)
        
        # å¯ä»¥æ·»åŠ å…¶ä»–é€šçŸ¥æ¸ é“å¦‚emailã€webhookç­‰
        # self.alert_manager.add_notification_channel(self._email_notification)
        # self.alert_manager.add_notification_channel(self._webhook_notification)
    
    async def _log_notification(self, alert: Alert):
        """æ—¥èªŒé€šçŸ¥æ¸ é“"""
        self.logger.warn(
            f"ğŸš¨ å‘Šè­¦è§¸ç™¼: {alert.message}",
            alert_id=alert.alert_id,
            severity=alert.severity.value,
            metric=alert.metric_name,
            value=alert.current_value,
            threshold=alert.threshold
        )
    
    async def start_monitoring(self):
        """å•Ÿå‹•å³æ™‚ç›£æ§"""
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        self.monitoring_task = asyncio.create_task(self._monitoring_loop())
        self.logger.info("å³æ™‚æ€§èƒ½ç›£æ§å·²å•Ÿå‹•")
    
    async def stop_monitoring(self):
        """åœæ­¢å³æ™‚ç›£æ§"""
        self.monitoring_active = False
        if self.monitoring_task:
            self.monitoring_task.cancel()
            try:
                await self.monitoring_task
            except asyncio.CancelledError:
                pass
        self.logger.info("å³æ™‚æ€§èƒ½ç›£æ§å·²åœæ­¢")
    
    async def _monitoring_loop(self):
        """ç›£æ§ä¸»å¾ªç’°"""
        last_dashboard_update = 0
        
        while self.monitoring_active:
            try:
                start_time = time.time()
                
                # æ”¶é›†æŒ‡æ¨™
                await self._collect_and_process_metrics()
                
                # æ›´æ–°å„€è¡¨æ¿æ•¸æ“š
                current_time = time.time()
                if current_time - last_dashboard_update >= self.dashboard_update_interval:
                    await self._update_dashboard_data()
                    last_dashboard_update = current_time
                
                # çµ±è¨ˆæ›´æ–°
                self.monitoring_stats["total_evaluations"] += 1
                
                # ç­‰å¾…ä¸‹æ¬¡ç›£æ§
                elapsed = time.time() - start_time
                sleep_time = max(0, self.monitoring_interval - elapsed)
                await asyncio.sleep(sleep_time)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"ç›£æ§å¾ªç’°ç•°å¸¸: {e}")
                await asyncio.sleep(self.monitoring_interval)
    
    async def _collect_and_process_metrics(self):
        """æ”¶é›†å’Œè™•ç†æŒ‡æ¨™"""
        try:
            # å¾çµ±ä¸€æŒ‡æ¨™æ”¶é›†å™¨ç²å–æœ€æ–°æŒ‡æ¨™
            latest_metrics = await self._get_latest_metrics()
            
            if not latest_metrics:
                return
            
            # æ·»åŠ åˆ°æ­·å²æ•¸æ“š
            self.recent_metrics.extend(latest_metrics)
            
            # ç•°å¸¸æª¢æ¸¬
            await self._perform_anomaly_detection(latest_metrics)
            
            # è©•ä¼°å‘Šè­¦è¦å‰‡
            new_alerts = self.alert_manager.evaluate_rules(latest_metrics)
            
            if new_alerts:
                self.monitoring_stats["alerts_generated"] += len(new_alerts)
                
                # ç™¼é€é€šçŸ¥
                await self.alert_manager.send_notifications(new_alerts)
                
                # è‡ªå‹•éŸ¿æ‡‰
                if self.auto_response_enabled:
                    await self._trigger_auto_response(new_alerts)
                    
        except Exception as e:
            self.logger.error(f"æŒ‡æ¨™æ”¶é›†å’Œè™•ç†å¤±æ•—: {e}")
    
    async def _get_latest_metrics(self) -> List[MetricValue]:
        """ç²å–æœ€æ–°æŒ‡æ¨™"""
        # é€™è£¡æ‡‰è©²å¾ UnifiedMetricsCollector ç²å–æœ€æ–°çš„æŒ‡æ¨™
        # æš«æ™‚ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
        return []
    
    async def _perform_anomaly_detection(self, metrics: List[MetricValue]):
        """åŸ·è¡Œç•°å¸¸æª¢æ¸¬"""
        anomalies_detected = 0
        
        for metric in metrics:
            # æ·»åŠ åˆ°ç•°å¸¸æª¢æ¸¬å™¨
            self.anomaly_detector.add_metric_value(
                metric.metric_name, 
                metric.value, 
                metric.timestamp
            )
            
            # æª¢æ¸¬ç•°å¸¸
            anomaly_result = self.anomaly_detector.detect_anomaly(
                metric.metric_name, 
                metric.value
            )
            
            if anomaly_result["is_anomaly"] and anomaly_result["confidence"] > 0.8:
                anomalies_detected += 1
                
                # è¨˜éŒ„ç•°å¸¸
                self.logger.warning(
                    f"æª¢æ¸¬åˆ°ç•°å¸¸: {metric.metric_name}",
                    value=metric.value,
                    confidence=anomaly_result["confidence"],
                    reason=anomaly_result["reason"],
                    baseline_mean=anomaly_result.get("baseline_mean"),
                    z_score=anomaly_result.get("z_score")
                )
                
                # å¯ä»¥å‰µå»ºç•°å¸¸å‘Šè­¦
                await self._create_anomaly_alert(metric, anomaly_result)
        
        if anomalies_detected > 0:
            self.monitoring_stats["anomalies_detected"] += anomalies_detected
    
    async def _create_anomaly_alert(self, metric: MetricValue, anomaly_result: Dict):
        """å‰µå»ºç•°å¸¸å‘Šè­¦"""
        # å‰µå»ºå‹•æ…‹ç•°å¸¸å‘Šè­¦è¦å‰‡
        rule_id = f"anomaly_{metric.metric_name}_{int(time.time())}"
        
        rule = AlertRule(
            rule_id=rule_id,
            name=f"ç•°å¸¸æª¢æ¸¬: {metric.metric_name}",
            description=f"æª¢æ¸¬åˆ° {metric.metric_name} ç•°å¸¸ï¼Œç½®ä¿¡åº¦: {anomaly_result['confidence']:.2f}",
            metric_name=metric.metric_name,
            condition="!=",  # ç”¨æ–¼ç•°å¸¸æª¢æ¸¬
            threshold=anomaly_result.get("baseline_mean", metric.value),
            severity=AlertSeverity.MEDIUM if anomaly_result["confidence"] > 0.9 else AlertSeverity.LOW,
            duration_seconds=0  # ç«‹å³è§¸ç™¼
        )
        
        # æš«æ™‚æ·»åŠ è¦å‰‡ä¸¦ç«‹å³è©•ä¼°
        self.alert_manager.add_rule(rule)
        new_alerts = self.alert_manager.evaluate_rules([metric])
        
        if new_alerts:
            await self.alert_manager.send_notifications(new_alerts)
        
        # ç§»é™¤è‡¨æ™‚è¦å‰‡
        self.alert_manager.remove_rule(rule_id)
    
    async def _trigger_auto_response(self, alerts: List[Alert]):
        """è§¸ç™¼è‡ªå‹•éŸ¿æ‡‰"""
        for alert in alerts:
            try:
                response_triggered = False
                
                # æ ¹æ“šå‘Šè­¦é¡å‹å’Œåš´é‡æ€§æ±ºå®šéŸ¿æ‡‰å‹•ä½œ
                if alert.severity == AlertSeverity.CRITICAL:
                    if "latency" in alert.metric_name.lower():
                        # è§¸ç™¼å»¶é²å„ªåŒ–
                        await self.performance_optimizer.manual_optimization(
                            domain=self.performance_optimizer.OptimizationDomain.LATENCY,
                            strategy=self.performance_optimizer.OptimizationStrategy.AGGRESSIVE
                        )
                        response_triggered = True
                        
                    elif "cpu" in alert.metric_name.lower():
                        # è§¸ç™¼CPUå„ªåŒ–
                        await self.performance_optimizer.manual_optimization(
                            domain=self.performance_optimizer.OptimizationDomain.RESOURCE_UTILIZATION,
                            strategy=self.performance_optimizer.OptimizationStrategy.AGGRESSIVE
                        )
                        response_triggered = True
                        
                elif alert.severity == AlertSeverity.HIGH:
                    if "throughput" in alert.metric_name.lower() or "transmission" in alert.metric_name.lower():
                        # è§¸ç™¼ååé‡å„ªåŒ–
                        await self.performance_optimizer.manual_optimization(
                            domain=self.performance_optimizer.OptimizationDomain.THROUGHPUT,
                            strategy=self.performance_optimizer.OptimizationStrategy.BALANCED
                        )
                        response_triggered = True
                        
                    elif "handover" in alert.metric_name.lower():
                        # è§¸ç™¼è¡›æ˜Ÿæ›æ‰‹å„ªåŒ–
                        await self.performance_optimizer.manual_optimization(
                            domain=self.performance_optimizer.OptimizationDomain.SATELLITE_HANDOVER,
                            strategy=self.performance_optimizer.OptimizationStrategy.BALANCED
                        )
                        response_triggered = True
                
                if response_triggered:
                    self.monitoring_stats["auto_responses_triggered"] += 1
                    self.logger.info(
                        f"è‡ªå‹•éŸ¿æ‡‰å·²è§¸ç™¼",
                        alert_id=alert.alert_id,
                        metric=alert.metric_name,
                        severity=alert.severity.value
                    )
                    
            except Exception as e:
                self.logger.error(f"è‡ªå‹•éŸ¿æ‡‰å¤±æ•— {alert.alert_id}: {e}")
    
    async def _update_dashboard_data(self):
        """æ›´æ–°å„€è¡¨æ¿æ•¸æ“š"""
        try:
            current_time = datetime.now()
            
            # çµ±è¨ˆæ´»èºå‘Šè­¦
            active_alerts = list(self.alert_manager.active_alerts.values())
            critical_count = sum(1 for a in active_alerts if a.severity == AlertSeverity.CRITICAL)
            high_count = sum(1 for a in active_alerts if a.severity == AlertSeverity.HIGH)
            
            # è¨ˆç®—æ•´é«”ç‹€æ…‹
            if critical_count > 0:
                overall_status = MonitoringStatus.CRITICAL
            elif high_count > 0 or len(active_alerts) > 5:
                overall_status = MonitoringStatus.WARNING
            else:
                overall_status = MonitoringStatus.HEALTHY
            
            # æœå‹™ç‹€æ…‹ï¼ˆæ¨¡æ“¬ï¼‰
            services_status = {
                "netstack-api": MonitoringStatus.HEALTHY,
                "simworld-backend": MonitoringStatus.HEALTHY,
                "performance-optimizer": MonitoringStatus.HEALTHY,
                "metrics-collector": MonitoringStatus.HEALTHY
            }
            
            # é—œéµæŒ‡æ¨™ï¼ˆå¾æœ€è¿‘çš„æŒ‡æ¨™ä¸­æå–ï¼‰
            key_metrics = {}
            if self.recent_metrics:
                recent_by_name = defaultdict(list)
                for metric in list(self.recent_metrics)[-50:]:  # æœ€è¿‘50å€‹æŒ‡æ¨™
                    recent_by_name[metric.metric_name].append(metric.value)
                
                for metric_name, values in recent_by_name.items():
                    if values:
                        key_metrics[metric_name] = values[-1]  # æœ€æ–°å€¼
            
            # æ€§èƒ½è¶¨å‹¢ï¼ˆæœ€è¿‘10å€‹å€¼ï¼‰
            performance_trends = {}
            if self.recent_metrics:
                recent_by_name = defaultdict(list)
                for metric in list(self.recent_metrics)[-100:]:
                    recent_by_name[metric.metric_name].append(metric.value)
                
                for metric_name, values in recent_by_name.items():
                    if len(values) >= 2:
                        performance_trends[metric_name] = values[-10:]  # æœ€è¿‘10å€‹å€¼
            
            # è¨ˆç®—ç³»çµ±å¥åº·åˆ†æ•¸
            health_score = self._calculate_system_health_score(active_alerts, key_metrics)
            
            self.dashboard_data = MonitoringDashboard(
                timestamp=current_time,
                overall_status=overall_status,
                active_alerts_count=len(active_alerts),
                critical_alerts_count=critical_count,
                high_alerts_count=high_count,
                services_status=services_status,
                key_metrics=key_metrics,
                performance_trends=performance_trends,
                system_health_score=health_score
            )
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°å„€è¡¨æ¿æ•¸æ“šå¤±æ•—: {e}")
    
    def _calculate_system_health_score(self, active_alerts: List[Alert], key_metrics: Dict[str, float]) -> float:
        """è¨ˆç®—ç³»çµ±å¥åº·åˆ†æ•¸ (0-100)"""
        base_score = 100.0
        
        # æ ¹æ“šå‘Šè­¦æ‰£åˆ†
        for alert in active_alerts:
            if alert.severity == AlertSeverity.CRITICAL:
                base_score -= 20
            elif alert.severity == AlertSeverity.HIGH:
                base_score -= 10
            elif alert.severity == AlertSeverity.MEDIUM:
                base_score -= 5
            elif alert.severity == AlertSeverity.LOW:
                base_score -= 2
        
        # æ ¹æ“šé—œéµæŒ‡æ¨™èª¿æ•´
        if "ntn_kpi_e2e_latency_ms" in key_metrics:
            latency = key_metrics["ntn_kpi_e2e_latency_ms"]
            if latency > 100:
                base_score -= 15
            elif latency > 50:
                base_score -= 8
        
        if "ntn_kpi_coverage_percent" in key_metrics:
            coverage = key_metrics["ntn_kpi_coverage_percent"]
            if coverage < 60:
                base_score -= 20
            elif coverage < 75:
                base_score -= 10
        
        return max(0.0, min(100.0, base_score))
    
    def get_dashboard_data(self) -> Optional[Dict[str, Any]]:
        """ç²å–å„€è¡¨æ¿æ•¸æ“š"""
        if not self.dashboard_data:
            return None
        
        return {
            "timestamp": self.dashboard_data.timestamp.isoformat(),
            "overall_status": self.dashboard_data.overall_status.value,
            "alerts": {
                "active_count": self.dashboard_data.active_alerts_count,
                "critical_count": self.dashboard_data.critical_alerts_count,
                "high_count": self.dashboard_data.high_alerts_count,
                "details": [
                    {
                        "id": alert.alert_id,
                        "rule_id": alert.rule_id,
                        "severity": alert.severity.value,
                        "status": alert.status.value,
                        "message": alert.message,
                        "timestamp": alert.timestamp.isoformat(),
                        "metric": alert.metric_name,
                        "current_value": alert.current_value,
                        "threshold": alert.threshold
                    }
                    for alert in self.alert_manager.active_alerts.values()
                ]
            },
            "services_status": {
                service: status.value 
                for service, status in self.dashboard_data.services_status.items()
            },
            "key_metrics": self.dashboard_data.key_metrics,
            "performance_trends": self.dashboard_data.performance_trends,
            "system_health_score": self.dashboard_data.system_health_score,
            "monitoring_stats": self.monitoring_stats
        }
    
    def get_alert_rules(self) -> List[Dict[str, Any]]:
        """ç²å–å‘Šè­¦è¦å‰‡åˆ—è¡¨"""
        return [
            {
                "rule_id": rule.rule_id,
                "name": rule.name,
                "description": rule.description,
                "metric_name": rule.metric_name,
                "condition": rule.condition,
                "threshold": rule.threshold,
                "severity": rule.severity.value,
                "duration_seconds": rule.duration_seconds,
                "enabled": rule.enabled,
                "tags": rule.tags
            }
            for rule in self.alert_manager.rules.values()
        ]
    
    def add_custom_rule(self, rule_data: Dict[str, Any]) -> bool:
        """æ·»åŠ è‡ªå®šç¾©å‘Šè­¦è¦å‰‡"""
        try:
            rule = AlertRule(
                rule_id=rule_data["rule_id"],
                name=rule_data["name"],
                description=rule_data.get("description", ""),
                metric_name=rule_data["metric_name"],
                condition=rule_data["condition"],
                threshold=float(rule_data["threshold"]),
                severity=AlertSeverity(rule_data["severity"]),
                duration_seconds=rule_data.get("duration_seconds", 60),
                evaluation_interval=rule_data.get("evaluation_interval", 30),
                enabled=rule_data.get("enabled", True),
                tags=rule_data.get("tags", {})
            )
            
            self.alert_manager.add_rule(rule)
            return True
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ è‡ªå®šç¾©è¦å‰‡å¤±æ•—: {e}")
            return False
    
    def update_rule(self, rule_id: str, updates: Dict[str, Any]) -> bool:
        """æ›´æ–°å‘Šè­¦è¦å‰‡"""
        try:
            if rule_id not in self.alert_manager.rules:
                return False
            
            rule = self.alert_manager.rules[rule_id]
            
            if "threshold" in updates:
                rule.threshold = float(updates["threshold"])
            if "enabled" in updates:
                rule.enabled = bool(updates["enabled"])
            if "severity" in updates:
                rule.severity = AlertSeverity(updates["severity"])
            if "duration_seconds" in updates:
                rule.duration_seconds = int(updates["duration_seconds"])
            
            return True
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°è¦å‰‡å¤±æ•— {rule_id}: {e}")
            return False
    
    def get_monitoring_summary(self) -> Dict[str, Any]:
        """ç²å–ç›£æ§æ‘˜è¦"""
        return {
            "monitoring_active": self.monitoring_active,
            "auto_response_enabled": self.auto_response_enabled,
            "monitoring_interval": self.monitoring_interval,
            "dashboard_update_interval": self.dashboard_update_interval,
            "total_rules": len(self.alert_manager.rules),
            "active_alerts": len(self.alert_manager.active_alerts),
            "recent_metrics_count": len(self.recent_metrics),
            "stats": self.monitoring_stats.copy(),
            "system_health_score": self.dashboard_data.system_health_score if self.dashboard_data else 0
        }


async def main():
    """ä¸»å‡½æ•¸ - ç¤ºä¾‹ç”¨æ³•"""
    # é€™è£¡éœ€è¦å¯¦éš›çš„ä¾è³´æ³¨å…¥
    from .unified_metrics_collector import UnifiedMetricsCollector
    from .enhanced_performance_optimizer import EnhancedPerformanceOptimizer
    from ..adapters.redis_adapter import RedisAdapter
    
    # åˆå§‹åŒ–ä¾è³´
    redis_adapter = RedisAdapter()
    metrics_collector = UnifiedMetricsCollector(redis_adapter)
    performance_optimizer = EnhancedPerformanceOptimizer()
    
    # å‰µå»ºç›£æ§ç³»çµ±
    monitoring_system = RealTimeMonitoringAlerting(metrics_collector, performance_optimizer)
    
    # å•Ÿå‹•ç›£æ§
    print("ğŸ” å•Ÿå‹•å³æ™‚æ€§èƒ½ç›£æ§å’Œå‘Šè­¦ç³»çµ±...")
    await monitoring_system.start_monitoring()
    
    # é‹è¡Œä¸€æ®µæ™‚é–“
    await asyncio.sleep(60)
    
    # ç²å–ç›£æ§æ‘˜è¦
    summary = monitoring_system.get_monitoring_summary()
    print(f"ğŸ“Š ç›£æ§æ‘˜è¦: {summary}")
    
    # ç²å–å„€è¡¨æ¿æ•¸æ“š
    dashboard = monitoring_system.get_dashboard_data()
    if dashboard:
        print(f"ğŸ“ˆ å„€è¡¨æ¿æ•¸æ“š: ç³»çµ±å¥åº·åˆ†æ•¸ {dashboard['system_health_score']:.1f}")
        print(f"   æ´»èºå‘Šè­¦: {dashboard['alerts']['active_count']}")
        print(f"   é—œéµæŒ‡æ¨™æ•¸é‡: {len(dashboard['key_metrics'])}")
    
    # åœæ­¢ç›£æ§
    await monitoring_system.stop_monitoring()
    print("âœ… å³æ™‚æ€§èƒ½ç›£æ§ç³»çµ±å·²åœæ­¢")


if __name__ == "__main__":
    asyncio.run(main())