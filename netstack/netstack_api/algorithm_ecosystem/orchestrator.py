"""
ğŸ­ æ›æ‰‹å”èª¿å™¨

ç®—æ³•ç”Ÿæ…‹ç³»çµ±çš„ä¸»æ§åˆ¶å™¨ï¼Œè² è²¬å”èª¿å¤šå€‹ç®—æ³•çš„åŸ·è¡Œã€è² è¼‰å‡è¡¡ã€éŒ¯èª¤è™•ç†å’Œæ€§èƒ½ç›£æ§ã€‚
"""

import asyncio
import logging
import time
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime, timedelta
import numpy as np
from collections import defaultdict, deque

from .interfaces import (
    HandoverAlgorithm,
    RLHandoverAlgorithm,
    HandoverContext,
    HandoverDecision,
    AlgorithmInfo,
    AlgorithmType,
    HandoverDecisionType
)
from .registry import AlgorithmRegistry
from .environment_manager import EnvironmentManager

logger = logging.getLogger(__name__)


class OrchestratorMode(Enum):
    """å”èª¿å™¨æ¨¡å¼"""
    SINGLE_ALGORITHM = "single"  # å–®ä¸€ç®—æ³•æ¨¡å¼
    LOAD_BALANCING = "load_balancing"  # è² è¼‰å‡è¡¡æ¨¡å¼
    A_B_TESTING = "ab_testing"  # A/B æ¸¬è©¦æ¨¡å¼
    ENSEMBLE = "ensemble"  # é›†æˆæ¨¡å¼
    ADAPTIVE = "adaptive"  # è‡ªé©æ‡‰æ¨¡å¼


class DecisionStrategy(Enum):
    """æ±ºç­–ç­–ç•¥"""
    PRIORITY_BASED = "priority"  # åŸºæ–¼å„ªå…ˆç´š
    PERFORMANCE_BASED = "performance"  # åŸºæ–¼æ€§èƒ½
    ROUND_ROBIN = "round_robin"  # è¼ªè©¢
    WEIGHTED_RANDOM = "weighted_random"  # åŠ æ¬Šéš¨æ©Ÿ
    CONFIDENCE_BASED = "confidence"  # åŸºæ–¼ä¿¡å¿ƒåº¦


@dataclass
class AlgorithmMetrics:
    """ç®—æ³•æ€§èƒ½æŒ‡æ¨™"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    total_response_time: float = 0.0
    average_response_time: float = 0.0
    min_response_time: float = float('inf')
    max_response_time: float = 0.0
    success_rate: float = 0.0
    confidence_scores: List[float] = None
    average_confidence: float = 0.0
    last_used: Optional[datetime] = None
    
    def __post_init__(self):
        if self.confidence_scores is None:
            self.confidence_scores = []


@dataclass
class OrchestratorConfig:
    """å”èª¿å™¨é…ç½®"""
    mode: OrchestratorMode = OrchestratorMode.SINGLE_ALGORITHM
    decision_strategy: DecisionStrategy = DecisionStrategy.PRIORITY_BASED
    default_algorithm: Optional[str] = None
    fallback_algorithm: Optional[str] = None
    timeout_seconds: float = 5.0
    max_concurrent_requests: int = 100
    enable_caching: bool = True
    cache_ttl_seconds: int = 60
    enable_monitoring: bool = True
    monitoring_window_minutes: int = 10
    ab_test_config: Optional[Dict[str, Any]] = None
    ensemble_config: Optional[Dict[str, Any]] = None


class HandoverOrchestrator:
    """æ›æ‰‹å”èª¿å™¨
    
    çµ±ä¸€ç®¡ç†å’Œå”èª¿å¤šå€‹æ›æ‰‹ç®—æ³•çš„åŸ·è¡Œï¼Œæä¾›è² è¼‰å‡è¡¡ã€éŒ¯èª¤è™•ç†ã€
    æ€§èƒ½ç›£æ§å’Œ A/B æ¸¬è©¦ç­‰åŠŸèƒ½ã€‚
    """
    
    def __init__(
        self, 
        algorithm_registry: AlgorithmRegistry,
        environment_manager: EnvironmentManager,
        config: Optional[OrchestratorConfig] = None
    ):
        """åˆå§‹åŒ–å”èª¿å™¨
        
        Args:
            algorithm_registry: ç®—æ³•è¨»å†Šä¸­å¿ƒ
            environment_manager: ç’°å¢ƒç®¡ç†å™¨
            config: å”èª¿å™¨é…ç½®
        """
        self.algorithm_registry = algorithm_registry
        self.environment_manager = environment_manager
        self.config = config or OrchestratorConfig()
        
        # ç®—æ³•æ€§èƒ½æŒ‡æ¨™
        self._algorithm_metrics: Dict[str, AlgorithmMetrics] = defaultdict(AlgorithmMetrics)
        
        # æ±ºç­–ç·©å­˜
        self._decision_cache: Dict[str, Tuple[HandoverDecision, datetime]] = {}
        
        # ä¸¦ç™¼æ§åˆ¶
        self._concurrent_requests = 0
        self._request_semaphore = asyncio.Semaphore(self.config.max_concurrent_requests)
        
        # A/B æ¸¬è©¦é…ç½®
        self._ab_test_weights: Dict[str, float] = {}
        self._ab_test_results: Dict[str, List[float]] = defaultdict(list)
        self._active_ab_tests: Dict[str, Dict[str, float]] = {}  # test_id -> traffic_split
        
        # è‡ªé©æ‡‰å­¸ç¿’
        self._performance_history: Dict[str, deque] = defaultdict(
            lambda: deque(maxlen=1000)
        )
        
        # é›†æˆæŠ•ç¥¨è¨˜éŒ„
        self._ensemble_decisions: List[Tuple[str, HandoverDecision, datetime]] = []
        
        # è¼ªè©¢è¨ˆæ•¸å™¨
        self._round_robin_counter = 0
        
        self._initialized = False
        
        logger.info("æ›æ‰‹å”èª¿å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self) -> None:
        """åˆå§‹åŒ–å”èª¿å™¨"""
        if self._initialized:
            return
        
        logger.info("é–‹å§‹åˆå§‹åŒ–æ›æ‰‹å”èª¿å™¨...")
        
        # ç¢ºä¿ä¾è³´çµ„ä»¶å·²åˆå§‹åŒ–
        if not self.algorithm_registry._initialized:
            await self.algorithm_registry.initialize()
        
        if not self.environment_manager._initialized:
            await self.environment_manager.initialize()
        
        # åˆå§‹åŒ– A/B æ¸¬è©¦é…ç½®
        if self.config.mode == OrchestratorMode.A_B_TESTING:
            await self._initialize_ab_testing()
        
        # åˆå§‹åŒ–é›†æˆé…ç½®
        if self.config.mode == OrchestratorMode.ENSEMBLE:
            await self._initialize_ensemble()
        
        self._initialized = True
        logger.info("æ›æ‰‹å”èª¿å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def predict_handover(
        self, 
        context: HandoverContext,
        algorithm_name: Optional[str] = None,
        use_cache: bool = None
    ) -> HandoverDecision:
        """åŸ·è¡Œæ›æ‰‹é æ¸¬
        
        Args:
            context: æ›æ‰‹ä¸Šä¸‹æ–‡
            algorithm_name: æŒ‡å®šç®—æ³•åç¨±ï¼ˆå¯é¸ï¼‰
            use_cache: æ˜¯å¦ä½¿ç”¨ç·©å­˜ï¼ˆå¯é¸ï¼‰
            
        Returns:
            HandoverDecision: æ›æ‰‹æ±ºç­–
        """
        if not self._initialized:
            await self.initialize()
        
        # ä¸¦ç™¼æ§åˆ¶
        async with self._request_semaphore:
            self._concurrent_requests += 1
            
            try:
                start_time = time.time()
                
                # æª¢æŸ¥ç·©å­˜
                if use_cache is None:
                    use_cache = self.config.enable_caching
                
                if use_cache:
                    cached_decision = self._get_cached_decision(context)
                    if cached_decision:
                        logger.debug(f"è¿”å›ç·©å­˜æ±ºç­–: {context.ue_id}")
                        return cached_decision
                
                # é¸æ“‡ç®—æ³•
                if algorithm_name:
                    algorithm = self.algorithm_registry.get_algorithm(algorithm_name)
                    if not algorithm:
                        logger.error(f"æŒ‡å®šç®—æ³• '{algorithm_name}' ä¸å­˜åœ¨")
                        return await self._get_fallback_decision(context)
                    selected_algorithm_name = algorithm_name
                else:
                    algorithm, selected_algorithm_name = await self._select_algorithm(context)
                    if not algorithm:
                        logger.error("æ²’æœ‰å¯ç”¨çš„ç®—æ³•")
                        return await self._get_fallback_decision(context)
                
                # åŸ·è¡Œç®—æ³•
                try:
                    decision = await asyncio.wait_for(
                        algorithm.predict_handover(context),
                        timeout=self.config.timeout_seconds
                    )
                    
                    # è¨­ç½®ç®—æ³•åç¨±
                    decision.algorithm_name = selected_algorithm_name
                    
                    # è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
                    execution_time = (time.time() - start_time) * 1000
                    await self._record_algorithm_metrics(
                        selected_algorithm_name, 
                        execution_time, 
                        True, 
                        decision.confidence
                    )
                    
                    # ç·©å­˜æ±ºç­–
                    if use_cache:
                        self._cache_decision(context, decision)
                    
                    # A/B æ¸¬è©¦è¨˜éŒ„
                    if self.config.mode == OrchestratorMode.A_B_TESTING:
                        await self._record_ab_test_result(selected_algorithm_name, decision)
                    
                    # é›†æˆæ¨¡å¼è™•ç†
                    if self.config.mode == OrchestratorMode.ENSEMBLE:
                        decision = await self._handle_ensemble_decision(context, decision, selected_algorithm_name)
                    
                    logger.debug(f"ç®—æ³• '{selected_algorithm_name}' å®Œæˆæ±ºç­–: {decision.handover_decision}")
                    return decision
                    
                except asyncio.TimeoutError:
                    logger.error(f"ç®—æ³• '{selected_algorithm_name}' åŸ·è¡Œè¶…æ™‚")
                    await self._record_algorithm_metrics(selected_algorithm_name, self.config.timeout_seconds * 1000, False, 0.0)
                    return await self._get_fallback_decision(context)
                
                except Exception as e:
                    logger.error(f"ç®—æ³• '{selected_algorithm_name}' åŸ·è¡Œå¤±æ•—: {e}")
                    await self._record_algorithm_metrics(selected_algorithm_name, 0.0, False, 0.0)
                    return await self._get_fallback_decision(context)
                
            finally:
                self._concurrent_requests -= 1
    
    async def _select_algorithm(self, context: HandoverContext) -> Tuple[Optional[HandoverAlgorithm], Optional[str]]:
        """é¸æ“‡ç®—æ³•
        
        Args:
            context: æ›æ‰‹ä¸Šä¸‹æ–‡
            
        Returns:
            Tuple[HandoverAlgorithm, str]: é¸æ“‡çš„ç®—æ³•å’Œåç¨±
        """
        available_algorithms = self.algorithm_registry.list_enabled_algorithms()
        
        if not available_algorithms:
            return None, None
        
        if self.config.mode == OrchestratorMode.SINGLE_ALGORITHM:
            # å–®ä¸€ç®—æ³•æ¨¡å¼
            algorithm_name = self.config.default_algorithm or available_algorithms[0]
            algorithm = self.algorithm_registry.get_algorithm(algorithm_name)
            return algorithm, algorithm_name
        
        elif self.config.decision_strategy == DecisionStrategy.PRIORITY_BASED:
            # å„ªå…ˆç´šé¸æ“‡
            algorithm = self.algorithm_registry.get_best_algorithm("priority")
            algorithm_name = algorithm.name if algorithm else None
            return algorithm, algorithm_name
        
        elif self.config.decision_strategy == DecisionStrategy.PERFORMANCE_BASED:
            # æ€§èƒ½é¸æ“‡
            best_algorithm_name = self._get_best_performing_algorithm()
            algorithm = self.algorithm_registry.get_algorithm(best_algorithm_name)
            return algorithm, best_algorithm_name
        
        elif self.config.decision_strategy == DecisionStrategy.ROUND_ROBIN:
            # è¼ªè©¢é¸æ“‡
            algorithm_name = available_algorithms[self._round_robin_counter % len(available_algorithms)]
            self._round_robin_counter += 1
            algorithm = self.algorithm_registry.get_algorithm(algorithm_name)
            return algorithm, algorithm_name
        
        elif self.config.decision_strategy == DecisionStrategy.WEIGHTED_RANDOM:
            # åŠ æ¬Šéš¨æ©Ÿé¸æ“‡
            algorithm_name = self._weighted_random_selection(available_algorithms)
            algorithm = self.algorithm_registry.get_algorithm(algorithm_name)
            return algorithm, algorithm_name
        
        elif self.config.decision_strategy == DecisionStrategy.CONFIDENCE_BASED:
            # åŸºæ–¼æ­·å²ä¿¡å¿ƒåº¦é¸æ“‡
            algorithm_name = self._confidence_based_selection(available_algorithms)
            algorithm = self.algorithm_registry.get_algorithm(algorithm_name)
            return algorithm, algorithm_name
        
        else:
            # é»˜èªé¸æ“‡ç¬¬ä¸€å€‹å¯ç”¨ç®—æ³•
            algorithm_name = available_algorithms[0]
            algorithm = self.algorithm_registry.get_algorithm(algorithm_name)
            return algorithm, algorithm_name
    
    def _get_best_performing_algorithm(self) -> str:
        """ç²å–æ€§èƒ½æœ€ä½³çš„ç®—æ³•"""
        available_algorithms = self.algorithm_registry.list_enabled_algorithms()
        
        if not available_algorithms:
            return None
        
        best_algorithm = available_algorithms[0]
        best_score = 0.0
        
        for algorithm_name in available_algorithms:
            metrics = self._algorithm_metrics[algorithm_name]
            if metrics.total_requests > 0:
                # ç¶œåˆè©•åˆ†ï¼šæˆåŠŸç‡ * 0.6 + (1 - æ¨™æº–åŒ–éŸ¿æ‡‰æ™‚é–“) * 0.3 + å¹³å‡ä¿¡å¿ƒåº¦ * 0.1
                success_score = metrics.success_rate * 0.6
                
                # æ¨™æº–åŒ–éŸ¿æ‡‰æ™‚é–“ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
                if metrics.average_response_time > 0:
                    time_score = max(0, 1 - metrics.average_response_time / 1000) * 0.3
                else:
                    time_score = 0.3
                
                confidence_score = metrics.average_confidence * 0.1
                
                total_score = success_score + time_score + confidence_score
                
                if total_score > best_score:
                    best_score = total_score
                    best_algorithm = algorithm_name
        
        return best_algorithm
    
    def _weighted_random_selection(self, algorithms: List[str]) -> str:
        """åŠ æ¬Šéš¨æ©Ÿé¸æ“‡"""
        weights = []
        for algorithm_name in algorithms:
            metrics = self._algorithm_metrics[algorithm_name]
            if metrics.total_requests > 0:
                # æ¬Šé‡åŸºæ–¼æˆåŠŸç‡å’Œä¿¡å¿ƒåº¦
                weight = metrics.success_rate * metrics.average_confidence
            else:
                weight = 0.5  # é»˜èªæ¬Šé‡
            weights.append(weight)
        
        # æ­¸ä¸€åŒ–æ¬Šé‡
        total_weight = sum(weights)
        if total_weight > 0:
            weights = [w / total_weight for w in weights]
        else:
            weights = [1.0 / len(algorithms)] * len(algorithms)
        
        # éš¨æ©Ÿé¸æ“‡
        return np.random.choice(algorithms, p=weights)
    
    def _confidence_based_selection(self, algorithms: List[str]) -> str:
        """åŸºæ–¼ä¿¡å¿ƒåº¦çš„é¸æ“‡"""
        best_algorithm = algorithms[0]
        highest_confidence = 0.0
        
        for algorithm_name in algorithms:
            metrics = self._algorithm_metrics[algorithm_name]
            if metrics.average_confidence > highest_confidence:
                highest_confidence = metrics.average_confidence
                best_algorithm = algorithm_name
        
        return best_algorithm
    
    async def _get_fallback_decision(self, context: HandoverContext) -> HandoverDecision:
        """ç²å–å›é€€æ±ºç­–"""
        if self.config.fallback_algorithm:
            fallback_algorithm = self.algorithm_registry.get_algorithm(self.config.fallback_algorithm)
            if fallback_algorithm:
                try:
                    decision = await fallback_algorithm.predict_handover(context)
                    decision.algorithm_name = f"{self.config.fallback_algorithm} (fallback)"
                    return decision
                except Exception as e:
                    logger.error(f"å›é€€ç®—æ³•åŸ·è¡Œå¤±æ•—: {e}")
        
        # æœ€çµ‚å›é€€ï¼šå®‰å…¨æ±ºç­–
        return HandoverDecision(
            target_satellite=None,
            handover_decision=HandoverDecisionType.NO_HANDOVER,
            confidence=0.1,
            timing=None,
            decision_reason="Fallback: No algorithm available",
            algorithm_name="fallback",
            decision_time=0.0,
            metadata={"fallback": True}
        )
    
    async def _record_algorithm_metrics(
        self, 
        algorithm_name: str, 
        execution_time: float, 
        success: bool, 
        confidence: float
    ) -> None:
        """è¨˜éŒ„ç®—æ³•æ€§èƒ½æŒ‡æ¨™"""
        metrics = self._algorithm_metrics[algorithm_name]
        
        metrics.total_requests += 1
        if success:
            metrics.successful_requests += 1
        else:
            metrics.failed_requests += 1
        
        metrics.total_response_time += execution_time
        metrics.average_response_time = metrics.total_response_time / metrics.total_requests
        
        if execution_time < metrics.min_response_time:
            metrics.min_response_time = execution_time
        if execution_time > metrics.max_response_time:
            metrics.max_response_time = execution_time
        
        metrics.success_rate = metrics.successful_requests / metrics.total_requests
        
        if success:
            metrics.confidence_scores.append(confidence)
            if len(metrics.confidence_scores) > 100:
                metrics.confidence_scores.pop(0)
            metrics.average_confidence = sum(metrics.confidence_scores) / len(metrics.confidence_scores)
        
        metrics.last_used = datetime.now()
        
        # è¨˜éŒ„æ€§èƒ½æ­·å²
        self._performance_history[algorithm_name].append({
            'timestamp': datetime.now(),
            'execution_time': execution_time,
            'success': success,
            'confidence': confidence
        })
    
    def _get_cached_decision(self, context: HandoverContext) -> Optional[HandoverDecision]:
        """ç²å–ç·©å­˜æ±ºç­–"""
        cache_key = self._generate_cache_key(context)
        
        if cache_key in self._decision_cache:
            decision, timestamp = self._decision_cache[cache_key]
            
            # æª¢æŸ¥ç·©å­˜æ˜¯å¦éæœŸ
            if datetime.now() - timestamp < timedelta(seconds=self.config.cache_ttl_seconds):
                return decision
            else:
                # æ¸…ç†éæœŸç·©å­˜
                del self._decision_cache[cache_key]
        
        return None
    
    def _cache_decision(self, context: HandoverContext, decision: HandoverDecision) -> None:
        """ç·©å­˜æ±ºç­–"""
        cache_key = self._generate_cache_key(context)
        self._decision_cache[cache_key] = (decision, datetime.now())
        
        # æ¸…ç†éæœŸç·©å­˜
        current_time = datetime.now()
        expired_keys = [
            key for key, (_, timestamp) in self._decision_cache.items()
            if current_time - timestamp >= timedelta(seconds=self.config.cache_ttl_seconds)
        ]
        for key in expired_keys:
            del self._decision_cache[key]
    
    def _generate_cache_key(self, context: HandoverContext) -> str:
        """ç”Ÿæˆç·©å­˜éµ"""
        # åŸºæ–¼é—œéµä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆå”¯ä¸€éµ
        return f"{context.ue_id}_{context.current_satellite}_{len(context.candidate_satellites)}_{hash(str(context.network_state))}"
    
    async def _initialize_ab_testing(self) -> None:
        """åˆå§‹åŒ– A/B æ¸¬è©¦"""
        if not self.config.ab_test_config:
            return
        
        traffic_split = self.config.ab_test_config.get('traffic_split', {})
        total_weight = sum(traffic_split.values())
        
        if total_weight > 0:
            self._ab_test_weights = {
                name: weight / total_weight 
                for name, weight in traffic_split.items()
            }
        
        logger.info(f"A/B æ¸¬è©¦é…ç½®: {self._ab_test_weights}")
    
    async def _record_ab_test_result(self, algorithm_name: str, decision: HandoverDecision) -> None:
        """è¨˜éŒ„ A/B æ¸¬è©¦çµæœ"""
        # é€™è£¡å¯ä»¥è¨˜éŒ„å„ç¨®æŒ‡æ¨™ï¼Œå¦‚ä¿¡å¿ƒåº¦ã€æ±ºç­–é¡å‹ç­‰
        self._ab_test_results[algorithm_name].append(decision.confidence)
        
        # é™åˆ¶æ­·å²è¨˜éŒ„å¤§å°
        if len(self._ab_test_results[algorithm_name]) > 1000:
            self._ab_test_results[algorithm_name].pop(0)
    
    async def _initialize_ensemble(self) -> None:
        """åˆå§‹åŒ–é›†æˆæ¨¡å¼"""
        if not self.config.ensemble_config:
            self.config.ensemble_config = {
                'voting_strategy': 'majority',  # majority, weighted, confidence_based
                'min_algorithms': 2,
                'max_algorithms': 5
            }
        
        logger.info(f"é›†æˆæ¨¡å¼é…ç½®: {self.config.ensemble_config}")
    
    async def _handle_ensemble_decision(
        self, 
        context: HandoverContext, 
        current_decision: HandoverDecision, 
        algorithm_name: str
    ) -> HandoverDecision:
        """è™•ç†é›†æˆæ±ºç­–"""
        # è¨˜éŒ„ç•¶å‰æ±ºç­–
        self._ensemble_decisions.append((algorithm_name, current_decision, datetime.now()))
        
        # æ¸…ç†èˆŠæ±ºç­–ï¼ˆåªä¿ç•™æœ€è¿‘ä¸€æ®µæ™‚é–“çš„ï¼‰
        cutoff_time = datetime.now() - timedelta(seconds=1)
        self._ensemble_decisions = [
            (name, decision, timestamp) for name, decision, timestamp in self._ensemble_decisions
            if timestamp > cutoff_time
        ]
        
        min_algorithms = self.config.ensemble_config.get('min_algorithms', 2)
        
        # å¦‚æœæ±ºç­–æ•¸é‡ä¸è¶³ï¼Œç›´æ¥è¿”å›ç•¶å‰æ±ºç­–
        if len(self._ensemble_decisions) < min_algorithms:
            return current_decision
        
        # åŸ·è¡Œé›†æˆæŠ•ç¥¨
        voting_strategy = self.config.ensemble_config.get('voting_strategy', 'majority')
        
        if voting_strategy == 'majority':
            return self._majority_voting()
        elif voting_strategy == 'weighted':
            return self._weighted_voting()
        elif voting_strategy == 'confidence_based':
            return self._confidence_voting()
        else:
            return current_decision
    
    def _majority_voting(self) -> HandoverDecision:
        """å¤šæ•¸æŠ•ç¥¨"""
        decisions = [decision for _, decision, _ in self._ensemble_decisions]
        
        # çµ±è¨ˆæ±ºç­–é¡å‹
        decision_counts = defaultdict(int)
        for decision in decisions:
            decision_counts[decision.handover_decision] += 1
        
        # æ‰¾å‡ºå¤šæ•¸æ±ºç­–
        majority_decision = max(decision_counts.items(), key=lambda x: x[1])[0]
        
        # æ‰¾å‡ºå…·æœ‰è©²æ±ºç­–é¡å‹ä¸”ä¿¡å¿ƒåº¦æœ€é«˜çš„æ±ºç­–
        best_decision = None
        highest_confidence = 0.0
        
        for decision in decisions:
            if decision.handover_decision == majority_decision and decision.confidence > highest_confidence:
                highest_confidence = decision.confidence
                best_decision = decision
        
        if best_decision:
            best_decision.algorithm_name += " (ensemble)"
            best_decision.metadata['ensemble_voting'] = 'majority'
            best_decision.metadata['ensemble_count'] = len(decisions)
        
        return best_decision or decisions[0]
    
    def _weighted_voting(self) -> HandoverDecision:
        """åŠ æ¬ŠæŠ•ç¥¨"""
        decisions = [decision for _, decision, _ in self._ensemble_decisions]
        algorithm_names = [name for name, _, _ in self._ensemble_decisions]
        
        # æ ¹æ“šç®—æ³•æ€§èƒ½è¨ˆç®—æ¬Šé‡
        weights = []
        for name in algorithm_names:
            metrics = self._algorithm_metrics[name]
            weight = metrics.success_rate * metrics.average_confidence if metrics.total_requests > 0 else 0.5
            weights.append(weight)
        
        # åŠ æ¬ŠæŠ•ç¥¨
        decision_scores = defaultdict(float)
        for i, decision in enumerate(decisions):
            decision_scores[decision.handover_decision] += weights[i]
        
        # é¸æ“‡å¾—åˆ†æœ€é«˜çš„æ±ºç­–é¡å‹
        best_decision_type = max(decision_scores.items(), key=lambda x: x[1])[0]
        
        # æ‰¾å‡ºè©²é¡å‹ä¸­ä¿¡å¿ƒåº¦æœ€é«˜çš„æ±ºç­–
        best_decision = None
        highest_confidence = 0.0
        
        for decision in decisions:
            if decision.handover_decision == best_decision_type and decision.confidence > highest_confidence:
                highest_confidence = decision.confidence
                best_decision = decision
        
        if best_decision:
            best_decision.algorithm_name += " (ensemble)"
            best_decision.metadata['ensemble_voting'] = 'weighted'
            best_decision.metadata['ensemble_count'] = len(decisions)
        
        return best_decision or decisions[0]
    
    def _confidence_voting(self) -> HandoverDecision:
        """åŸºæ–¼ä¿¡å¿ƒåº¦çš„æŠ•ç¥¨"""
        decisions = [decision for _, decision, _ in self._ensemble_decisions]
        
        # ç›´æ¥é¸æ“‡ä¿¡å¿ƒåº¦æœ€é«˜çš„æ±ºç­–
        best_decision = max(decisions, key=lambda x: x.confidence)
        best_decision.algorithm_name += " (ensemble)"
        best_decision.metadata['ensemble_voting'] = 'confidence_based'
        best_decision.metadata['ensemble_count'] = len(decisions)
        
        return best_decision
    
    def get_orchestrator_stats(self) -> Dict[str, Any]:
        """ç²å–å”èª¿å™¨çµ±è¨ˆä¿¡æ¯"""
        return {
            'mode': self.config.mode.value,
            'decision_strategy': self.config.decision_strategy.value,
            'algorithm_metrics': {
                name: asdict(metrics) for name, metrics in self._algorithm_metrics.items()
            },
            'concurrent_requests': self._concurrent_requests,
            'cache_size': len(self._decision_cache),
            'ab_test_results': dict(self._ab_test_results) if self.config.mode == OrchestratorMode.A_B_TESTING else {},
            'performance_history_size': {
                name: len(history) for name, history in self._performance_history.items()
            },
            'initialized': self._initialized
        }
    
    async def update_config(self, new_config: OrchestratorConfig) -> None:
        """æ›´æ–°å”èª¿å™¨é…ç½®"""
        self.config = new_config
        
        # é‡æ–°åˆå§‹åŒ–ç›¸é—œçµ„ä»¶
        if self.config.mode == OrchestratorMode.A_B_TESTING:
            await self._initialize_ab_testing()
        elif self.config.mode == OrchestratorMode.ENSEMBLE:
            await self._initialize_ensemble()
        
        logger.info("å”èª¿å™¨é…ç½®æ›´æ–°å®Œæˆ")
    
    async def cleanup(self) -> None:
        """æ¸…ç†è³‡æº"""
        logger.info("é–‹å§‹æ¸…ç†æ›æ‰‹å”èª¿å™¨...")
        
        # æ¸…ç†ç·©å­˜
        self._decision_cache.clear()
        
        # æ¸…ç†çµ±è¨ˆä¿¡æ¯
        self._algorithm_metrics.clear()
        self._ab_test_results.clear()
        self._performance_history.clear()
        self._ensemble_decisions.clear()
        
        self._initialized = False
        logger.info("æ›æ‰‹å”èª¿å™¨æ¸…ç†å®Œæˆ")
    
    # A/B æ¸¬è©¦æ”¯æŒæ–¹æ³•ï¼ˆç”¨æ–¼åˆ†æå¼•æ“ï¼‰
    def set_ab_test_config(self, test_id: str, traffic_split: Dict[str, float]) -> None:
        """è¨­ç½® A/B æ¸¬è©¦é…ç½®
        
        Args:
            test_id: æ¸¬è©¦ID
            traffic_split: æµé‡åˆ†é…æ¯”ä¾‹
        """
        self._active_ab_tests[test_id] = traffic_split
        self._ab_test_weights = traffic_split
        
        # æ›´æ–°æ¨¡å¼ç‚º A/B æ¸¬è©¦
        if self.config.mode != OrchestratorMode.A_B_TESTING:
            self.config.mode = OrchestratorMode.A_B_TESTING
        
        logger.info(f"è¨­ç½® A/B æ¸¬è©¦é…ç½®: {test_id} -> {traffic_split}")
    
    def clear_ab_test_config(self, test_id: str) -> None:
        """æ¸…é™¤ A/B æ¸¬è©¦é…ç½®
        
        Args:
            test_id: æ¸¬è©¦ID
        """
        if test_id in self._active_ab_tests:
            del self._active_ab_tests[test_id]
        
        # å¦‚æœæ²’æœ‰æ´»èºçš„ A/B æ¸¬è©¦ï¼Œåˆ‡æ›å›å–®ä¸€ç®—æ³•æ¨¡å¼
        if not self._active_ab_tests:
            self._ab_test_weights.clear()
            self.config.mode = OrchestratorMode.SINGLE_ALGORITHM
        
        logger.info(f"æ¸…é™¤ A/B æ¸¬è©¦é…ç½®: {test_id}")
    
    def get_ab_test_performance(self, test_id: str) -> Dict[str, Any]:
        """ç²å– A/B æ¸¬è©¦æ€§èƒ½æ•¸æ“š
        
        Args:
            test_id: æ¸¬è©¦ID
            
        Returns:
            Dict[str, Any]: æ€§èƒ½æ•¸æ“š
        """
        if test_id not in self._active_ab_tests:
            return {}
        
        traffic_split = self._active_ab_tests[test_id]
        performance_data = {}
        
        for algorithm_name in traffic_split.keys():
            if algorithm_name in self._algorithm_metrics:
                metrics = self._algorithm_metrics[algorithm_name]
                performance_data[algorithm_name] = {
                    'total_requests': metrics.total_requests,
                    'success_rate': metrics.success_rate,
                    'average_response_time': metrics.average_response_time,
                    'average_confidence': metrics.average_confidence,
                    'traffic_allocation': traffic_split[algorithm_name]
                }
        
        return performance_data
    
    def export_metrics_for_analysis(self) -> Dict[str, Any]:
        """å°å‡ºæŒ‡æ¨™æ•¸æ“šä¾›åˆ†æå¼•æ“ä½¿ç”¨
        
        Returns:
            Dict[str, Any]: æŒ‡æ¨™æ•¸æ“š
        """
        export_data = {
            'algorithm_metrics': {},
            'performance_history': {},
            'ab_test_results': dict(self._ab_test_results),
            'active_ab_tests': self._active_ab_tests.copy(),
            'ensemble_decisions': [
                {
                    'algorithm_name': name,
                    'handover_decision': decision.handover_decision.name,
                    'confidence': decision.confidence,
                    'timestamp': timestamp.isoformat()
                }
                for name, decision, timestamp in self._ensemble_decisions
            ]
        }
        
        # å°å‡ºç®—æ³•æŒ‡æ¨™
        for name, metrics in self._algorithm_metrics.items():
            export_data['algorithm_metrics'][name] = {
                'total_requests': metrics.total_requests,
                'success_rate': metrics.success_rate,
                'average_response_time': metrics.average_response_time,
                'min_response_time': metrics.min_response_time,
                'max_response_time': metrics.max_response_time,
                'average_confidence': metrics.average_confidence,
                'last_used': metrics.last_used.isoformat() if metrics.last_used else None
            }
        
        # å°å‡ºæ€§èƒ½æ­·å²
        for name, history in self._performance_history.items():
            export_data['performance_history'][name] = [
                {
                    'timestamp': record['timestamp'].isoformat(),
                    'execution_time': record['execution_time'],
                    'success': record['success'],
                    'confidence': record['confidence']
                }
                for record in list(history)
            ]
        
        return export_data