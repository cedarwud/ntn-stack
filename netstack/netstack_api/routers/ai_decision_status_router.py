"""
ğŸ¤– AI æ±ºç­–ç‹€æ…‹è·¯ç”±å™¨

æä¾› AI æ±ºç­–ç³»çµ±ç‹€æ…‹ä¿¡æ¯ï¼Œèˆ‡ RL ç›£æ§é…åˆå·¥ä½œã€‚
"""

import logging
from datetime import datetime
from typing import Dict, Any
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field

# å˜—è©¦å°å…¥ç®—æ³•ç”Ÿæ…‹ç³»çµ±çµ„ä»¶
try:
    from ..algorithm_ecosystem import AlgorithmEcosystemManager
    ECOSYSTEM_AVAILABLE = True
except ImportError:
    ECOSYSTEM_AVAILABLE = False
    # å®šç¾©é¡å‹åˆ¥åé¿å…é‹è¡Œæ™‚éŒ¯èª¤
    AlgorithmEcosystemManager = None

# å˜—è©¦å°å…¥ RL ç›£æ§è·¯ç”±å™¨çš„è¨“ç·´æœƒè©±æ•¸æ“š
try:
    from .rl_monitoring_router import training_sessions, ecosystem_manager
    RL_MONITORING_AVAILABLE = True
except ImportError:
    RL_MONITORING_AVAILABLE = False
    training_sessions = {}
    ecosystem_manager = None

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/v1/ai-decision", tags=["AI æ±ºç­–ç‹€æ…‹"])

class AIDecisionStatusResponse(BaseModel):
    """AI æ±ºç­–ç‹€æ…‹éŸ¿æ‡‰æ¨¡å‹"""
    environment: str = Field(..., description="ç’°å¢ƒåç¨±")
    training_stats: Dict[str, Any] = Field({}, description="è¨“ç·´çµ±è¨ˆ")
    prediction_accuracy: float = Field(0.0, description="é æ¸¬æº–ç¢ºç‡")
    training_progress: float = Field(0.0, description="è¨“ç·´é€²åº¦")
    model_version: str = Field("2.0.0", description="æ¨¡å‹ç‰ˆæœ¬")

async def get_ecosystem_manager() -> Any:
    """ç²å–ç”Ÿæ…‹ç³»çµ±ç®¡ç†å™¨"""
    global ecosystem_manager
    
    if not ECOSYSTEM_AVAILABLE:
        raise HTTPException(status_code=503, detail="ç®—æ³•ç”Ÿæ…‹ç³»çµ±ä¸å¯ç”¨")
    
    if ecosystem_manager is None:
        if AlgorithmEcosystemManager is not None:
            ecosystem_manager = AlgorithmEcosystemManager()
            await ecosystem_manager.initialize()
        else:
            raise HTTPException(status_code=503, detail="AlgorithmEcosystemManager é¡å‹ä¸å¯ç”¨")
    
    return ecosystem_manager

@router.get("/status", response_model=AIDecisionStatusResponse)
async def get_ai_decision_status():
    """ç²å– AI æ±ºç­–ç³»çµ±ç‹€æ…‹"""
    try:
        manager = await get_ecosystem_manager()
        system_status = manager.get_system_status()
        
        # è¨ˆç®—æ•´é«”è¨“ç·´é€²åº¦
        total_progress = 0.0
        algorithm_count = 0
        
        for session in training_sessions.values():
            if session['status'] == 'active':
                progress = (session['episodes_completed'] / session['episodes_target']) * 100
                total_progress += progress
                algorithm_count += 1
        
        overall_progress = total_progress / algorithm_count if algorithm_count > 0 else 0.0
        
        # æ§‹å»ºè¨“ç·´çµ±è¨ˆ
        training_stats = {
            'active_sessions': len([s for s in training_sessions.values() if s['status'] == 'active']),
            'total_sessions': len(training_sessions),
            'algorithms_available': len(system_status.get('registered_algorithms', [])),
            'system_uptime_hours': system_status.get('uptime_seconds', 0) / 3600
        }
        
        # å¾æ€§èƒ½åˆ†æå¼•æ“ç²å–é æ¸¬æº–ç¢ºç‡
        prediction_accuracy = 0.87  # é è¨­å€¼
        try:
            if hasattr(manager, 'analysis_engine') and manager.analysis_engine:
                # é€™è£¡å¯ä»¥å¾åˆ†æå¼•æ“ç²å–å¯¦éš›çš„é æ¸¬æº–ç¢ºç‡
                performance_report = manager.generate_performance_report()
                # å¾å ±å‘Šä¸­æå–æº–ç¢ºç‡ä¿¡æ¯
                if 'summary' in performance_report and 'best_by_metric' in performance_report['summary']:
                    accuracy_metric = performance_report['summary']['best_by_metric'].get('prediction_accuracy')
                    if accuracy_metric:
                        prediction_accuracy = accuracy_metric.get('value', 0.87)
        except Exception as e:
            logger.warning(f"ç„¡æ³•ç²å–å¯¦éš›é æ¸¬æº–ç¢ºç‡: {e}")
        
        return AIDecisionStatusResponse(
            environment="LEOSatelliteHandoverEnv-v1",
            training_stats=training_stats,
            prediction_accuracy=prediction_accuracy,
            training_progress=overall_progress,
            model_version="2.0.0"
        )
        
    except Exception as e:
        logger.error(f"ç²å– AI æ±ºç­–ç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å– AI æ±ºç­–ç‹€æ…‹å¤±æ•—: {str(e)}")

@router.get("/health")
async def ai_decision_health_check():
    """AI æ±ºç­–ç³»çµ±å¥åº·æª¢æŸ¥"""
    try:
        status = "healthy"
        details = {}
        
        # æª¢æŸ¥ç”Ÿæ…‹ç³»çµ±æ˜¯å¦å¯ç”¨
        if ECOSYSTEM_AVAILABLE:
            try:
                manager = await get_ecosystem_manager()
                system_status = manager.get_system_status()
                details['ecosystem_status'] = system_status['status']
                details['registered_algorithms'] = len(system_status.get('registered_algorithms', []))
            except Exception as e:
                status = "degraded"
                details['ecosystem_error'] = str(e)
        else:
            status = "degraded"
            details['ecosystem_available'] = False
        
        # æª¢æŸ¥ RL ç›£æ§é€£æ¥
        details['rl_monitoring_available'] = RL_MONITORING_AVAILABLE
        details['active_training_sessions'] = len([s for s in training_sessions.values() if s['status'] == 'active'])
        
        return {
            "status": status,
            "timestamp": datetime.now().isoformat(),
            "details": details
        }
        
    except Exception as e:
        logger.error(f"AI æ±ºç­–å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
        return {
            "status": "error",
            "timestamp": datetime.now().isoformat(),
            "error": str(e)
        }