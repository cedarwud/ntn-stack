"""
ğŸ§  RL ç›£æ§è·¯ç”±å™¨

ç‚ºå‰ç«¯ RL ç›£æ§å„€è¡¨æ¿æä¾› API ç«¯é»ï¼Œæ”¯æŒè¨“ç·´ç‹€æ…‹ç›£æ§ã€ç®—æ³•ç®¡ç†å’Œæ€§èƒ½åˆ†æã€‚
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from fastapi import APIRouter, HTTPException, BackgroundTasks, Query
from pydantic import BaseModel, Field
import psutil

try:
    import GPUtil
    GPU_AVAILABLE = True
except ImportError:
    GPU_AVAILABLE = False

# å˜—è©¦å°å…¥ç®—æ³•ç”Ÿæ…‹ç³»çµ±çµ„ä»¶
try:
    from ..algorithm_ecosystem import (
        AlgorithmEcosystemManager,
        PerformanceAnalysisEngine, 
        RLTrainingPipeline
    )
    ECOSYSTEM_AVAILABLE = True
except ImportError:
    ECOSYSTEM_AVAILABLE = False
    # å®šç¾©é¡å‹åˆ¥åé¿å…é‹è¡Œæ™‚éŒ¯èª¤
    AlgorithmEcosystemManager = None
    PerformanceAnalysisEngine = None
    RLTrainingPipeline = None

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/v1/rl", tags=["RL ç›£æ§"])

# å…¨å±€è®Šé‡
ecosystem_manager: Optional[Any] = None
training_sessions: Dict[str, Dict[str, Any]] = {}

class RLEngineMetrics(BaseModel):
    """RL å¼•æ“æŒ‡æ¨™æ•¸æ“šæ¨¡å‹"""
    engine_type: str = Field(..., description="å¼•æ“é¡å‹ (dqn, ppo, sac, null)")
    algorithm: str = Field(..., description="ç®—æ³•åç¨±")
    environment: str = Field(..., description="ç’°å¢ƒåç¨±")
    model_status: str = Field(..., description="æ¨¡å‹ç‹€æ…‹ (training, inference, idle, error)")
    episodes_completed: int = Field(0, description="å·²å®Œæˆå›åˆæ•¸")
    average_reward: float = Field(0.0, description="å¹³å‡çå‹µ")
    current_epsilon: float = Field(0.0, description="ç•¶å‰æ¢ç´¢ç‡")
    training_progress: float = Field(0.0, description="è¨“ç·´é€²åº¦ (0-100)")
    prediction_accuracy: float = Field(0.0, description="é æ¸¬æº–ç¢ºç‡")
    response_time_ms: float = Field(0.0, description="éŸ¿æ‡‰æ™‚é–“ (æ¯«ç§’)")
    memory_usage: float = Field(0.0, description="è¨˜æ†¶é«”ä½¿ç”¨ç‡")
    gpu_utilization: Optional[float] = Field(None, description="GPU ä½¿ç”¨ç‡")

class SystemResourcesModel(BaseModel):
    """ç³»çµ±è³‡æºæ¨¡å‹"""
    cpu_usage: float = Field(..., description="CPU ä½¿ç”¨ç‡")
    memory_usage: float = Field(..., description="è¨˜æ†¶é«”ä½¿ç”¨ç‡")
    disk_usage: float = Field(..., description="ç£ç¢Ÿä½¿ç”¨ç‡")
    gpu_utilization: Optional[float] = Field(None, description="GPU ä½¿ç”¨ç‡")
    avg_response_time: float = Field(0.0, description="å¹³å‡éŸ¿æ‡‰æ™‚é–“")

class TrainingSessionModel(BaseModel):
    """è¨“ç·´æœƒè©±æ¨¡å‹"""
    session_id: str = Field(..., description="æœƒè©± ID")
    algorithm_name: str = Field(..., description="ç®—æ³•åç¨±")
    status: str = Field(..., description="ç‹€æ…‹ (active, paused, completed, error)")
    start_time: datetime = Field(..., description="é–‹å§‹æ™‚é–“")
    episodes_target: int = Field(..., description="ç›®æ¨™å›åˆæ•¸")
    episodes_completed: int = Field(0, description="å·²å®Œæˆå›åˆæ•¸")
    current_reward: float = Field(0.0, description="ç•¶å‰çå‹µ")
    best_reward: float = Field(0.0, description="æœ€ä½³çå‹µ")

class RLStatusResponse(BaseModel):
    """RL ç‹€æ…‹éŸ¿æ‡‰æ¨¡å‹"""
    engines: Dict[str, RLEngineMetrics] = Field(..., description="RL å¼•æ“æŒ‡æ¨™")
    system_resources: SystemResourcesModel = Field(..., description="ç³»çµ±è³‡æº")
    training_active: bool = Field(False, description="æ˜¯å¦æœ‰æ´»èºçš„è¨“ç·´")
    available_algorithms: List[str] = Field([], description="å¯ç”¨ç®—æ³•åˆ—è¡¨")

class AIDecisionStatusResponse(BaseModel):
    """AI æ±ºç­–ç‹€æ…‹éŸ¿æ‡‰æ¨¡å‹"""
    environment: str = Field(..., description="ç’°å¢ƒåç¨±")
    training_stats: Dict[str, Any] = Field({}, description="è¨“ç·´çµ±è¨ˆ")
    prediction_accuracy: float = Field(0.0, description="é æ¸¬æº–ç¢ºç‡")
    training_progress: float = Field(0.0, description="è¨“ç·´é€²åº¦")
    model_version: str = Field("1.0.0", description="æ¨¡å‹ç‰ˆæœ¬")

async def get_ecosystem_manager() -> Any:
    """ç²å–ç”Ÿæ…‹ç³»çµ±ç®¡ç†å™¨"""
    global ecosystem_manager
    
    if not ECOSYSTEM_AVAILABLE:
        raise HTTPException(status_code=503, detail="ç®—æ³•ç”Ÿæ…‹ç³»çµ±ä¸å¯ç”¨")
    
    if ecosystem_manager is None:
        if AlgorithmEcosystemManager is not None:
            ecosystem_manager = AlgorithmEcosystemManager()
            await ecosystem_manager.initialize()
        else:
            raise HTTPException(status_code=503, detail="AlgorithmEcosystemManager é¡å‹ä¸å¯ç”¨")
    
    return ecosystem_manager

def get_system_resources() -> SystemResourcesModel:
    """ç²å–ç³»çµ±è³‡æºä¿¡æ¯"""
    try:
        # CPU ä½¿ç”¨ç‡
        cpu_usage = psutil.cpu_percent(interval=1)
        
        # è¨˜æ†¶é«”ä½¿ç”¨ç‡
        memory = psutil.virtual_memory()
        memory_usage = memory.percent
        
        # ç£ç¢Ÿä½¿ç”¨ç‡
        disk = psutil.disk_usage('/')
        disk_usage = (disk.used / disk.total) * 100
        
        # GPU ä½¿ç”¨ç‡
        gpu_utilization = None
        if GPU_AVAILABLE:
            try:
                gpus = GPUtil.getGPUs()
                if gpus:
                    gpu_utilization = gpus[0].load * 100
            except Exception:
                pass
        
        return SystemResourcesModel(
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            disk_usage=disk_usage,
            gpu_utilization=gpu_utilization,
            avg_response_time=50.0  # é è¨­å€¼ï¼Œå¯ä»¥å¾å¯¦éš›æŒ‡æ¨™ä¸­ç²å–
        )
        
    except Exception as e:
        logger.error(f"ç²å–ç³»çµ±è³‡æºå¤±æ•—: {e}")
        return SystemResourcesModel(
            cpu_usage=0.0,
            memory_usage=0.0,
            disk_usage=0.0,
            avg_response_time=0.0
        )

def create_mock_rl_metrics(engine_type: str, algorithm: str) -> RLEngineMetrics:
    """å‰µå»ºæ¨¡æ“¬ RL æŒ‡æ¨™ï¼ˆç•¶å¯¦éš›è¨“ç·´ä¸æ´»èºæ™‚ä½¿ç”¨ï¼‰"""
    import random
    
    base_episode = random.randint(1000, 5000)
    base_reward = random.uniform(-100, 300)
    
    return RLEngineMetrics(
        engine_type=engine_type,
        algorithm=algorithm,
        environment="LEOSatelliteHandoverEnv-v1",
        model_status="idle",
        episodes_completed=base_episode,
        average_reward=base_reward,
        current_epsilon=random.uniform(0.01, 0.3),
        training_progress=random.uniform(60, 95),
        prediction_accuracy=random.uniform(0.75, 0.92),
        response_time_ms=random.uniform(20, 80),
        memory_usage=random.uniform(30, 70),
        gpu_utilization=random.uniform(0, 20) if GPU_AVAILABLE else None
    )

@router.get("/status", response_model=RLStatusResponse)
async def get_rl_status():
    """ç²å– RL ç³»çµ±ç‹€æ…‹"""
    try:
        manager = await get_ecosystem_manager()
        
        # ç²å–å·²è¨»å†Šçš„ç®—æ³•
        available_algorithms = manager.get_registered_algorithms()
        
        # ç²å–ç³»çµ±ç‹€æ…‹
        system_status = manager.get_system_status()
        
        # æ§‹å»ºå¼•æ“æŒ‡æ¨™
        engines = {}
        training_active = False
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ´»èºçš„è¨“ç·´
        active_ab_tests = system_status.get('active_ab_tests', {})
        training_active = len(active_ab_tests) > 0 or len(training_sessions) > 0
        
        # ç‚ºä¸»è¦çš„ RL ç®—æ³•å‰µå»ºæŒ‡æ¨™
        rl_algorithms = ['dqn_handover', 'ppo_handover', 'sac_handover']
        
        for algorithm in rl_algorithms:
            if algorithm in available_algorithms:
                engine_type = algorithm.split('_')[0]  # æå–å¼•æ“é¡å‹
                
                # å˜—è©¦å¾è¨“ç·´æœƒè©±ç²å–çœŸå¯¦æ•¸æ“š
                real_metrics = None
                for session_id, session in training_sessions.items():
                    if session['algorithm_name'] == algorithm:
                        real_metrics = session
                        break
                
                if real_metrics:
                    engines[engine_type] = RLEngineMetrics(
                        engine_type=engine_type,
                        algorithm=algorithm,
                        environment="LEOSatelliteHandoverEnv-v1",
                        model_status="training" if real_metrics['status'] == 'active' else "idle",
                        episodes_completed=real_metrics['episodes_completed'],
                        average_reward=real_metrics['current_reward'],
                        current_epsilon=0.1,  # å¯ä»¥å¾ç®—æ³•å¯¦ä¾‹ç²å–
                        training_progress=(real_metrics['episodes_completed'] / real_metrics['episodes_target']) * 100,
                        prediction_accuracy=0.85,  # å¯ä»¥å¾æ€§èƒ½åˆ†æå¼•æ“ç²å–
                        response_time_ms=50.0,
                        memory_usage=psutil.virtual_memory().percent,
                        gpu_utilization=None
                    )
                else:
                    engines[engine_type] = create_mock_rl_metrics(engine_type, algorithm)
        
        # å¦‚æœæ²’æœ‰ RL ç®—æ³•ï¼Œå‰µå»ºç©ºå¼•æ“
        if not engines:
            engines['null'] = RLEngineMetrics(
                engine_type='null',
                algorithm='none',
                environment='none',
                model_status='idle',
                episodes_completed=0,
                average_reward=0.0,
                current_epsilon=0.0,
                training_progress=0.0,
                prediction_accuracy=0.0,
                response_time_ms=0.0,
                memory_usage=0.0
            )
        
        return RLStatusResponse(
            engines=engines,
            system_resources=get_system_resources(),
            training_active=training_active,
            available_algorithms=available_algorithms
        )
        
    except Exception as e:
        logger.error(f"ç²å– RL ç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å– RL ç‹€æ…‹å¤±æ•—: {str(e)}")

@router.get("/ai-decision/status", response_model=AIDecisionStatusResponse)
async def get_ai_decision_status():
    """ç²å– AI æ±ºç­–ç³»çµ±ç‹€æ…‹"""
    try:
        manager = await get_ecosystem_manager()
        system_status = manager.get_system_status()
        
        # è¨ˆç®—æ•´é«”è¨“ç·´é€²åº¦
        total_progress = 0.0
        algorithm_count = 0
        
        for session in training_sessions.values():
            if session['status'] == 'active':
                progress = (session['episodes_completed'] / session['episodes_target']) * 100
                total_progress += progress
                algorithm_count += 1
        
        overall_progress = total_progress / algorithm_count if algorithm_count > 0 else 0.0
        
        # æ§‹å»ºè¨“ç·´çµ±è¨ˆ
        training_stats = {
            'active_sessions': len([s for s in training_sessions.values() if s['status'] == 'active']),
            'total_sessions': len(training_sessions),
            'algorithms_available': len(system_status.get('registered_algorithms', [])),
            'system_uptime_hours': system_status.get('uptime_seconds', 0) / 3600
        }
        
        return AIDecisionStatusResponse(
            environment="LEOSatelliteHandoverEnv-v1",
            training_stats=training_stats,
            prediction_accuracy=0.87,  # å¯ä»¥å¾åˆ†æå¼•æ“ç²å–å¯¦éš›æ•¸æ“š
            training_progress=overall_progress,
            model_version="2.0.0"
        )
        
    except Exception as e:
        logger.error(f"ç²å– AI æ±ºç­–ç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å– AI æ±ºç­–ç‹€æ…‹å¤±æ•—: {str(e)}")

@router.get("/training/sessions", response_model=List[TrainingSessionModel])
async def get_training_sessions():
    """ç²å–è¨“ç·´æœƒè©±åˆ—è¡¨"""
    try:
        sessions = []
        for session_id, session_data in training_sessions.items():
            sessions.append(TrainingSessionModel(
                session_id=session_id,
                algorithm_name=session_data['algorithm_name'],
                status=session_data['status'],
                start_time=session_data['start_time'],
                episodes_target=session_data['episodes_target'],
                episodes_completed=session_data['episodes_completed'],
                current_reward=session_data['current_reward'],
                best_reward=session_data['best_reward']
            ))
        
        return sessions
        
    except Exception as e:
        logger.error(f"ç²å–è¨“ç·´æœƒè©±å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–è¨“ç·´æœƒè©±å¤±æ•—: {str(e)}")

@router.post("/training/start/{algorithm_name}")
async def start_training(
    algorithm_name: str,
    episodes: int = Query(1000, description="è¨“ç·´å›åˆæ•¸"),
    background_tasks: BackgroundTasks = None
):
    """å•Ÿå‹•ç®—æ³•è¨“ç·´"""
    try:
        manager = await get_ecosystem_manager()
        
        # æª¢æŸ¥ç®—æ³•æ˜¯å¦å­˜åœ¨
        available_algorithms = manager.get_registered_algorithms()
        if algorithm_name not in available_algorithms:
            raise HTTPException(status_code=404, detail=f"ç®—æ³• '{algorithm_name}' ä¸å­˜åœ¨")
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰æ´»èºçš„è¨“ç·´æœƒè©±
        for session in training_sessions.values():
            if session['algorithm_name'] == algorithm_name and session['status'] == 'active':
                raise HTTPException(status_code=409, detail=f"ç®—æ³• '{algorithm_name}' å·²åœ¨è¨“ç·´ä¸­")
        
        # å‰µå»ºè¨“ç·´æœƒè©±
        session_id = f"{algorithm_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        training_sessions[session_id] = {
            'algorithm_name': algorithm_name,
            'status': 'active',
            'start_time': datetime.now(),
            'episodes_target': episodes,
            'episodes_completed': 0,
            'current_reward': 0.0,
            'best_reward': -float('inf')
        }
        
        # åœ¨èƒŒæ™¯å•Ÿå‹•è¨“ç·´
        if background_tasks:
            background_tasks.add_task(run_training_session, manager, session_id, algorithm_name, episodes)
        else:
            # å¦‚æœæ²’æœ‰èƒŒæ™¯ä»»å‹™ï¼Œä½¿ç”¨ asyncio å‰µå»ºä»»å‹™
            asyncio.create_task(run_training_session(manager, session_id, algorithm_name, episodes))
        
        return {
            "message": f"ç®—æ³• '{algorithm_name}' è¨“ç·´å·²å•Ÿå‹•",
            "session_id": session_id,
            "episodes": episodes
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å•Ÿå‹•è¨“ç·´å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"å•Ÿå‹•è¨“ç·´å¤±æ•—: {str(e)}")

@router.post("/training/stop/{session_id}")
async def stop_training(session_id: str):
    """åœæ­¢è¨“ç·´æœƒè©±"""
    try:
        if session_id not in training_sessions:
            raise HTTPException(status_code=404, detail=f"è¨“ç·´æœƒè©± '{session_id}' ä¸å­˜åœ¨")
        
        session = training_sessions[session_id]
        if session['status'] != 'active':
            raise HTTPException(status_code=409, detail=f"è¨“ç·´æœƒè©± '{session_id}' ä¸æ˜¯æ´»èºç‹€æ…‹")
        
        # æ¨™è¨˜ç‚ºåœæ­¢
        session['status'] = 'stopped'
        
        return {
            "message": f"è¨“ç·´æœƒè©± '{session_id}' å·²åœæ­¢",
            "session_id": session_id
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åœæ­¢è¨“ç·´å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"åœæ­¢è¨“ç·´å¤±æ•—: {str(e)}")

@router.get("/algorithms")
async def get_available_algorithms():
    """ç²å–å¯ç”¨ç®—æ³•åˆ—è¡¨"""
    try:
        manager = await get_ecosystem_manager()
        algorithms = manager.get_registered_algorithms()
        
        return {
            "algorithms": algorithms,
            "count": len(algorithms)
        }
        
    except Exception as e:
        logger.error(f"ç²å–ç®—æ³•åˆ—è¡¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–ç®—æ³•åˆ—è¡¨å¤±æ•—: {str(e)}")

@router.get("/performance/report")
async def get_performance_report(
    algorithms: Optional[str] = Query(None, description="ç®—æ³•åˆ—è¡¨ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰"),
    hours: Optional[int] = Query(24, description="æ™‚é–“çª—å£ï¼ˆå°æ™‚ï¼‰")
):
    """ç²å–æ€§èƒ½åˆ†æå ±å‘Š"""
    try:
        manager = await get_ecosystem_manager()
        
        algorithm_list = algorithms.split(',') if algorithms else None
        time_window = timedelta(hours=hours) if hours else None
        
        report = manager.generate_performance_report(algorithm_list, time_window)
        
        return report
        
    except Exception as e:
        logger.error(f"ç²å–æ€§èƒ½å ±å‘Šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æ€§èƒ½å ±å‘Šå¤±æ•—: {str(e)}")

async def run_training_session(manager: Any, session_id: str, 
                             algorithm_name: str, episodes: int):
    """åœ¨èƒŒæ™¯åŸ·è¡Œè¨“ç·´æœƒè©±"""
    try:
        logger.info(f"é–‹å§‹è¨“ç·´æœƒè©±: {session_id}")
        
        # åŸ·è¡Œå¯¦éš›è¨“ç·´
        result = await manager.train_rl_algorithm(algorithm_name, episodes)
        
        # æ›´æ–°æœƒè©±ç‹€æ…‹
        if session_id in training_sessions:
            session = training_sessions[session_id]
            if result.get('status') == 'completed':
                session['status'] = 'completed'
                session['episodes_completed'] = episodes
                final_stats = result.get('final_stats', {})
                session['current_reward'] = final_stats.get('mean_reward', 0.0)
                session['best_reward'] = result.get('best_reward', 0.0)
            else:
                session['status'] = 'error'
        
        logger.info(f"è¨“ç·´æœƒè©±å®Œæˆ: {session_id}")
        
    except Exception as e:
        logger.error(f"è¨“ç·´æœƒè©±åŸ·è¡Œå¤±æ•—: {session_id}, éŒ¯èª¤: {e}")
        if session_id in training_sessions:
            training_sessions[session_id]['status'] = 'error'

# å¥åº·æª¢æŸ¥ç«¯é»
@router.get("/health")
async def rl_health_check():
    """RL ç³»çµ±å¥åº·æª¢æŸ¥"""
    try:
        status = "healthy"
        details = {}
        
        # æª¢æŸ¥ç”Ÿæ…‹ç³»çµ±æ˜¯å¦å¯ç”¨
        if ECOSYSTEM_AVAILABLE:
            try:
                manager = await get_ecosystem_manager()
                system_status = manager.get_system_status()
                details['ecosystem_status'] = system_status['status']
                details['registered_algorithms'] = len(system_status.get('registered_algorithms', []))
            except Exception as e:
                status = "degraded"
                details['ecosystem_error'] = str(e)
        else:
            status = "degraded"
            details['ecosystem_available'] = False
        
        # æª¢æŸ¥ç³»çµ±è³‡æº
        try:
            resources = get_system_resources()
            details['system_resources'] = {
                'cpu_usage': resources.cpu_usage,
                'memory_usage': resources.memory_usage,
                'gpu_available': GPU_AVAILABLE
            }
        except Exception as e:
            details['resource_error'] = str(e)
        
        details['active_training_sessions'] = len([s for s in training_sessions.values() if s['status'] == 'active'])
        
        return {
            "status": status,
            "timestamp": datetime.now().isoformat(),
            "details": details
        }
        
    except Exception as e:
        logger.error(f"å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
        return {
            "status": "error",
            "timestamp": datetime.now().isoformat(),
            "error": str(e)
        }