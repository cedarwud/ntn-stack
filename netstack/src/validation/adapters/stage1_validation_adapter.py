"""
Stage 1 é©—è­‰è½‰æ¥å™¨
Stage 1 Validation Adapter

å°‡æ–°é©—è­‰æ¡†æ¶æ•´åˆåˆ° Stage1TLEProcessor ä¸­
é©é…ç¾æœ‰è»Œé“è¨ˆç®—è™•ç†å™¨ï¼Œå¯¦ç¾é›¶ä¾µå…¥å¼é©—è­‰æ•´åˆ
"""

from typing import Dict, List, Any, Optional, Tuple
import json
import logging
from datetime import datetime, timezone
# asdict removed - using ValidationResult.to_dict() instead

logger = logging.getLogger(__name__)

from validation.core.base_validator import ValidationResult, ValidationStatus, ValidationLevel
from validation.engines.academic_standards_engine import (
    GradeADataValidator,
    ZeroValueDetector, 
    TimeBaseContinuityChecker,
    PhysicalParameterValidator
)
from validation.engines.data_quality_engine import (
    DataStructureValidator,
    StatisticalAnalyzer
)
from validation.engines.execution_control_engine import (
    ValidationOrchestrator,
    StageGatekeeper,
    ValidationSnapshotManager
)
from validation.config.academic_standards_config import get_academic_config
from validation.config.data_quality_config import get_data_quality_config


class Stage1ValidationAdapter:
    """Stage 1 è»Œé“è¨ˆç®—é©—è­‰è½‰æ¥å™¨"""
    
    def __init__(self, output_dir: str = "/app/data"):
        # é©—è­‰å¼•æ“åˆå§‹åŒ–
        self.academic_config = get_academic_config()
        self.quality_config = get_data_quality_config()
        
        # Stage 1 å°ˆç”¨é©—è­‰å™¨
        self.grade_a_validator = GradeADataValidator(self.academic_config)
        self.zero_value_detector = ZeroValueDetector(self.academic_config)
        self.time_base_checker = TimeBaseContinuityChecker(self.academic_config)
        self.physics_validator = PhysicalParameterValidator(self.academic_config)
        self.structure_validator = DataStructureValidator(self.quality_config)
        self.statistical_analyzer = StatisticalAnalyzer(self.quality_config)
        
        # åŸ·è¡Œæ§åˆ¶çµ„ä»¶
        self.orchestrator = ValidationOrchestrator()
        self.gatekeeper = StageGatekeeper(self.orchestrator)
        self.snapshot_manager = ValidationSnapshotManager("/app/data/validation_snapshots")
        
        # é©—è­‰æ­·å²è¨˜éŒ„
        self.validation_history: List[Dict[str, Any]] = []
        self.current_validation_context = {}
    
    async def pre_process_validation(self, input_data: Dict, validation_context: Dict) -> Dict:
        """åŸ·è¡Œé è™•ç†é©—è­‰"""
        validation_start = datetime.now(timezone.utc)
        validation_results = []
        
        try:
            logger.info("ğŸ” åŸ·è¡Œéšæ®µä¸€é è™•ç†é©—è­‰...")
            
            # TLEå®Œæ•´æ€§æª¢æŸ¥
            tle_result = await self._validate_tle_completeness(
                input_data.get('tle_data', []), 
                validation_context
            )
            validation_results.append(tle_result)
            
            # æ™‚é–“åŸºæº–é é©—è­‰
            time_result = await self._pre_validate_time_base(
                input_data.get('tle_data', []), 
                validation_context
            )
            validation_results.append(time_result)
            
            # å­¸è¡“æ¨™æº–é æª¢æŸ¥
            academic_result = await self._validate_academic_standards(
                input_data.get('tle_data', []), 
                validation_context
            )
            validation_results.append(academic_result)
            
            # è©•ä¼°é è™•ç†é©—è­‰æˆåŠŸæ€§
            pre_process_success = self._evaluate_pre_process_success(validation_results)
            
            validation_summary = {
                'phase': 'pre_process',
                'start_time': validation_start.isoformat(),
                'end_time': datetime.now(timezone.utc).isoformat(),
                'success': pre_process_success,
                'validation_results': [result.to_dict() for result in validation_results],
                'context': validation_context,
                'recommendations': self._generate_pre_process_recommendations(validation_results)
            }
            
            logger.info(f"âœ… éšæ®µä¸€é è™•ç†é©—è­‰å®Œæˆ: {'æˆåŠŸ' if pre_process_success else 'å¤±æ•—'}")
            return validation_summary
            
        except Exception as e:
            logger.error(f"âŒ éšæ®µä¸€é è™•ç†é©—è­‰å¤±æ•—: {e}")
            error_result = ValidationResult(
                validator_name="Pre_Processing_Validator",
                status=ValidationStatus.ERROR,
                level=ValidationLevel.CRITICAL,
                message=f"Pre-processing validation error: {str(e)}",
                details={
                    'exception': str(e),
                    'validation_errors': [f"Pre-processing validation failed: {str(e)}"],
                    'validation_warnings': []
                },
                metadata={'validation_type': 'pre_processing'}
            )
            
            validation_results.append(error_result)
            return {
                'phase': 'pre_process',
                'start_time': validation_start.isoformat(),
                'end_time': datetime.now(timezone.utc).isoformat(),
                'success': False,
                'validation_results': [result.to_dict() for result in validation_results],
                'context': validation_context,
                'error': str(e)
            }
    
    async def post_process_validation(self, orbital_data: List[Dict[str, Any]], 
                                    processing_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """å¾Œè™•ç†é©—è­‰ - SGP4 è»Œé“è¨ˆç®—å¾Œæª¢æŸ¥"""
        validation_start = datetime.now(timezone.utc)
        
        try:
            # æ›´æ–°é©—è­‰ä¸Šä¸‹æ–‡
            validation_context = self.current_validation_context.copy()
            validation_context.update({
                'phase': 'post_process',
                'output_data_size': len(orbital_data),
                'processing_metrics': processing_metrics,
                'validation_timestamp': validation_start.isoformat()
            })
            
            # æ ¸å¿ƒå­¸è¡“æ¨™æº–é©—è­‰ (Zero Tolerance)
            academic_result = await self._validate_academic_standards(orbital_data, validation_context)
            
            # ECI åº§æ¨™é›¶å€¼æª¢æ¸¬ (OneWeb å•é¡Œé˜²è­·)
            zero_value_result = await self._detect_zero_coordinates(orbital_data, validation_context)
            
            # è»Œé“ç‰©ç†åƒæ•¸é©—è­‰
            physics_result = await self._validate_orbital_physics(orbital_data, validation_context)
            
            # çµ±è¨ˆå“è³ªåˆ†æ
            statistical_result = await self._analyze_orbital_statistics(orbital_data, validation_context)
            
            # æ™‚é–“åŸºæº–åˆè¦æ€§æª¢æŸ¥
            time_compliance_result = await self._validate_time_compliance(
                orbital_data, processing_metrics, validation_context
            )
            
            # ç¶œåˆæ‰€æœ‰é©—è­‰çµæœ
            validation_results = [
                academic_result,
                zero_value_result, 
                physics_result,
                statistical_result,
                time_compliance_result
            ]
            
            # å“è³ªé–€ç¦æª¢æŸ¥
            gate_result = await self.gatekeeper.evaluate_stage_gate(
                'stage1_orbital_calculation', 
                {'validation_results': [result.to_dict() for result in validation_results]},
                orbital_data
            )
            
            # ç¢ºå®šå¾Œè™•ç†é©—è­‰ç‹€æ…‹
            post_process_success = self._evaluate_post_process_success(validation_results, gate_result)
            
            # å‰µå»ºåŸ·è¡Œå¿«ç…§
            snapshot = await self._create_stage1_snapshot(
                validation_results, processing_metrics, validation_context
            )
            
            validation_summary = {
                'phase': 'post_process',
                'start_time': validation_start.isoformat(),
                'end_time': datetime.now(timezone.utc).isoformat(),
                'success': post_process_success,
                'validation_results': [result.to_dict() for result in validation_results],
                'quality_gate': gate_result,
                'snapshot': {'snapshot_id': snapshot.snapshot_id, 'timestamp': snapshot.timestamp.isoformat(), 'stage_id': snapshot.stage_id, 'execution_status': snapshot.execution_status.value} if snapshot else None,
                'context': validation_context,
                'academic_compliance': self._assess_academic_compliance(validation_results),
                'recommendations': self._generate_post_process_recommendations(validation_results)
            }
            
            # è¨˜éŒ„é©—è­‰æ­·å²
            self.validation_history.append(validation_summary)
            
            # å¦‚æœå“è³ªé–€ç¦é˜»æ–·ï¼Œæ‹‹å‡ºéŒ¯èª¤
            if gate_result.get('status') == 'CLOSED':
                blocking_reasons = [rule['rule_name'] for rule in gate_result.get('blocking_rules', [])]
                raise ValidationError(f"Quality gate blocked: {blocking_reasons}")
            
            return validation_summary
            
        except Exception as e:
            error_summary = {
                'phase': 'post_process',
                'start_time': validation_start.isoformat(),
                'end_time': datetime.now(timezone.utc).isoformat(),
                'success': False,
                'error': str(e),
                'context': validation_context
            }
            self.validation_history.append(error_summary)
            return error_summary
    
    async def _validate_tle_structure(self, tle_data: List[Dict], context: Dict) -> ValidationResult:
        """TLE æ•¸æ“šçµæ§‹é©—è­‰"""
        try:
            # æº–å‚™çµæ§‹é©—è­‰æ•¸æ“š
            if not tle_data:
                return ValidationResult(
                    validator_name="TLE_Structure_Validator",
                    status=ValidationStatus.FAILED,
                    level=ValidationLevel.CRITICAL,
                    message="No TLE data provided",
                    details={
                        'data_count': 0,
                        'validation_errors': ["Empty TLE dataset"],
                        'validation_warnings': []
                    },
                    metadata={'validation_type': 'tle_structure'}
                )
            
            # ä½¿ç”¨æ•¸æ“šçµæ§‹é©—è­‰å™¨
            sample_tle = tle_data[0]  # æª¢æŸ¥ç¬¬ä¸€å€‹æ¨£æœ¬
            context['data_type'] = 'tle_data_structure'
            
            return await self.structure_validator.validate(sample_tle, context)
            
        except Exception as e:
            return ValidationResult(
                validator_name="TLE_Structure_Validator",
                status=ValidationStatus.ERROR,
                level=ValidationLevel.CRITICAL,
                message=f"TLE structure validation error: {str(e)}",
                details={
                    'exception': str(e),
                    'validation_errors': [f"Structure validation failed: {str(e)}"],
                    'validation_warnings': []
                },
                metadata={'validation_type': 'tle_structure'}
            )
    
    async def _validate_tle_completeness(self, tle_data: List[Dict], context: Dict) -> ValidationResult:
        """TLE æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥"""
        try:
            missing_fields = []
            invalid_satellites = []
            
            required_fields = ['satellite_name', 'line1', 'line2']
            
            for i, tle in enumerate(tle_data[:100]):  # æª¢æŸ¥å‰100å€‹
                for field in required_fields:
                    if field not in tle or not tle[field]:
                        missing_fields.append(f"Satellite {i}: missing {field}")
                
                # æª¢æŸ¥ TLE è¡Œæ ¼å¼
                if len(tle.get('line1', '')) != 69:
                    invalid_satellites.append(f"Satellite {i}: invalid line1 length")
                if len(tle.get('line2', '')) != 69:
                    invalid_satellites.append(f"Satellite {i}: invalid line2 length")
            
            completeness_errors = missing_fields + invalid_satellites
            is_complete = len(completeness_errors) == 0
            
            return ValidationResult(
                validator_name="TLE_Completeness_Validator",
                status=ValidationStatus.PASSED if is_complete else ValidationStatus.FAILED,
                level=ValidationLevel.INFO if is_complete else ValidationLevel.CRITICAL,
                message=f"TLE completeness check {'passed' if is_complete else 'failed'}",
                details={
                    'total_satellites': len(tle_data),
                    'checked_satellites': min(100, len(tle_data)),
                    'completeness_issues': len(completeness_errors),
                    'validation_errors': completeness_errors,
                    'validation_warnings': []
                },
                metadata={'validation_type': 'tle_completeness'}
            )
            
        except Exception as e:
            return ValidationResult(
                validator_name="TLE_Completeness_Validator",
                status=ValidationStatus.ERROR,
                level=ValidationLevel.CRITICAL,
                message=f"TLE completeness validation error: {str(e)}",
                details={
                    'exception': str(e),
                    'validation_errors': [f"Completeness validation failed: {str(e)}"],
                    'validation_warnings': []
                },
                metadata={'validation_type': 'tle_completeness'}
            )
    
    async def _pre_validate_time_base(self, tle_data: List[Dict], context: Dict) -> ValidationResult:
        """é æª¢æŸ¥æ™‚é–“åŸºæº–è¨­å®š"""
        try:
            # æª¢æŸ¥ TLE epoch æ™‚é–“
            epoch_issues = []
            current_time = datetime.now(timezone.utc)
            
            for i, tle in enumerate(tle_data[:50]):  # æª¢æŸ¥å‰50å€‹
                try:
                    # é€™è£¡æ‡‰è©²è§£æ TLE epochï¼Œç°¡åŒ–å¯¦ç¾
                    epoch_year = int(tle.get('line1', '')[18:20])
                    epoch_day = float(tle.get('line1', '')[20:32])
                    
                    # æª¢æŸ¥ epoch å¹´ä»½åˆç†æ€§
                    full_year = 2000 + epoch_year if epoch_year < 57 else 1900 + epoch_year
                    if not (2020 <= full_year <= current_time.year + 1):
                        epoch_issues.append(f"Satellite {i}: invalid epoch year {full_year}")
                    
                    # æª¢æŸ¥ epoch å¤©æ•¸åˆç†æ€§
                    if not (1 <= epoch_day <= 366):
                        epoch_issues.append(f"Satellite {i}: invalid epoch day {epoch_day}")
                        
                except Exception as e:
                    epoch_issues.append(f"Satellite {i}: epoch parsing error - {str(e)}")
            
            time_base_valid = len(epoch_issues) == 0
            
            return ValidationResult(
                validator_name="Time_Base_Pre_Validator",
                status=ValidationStatus.PASSED if time_base_valid else ValidationStatus.FAILED,
                level=ValidationLevel.INFO if time_base_valid else ValidationLevel.CRITICAL,
                message=f"Time base pre-validation {'passed' if time_base_valid else 'failed'}",
                details={
                    'checked_satellites': min(50, len(tle_data)),
                    'epoch_issues': len(epoch_issues),
                    'validation_errors': epoch_issues,
                    'validation_warnings': []
                },
                metadata={'validation_type': 'time_base_pre_check'}
            )
            
        except Exception as e:
            return ValidationResult(
                validator_name="Time_Base_Pre_Validator",
                status=ValidationStatus.ERROR,
                level=ValidationLevel.CRITICAL,
                message=f"Time base pre-validation error: {str(e)}",
                details={
                    'exception': str(e),
                    'validation_errors': [f"Time base pre-validation failed: {str(e)}"],
                    'validation_warnings': []
                },
                metadata={'validation_type': 'time_base_pre_check'}
            )
    
    async def _validate_academic_standards(self, orbital_data: List[Dict], context: Dict) -> ValidationResult:
        """å­¸è¡“æ¨™æº–é©—è­‰ (Zero Tolerance)"""
        try:
            # æº–å‚™å­¸è¡“æ¨™æº–æª¢æŸ¥æ•¸æ“š
            academic_data = {
                'orbital_data': orbital_data,
                'metadata': context,
                'grade_level': 'A'  # Stage 1 è¦æ±‚ Grade A æ¨™æº–
            }
            
            return await self.grade_a_validator.validate(academic_data, context)
            
        except Exception as e:
            return ValidationResult(
                validator_name="Academic_Standards_Validator",
                status=ValidationStatus.ERROR,
                level=ValidationLevel.CRITICAL,
                message=f"Academic standards validation error: {str(e)}",
                details={
                    'exception': str(e),
                    'validation_errors': [f"Academic validation failed: {str(e)}"],
                    'validation_warnings': []
                },
                metadata={'validation_type': 'academic_standards'}
            )
    
    async def _detect_zero_coordinates(self, orbital_data: List[Dict], context: Dict) -> ValidationResult:
        """ECI åº§æ¨™é›¶å€¼æª¢æ¸¬ (OneWeb å•é¡Œå°ˆé–€é˜²è­·)"""
        try:
            # æå– ECI åº§æ¨™æ•¸æ“š
            eci_coordinates = []
            for data_point in orbital_data:
                if 'satellite_positions' in data_point:
                    for position in data_point['satellite_positions']:
                        if all(coord in position for coord in ['x', 'y', 'z']):
                            eci_coordinates.append({
                                'x': position['x'],
                                'y': position['y'],
                                'z': position['z'],
                                'satellite_id': position.get('satellite_id', 'unknown'),
                                'timestamp': position.get('timestamp', 'unknown')
                            })
            
            # ä½¿ç”¨å°ˆé–€çš„é›¶å€¼æª¢æ¸¬å™¨
            zero_detection_data = {'eci_coordinates': eci_coordinates}
            return await self.zero_value_detector.validate(zero_detection_data, context)
            
        except Exception as e:
            return ValidationResult(
                validator_name="Zero_Value_Detector",
                status=ValidationStatus.ERROR,
                level=ValidationLevel.CRITICAL,
                message=f"Zero value detection error: {str(e)}",
                details={
                    'exception': str(e),
                    'validation_errors': [f"Zero value detection failed: {str(e)}"],
                    'validation_warnings': []
                },
                metadata={'validation_type': 'zero_value_detection'}
            )
    
    async def _validate_orbital_physics(self, orbital_data: List[Dict], context: Dict) -> ValidationResult:
        """è»Œé“ç‰©ç†åƒæ•¸é©—è­‰"""
        try:
            # æº–å‚™ç‰©ç†åƒæ•¸æ•¸æ“š
            physics_data = {
                'orbital_data': orbital_data,
                'context': context
            }
            
            return await self.physics_validator.validate(physics_data, context)
            
        except Exception as e:
            return ValidationResult(
                validator_name="Physics_Parameter_Validator",
                status=ValidationStatus.ERROR,
                level=ValidationLevel.CRITICAL,
                message=f"Physics validation error: {str(e)}",
                details={
                    'exception': str(e),
                    'validation_errors': [f"Physics validation failed: {str(e)}"],
                    'validation_warnings': []
                },
                metadata={'validation_type': 'orbital_physics'}
            )
    
    async def _analyze_orbital_statistics(self, orbital_data: List[Dict], context: Dict) -> ValidationResult:
        """è»Œé“æ•¸æ“šçµ±è¨ˆåˆ†æ"""
        try:
            # ä½¿ç”¨çµ±è¨ˆåˆ†æå™¨
            return await self.statistical_analyzer.validate(orbital_data, context)
            
        except Exception as e:
            return ValidationResult(
                validator_name="Statistical_Analyzer",
                status=ValidationStatus.ERROR,
                level=ValidationLevel.CRITICAL,
                message=f"Statistical analysis error: {str(e)}",
                details={
                    'exception': str(e),
                    'validation_errors': [f"Statistical analysis failed: {str(e)}"],
                    'validation_warnings': []
                },
                metadata={'validation_type': 'statistical_analysis'}
            )
    
    async def _validate_time_compliance(self, orbital_data: List[Dict], 
                                      processing_metrics: Dict, context: Dict) -> ValidationResult:
        """æ™‚é–“åŸºæº–åˆè¦æ€§æª¢æŸ¥"""
        try:
            # æº–å‚™æ™‚é–“åˆè¦æª¢æŸ¥æ•¸æ“š
            time_data = {
                'orbital_data': orbital_data,
                'processing_metadata': processing_metrics,
                'context': context
            }
            
            return await self.time_base_checker.validate(time_data, context)
            
        except Exception as e:
            return ValidationResult(
                validator_name="Time_Base_Compliance_Checker",
                status=ValidationStatus.ERROR,
                level=ValidationLevel.CRITICAL,
                message=f"Time compliance validation error: {str(e)}",
                details={
                    'exception': str(e),
                    'validation_errors': [f"Time compliance validation failed: {str(e)}"],
                    'validation_warnings': []
                },
                metadata={'validation_type': 'time_compliance'}
            )
    
    def _evaluate_post_process_success(self, validation_results: List[ValidationResult], 
                                     gate_result: Dict[str, Any]) -> bool:
        """è©•ä¼°å¾Œè™•ç†é©—è­‰æ˜¯å¦æˆåŠŸ"""
        # æª¢æŸ¥æ˜¯å¦æœ‰é©—è­‰å¤±æ•—æˆ–éŒ¯èª¤
        has_failures = any(result.status in [ValidationStatus.FAILED, ValidationStatus.ERROR] 
                          for result in validation_results)
        
        # æª¢æŸ¥å“è³ªé–€ç¦æ˜¯å¦é˜»æ–·
        gate_blocked = gate_result.get('status') == 'CLOSED'
        
        return not (has_failures or gate_blocked)
    
    async def _create_stage1_snapshot(self, validation_results: List[ValidationResult],
                                    processing_metrics: Dict, context: Dict) -> Optional[Any]:
        """å‰µå»º Stage 1 åŸ·è¡Œå¿«ç…§"""
        try:
            from validation.engines.execution_control_engine import ExecutionSnapshot, ExecutionStatus
            
            # ç¢ºå®šåŸ·è¡Œç‹€æ…‹
            has_errors = any(result.status == ValidationStatus.ERROR for result in validation_results)
            has_failures = any(result.status == ValidationStatus.FAILED for result in validation_results)
            
            if has_errors:
                execution_status = ExecutionStatus.FAILED
            elif has_failures:
                execution_status = ExecutionStatus.FAILED
            else:
                execution_status = ExecutionStatus.COMPLETED
            
            # è¨ˆç®—å“è³ªæŒ‡æ¨™
            quality_metrics = self._calculate_stage1_quality_metrics(validation_results)
            
            # å‰µå»ºéŒ¯èª¤æ‘˜è¦
            error_summary = self._create_stage1_error_summary(validation_results)
            
            snapshot = ExecutionSnapshot(
                snapshot_id=f"stage1_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                timestamp=datetime.now(timezone.utc),
                stage_id='stage1_orbital_calculation',
                execution_status=execution_status,
                validation_results=validation_results,
                quality_metrics=quality_metrics,
                error_summary=error_summary,
                recovery_actions=[],
                metadata={
                    'processing_metrics': processing_metrics,
                    'validation_context': context,
                    'stage_specific_info': {
                        'tle_processing': True,
                        'sgp4_calculation': True,
                        'eci_coordinate_generation': True
                    }
                }
            )
            
            # ä¿å­˜å¿«ç…§
            await self.snapshot_manager.save_snapshot(snapshot)
            return snapshot
            
        except Exception as e:
            # å¦‚æœå¿«ç…§å‰µå»ºå¤±æ•—ï¼Œè¨˜éŒ„ä½†ä¸é˜»æ–·æµç¨‹
            print(f"Warning: Failed to create Stage 1 snapshot: {str(e)}")
            return None
    
    def _calculate_stage1_quality_metrics(self, validation_results: List[ValidationResult]) -> Dict[str, float]:
        """è¨ˆç®— Stage 1 ç‰¹å®šå“è³ªæŒ‡æ¨™"""
        if not validation_results:
            return {}
        
        total_validations = len(validation_results)
        passed_count = sum(1 for result in validation_results if result.status == ValidationStatus.PASSED)
        failed_count = sum(1 for result in validation_results if result.status == ValidationStatus.FAILED)
        error_count = sum(1 for result in validation_results if result.status == ValidationStatus.ERROR)
        
        return {
            'success_rate': (passed_count / total_validations) * 100,
            'failure_rate': (failed_count / total_validations) * 100,
            'error_rate': (error_count / total_validations) * 100,
            'total_validations': total_validations,
            'stage1_quality_score': max(0, 100 - (failed_count * 20) - (error_count * 30)),
            'orbital_calculation_reliability': (passed_count / total_validations) * 100,
            'academic_compliance_rate': 100.0 if failed_count == 0 else 0.0
        }
    
    def _create_stage1_error_summary(self, validation_results: List[ValidationResult]) -> Dict[str, Any]:
        """å‰µå»º Stage 1 ç‰¹å®šéŒ¯èª¤æ‘˜è¦"""
        all_errors = []
        all_warnings = []
        
        for result in validation_results:
            # ValidationResultå°‡errorså’Œwarningså­˜å„²åœ¨detailsä¸­
            details = result.details or {}
            all_errors.extend(details.get('validation_errors', []))
            all_warnings.extend(details.get('validation_warnings', []))
        
        # Stage 1 ç‰¹å®šéŒ¯èª¤åˆ†é¡
        error_categories = {
            'eci_zero_value_errors': [e for e in all_errors if 'zero' in e.lower() or 'eci' in e.lower()],
            'tle_format_errors': [e for e in all_errors if 'tle' in e.lower() or 'format' in e.lower()],
            'time_base_errors': [e for e in all_errors if 'time' in e.lower() or 'epoch' in e.lower()],
            'physics_violations': [e for e in all_errors if 'physics' in e.lower() or 'orbital' in e.lower()],
            'academic_violations': [e for e in all_errors if 'academic' in e.lower() or 'grade' in e.lower()],
            'other_errors': []
        }
        
        # åˆ†é¡å‰©é¤˜éŒ¯èª¤
        categorized_errors = set()
        for category_errors in error_categories.values():
            categorized_errors.update(category_errors)
        
        error_categories['other_errors'] = [e for e in all_errors if e not in categorized_errors]
        
        return {
            'total_errors': len(all_errors),
            'total_warnings': len(all_warnings),
            'error_categories': error_categories,
            'critical_errors': error_categories['eci_zero_value_errors'] + error_categories['academic_violations'],
            'stage1_specific_issues': {
                'oneWeb_protection_status': 'active' if error_categories['eci_zero_value_errors'] else 'passed',
                'tle_data_quality': 'degraded' if error_categories['tle_format_errors'] else 'good',
                'time_base_compliance': 'violated' if error_categories['time_base_errors'] else 'compliant'
            },
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
    
    def _assess_academic_compliance(self, validation_results: List[ValidationResult]) -> Dict[str, Any]:
        """è©•ä¼°å­¸è¡“åˆè¦æ€§"""
        academic_errors = []
        for result in validation_results:
            if result.validator_name in ['Academic_Standards_Validator', 'Grade_A_Data_Validator']:
                details = result.details or {}
                academic_errors.extend(details.get('validation_errors', []))
        
        return {
            'grade_level': 'A',
            'compliant': len(academic_errors) == 0,
            'violations': academic_errors,
            'violation_count': len(academic_errors),
            'compliance_score': 100.0 if len(academic_errors) == 0 else 0.0,
            'assessment_timestamp': datetime.now(timezone.utc).isoformat()
        }
    
    def _generate_pre_process_recommendations(self, validation_results: List[ValidationResult]) -> List[str]:
        """ç”Ÿæˆé è™•ç†å»ºè­°"""
        recommendations = []
        
        for result in validation_results:
            if result.status == ValidationStatus.FAILED:
                if 'structure' in result.validator_name.lower():
                    recommendations.append("æª¢æŸ¥ TLE æ•¸æ“šæ ¼å¼ï¼Œç¢ºä¿ç¬¦åˆæ¨™æº– 69 å­—å…ƒæ ¼å¼")
                elif 'completeness' in result.validator_name.lower():
                    recommendations.append("é©—è­‰ TLE æ•¸æ“šå®Œæ•´æ€§ï¼Œç¢ºä¿æ‰€æœ‰å¿…è¦æ¬„ä½éƒ½å­˜åœ¨")
                elif 'time' in result.validator_name.lower():
                    recommendations.append("æª¢æŸ¥ TLE epoch æ™‚é–“ï¼Œç¢ºä¿åœ¨åˆç†çš„æ™‚é–“ç¯„åœå…§")
        
        if not recommendations:
            recommendations.append("é è™•ç†é©—è­‰é€šéï¼Œå¯ç¹¼çºŒé€²è¡Œè»Œé“è¨ˆç®—")
        
        return recommendations
    
    def _generate_post_process_recommendations(self, validation_results: List[ValidationResult]) -> List[str]:
        """ç”Ÿæˆå¾Œè™•ç†å»ºè­°"""
        recommendations = []
        
        for result in validation_results:
            if result.status == ValidationStatus.FAILED:
                if 'zero' in result.validator_name.lower():
                    recommendations.append("ç™¼ç¾ ECI åº§æ¨™é›¶å€¼å•é¡Œï¼Œå»ºè­°æª¢æŸ¥ SGP4 è¨ˆç®—é‚è¼¯å’Œ TLE æ•¸æ“šå®Œæ•´æ€§")
                elif 'academic' in result.validator_name.lower():
                    recommendations.append("å­¸è¡“æ¨™æº–é•è¦ï¼Œå¿…é ˆä¿®å¾©å¾Œæ‰èƒ½é€²å…¥ä¸‹ä¸€éšæ®µè™•ç†")
                elif 'physics' in result.validator_name.lower():
                    recommendations.append("è»Œé“ç‰©ç†åƒæ•¸é©—è­‰å¤±æ•—ï¼Œæª¢æŸ¥è»Œé“é«˜åº¦ã€å‚¾è§’ã€å‘¨æœŸç­‰åƒæ•¸")
                elif 'time' in result.validator_name.lower():
                    recommendations.append("æ™‚é–“åŸºæº–é•è¦ï¼Œç¢ºä¿ä½¿ç”¨ TLE epoch æ™‚é–“è€Œéç•¶å‰æ™‚é–“")
        
        if not recommendations:
            recommendations.append("å¾Œè™•ç†é©—è­‰é€šéï¼Œæ•¸æ“šå“è³ªç¬¦åˆå­¸è¡“æ¨™æº–ï¼Œå¯é€²å…¥ä¸‹ä¸€éšæ®µ")
        
        return recommendations
    
    def get_validation_summary(self) -> Dict[str, Any]:
        """ç²å–é©—è­‰æ‘˜è¦å ±å‘Š"""
        if not self.validation_history:
            return {'message': 'No validation history available'}
        
        latest_validation = self.validation_history[-1]
        
        return {
            'stage': 'stage1_orbital_calculation',
            'total_validations': len(self.validation_history),
            'latest_validation': latest_validation,
            'success_rate': sum(1 for v in self.validation_history if v.get('success', False)) / len(self.validation_history) * 100,
            'common_issues': self._identify_common_issues(),
            'academic_compliance_status': latest_validation.get('academic_compliance', {}),
            'summary_generated': datetime.now(timezone.utc).isoformat()
        }
    
    def _identify_common_issues(self) -> List[str]:
        """è­˜åˆ¥å¸¸è¦‹å•é¡Œæ¨¡å¼"""
        all_errors = []
        for validation in self.validation_history:
            for result in validation.get('validation_results', []):
                if isinstance(result, dict):
                    all_errors.extend(result.get('validation_errors', []))
        
        # çµ±è¨ˆéŒ¯èª¤é »ç‡
        error_counts = {}
        for error in all_errors:
            error_type = self._classify_error_type(error)
            error_counts[error_type] = error_counts.get(error_type, 0) + 1
        
        # è¿”å›æœ€å¸¸è¦‹çš„å•é¡Œ
        common_issues = sorted(error_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        return [issue[0] for issue in common_issues]
    
    def _classify_error_type(self, error: str) -> str:
        """åˆ†é¡éŒ¯èª¤é¡å‹"""
        error_lower = error.lower()
        if 'zero' in error_lower or 'eci' in error_lower:
            return 'ECIé›¶å€¼å•é¡Œ'
        elif 'tle' in error_lower:
            return 'TLEæ•¸æ“šå•é¡Œ'
        elif 'time' in error_lower or 'epoch' in error_lower:
            return 'æ™‚é–“åŸºæº–å•é¡Œ'
        elif 'academic' in error_lower:
            return 'å­¸è¡“æ¨™æº–é•è¦'
        elif 'physics' in error_lower:
            return 'ç‰©ç†åƒæ•¸å•é¡Œ'
        else:
            return 'å…¶ä»–å•é¡Œ'


# ç‚ºäº†é¿å…å¾ªç’°å°å…¥ï¼Œåœ¨é€™è£¡å®šç¾©ä¸€å€‹ç°¡åŒ–çš„é©—è­‰éŒ¯èª¤é¡
class ValidationError(Exception):
    """é©—è­‰éŒ¯èª¤ç•°å¸¸"""
    pass