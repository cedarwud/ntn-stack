#!/usr/bin/env python3
"""
å–®éšæ®µé™¤éŒ¯å·¥å…·

é€™å€‹å·¥å…·å…è¨±é–‹ç™¼è€…å–®ç¨åŸ·è¡Œä»»ä½•éšæ®µï¼Œç”¨æ–¼é™¤éŒ¯å’Œæ¸¬è©¦ç›®çš„ã€‚
æ˜¯å…­éšæ®µé‡æ§‹å¾Œæœ€é‡è¦çš„é™¤éŒ¯åŠŸèƒ½ã€‚

ä½¿ç”¨ç¯„ä¾‹:
    python -m pipeline.scripts.run_single_stage --stage=5
    python -m pipeline.scripts.run_single_stage --stage=5 --input=test_data.json --debug=DEBUG
"""

import argparse
import json
import logging
import sys
from pathlib import Path
from datetime import datetime, timezone
from typing import Optional, Dict, Any

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
current_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(current_dir))

from pipeline.shared.pipeline_coordinator import PipelineCoordinator

class SingleStageDebugger:
    """å–®éšæ®µé™¤éŒ¯å·¥å…·"""
    
    def __init__(self, stage_number: int, debug_level: str = 'INFO'):
        self.stage_number = stage_number
        self.setup_logging(debug_level)
        self.coordinator = PipelineCoordinator()
    
    def setup_logging(self, debug_level: str):
        """è¨­ç½®æ—¥èªŒé…ç½®"""
        level = getattr(logging, debug_level.upper(), logging.INFO)
        
        # é…ç½®æ ¹æ—¥èªŒè¨˜éŒ„å™¨
        logging.basicConfig(
            level=level,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        self.logger = logging.getLogger('SingleStageDebugger')
        self.logger.info(f"é™¤éŒ¯å·¥å…·åˆå§‹åŒ–å®Œæˆï¼Œæ—¥èªŒç­‰ç´š: {debug_level}")
    
    def load_previous_stage_output(self) -> Optional[Dict[str, Any]]:
        """è¼‰å…¥å‰ä¸€éšæ®µçš„è¼¸å‡ºæ•¸æ“š"""
        if self.stage_number == 1:
            self.logger.info("Stage 1 ç„¡å‰ç½®ä¾è³´ï¼Œå°‡ä½¿ç”¨ç©ºè¼¸å…¥")
            return None
        
        prev_stage = self.stage_number - 1
        prev_output_dir = Path(f"/app/data/stage{prev_stage}_outputs")
        
        # å°‹æ‰¾å‰ä¸€éšæ®µçš„è¼¸å‡ºæ–‡ä»¶
        possible_files = [
            f"stage{prev_stage}_output.json",
            f"{self.get_stage_name(prev_stage)}_output.json",
            "output.json"
        ]
        
        for filename in possible_files:
            output_file = prev_output_dir / filename
            if output_file.exists():
                self.logger.info(f"æ‰¾åˆ°å‰ä¸€éšæ®µè¼¸å‡ºæ–‡ä»¶: {output_file}")
                try:
                    with open(output_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    self.logger.info(f"æˆåŠŸè¼‰å…¥å‰ä¸€éšæ®µæ•¸æ“šï¼Œè¨˜éŒ„æ•¸: {data.get('metadata', {}).get('total_records', 'unknown')}")
                    return data
                except Exception as e:
                    self.logger.error(f"è¼‰å…¥å‰ä¸€éšæ®µè¼¸å‡ºå¤±æ•—: {e}")
                    continue
        
        self.logger.warning(f"æœªæ‰¾åˆ° Stage {prev_stage} çš„è¼¸å‡ºæ–‡ä»¶ï¼Œå°‡ä½¿ç”¨ç©ºè¼¸å…¥")
        return None
    
    def get_stage_name(self, stage_number: int) -> str:
        """ç²å–éšæ®µåç¨±"""
        stage_names = {
            1: "orbital_calculation",
            2: "visibility_filter", 
            3: "timeseries_preprocessing",
            4: "signal_analysis",
            5: "data_integration",
            6: "dynamic_planning"
        }
        return stage_names.get(stage_number, f"stage{stage_number}")
    
    def execute_stage_only(self, input_file: str = None, output_dir: str = None) -> Dict[str, Any]:
        """åªåŸ·è¡ŒæŒ‡å®šéšæ®µ"""
        print(f"ğŸ” é–‹å§‹é™¤éŒ¯ Stage {self.stage_number}")
        print(f"â° æ™‚é–“: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}")
        
        # è¼‰å…¥è¼¸å…¥æ•¸æ“š
        if input_file:
            self.logger.info(f"ä½¿ç”¨æŒ‡å®šçš„è¼¸å…¥æ–‡ä»¶: {input_file}")
            try:
                with open(input_file, 'r', encoding='utf-8') as f:
                    input_data = json.load(f)
                print(f"ğŸ“¥ å·²è¼‰å…¥è¼¸å…¥æ•¸æ“š: {input_file}")
                
                # é¡¯ç¤ºè¼¸å…¥æ•¸æ“šçµ±è¨ˆ
                if isinstance(input_data, dict) and 'metadata' in input_data:
                    metadata = input_data['metadata']
                    print(f"   - æ•¸æ“šä¾†æº: Stage {metadata.get('stage_number', 'unknown')}")
                    print(f"   - è¨˜éŒ„æ•¸é‡: {metadata.get('total_records', 'unknown')}")
                    print(f"   - è™•ç†æ™‚é–“: {metadata.get('processing_timestamp', 'unknown')}")
                
            except Exception as e:
                self.logger.error(f"è¼‰å…¥è¼¸å…¥æ–‡ä»¶å¤±æ•—: {e}")
                print(f"âŒ è¼‰å…¥è¼¸å…¥æ–‡ä»¶å¤±æ•—: {e}")
                return None
        else:
            # å¾å‰ä¸€éšæ®µè¼‰å…¥æ¨™æº–è¼¸å‡º
            self.logger.info("å˜—è©¦å¾å‰ä¸€éšæ®µè¼‰å…¥è¼¸å‡ºæ•¸æ“š")
            input_data = self.load_previous_stage_output()
            
            if input_data:
                print(f"ğŸ“¥ å·²å¾ Stage {self.stage_number-1} è¼‰å…¥è¼¸å…¥æ•¸æ“š")
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°å‰ä¸€éšæ®µè¼¸å‡ºï¼Œå°‡ä½¿ç”¨ç©ºè¼¸å…¥")
        
        # åŸ·è¡Œå–®éšæ®µ
        try:
            print(f"ğŸš€ é–‹å§‹åŸ·è¡Œ Stage {self.stage_number}...")
            
            # æª¢æŸ¥éšæ®µæ˜¯å¦å·²å¯¦æ–½
            if self.coordinator.stages_registry[self.stage_number] is None:
                error_msg = f"Stage {self.stage_number} è™•ç†å™¨å°šæœªå¯¦æ–½"
                print(f"âŒ {error_msg}")
                print(f"ğŸ’¡ å»ºè­°: è«‹å…ˆå¯¦æ–½ Stage{self.stage_number}Processor é¡")
                print(f"ğŸ“ ä½ç½®: /netstack/src/pipeline/stages/stage{self.stage_number}_{self.get_stage_name(self.stage_number)}/")
                return None
            
            result = self.coordinator.execute_single_stage(
                self.stage_number, 
                input_data,
                debug_mode=True
            )
            
            # é¡¯ç¤ºåŸ·è¡Œçµæœçµ±è¨ˆ
            print(f"âœ… Stage {self.stage_number} é™¤éŒ¯åŸ·è¡Œå®Œæˆ")
            
            if isinstance(result, dict) and 'metadata' in result:
                metadata = result['metadata']
                print(f"ğŸ“Š åŸ·è¡Œçµ±è¨ˆ:")
                print(f"   - è™•ç†æ™‚é–“: {metadata.get('processing_duration', 'unknown')} ç§’")
                print(f"   - è¼¸å‡ºè¨˜éŒ„: {metadata.get('total_records', 'unknown')}")
                print(f"   - è¼¸å‡ºæ–‡ä»¶: {metadata.get('output_file', 'unknown')}")
            
            # ä¿å­˜çµæœ  
            if output_dir:
                output_path = Path(output_dir)
                output_path.mkdir(parents=True, exist_ok=True)
                output_file = output_path / f"stage{self.stage_number}_debug_output.json"
                
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, indent=2, ensure_ascii=False)
                print(f"ğŸ’¾ çµæœå·²ä¿å­˜: {output_file}")
            
            return result
            
        except Exception as e:
            print(f"âŒ Stage {self.stage_number} åŸ·è¡Œå¤±æ•—: {e}")
            self.print_debug_info(e)
            raise
    
    def print_debug_info(self, exception: Exception):
        """è¼¸å‡ºè©³ç´°çš„é™¤éŒ¯è³‡è¨Š"""
        import traceback
        
        print(f"\nğŸ” è©³ç´°é™¤éŒ¯è³‡è¨Š:")
        print(f"   éšæ®µ: Stage {self.stage_number}")
        print(f"   éŒ¯èª¤é¡å‹: {type(exception).__name__}")
        print(f"   éŒ¯èª¤è¨Šæ¯: {str(exception)}")
        
        # è¼¸å‡ºå †ç–Šè¿½è¹¤
        if self.logger.isEnabledFor(logging.DEBUG):
            print(f"\nğŸ“‹ å®Œæ•´å †ç–Šè¿½è¹¤:")
            traceback.print_exc()
        
        # è¼¸å‡ºå¯èƒ½çš„è§£æ±ºå»ºè­°
        print(f"\nğŸ’¡ é™¤éŒ¯å»ºè­°:")
        if "å°šæœªå¯¦æ–½" in str(exception):
            print(f"   1. å¯¦æ–½ Stage{self.stage_number}Processor é¡")
            print(f"   2. åœ¨ pipeline_coordinator.py ä¸­è¨»å†Šè™•ç†å™¨")
            print(f"   3. ç¢ºä¿æ‰€æœ‰ä¾è³´é …éƒ½å·²å®‰è£")
        else:
            print(f"   1. æª¢æŸ¥è¼¸å…¥æ•¸æ“šæ ¼å¼æ˜¯å¦æ­£ç¢º")
            print(f"   2. é©—è­‰å‰ä¸€éšæ®µçš„è¼¸å‡ºæ˜¯å¦å­˜åœ¨")
            print(f"   3. æŸ¥çœ‹æ—¥èªŒäº†è§£æ›´å¤šè©³ç´°è³‡è¨Š")

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description='å–®éšæ®µé™¤éŒ¯å·¥å…· - å…­éšæ®µé‡æ§‹çš„æ ¸å¿ƒé™¤éŒ¯åŠŸèƒ½',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  %(prog)s --stage=5                                    # åŸ·è¡ŒStage 5ï¼Œè‡ªå‹•è¼‰å…¥å‰ä¸€éšæ®µè¼¸å‡º
  %(prog)s --stage=5 --debug=DEBUG                     # å•Ÿç”¨è©³ç´°é™¤éŒ¯æ—¥èªŒ
  %(prog)s --stage=5 --input=test_data.json            # ä½¿ç”¨è‡ªå®šç¾©è¼¸å…¥æ•¸æ“š
  %(prog)s --stage=5 --output-dir=/tmp/debug           # æŒ‡å®šè¼¸å‡ºç›®éŒ„
        """
    )
    
    parser.add_argument('--stage', type=int, required=True, 
                       choices=range(1, 7), metavar='N',
                       help='éšæ®µç·¨è™Ÿ (1-6)')
    parser.add_argument('--input', 
                       help='è¼¸å…¥æ•¸æ“šæ–‡ä»¶è·¯å¾‘ï¼ˆJSONæ ¼å¼ï¼‰')
    parser.add_argument('--output-dir', 
                       help='è¼¸å‡ºç›®éŒ„ï¼ˆä¿å­˜é™¤éŒ¯çµæœï¼‰')
    parser.add_argument('--debug', default='INFO', 
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       help='é™¤éŒ¯ç­‰ç´š (é è¨­: INFO)')
    
    args = parser.parse_args()
    
    try:
        # å‰µå»ºé™¤éŒ¯å™¨ä¸¦åŸ·è¡Œ
        debugger = SingleStageDebugger(args.stage, args.debug)
        result = debugger.execute_stage_only(args.input, args.output_dir)
        
        if result is not None:
            print(f"\nğŸ‰ Stage {args.stage} é™¤éŒ¯åŸ·è¡ŒæˆåŠŸå®Œæˆï¼")
            sys.exit(0)
        else:
            print(f"\nğŸ’¥ Stage {args.stage} é™¤éŒ¯åŸ·è¡Œå¤±æ•—")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
        sys.exit(130)
    except Exception as e:
        print(f"\nğŸ’¥ é™¤éŒ¯å·¥å…·åŸ·è¡Œå¤±æ•—: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()