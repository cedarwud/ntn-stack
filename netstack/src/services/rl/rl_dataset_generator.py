#!/usr/bin/env python3
"""
Phase 3: RL è¨“ç·´æ•¸æ“šé›†ç”Ÿæˆå™¨
åŸºæ–¼ Phase 0 é è¨ˆç®—çµæœç”Ÿæˆæ¨™æº–åŒ–çš„ RL è¨“ç·´æ•¸æ“š
"""

import json
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import logging
import sys

# æ·»åŠ è·¯å¾‘
sys.path.append('/app/src')
sys.path.append('/app')

logger = logging.getLogger(__name__)

class RLDatasetGenerator:
    """RL è¨“ç·´æ•¸æ“šé›†ç”Ÿæˆå™¨"""
    
    def __init__(self, precomputed_orbit_data: Dict):
        self.orbit_data = precomputed_orbit_data
        self.observer_location = precomputed_orbit_data.get('observer_location', {})
        self.constellations = precomputed_orbit_data.get('constellations', {})
        
        # RL ç’°å¢ƒåƒæ•¸
        self.state_dim = 12  # ç‹€æ…‹ç©ºé–“ç¶­åº¦
        self.action_dim = 3  # å‹•ä½œç©ºé–“ç¶­åº¦ (ç›®æ¨™è¡›æ˜Ÿé¸æ“‡ã€æ›æ‰‹æ™‚æ©Ÿã€åŠŸç‡æ§åˆ¶)
        self.episode_length = 96  # 96åˆ†é˜è»Œé“é€±æœŸï¼Œæ¯åˆ†é˜ä¸€å€‹æ±ºç­–é»
        
        # çå‹µå‡½æ•¸æ¬Šé‡
        self.reward_weights = {
            'handover_success': 10.0,
            'service_continuity': 5.0,
            'signal_quality': 3.0,
            'handover_frequency_penalty': -2.0,
            'energy_efficiency': 1.0
        }
    
    def extract_satellite_trajectories(self, constellation: str) -> Dict[str, List[Dict]]:
        """æå–è¡›æ˜Ÿè»Œè·¡æ•¸æ“š"""
        if constellation not in self.constellations:
            logger.error(f"æ˜Ÿåº§ {constellation} ä¸å­˜åœ¨æ–¼é è¨ˆç®—æ•¸æ“šä¸­")
            return {}
        
        constellation_data = self.constellations[constellation]
        orbit_data = constellation_data.get('orbit_data', {})
        
        trajectories = {}
        
        for sat_id, sat_data in orbit_data.items():
            if 'trajectory' in sat_data:
                trajectory = sat_data['trajectory']
                
                # æ¨™æº–åŒ–è»Œè·¡æ•¸æ“šæ ¼å¼
                standardized_trajectory = []
                
                for i, timestamp in enumerate(trajectory.get('timestamps', [])):
                    if i < len(trajectory.get('positions', [])) and i < len(trajectory.get('elevations', [])):
                        point = {
                            'timestamp': timestamp,
                            'position': trajectory['positions'][i],
                            'elevation': trajectory['elevations'][i],
                            'azimuth': trajectory.get('azimuths', [0])[i] if i < len(trajectory.get('azimuths', [])) else 0,
                            'range_km': trajectory.get('ranges', [1000])[i] if i < len(trajectory.get('ranges', [])) else 1000,
                            'is_visible': trajectory['elevations'][i] > 10.0,  # 10åº¦ä»°è§’é–¾å€¼
                            'signal_strength': self.calculate_signal_strength(trajectory['elevations'][i], trajectory.get('ranges', [1000])[i] if i < len(trajectory.get('ranges', [])) else 1000)
                        }
                        standardized_trajectory.append(point)
                
                trajectories[sat_id] = standardized_trajectory
        
        logger.info(f"âœ… æå– {constellation} æ˜Ÿåº§ {len(trajectories)} é¡†è¡›æ˜Ÿè»Œè·¡")
        return trajectories
    
    def calculate_signal_strength(self, elevation: float, range_km: float) -> float:
        """è¨ˆç®—ä¿¡è™Ÿå¼·åº¦ (ç°¡åŒ–æ¨¡å‹)"""
        if elevation < 10.0:
            return 0.0
        
        # åŸºæ–¼è‡ªç”±ç©ºé–“è·¯å¾‘æè€—çš„ç°¡åŒ–è¨ˆç®—
        # FSPL = 20*log10(d) + 20*log10(f) + 32.45
        # å‡è¨­ Ku é »æ®µ (12 GHz)
        frequency_ghz = 12.0
        fspl_db = 20 * np.log10(range_km) + 20 * np.log10(frequency_ghz) + 32.45
        
        # è€ƒæ…®ä»°è§’å¢ç›Š (ä»°è§’è¶Šé«˜ï¼Œä¿¡è™Ÿè¶Šå¼·)
        elevation_gain = min(elevation / 90.0, 1.0) * 10  # æœ€å¤§ 10dB å¢ç›Š
        
        # å‡è¨­ç™¼å°„åŠŸç‡ 40dBmï¼Œæ¥æ”¶å¤©ç·šå¢ç›Š 35dBi
        tx_power_dbm = 40
        rx_gain_dbi = 35
        
        received_power = tx_power_dbm + rx_gain_dbi - fspl_db + elevation_gain
        
        # è½‰æ›ç‚º 0-1 ç¯„åœçš„ä¿¡è™Ÿå¼·åº¦
        # -100dBm ç‚ºæœ€ä½å¯ç”¨ä¿¡è™Ÿï¼Œ-50dBm ç‚ºå„ªç§€ä¿¡è™Ÿ
        normalized_strength = max(0, min(1, (received_power + 100) / 50))
        
        return normalized_strength
    
    def generate_handover_episodes(self, constellation: str = 'starlink') -> List[Dict]:
        """ç”Ÿæˆæ›æ‰‹æ±ºç­– episode"""
        logger.info(f"ğŸ¯ ç”Ÿæˆ {constellation} æ˜Ÿåº§æ›æ‰‹æ±ºç­– episodes")
        
        trajectories = self.extract_satellite_trajectories(constellation)
        if not trajectories:
            return []
        
        episodes = []
        satellite_ids = list(trajectories.keys())
        
        # ç‚ºæ¯å€‹å¯è¦‹è¡›æ˜Ÿçª—å£ç”Ÿæˆ episode
        for primary_sat_id in satellite_ids[:10]:  # é™åˆ¶è™•ç†æ•¸é‡ä»¥é¿å…éå¤šæ•¸æ“š
            primary_trajectory = trajectories[primary_sat_id]
            
            # æ‰¾åˆ°å¯è¦‹çª—å£
            visible_windows = self.find_visibility_windows(primary_trajectory)
            
            for window_start, window_end in visible_windows:
                episode = self.generate_single_episode(
                    primary_sat_id, 
                    primary_trajectory[window_start:window_end],
                    trajectories,
                    satellite_ids
                )
                
                if episode:
                    episodes.append(episode)
        
        logger.info(f"âœ… ç”Ÿæˆ {len(episodes)} å€‹æ›æ‰‹æ±ºç­– episodes")
        return episodes
    
    def find_visibility_windows(self, trajectory: List[Dict]) -> List[Tuple[int, int]]:
        """æ‰¾åˆ°å¯è¦‹æ€§çª—å£"""
        windows = []
        start_idx = None
        
        for i, point in enumerate(trajectory):
            if point['is_visible'] and start_idx is None:
                start_idx = i
            elif not point['is_visible'] and start_idx is not None:
                if i - start_idx > 5:  # è‡³å°‘ 5 åˆ†é˜çš„å¯è¦‹çª—å£
                    windows.append((start_idx, i))
                start_idx = None
        
        # è™•ç†æœ€å¾Œä¸€å€‹çª—å£
        if start_idx is not None and len(trajectory) - start_idx > 5:
            windows.append((start_idx, len(trajectory)))
        
        return windows
    
    def generate_single_episode(self, primary_sat_id: str, primary_trajectory: List[Dict], 
                               all_trajectories: Dict[str, List[Dict]], 
                               satellite_ids: List[str]) -> Optional[Dict]:
        """ç”Ÿæˆå–®å€‹ episode"""
        if len(primary_trajectory) < 10:
            return None
        
        episode = {
            'episode_id': f"{primary_sat_id}_{datetime.now().timestamp()}",
            'primary_satellite': primary_sat_id,
            'duration_minutes': len(primary_trajectory),
            'states': [],
            'actions': [],
            'rewards': [],
            'next_states': [],
            'done': []
        }
        
        current_satellite = primary_sat_id
        handover_count = 0
        
        for i, current_point in enumerate(primary_trajectory[:-1]):
            # æ§‹å»ºç‹€æ…‹å‘é‡
            state = self.build_state_vector(
                current_point, 
                current_satellite,
                all_trajectories,
                satellite_ids,
                i
            )
            
            # æ±ºå®šå‹•ä½œ (ç°¡åŒ–çš„è²ªå¿ƒç­–ç•¥ä½œç‚ºç¤ºä¾‹)
            action, target_satellite = self.generate_action(
                current_point,
                all_trajectories,
                satellite_ids,
                i
            )
            
            # è¨ˆç®—çå‹µ
            next_point = primary_trajectory[i + 1]
            reward = self.calculate_reward(
                current_point,
                next_point,
                action,
                target_satellite,
                handover_count
            )
            
            # æ§‹å»ºä¸‹ä¸€ç‹€æ…‹
            next_state = self.build_state_vector(
                next_point,
                target_satellite if action[1] > 0.5 else current_satellite,
                all_trajectories,
                satellite_ids,
                i + 1
            )
            
            episode['states'].append(state.tolist())
            episode['actions'].append(action.tolist())
            episode['rewards'].append(reward)
            episode['next_states'].append(next_state.tolist())
            episode['done'].append(i == len(primary_trajectory) - 2)
            
            # æ›´æ–°ç•¶å‰è¡›æ˜Ÿ
            if action[1] > 0.5:  # åŸ·è¡Œæ›æ‰‹
                current_satellite = target_satellite
                handover_count += 1
        
        episode['total_handovers'] = handover_count
        episode['average_reward'] = np.mean(episode['rewards'])
        
        return episode
    
    def build_state_vector(self, current_point: Dict, current_satellite: str,
                          all_trajectories: Dict[str, List[Dict]], 
                          satellite_ids: List[str], time_idx: int) -> np.ndarray:
        """æ§‹å»ºç‹€æ…‹å‘é‡"""
        state = np.zeros(self.state_dim)
        
        # ç•¶å‰è¡›æ˜Ÿç‹€æ…‹ (0-5)
        state[0] = current_point['elevation'] / 90.0  # æ­¸ä¸€åŒ–ä»°è§’
        state[1] = current_point['azimuth'] / 360.0   # æ­¸ä¸€åŒ–æ–¹ä½è§’
        state[2] = min(current_point['range_km'] / 2000.0, 1.0)  # æ­¸ä¸€åŒ–è·é›¢
        state[3] = current_point['signal_strength']
        state[4] = 1.0 if current_point['is_visible'] else 0.0
        state[5] = time_idx / 96.0  # æ­¸ä¸€åŒ–æ™‚é–“é€²åº¦
        
        # å€™é¸è¡›æ˜Ÿç‹€æ…‹ (6-11) - é¸æ“‡ä¿¡è™Ÿæœ€å¼·çš„å€™é¸è¡›æ˜Ÿ
        best_candidate = self.find_best_candidate(
            current_point, all_trajectories, satellite_ids, current_satellite, time_idx
        )
        
        if best_candidate:
            state[6] = best_candidate['elevation'] / 90.0
            state[7] = best_candidate['azimuth'] / 360.0
            state[8] = min(best_candidate['range_km'] / 2000.0, 1.0)
            state[9] = best_candidate['signal_strength']
            state[10] = 1.0 if best_candidate['is_visible'] else 0.0
            state[11] = best_candidate['signal_strength'] - current_point['signal_strength']  # ä¿¡è™Ÿå·®ç•°
        
        return state
    
    def find_best_candidate(self, current_point: Dict, all_trajectories: Dict[str, List[Dict]],
                           satellite_ids: List[str], current_satellite: str, time_idx: int) -> Optional[Dict]:
        """æ‰¾åˆ°æœ€ä½³å€™é¸è¡›æ˜Ÿ"""
        best_candidate = None
        best_signal = 0.0
        
        for sat_id in satellite_ids:
            if sat_id == current_satellite:
                continue
            
            trajectory = all_trajectories.get(sat_id, [])
            if time_idx < len(trajectory):
                candidate_point = trajectory[time_idx]
                
                if candidate_point['is_visible'] and candidate_point['signal_strength'] > best_signal:
                    best_signal = candidate_point['signal_strength']
                    best_candidate = candidate_point
        
        return best_candidate
    
    def generate_action(self, current_point: Dict, all_trajectories: Dict[str, List[Dict]],
                       satellite_ids: List[str], time_idx: int) -> Tuple[np.ndarray, str]:
        """ç”Ÿæˆå‹•ä½œ (ç°¡åŒ–ç­–ç•¥)"""
        action = np.zeros(self.action_dim)
        
        # æ‰¾åˆ°æœ€ä½³å€™é¸è¡›æ˜Ÿ
        best_candidate = self.find_best_candidate(
            current_point, all_trajectories, satellite_ids, "current", time_idx
        )
        
        if best_candidate:
            # å‹•ä½œ 0: ç›®æ¨™è¡›æ˜Ÿé¸æ“‡ (0-1, 1è¡¨ç¤ºé¸æ“‡æœ€ä½³å€™é¸)
            action[0] = 1.0
            
            # å‹•ä½œ 1: æ›æ‰‹æ™‚æ©Ÿ (0-1, åŸºæ–¼ä¿¡è™Ÿå¼·åº¦å·®ç•°)
            signal_diff = best_candidate['signal_strength'] - current_point['signal_strength']
            action[1] = 1.0 if signal_diff > 0.1 else 0.0
            
            # å‹•ä½œ 2: åŠŸç‡æ§åˆ¶ (0-1)
            action[2] = min(1.0, max(0.0, 1.0 - current_point['signal_strength']))
            
            return action, "best_candidate"
        
        # æ²’æœ‰å¥½çš„å€™é¸è¡›æ˜Ÿï¼Œä¿æŒç•¶å‰é€£æ¥
        action[0] = 0.0  # ä¸é¸æ“‡æ–°è¡›æ˜Ÿ
        action[1] = 0.0  # ä¸åŸ·è¡Œæ›æ‰‹
        action[2] = min(1.0, max(0.0, 1.0 - current_point['signal_strength']))
        
        return action, "current"
    
    def calculate_reward(self, current_point: Dict, next_point: Dict, 
                        action: np.ndarray, target_satellite: str, handover_count: int) -> float:
        """è¨ˆç®—çå‹µ"""
        reward = 0.0
        
        # æœå‹™é€£çºŒæ€§çå‹µ
        if next_point['is_visible'] and next_point['signal_strength'] > 0.3:
            reward += self.reward_weights['service_continuity']
        
        # ä¿¡è™Ÿå“è³ªçå‹µ
        reward += self.reward_weights['signal_quality'] * next_point['signal_strength']
        
        # æ›æ‰‹æˆåŠŸçå‹µ
        if action[1] > 0.5:  # åŸ·è¡Œäº†æ›æ‰‹
            if next_point['signal_strength'] > current_point['signal_strength']:
                reward += self.reward_weights['handover_success']
            else:
                reward -= self.reward_weights['handover_success'] * 0.5  # æ›æ‰‹å¤±æ•—æ‡²ç½°
        
        # æ›æ‰‹é »ç‡æ‡²ç½°
        if handover_count > 5:  # éæ–¼é »ç¹çš„æ›æ‰‹
            reward += self.reward_weights['handover_frequency_penalty']
        
        # èƒ½æ•ˆçå‹µ (åŠŸç‡æ§åˆ¶)
        power_efficiency = 1.0 - action[2]  # åŠŸç‡è¶Šä½è¶Šå¥½
        reward += self.reward_weights['energy_efficiency'] * power_efficiency
        
        return reward
    
    def export_ml_format(self, episodes: List[Dict], format_type: str = "pytorch", 
                        output_dir: str = "rl_datasets") -> Dict[str, str]:
        """å°å‡º ML æ¡†æ¶é©ç”¨æ ¼å¼"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        exported_files = {}
        
        if format_type == "pytorch":
            exported_files.update(self.export_pytorch_format(episodes, output_path))
        elif format_type == "tensorflow":
            exported_files.update(self.export_tensorflow_format(episodes, output_path))
        elif format_type == "csv":
            exported_files.update(self.export_csv_format(episodes, output_path))
        elif format_type == "json":
            exported_files.update(self.export_json_format(episodes, output_path))
        else:
            logger.error(f"ä¸æ”¯æ´çš„æ ¼å¼: {format_type}")
            return {}
        
        logger.info(f"âœ… æ•¸æ“šé›†å·²å°å‡ºç‚º {format_type} æ ¼å¼")
        return exported_files
    
    def export_pytorch_format(self, episodes: List[Dict], output_path: Path) -> Dict[str, str]:
        """å°å‡º PyTorch æ ¼å¼"""
        try:
            import torch
            
            # åˆä½µæ‰€æœ‰ episodes çš„æ•¸æ“š
            all_states = []
            all_actions = []
            all_rewards = []
            all_next_states = []
            all_done = []
            
            for episode in episodes:
                all_states.extend(episode['states'])
                all_actions.extend(episode['actions'])
                all_rewards.extend(episode['rewards'])
                all_next_states.extend(episode['next_states'])
                all_done.extend(episode['done'])
            
            # è½‰æ›ç‚º PyTorch tensors
            states_tensor = torch.FloatTensor(all_states)
            actions_tensor = torch.FloatTensor(all_actions)
            rewards_tensor = torch.FloatTensor(all_rewards)
            next_states_tensor = torch.FloatTensor(all_next_states)
            done_tensor = torch.BoolTensor(all_done)
            
            # ä¿å­˜
            torch_file = output_path / "handover_dataset.pt"
            torch.save({
                'states': states_tensor,
                'actions': actions_tensor,
                'rewards': rewards_tensor,
                'next_states': next_states_tensor,
                'done': done_tensor,
                'metadata': {
                    'state_dim': self.state_dim,
                    'action_dim': self.action_dim,
                    'num_episodes': len(episodes),
                    'total_transitions': len(all_states)
                }
            }, torch_file)
            
            return {'pytorch': str(torch_file)}
            
        except ImportError:
            logger.warning("PyTorch æœªå®‰è£ï¼Œè·³é PyTorch æ ¼å¼å°å‡º")
            return {}
    
    def export_csv_format(self, episodes: List[Dict], output_path: Path) -> Dict[str, str]:
        """å°å‡º CSV æ ¼å¼"""
        # å±•å¹³æ‰€æœ‰æ•¸æ“š
        rows = []
        
        for episode in episodes:
            episode_id = episode['episode_id']
            
            for i in range(len(episode['states'])):
                row = {
                    'episode_id': episode_id,
                    'step': i,
                    'reward': episode['rewards'][i],
                    'done': episode['done'][i]
                }
                
                # æ·»åŠ ç‹€æ…‹ç‰¹å¾µ
                for j, state_val in enumerate(episode['states'][i]):
                    row[f'state_{j}'] = state_val
                
                # æ·»åŠ å‹•ä½œç‰¹å¾µ
                for j, action_val in enumerate(episode['actions'][i]):
                    row[f'action_{j}'] = action_val
                
                # æ·»åŠ ä¸‹ä¸€ç‹€æ…‹ç‰¹å¾µ
                for j, next_state_val in enumerate(episode['next_states'][i]):
                    row[f'next_state_{j}'] = next_state_val
                
                rows.append(row)
        
        # ä¿å­˜ç‚º CSV
        df = pd.DataFrame(rows)
        csv_file = output_path / "handover_dataset.csv"
        df.to_csv(csv_file, index=False)
        
        return {'csv': str(csv_file)}
    
    def export_json_format(self, episodes: List[Dict], output_path: Path) -> Dict[str, str]:
        """å°å‡º JSON æ ¼å¼"""
        json_file = output_path / "handover_dataset.json"
        
        dataset = {
            'metadata': {
                'generation_date': datetime.now().isoformat(),
                'state_dim': self.state_dim,
                'action_dim': self.action_dim,
                'num_episodes': len(episodes),
                'reward_weights': self.reward_weights
            },
            'episodes': episodes
        }
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, indent=2, ensure_ascii=False)
        
        return {'json': str(json_file)}
