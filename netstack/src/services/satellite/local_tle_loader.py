#!/usr/bin/env python3
"""
æœ¬åœ° TLE æ–‡å­—æª”è¼‰å…¥å™¨
æ”¯æ´å¾æœ¬åœ°æ–‡å­—æª”è¼‰å…¥ Starlink TLE æ•¸æ“š

ä½¿ç”¨æ–¹æ³•ï¼š
1. å°‡ TLE æ–‡å­—æª”æ”¾åœ¨ data/ ç›®éŒ„
2. æ”¯æ´çš„æª”æ¡ˆåï¼šstarlink.txt, starlink.tle, starlink_tle.txt
3. æ ¼å¼ï¼šæ¨™æº– TLE ä¸‰è¡Œæ ¼å¼
"""

import json
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any

logger = logging.getLogger(__name__)

class LocalTLELoader:
    """æœ¬åœ° TLE æ•¸æ“šåŠ è¼‰å™¨ - Phase 0 å¢å¼·ç‰ˆæœ¬ï¼Œæ”¯æ´å¯¦éš›æ—¥æœŸå‘½å"""
    
    def __init__(self, tle_data_dir: str = "/app/tle_data"):
        """
        åˆå§‹åŒ–æœ¬åœ° TLE æ•¸æ“šåŠ è¼‰å™¨
        
        Args:
            tle_data_dir: TLE æ•¸æ“šæ ¹ç›®éŒ„ï¼Œé è¨­ç‚º /app/tle_data
        """
        self.tle_data_dir = Path(tle_data_dir)
        logger.info(f"LocalTLELoader åˆå§‹åŒ–ï¼Œæ•¸æ“šç›®éŒ„: {self.tle_data_dir}")
        
        # Phase 0 æ”¯æ´çš„æ˜Ÿåº§
        self.supported_constellations = ['starlink', 'oneweb']
        
        # èˆŠç‰ˆå…¼å®¹æ€§ï¼šå‚³çµ±æª”æ¡ˆåç¨±æ”¯æ´
        self.legacy_supported_filenames = [
            "starlink.txt",
            "starlink.tle", 
            "starlink_tle.txt",
            "celestrak_starlink.txt",
            "starlink_latest.txt"
        ]
        
    def scan_available_dates(self, constellation: str) -> List[str]:
        """
        æƒææŒ‡å®šæ˜Ÿåº§çš„å¯ç”¨æ—¥æœŸ
        
        Args:
            constellation: æ˜Ÿåº§åç¨± ('starlink' æˆ– 'oneweb')
            
        Returns:
            List[str]: å¯ç”¨æ—¥æœŸåˆ—è¡¨ (YYYYMMDD æ ¼å¼)
        """
        if constellation not in self.supported_constellations:
            logger.error(f"ä¸æ”¯æ´çš„æ˜Ÿåº§: {constellation}")
            return []
            
        tle_dir = self.tle_data_dir / constellation / "tle"
        if not tle_dir.exists():
            logger.warning(f"TLE ç›®éŒ„ä¸å­˜åœ¨: {tle_dir}")
            return []
            
        available_dates = []
        pattern = f"{constellation}_*.tle"
        
        import glob
        import re
        
        for tle_file in glob.glob(str(tle_dir / pattern)):
            # æå–æ—¥æœŸ (YYYYMMDD)
            match = re.search(r'(\d{8})\.tle$', tle_file)
            if match:
                date_str = match.group(1)
                # é©—è­‰æ–‡ä»¶å­˜åœ¨ä¸”éç©º
                if Path(tle_file).stat().st_size > 0:
                    available_dates.append(date_str)
                    
        available_dates.sort()
        logger.info(f"{constellation} å¯ç”¨æ—¥æœŸ: {len(available_dates)} å¤©ï¼Œç¯„åœ: {available_dates[0] if available_dates else 'N/A'} - {available_dates[-1] if available_dates else 'N/A'}")
        return available_dates
    
    def load_collected_data(self, constellation: str = "starlink", 
                           start_date: str = None, end_date: str = None) -> Dict[str, Any]:
        """
        è¼‰å…¥æ‰‹å‹•æ”¶é›†çš„TLEæ­·å²æ•¸æ“š
        
        Args:
            constellation: æ˜Ÿåº§åç¨± ('starlink' æˆ– 'oneweb')
            start_date: é–‹å§‹æ—¥æœŸ (YYYYMMDD)ï¼ŒNone è¡¨ç¤ºç„¡é™åˆ¶
            end_date: çµæŸæ—¥æœŸ (YYYYMMDD)ï¼ŒNone è¡¨ç¤ºç„¡é™åˆ¶
            
        Returns:
            Dict: åŒ…å«æ”¶é›†æ•¸æ“šçš„è©³ç´°ä¿¡æ¯
        """
        if constellation not in self.supported_constellations:
            return {'error': f'ä¸æ”¯æ´çš„æ˜Ÿåº§: {constellation}'}
            
        tle_dir = self.tle_data_dir / constellation / "tle"
        json_dir = self.tle_data_dir / constellation / "json"
        
        if not tle_dir.exists():
            return {'error': f'TLE ç›®éŒ„ä¸å­˜åœ¨: {tle_dir}'}
            
        collected_data = []
        available_dates = []
        
        import glob
        import re
        
        # æƒææ‰€æœ‰å¯ç”¨çš„ TLE æª”æ¡ˆ
        tle_pattern = str(tle_dir / f"{constellation}_*.tle")
        tle_files = glob.glob(tle_pattern)
        
        for tle_file in tle_files:
            # æå–å¯¦éš›æ—¥æœŸ (YYYYMMDD)
            match = re.search(r'(\d{8})\.tle$', tle_file)
            if match:
                date_str = match.group(1)
                
                # æ—¥æœŸç¯„åœéæ¿¾
                if start_date and date_str < start_date:
                    continue
                if end_date and date_str > end_date:
                    continue
                
                tle_path = Path(tle_file)
                json_path = json_dir / f"{constellation}_{date_str}.json"
                
                if tle_path.exists() and tle_path.stat().st_size > 0:
                    # è§£æ TLE æ•¸æ“š
                    daily_tle_data = self.parse_tle_file(tle_path)
                    daily_json_data = None
                    
                    # å˜—è©¦è®€å–å°æ‡‰çš„ JSON æ•¸æ“š
                    if json_path.exists() and json_path.stat().st_size > 0:
                        daily_json_data = self.parse_json_file(json_path)
                    
                    if daily_tle_data:
                        collected_data.append({
                            'date': date_str,
                            'tle_file': str(tle_path),
                            'json_file': str(json_path) if daily_json_data else None,
                            'satellites': daily_tle_data,
                            'satellite_count': len(daily_tle_data),
                            'json_metadata': daily_json_data[:3] if daily_json_data else None,  # åªä¿ç•™å‰3å€‹ä½œç‚ºæ¨£æœ¬
                            'has_dual_format': daily_json_data is not None
                        })
                        available_dates.append(date_str)
        
        # æŒ‰æ—¥æœŸæ’åº
        collected_data.sort(key=lambda x: x['date'])
        available_dates.sort()
        
        return {
            'constellation': constellation,
            'total_days_collected': len(collected_data),
            'date_range': {
                'start': available_dates[0] if available_dates else None,
                'end': available_dates[-1] if available_dates else None,
                'available_dates': available_dates
            },
            'dual_format_coverage': sum(1 for d in collected_data if d['has_dual_format']),
            'coverage_percentage': len(collected_data) / len(available_dates) * 100 if available_dates else 0,
            'daily_data': collected_data
        }
    
    def parse_tle_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """è§£æ TLE æ–‡ä»¶"""
        satellites = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.strip().split('\n')
            lines = [line.strip() for line in lines if line.strip()]
            
            i = 0
            while i < len(lines):
                if i + 2 < len(lines):
                    name_line = lines[i].strip()
                    line1 = lines[i + 1].strip()
                    line2 = lines[i + 2].strip()
                    
                    # é©—è­‰ TLE æ ¼å¼
                    if (line1.startswith('1 ') and 
                        line2.startswith('2 ') and 
                        len(line1) >= 69 and 
                        len(line2) >= 69):
                        
                        try:
                            norad_id = int(line1[2:7].strip())
                            
                            satellite_data = {
                                'name': name_line,
                                'norad_id': norad_id,
                                'line1': line1,
                                'line2': line2,
                                'data_source': 'local_collection'
                            }
                            
                            satellites.append(satellite_data)
                            
                        except ValueError as e:
                            logger.warning(f"ç„¡æ³•è§£æ NORAD ID: {line1[:10]} - {e}")
                    
                    i += 3
                else:
                    i += 1
                    
        except Exception as e:
            logger.error(f"è§£æ TLE æ–‡ä»¶å¤±æ•— {file_path}: {e}")
            
        logger.debug(f"å¾ {file_path} è§£æå‡º {len(satellites)} é¡†è¡›æ˜Ÿ")
        return satellites
    
    def parse_json_file(self, file_path: Path) -> Optional[List[Dict[str, Any]]]:
        """è§£æ JSON æ–‡ä»¶"""
        try:
            import json
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list):
                logger.debug(f"å¾ {file_path} è§£æå‡º {len(data)} ç­† JSON è¨˜éŒ„")
                return data
            else:
                logger.warning(f"JSON æ–‡ä»¶æ ¼å¼ä¸æ­£ç¢º: {file_path}")
                return None
                
        except Exception as e:
            logger.error(f"è§£æ JSON æ–‡ä»¶å¤±æ•— {file_path}: {e}")
            return None
    
    def get_data_coverage_status(self) -> Dict[str, Any]:
        """æª¢æŸ¥æ‰‹å‹•æ”¶é›†æ•¸æ“šçš„ç‹€æ…‹å’Œè¦†è“‹ç‡"""
        status = {'starlink': {}, 'oneweb': {}, 'overall': {}}
        
        # ç²å–å…©å€‹æ˜Ÿåº§çš„æ•¸æ“š
        starlink_data = self.load_collected_data('starlink')
        oneweb_data = self.load_collected_data('oneweb')
        
        # è¨ˆç®—æ—¥æœŸè¦†è“‹ç¯„åœ
        all_dates = set()
        starlink_dates = set()
        oneweb_dates = set()
        
        if 'date_range' in starlink_data and starlink_data['date_range']['available_dates']:
            starlink_dates = set(starlink_data['date_range']['available_dates'])
            all_dates.update(starlink_dates)
        
        if 'date_range' in oneweb_data and oneweb_data['date_range']['available_dates']:
            oneweb_dates = set(oneweb_data['date_range']['available_dates'])
            all_dates.update(oneweb_dates)
        
        status['starlink'] = {
            'days_collected': starlink_data.get('total_days_collected', 0),
            'dates': sorted(list(starlink_dates)),
            'dual_format_count': starlink_data.get('dual_format_coverage', 0),
            'dual_format_percentage': (starlink_data.get('dual_format_coverage', 0) / 
                                     starlink_data.get('total_days_collected', 1) * 100) if starlink_data.get('total_days_collected', 0) > 0 else 0
        }
        
        status['oneweb'] = {
            'days_collected': oneweb_data.get('total_days_collected', 0),
            'dates': sorted(list(oneweb_dates)),
            'dual_format_count': oneweb_data.get('dual_format_coverage', 0),
            'dual_format_percentage': (oneweb_data.get('dual_format_coverage', 0) / 
                                     oneweb_data.get('total_days_collected', 1) * 100) if oneweb_data.get('total_days_collected', 0) > 0 else 0
        }
        
        status['overall'] = {
            'total_unique_dates': len(all_dates),
            'date_range': {
                'start': min(all_dates) if all_dates else None,
                'end': max(all_dates) if all_dates else None
            },
            'common_dates': len(starlink_dates & oneweb_dates),
            'coverage_days': len(all_dates)
        }
        
        return status
    
    def validate_daily_data_quality(self, constellation: str, date_str: str) -> Dict[str, Any]:
        """é©—è­‰ç‰¹å®šæ—¥æœŸæ•¸æ“šå“è³ª"""
        tle_path = self.tle_data_dir / constellation / "tle" / f"{constellation}_{date_str}.tle"
        json_path = self.tle_data_dir / constellation / "json" / f"{constellation}_{date_str}.json"
        
        if not tle_path.exists():
            return {'valid': False, 'error': 'TLE file not found', 'date': date_str}
            
        # è§£æ TLE æ•¸æ“š
        satellites = self.parse_tle_file(tle_path)
        
        # å˜—è©¦è§£æ JSON æ•¸æ“š
        json_data = None
        has_json = json_path.exists() and json_path.stat().st_size > 0
        if has_json:
            json_data = self.parse_json_file(json_path)
        
        validation_result = {
            'valid': True,
            'date': date_str,
            'satellite_count': len(satellites),
            'has_dual_format': has_json,
            'json_satellite_count': len(json_data) if json_data else 0,
            'format_errors': [],
            'orbit_warnings': [],
            'data_quality_score': 0
        }
        
        # åŸºç¤é©—è­‰
        format_errors = 0
        orbit_warnings = 0
        
        for sat in satellites:
            # ç°¡å–®æ ¼å¼æª¢æŸ¥
            if len(sat.get('line1', '')) < 69 or len(sat.get('line2', '')) < 69:
                format_errors += 1
                validation_result['format_errors'].append(f"Invalid TLE length: {sat.get('name', 'Unknown')}")
            
            # åŸºæœ¬è»Œé“åƒæ•¸æª¢æŸ¥ (å¯å¾ŒçºŒå¢å¼·)
            try:
                if not (1 <= sat.get('norad_id', 0) <= 99999):
                    orbit_warnings += 1
                    validation_result['orbit_warnings'].append(f"Suspicious NORAD ID: {sat.get('name', 'Unknown')}")
            except:
                orbit_warnings += 1
        
        # è¨ˆç®—å“è³ªåˆ†æ•¸
        total_sats = len(satellites)
        if total_sats > 0:
            validation_result['data_quality_score'] = max(0, 
                100 - (format_errors * 10) - (orbit_warnings * 2))
        
        validation_result['valid'] = (format_errors == 0 and total_sats > 0)
        
        return validation_result
    
    # === èˆŠç‰ˆå…¼å®¹æ€§æ–¹æ³• ===
    
    def find_tle_file(self) -> Optional[Path]:
        """å°‹æ‰¾å¯ç”¨çš„ TLE æª”æ¡ˆ (èˆŠç‰ˆå…¼å®¹)"""
        data_dir = Path("data")  # èˆŠç‰ˆé è¨­ç›®éŒ„
        data_dir.mkdir(parents=True, exist_ok=True)
        
        for filename in self.legacy_supported_filenames:
            file_path = data_dir / filename
            if file_path.exists():
                logger.info(f"æ‰¾åˆ°å‚³çµ± TLE æª”æ¡ˆ: {file_path}")
                return file_path
        
        logger.warning(f"æœªæ‰¾åˆ°å‚³çµ± TLE æª”æ¡ˆï¼ŒæŸ¥æ‰¾è·¯å¾‘: {data_dir}")
        return None
    
    def get_starlink_tle_data(self) -> List[Dict[str, str]]:
        """ç²å– Starlink TLE æ•¸æ“š (èˆŠç‰ˆå…¼å®¹)"""
        # 1. å˜—è©¦è¼‰å…¥æœ€æ–°çš„æ”¶é›†æ•¸æ“š
        collected_data = self.load_collected_data('starlink')
        
        if collected_data.get('daily_data'):
            # è¿”å›æœ€æ–°æ—¥æœŸçš„æ•¸æ“š
            latest_data = collected_data['daily_data'][-1]
            satellites = latest_data['satellites']
            
            # è½‰æ›ç‚ºèˆŠæ ¼å¼
            legacy_format = []
            for sat in satellites:
                legacy_sat = {
                    'name': sat['name'],
                    'norad_id': str(sat['norad_id']),
                    'line1': sat['line1'],
                    'line2': sat['line2'],
                    'download_time': datetime.now(timezone.utc).isoformat(),
                    'data_source': 'collected_data'
                }
                legacy_format.append(legacy_sat)
            
            logger.info(f"å¾æ”¶é›†æ•¸æ“šè¼‰å…¥ {len(legacy_format)} é¡† Starlink è¡›æ˜Ÿ")
            return legacy_format
        
        # 2. å›é€€åˆ°å‚³çµ±æ–‡ä»¶æŸ¥æ‰¾
        tle_file = self.find_tle_file()
        if tle_file:
            satellites = self.load_tle_from_file(tle_file)
            if satellites:
                logger.info(f"å¾å‚³çµ±æ–‡ä»¶è¼‰å…¥ {len(satellites)} é¡† Starlink è¡›æ˜Ÿ")
                return satellites
        
        # 3. æœ€å¾Œå›é€€åˆ°æ­·å²æ•¸æ“š
        logger.warning("æœ¬åœ°æ•¸æ“šä¸å¯ç”¨ï¼Œå›é€€åˆ°æ­·å²æ•¸æ“š")
        return self.load_historical_data()
    
    def load_tle_from_file(self, file_path: Path) -> List[Dict[str, str]]:
        """å¾æª”æ¡ˆè¼‰å…¥ TLE æ•¸æ“š (èˆŠç‰ˆå…¼å®¹)"""
        try:
            satellites_data = self.parse_tle_file(file_path)
            
            # è½‰æ›ç‚ºèˆŠæ ¼å¼
            legacy_format = []
            for sat in satellites_data:
                legacy_sat = {
                    'name': sat['name'],
                    'norad_id': str(sat['norad_id']),
                    'line1': sat['line1'],
                    'line2': sat['line2'],
                    'download_time': datetime.now(timezone.utc).isoformat(),
                    'data_source': 'local_file'
                }
                legacy_format.append(legacy_sat)
            
            return legacy_format
            
        except Exception as e:
            logger.error(f"è®€å–æª”æ¡ˆå¤±æ•— {file_path}: {e}")
            return []
    
    def load_historical_data(self) -> List[Dict[str, str]]:
        """è¼‰å…¥æ­·å²æ•¸æ“šä½œç‚ºå‚™ç”¨ (èˆŠç‰ˆå…¼å®¹)"""
        try:
            import sys
            sys.path.append('/app/netstack_api')
            from netstack_api.data.historical_tle_data import get_historical_tle_data
            
            historical_starlink = get_historical_tle_data('starlink')
            
            # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
            satellites = []
            for sat_data in historical_starlink:
                satellite = {
                    'name': sat_data['name'],
                    'norad_id': str(sat_data['norad_id']),
                    'line1': sat_data['line1'],
                    'line2': sat_data['line2'],
                    'download_time': datetime.now(timezone.utc).isoformat(),
                    'data_source': 'historical_data'
                }
                satellites.append(satellite)
            
            logger.info(f"è¼‰å…¥æ­·å²æ•¸æ“š: {len(satellites)} é¡†è¡›æ˜Ÿ")
            return satellites
            
        except Exception as e:
            logger.error(f"è¼‰å…¥æ­·å²æ•¸æ“šå¤±æ•—: {e}")
            return []

def main():
    """ä¸»å‡½æ•¸ - æ¼”ç¤ºæœ¬åœ° TLE è¼‰å…¥"""
    print("ğŸ“„ æœ¬åœ° TLE æ–‡å­—æª”è¼‰å…¥å™¨")
    print("=" * 40)
    
    loader = LocalTLELoader()
    
    # å‰µå»ºç¯„ä¾‹æª”æ¡ˆ
    loader.save_sample_file()
    
    # å˜—è©¦è¼‰å…¥æ•¸æ“š
    satellites = loader.get_starlink_tle_data()
    
    if satellites:
        print(f"\nâœ… æˆåŠŸè¼‰å…¥ {len(satellites)} é¡†è¡›æ˜Ÿæ•¸æ“š")
        print(f"ğŸ“Š æ•¸æ“šä¾†æº: {satellites[0].get('data_source', 'unknown')}")
        
        # é¡¯ç¤ºå‰å¹¾é¡†è¡›æ˜Ÿ
        print(f"\nğŸ“ å‰5é¡†è¡›æ˜Ÿ:")
        for i, sat in enumerate(satellites[:5]):
            print(f"  {i+1}. {sat['name']} (ID: {sat['norad_id']})")
    else:
        print("âŒ æœªè¼‰å…¥ä»»ä½•æ•¸æ“š")

if __name__ == "__main__":
    main()