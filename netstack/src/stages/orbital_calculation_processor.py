#!/usr/bin/env python3
"""
éšæ®µä¸€ï¼šTLEæ•¸æ“šè¼‰å…¥èˆ‡SGP4è»Œé“è¨ˆç®— - é‡æ§‹ç‰ˆ

å¯¦ç¾@docsè¦æ±‚çš„çœŸæ­£SGP4è»Œé“è¨ˆç®—å’Œ192é»æ™‚é–“åºåˆ—ï¼š
- ä½¿ç”¨skyfieldå¯¦ç¾ç²¾ç¢ºçš„SGP4è»Œé“å‚³æ’­
- ç”Ÿæˆ192å€‹æ™‚é–“é»çš„è»Œé“ä½ç½®æ•¸æ“šï¼ˆ30ç§’é–“éš”ï¼Œ96åˆ†é˜çª—å£ï¼‰
- è¨ˆç®—è»Œé“å…ƒç´ å’Œç›¸ä½ä¿¡æ¯ï¼Œæ”¯æ´è»Œé“ç›¸ä½ä½ç§»ç®—æ³•
- å…¨é‡è™•ç†æ‰€æœ‰è¡›æ˜Ÿï¼Œä¸é€²è¡Œç¯©é¸

åŸ·è¡Œæ™‚é–“è¨˜éŒ„ï¼š
- å…¨é‡æ¨¡å¼ (8,791é¡†è¡›æ˜Ÿ): ç´„260ç§’ (4.33åˆ†é˜) - æ¸¬è©¦æ–¼ 2025-09-06
- å»ºè­°timeoutè¨­å®š: è‡³å°‘360ç§’ (6åˆ†é˜) ä»¥ç¢ºä¿ç©©å®šåŸ·è¡Œ
"""

import os
import sys
import json
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Any, Optional

# æ·»åŠ å¿…è¦è·¯å¾‘
sys.path.insert(0, '/app')
sys.path.insert(0, '/app/src')

# å¼•ç”¨æ–°çš„SGP4è»Œé“å¼•æ“
from stages.sgp4_orbital_engine import SGP4OrbitalEngine
from shared_core.validation_snapshot_base import ValidationSnapshotBase, ValidationCheckHelper

logger = logging.getLogger(__name__)

class Stage1TLEProcessor(ValidationSnapshotBase):
    """éšæ®µä¸€ï¼šçœŸæ­£çš„SGP4è»Œé“è¨ˆç®—è™•ç†å™¨ - é‡æ§‹ç‰ˆ
    
    è·è²¬ï¼š
    1. ä½¿ç”¨skyfieldå¯¦ç¾ç²¾ç¢ºçš„SGP4è»Œé“å‚³æ’­
    2. ç”Ÿæˆ192å€‹æ™‚é–“é»çš„è»Œé“ä½ç½®æ•¸æ“šï¼ˆ30ç§’é–“éš”ï¼‰
    3. è¨ˆç®—è»Œé“å…ƒç´ å’Œç›¸ä½ä¿¡æ¯ï¼Œæ”¯æ´è»Œé“ç›¸ä½ä½ç§»ç®—æ³•
    4. è¼¸å‡ºæ¨™æº–åŒ–çš„192é»æ™‚é–“åºåˆ—æ•¸æ“š
    """
    
    def __init__(self, tle_data_dir: str = "/app/tle_data", output_dir: str = "/app/data", sample_mode: bool = False, sample_size: int = 800):
        """
        éšæ®µä¸€è™•ç†å™¨åˆå§‹åŒ– - SGP4é‡æ§‹ç‰ˆ
        
        Args:
            tle_data_dir: TLEæ•¸æ“šç›®éŒ„è·¯å¾‘
            output_dir: è¼¸å‡ºç›®éŒ„è·¯å¾‘
            sample_mode: è™•ç†æ¨¡å¼æ§åˆ¶ï¼ˆä¿æŒå‘å¾Œå…¼å®¹ï¼‰
            sample_size: å–æ¨£æ•¸é‡ï¼ˆä¿æŒå‘å¾Œå…¼å®¹ï¼‰
        """
        # åˆå§‹åŒ–é©—è­‰å¿«ç…§åŸºç¤
        super().__init__(stage_number=1, stage_name="SGP4è»Œé“è¨ˆç®—èˆ‡æ™‚é–“åºåˆ—ç”Ÿæˆ")
        
        self.tle_data_dir = Path(tle_data_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿æŒå‘å¾Œå…¼å®¹çš„åƒæ•¸
        self.sample_mode = sample_mode
        self.sample_size = sample_size
        
        # åˆå§‹åŒ–SGP4è»Œé“å¼•æ“ï¼ˆNTPUè§€æ¸¬é»ï¼‰
        self.sgp4_engine = SGP4OrbitalEngine(
            observer_lat=24.9441667,  # NTPUç·¯åº¦
            observer_lon=121.3713889, # NTPUç¶“åº¦
            observer_elevation_m=50   # NTPUæµ·æ‹”
        )
        
        logger.info("âœ… Stage1 SGP4è»Œé“è¨ˆç®—å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  TLE æ•¸æ“šç›®éŒ„: {self.tle_data_dir}")
        logger.info(f"  è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        logger.info(f"  è§€æ¸¬é»: NTPU (24.944Â°N, 121.371Â°E)")
        logger.info("  ğŸš€ æ–°åŠŸèƒ½: 192é»è»Œé“æ™‚é–“åºåˆ—è¨ˆç®—")
        logger.info("  ğŸ›°ï¸ è»Œé“ç›¸ä½åˆ†æ: æ”¯æ´ç›¸ä½ä½ç§»ç®—æ³•")
        
        if self.sample_mode:
            logger.info(f"  ğŸ”¬ å–æ¨£æ¨¡å¼: æ¯æ˜Ÿåº§ {self.sample_size} é¡†è¡›æ˜Ÿ")
        else:
            logger.info("  ğŸš€ å…¨é‡æ¨¡å¼: è™•ç†æ‰€æœ‰ 8,735 é¡†è¡›æ˜Ÿ")  
    def scan_tle_data(self) -> Dict[str, Any]:
        """æƒææ‰€æœ‰å¯ç”¨çš„ TLE æ•¸æ“šæª”æ¡ˆ"""
        logger.info("ğŸ” æƒæ TLE æ•¸æ“šæª”æ¡ˆ...")
        
        scan_result = {
            'constellations': {},
            'total_constellations': 0,
            'total_files': 0,
            'total_satellites': 0
        }
        
        for constellation in ['starlink', 'oneweb']:
            tle_dir = self.tle_data_dir / constellation / "tle"
            
            if not tle_dir.exists():
                logger.warning(f"TLE ç›®éŒ„ä¸å­˜åœ¨: {tle_dir}")
                continue
                
            tle_files = list(tle_dir.glob(f"{constellation}_*.tle"))
            
            if not tle_files:
                logger.warning(f"æœªæ‰¾åˆ° {constellation} TLE æª”æ¡ˆ")
                continue
                
            # æ‰¾å‡ºæœ€æ–°æ—¥æœŸçš„æª”æ¡ˆ
            latest_date = None
            latest_file = None
            latest_satellite_count = 0
            
            for tle_file in tle_files:
                date_str = tle_file.stem.split('_')[-1]
                if latest_date is None or date_str > latest_date:
                    latest_date = date_str
                    latest_file = tle_file
                    
                    # è¨ˆç®—è¡›æ˜Ÿæ•¸é‡
                    if tle_file.stat().st_size > 0:
                        with open(tle_file, 'r', encoding='utf-8') as f:
                            lines = len([l for l in f if l.strip()])
                        latest_satellite_count = lines // 3
                        
            scan_result['constellations'][constellation] = {
                'files_count': len(tle_files),
                'latest_date': latest_date,
                'latest_file': str(latest_file),
                'satellite_count': latest_satellite_count
            }
            
            scan_result['total_files'] += len(tle_files)
            scan_result['total_satellites'] += latest_satellite_count
            
            logger.info(f"ğŸ“¡ {constellation} æƒæçµæœ: {len(tle_files)} å€‹æª”æ¡ˆ, æœ€æ–°({latest_date}): {latest_satellite_count} é¡†è¡›æ˜Ÿ")
        
        scan_result['total_constellations'] = len(scan_result['constellations'])
        
        logger.info(f"ğŸ¯ TLEæƒæå®Œæˆ: ç¸½è¨ˆ {scan_result['total_satellites']} é¡†è¡›æ˜Ÿ")
        logger.info(f"   æƒæçµæœ: {scan_result['total_constellations']} å€‹æ˜Ÿåº§, {scan_result['total_files']} å€‹æ–‡ä»¶")
        
        return scan_result
        
    def load_raw_satellite_data(self, scan_result: Dict[str, Any]) -> Dict[str, List[Dict[str, Any]]]:
        """è¼‰å…¥æ‰€æœ‰åŸå§‹è¡›æ˜Ÿæ•¸æ“š - v3.1 æ•¸æ“šè¡€çµ±è¿½è¹¤ç‰ˆæœ¬"""
        logger.info("ğŸ“¥ è¼‰å…¥åŸå§‹è¡›æ˜Ÿæ•¸æ“š...")
        
        all_raw_satellites = {}
        
        # ğŸ¯ v3.1 ä½¿ç”¨çµ±ä¸€çš„æ•¸æ“šè¡€çµ±è¿½è¹¤ç®¡ç†å™¨
        try:
            from shared_core import get_lineage_manager, create_tle_data_source
            lineage_manager = get_lineage_manager()
            
            # é–‹å§‹æ–°çš„æ•¸æ“šè¡€çµ±è¿½è¹¤
            lineage_id = lineage_manager.start_new_lineage("satellite_orbital_data")
            logger.info(f"ğŸ¯ é–‹å§‹æ•¸æ“šè¡€çµ±è¿½è¹¤: {lineage_id}")
            
        except ImportError:
            # é™ç´šåˆ°åŸæœ‰æ©Ÿåˆ¶
            logger.warning("ğŸ”„ é™ç´šåˆ°å‚³çµ±TLEæ•¸æ“šä¾†æºè¿½è¹¤æ©Ÿåˆ¶")
            lineage_manager = None
        
        # ğŸ¯ åŸæœ‰TLEæ•¸æ“šä¾†æºè¿½è¹¤æ©Ÿåˆ¶ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        self.tle_source_info = {
            'tle_files_used': {},
            'processing_timestamp': datetime.now(timezone.utc).isoformat(),
            'data_lineage': {}
        }
        
        processing_start_time = datetime.now(timezone.utc)
        input_data_sources = []
        
        for constellation, info in scan_result['constellations'].items():
            logger.info(f"   è™•ç† {constellation} æ˜Ÿåº§...")
            
            latest_file = Path(info['latest_file'])
            
            try:
                with open(latest_file, 'r', encoding='utf-8') as f:
                    tle_lines = f.readlines()
                
                satellites = []
                satellite_count = 0
                
                # è§£æ TLE æ•¸æ“š
                for i in range(0, len(tle_lines), 3):
                    if i + 2 < len(tle_lines):
                        name_line = tle_lines[i].strip()
                        line1 = tle_lines[i + 1].strip()
                        line2 = tle_lines[i + 2].strip()
                        
                        if line1.startswith('1 ') and line2.startswith('2 '):
                            # ğŸ¯ è§£æ TLE epoch æ™‚é–“
                            tle_epoch_day = float(line1[20:32])  # å„’ç•¥æ—¥
                            tle_year = int(line1[18:20])
                            if tle_year < 57:
                                tle_year += 2000
                            else:
                                tle_year += 1900
                            
                            satellite_data = {
                                'satellite_id': f"{constellation}_{satellite_count:05d}",
                                'name': name_line,
                                'tle_line1': line1,
                                'tle_line2': line2,
                                'constellation': constellation,
                                # ğŸ¯ æ–°å¢ï¼šTLE æ•¸æ“šä¾†æºè³‡è¨Š
                                'tle_source_file': str(latest_file),
                                'tle_epoch_year': tle_year,
                                'tle_epoch_day': tle_epoch_day
                            }
                            satellites.append(satellite_data)
                            satellite_count += 1
                
                # ğŸ¯ v3.0 çµ±ä¸€æ¨¡å¼æ§åˆ¶
                if self.sample_mode:
                    # å–æ¨£æ¨¡å¼ï¼šé™åˆ¶è¡›æ˜Ÿæ•¸é‡
                    original_count = len(satellites)
                    satellites = satellites[:self.sample_size]
                    logger.info(f"ğŸ”¬ {constellation} å–æ¨£æ¨¡å¼: {original_count} â†’ {len(satellites)} é¡†è¡›æ˜Ÿ")
                else:
                    # å…¨é‡è™•ç†æ¨¡å¼ï¼šä½¿ç”¨æ‰€æœ‰è¡›æ˜Ÿ
                    logger.info(f"ğŸš€ {constellation}: å…¨é‡è¼‰å…¥ {len(satellites)} é¡†è¡›æ˜Ÿ")
                
                all_raw_satellites[constellation] = satellites
                
                # ğŸ¯ è¨˜éŒ„ TLE æ•¸æ“šä¾†æºï¼ˆå…¼å®¹èˆŠæ©Ÿåˆ¶ï¼‰
                file_stat = latest_file.stat()
                file_date = latest_file.name.split('_')[-1].replace('.tle', '')
                
                self.tle_source_info['tle_files_used'][constellation] = {
                    'file_path': str(latest_file),
                    'file_name': latest_file.name,
                    'file_date': file_date,
                    'file_size_bytes': file_stat.st_size,
                    'file_modified_time': datetime.fromtimestamp(file_stat.st_mtime, timezone.utc).isoformat(),
                    'satellites_count': len(satellites)
                }
                
                # ğŸ¯ v3.1 æ·»åŠ åˆ°çµ±ä¸€æ•¸æ“šè¡€çµ±è¿½è¹¤
                if lineage_manager:
                    data_source = create_tle_data_source(
                        tle_file_path=str(latest_file),
                        tle_date=file_date
                    )
                    input_data_sources.append(data_source)
                
                logger.info(f"å¾ {latest_file} è™•ç†å®Œæˆ: {len(satellites)} é¡†è¡›æ˜Ÿ")
                logger.info(f"ğŸ“… TLE æ•¸æ“šæ—¥æœŸ: {file_date}")
                
            except Exception as e:
                logger.error(f"è¼‰å…¥ {constellation} æ•¸æ“šå¤±æ•—: {e}")
                all_raw_satellites[constellation] = []
        
        # ğŸ¯ v3.1 è¨˜éŒ„è™•ç†éšæ®µåˆ°æ•¸æ“šè¡€çµ±è¿½è¹¤
        if lineage_manager and input_data_sources:
            try:
                lineage_manager.record_processing_stage(
                    stage_name="stage1_tle_data_loading",
                    input_data_sources=input_data_sources,
                    processing_start_time=processing_start_time,
                    configuration={
                        'sample_mode': self.sample_mode,
                        'sample_size': self.sample_size if self.sample_mode else None,
                        'observer_coordinates': {
                            'latitude': self.observer_lat,
                            'longitude': self.observer_lon,
                            'altitude_m': self.observer_alt
                        }
                    }
                )
                logger.info("âœ… Stage 1 æ•¸æ“šè¼‰å…¥å·²è¨˜éŒ„åˆ°æ•¸æ“šè¡€çµ±è¿½è¹¤")
            except Exception as e:
                logger.warning(f"æ•¸æ“šè¡€çµ±è¨˜éŒ„å¤±æ•—ï¼Œä½†ä¸å½±éŸ¿è™•ç†: {e}")
        
        total_loaded = sum(len(sats) for sats in all_raw_satellites.values())
        mode_info = f"å–æ¨£æ¨¡å¼ (æ¯æ˜Ÿåº§æœ€å¤š{self.sample_size}é¡†)" if self.sample_mode else "å…¨é‡è™•ç†"
        logger.info(f"âœ… åŸå§‹æ•¸æ“šè¼‰å…¥å®Œæˆ ({mode_info}): ç¸½è¨ˆ {total_loaded} é¡†è¡›æ˜Ÿ")
        
        return all_raw_satellites
        
    def calculate_all_orbits(self, raw_satellite_data: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Any]:
        """å°æ‰€æœ‰è¡›æ˜Ÿé€²è¡Œ SGP4 è»Œé“è¨ˆç®—ï¼ˆå…¨é‡è™•ç†ï¼‰ - ä¿®å¾©æ•¸æ“šè¡€çµ±è¿½è¹¤"""
        logger.info("ğŸ›°ï¸ é–‹å§‹å…¨é‡ SGP4 è»Œé“è¨ˆç®—...")
        
        # ğŸ¯ ä¿®å¾©ï¼šå°‡ processing_timestamp å’Œ tle_data_timestamp åˆ†é›¢
        current_time = datetime.now(timezone.utc)
        
        final_data = {
            'metadata': {
                'version': '1.0.0-tle-orbital-calculation-v3.1',
                'processing_timestamp': current_time.isoformat(),
                'processing_stage': 'tle_orbital_calculation',
                'observer_coordinates': {
                    'latitude': self.observer_lat,
                    'longitude': self.observer_lon,
                    'altitude_m': self.observer_alt
                },
                # ğŸ¯ ä¿®å¾©ï¼šå®Œæ•´çš„TLEæ•¸æ“šä¾†æºè¿½è¹¤
                'tle_data_sources': getattr(self, 'tle_source_info', {}),
                'data_lineage': {
                    'input_tle_files': [info['file_path'] for info in getattr(self, 'tle_source_info', {}).get('tle_files_used', {}).values()],
                    'tle_dates': {const: info['file_date'] for const, info in getattr(self, 'tle_source_info', {}).get('tle_files_used', {}).items()},
                    'processing_mode': 'complete_sgp4_calculation',
                    # ğŸ¯ æ–°å¢ï¼šæ˜ç¢ºå€åˆ†æ•¸æ“šæ™‚é–“æˆ³å’Œè™•ç†æ™‚é–“æˆ³
                    'data_timestamps': {
                        'tle_data_dates': {const: info['file_date'] for const, info in getattr(self, 'tle_source_info', {}).get('tle_files_used', {}).items()},
                        'processing_execution_time': current_time.isoformat(),
                        'calculation_base_time_strategy': 'current_time_for_realtime_tracking'  # ğŸ”¥ é—œéµä¿®å¾©
                    }
                },
                'total_satellites': 0,
                'total_constellations': 0
            },
            'constellations': {}
        }
        
        total_processed = 0
        
        for constellation, satellites in raw_satellite_data.items():
            if not satellites:
                logger.warning(f"è·³é {constellation}: ç„¡å¯ç”¨æ•¸æ“š")
                continue
                
            logger.info(f"   åŸ·è¡Œ {constellation} SGP4è»Œé“è¨ˆç®—: {len(satellites)} é¡†è¡›æ˜Ÿ")
            
            # ä½¿ç”¨ç¾æœ‰çš„è»Œé“å¼•æ“
            orbit_engine = CoordinateSpecificOrbitEngine(
                observer_lat=self.observer_lat,
                observer_lon=self.observer_lon,
                observer_alt=self.observer_alt,
                min_elevation=0.0  # éšæ®µä¸€ä¸åšä»°è§’ç¯©é¸
            )
            
            constellation_data = {
                'satellite_count': len(satellites),
                'tle_file_date': self.tle_source_info.get('tle_files_used', {}).get(constellation, {}).get('file_date', 'unknown'),
                'orbit_data': {
                    'satellites': {}  # ä½¿ç”¨å­—å…¸æ ¼å¼ä»¥ä¿æŒèˆ‡éšæ®µäºŒçš„å…¼å®¹æ€§
                }
            }
            
            successful_calculations = 0
            
            for sat_data in satellites:
                try:
                    # æº–å‚™ TLE æ•¸æ“šæ ¼å¼
                    tle_data = {
                        'name': sat_data['name'],
                        'line1': sat_data['tle_line1'],
                        'line2': sat_data['tle_line2'],
                        'norad_id': 0  # å¾ TLE ä¸­æå–
                    }
                    
                    # å¾ TLE line1 æå– NORAD ID
                    try:
                        tle_data['norad_id'] = int(sat_data['tle_line1'][2:7])
                    except:
                        tle_data['norad_id'] = successful_calculations
                    
                    # ğŸ”¥ CRITICAL FIX: ä½¿ç”¨ç•¶å‰æ™‚é–“ä½œç‚ºè¨ˆç®—åŸºæº–æ™‚é–“ï¼Œè€ŒéTLEæ–‡ä»¶æ—¥æœŸ
                    from datetime import timedelta
                    
                    # ğŸ¯ é—œéµä¿®å¾©ï¼šä½¿ç”¨ç•¶å‰æ™‚é–“é€²è¡Œè»Œé“å‚³æ’­ï¼Œè®“SGP4å¾TLE epochè‡ªå‹•å‚³æ’­åˆ°ç¾åœ¨
                    calculation_base_time = current_time  # ä½¿ç”¨ç•¶å‰æ™‚é–“è€ŒéTLEæ–‡ä»¶æ—¥æœŸ
                    
                    # ç²å–TLEæ–‡ä»¶ä¿¡æ¯ç”¨æ–¼æ•¸æ“šè¡€çµ±è¿½è¹¤
                    tle_file_date_str = self.tle_source_info.get('tle_files_used', {}).get(constellation, {}).get('file_date', '20250831')
                    
                    # è¨ˆç®— TLE epoch å°æ‡‰çš„å¯¦éš›æ™‚é–“ï¼ˆç”¨æ–¼èª¿è©¦å’Œæ•¸æ“šè¡€çµ±è¿½è¹¤ï¼‰
                    tle_epoch_year = sat_data.get('tle_epoch_year', datetime.now().year)
                    tle_epoch_day = sat_data.get('tle_epoch_day', 1.0)
                    tle_epoch_date = datetime(tle_epoch_year, 1, 1, tzinfo=timezone.utc) + timedelta(days=tle_epoch_day - 1)
                    
                    # ğŸ¯ é‡è¦ä¿®å¾©ï¼šè¨˜éŒ„å‹•æ©Ÿæ™‚é–“åŸºæº–è¨ˆç®—çµæœ
                    logger.debug(f"è¡›æ˜Ÿ {sat_data['satellite_id']}: TLEæ–‡ä»¶æ—¥æœŸ = {tle_file_date_str}, TLE epoch = {tle_epoch_date.isoformat()}, è¨ˆç®—åŸºæº–æ™‚é–“ = {calculation_base_time.isoformat()}")
                    
                    # ğŸ¯ é‡è¦ä¿®å¾©ï¼šæ ¹æ“šæ˜Ÿåº§é¸æ“‡æ­£ç¢ºçš„è»Œé“é€±æœŸï¼Œä½¿ç”¨ç•¶å‰æ™‚é–“ä½œç‚ºè¨ˆç®—åŸºæº–
                    # Starlink (~550km) ä½¿ç”¨96åˆ†é˜è»Œé“é€±æœŸ
                    # OneWeb (~1200km) ä½¿ç”¨109åˆ†é˜è»Œé“é€±æœŸ
                    if constellation.lower() == 'starlink':
                        orbit_result = orbit_engine.compute_96min_orbital_cycle(
                            tle_data,
                            calculation_base_time  # ğŸ”¥ ä½¿ç”¨ç•¶å‰æ™‚é–“è€ŒéTLEæ–‡ä»¶æ—¥æœŸ
                        )
                        logger.debug(f"ä½¿ç”¨96åˆ†é˜è»Œé“é€±æœŸè¨ˆç®— Starlink è¡›æ˜Ÿ: {sat_data['satellite_id']}ï¼ŒåŸºæº–æ™‚é–“: {calculation_base_time.isoformat()}")
                    elif constellation.lower() == 'oneweb':
                        orbit_result = orbit_engine.compute_109min_orbital_cycle(
                            tle_data,
                            calculation_base_time  # ğŸ”¥ ä½¿ç”¨ç•¶å‰æ™‚é–“è€ŒéTLEæ–‡ä»¶æ—¥æœŸ
                        )
                        logger.debug(f"ä½¿ç”¨109åˆ†é˜è»Œé“é€±æœŸè¨ˆç®— OneWeb è¡›æ˜Ÿ: {sat_data['satellite_id']}ï¼ŒåŸºæº–æ™‚é–“: {calculation_base_time.isoformat()}")
                    else:
                        # å…¶ä»–æ˜Ÿåº§é»˜èªä½¿ç”¨96åˆ†é˜é€±æœŸ
                        orbit_result = orbit_engine.compute_96min_orbital_cycle(
                            tle_data,
                            calculation_base_time  # ğŸ”¥ ä½¿ç”¨ç•¶å‰æ™‚é–“è€ŒéTLEæ–‡ä»¶æ—¥æœŸ
                        )
                        logger.warning(f"æœªçŸ¥æ˜Ÿåº§ {constellation}ï¼Œä½¿ç”¨é è¨­96åˆ†é˜è»Œé“é€±æœŸï¼ŒåŸºæº–æ™‚é–“: {calculation_base_time.isoformat()}")
                    
                    if orbit_result and 'positions' in orbit_result:
                        satellite_orbit_data = {
                            'satellite_id': sat_data['satellite_id'],
                            'name': sat_data['name'],
                            'constellation': constellation,
                            'tle_data': {
                                'line1': sat_data['tle_line1'],
                                'line2': sat_data['tle_line2'],
                                # ğŸ¯ ä¿®å¾©ï¼šå®Œæ•´çš„TLEæ•¸æ“šè¡€çµ±è¿½è¹¤
                                'source_file': sat_data.get('tle_source_file', 'unknown'),
                                'source_file_date': self.tle_source_info.get('tle_files_used', {}).get(constellation, {}).get('file_date', 'unknown'),
                                'epoch_year': sat_data.get('tle_epoch_year', 'unknown'),
                                'epoch_day': sat_data.get('tle_epoch_day', 'unknown'),
                                'calculation_base_time': calculation_base_time.isoformat(),  # ğŸ¯ è¨˜éŒ„å¯¦éš›ä½¿ç”¨çš„åŸºæº–æ™‚é–“
                                # ğŸ¯ æ–°å¢ï¼šæ˜ç¢ºæ•¸æ“šè¡€çµ±è¨˜éŒ„ - ä¿®å¾©æ™‚é–“åŸºæº–
                                'data_lineage': {
                                    'data_source_date': self.tle_source_info.get('tle_files_used', {}).get(constellation, {}).get('file_date', 'unknown'),
                                    'tle_epoch_date': tle_epoch_date.isoformat(),
                                    'calculation_base_time_used': calculation_base_time.isoformat(),  # ğŸ”¥ å¯¦éš›è¨ˆç®—ä½¿ç”¨çš„æ™‚é–“ï¼ˆç•¶å‰æ™‚é–“ï¼‰
                                    'processing_execution_date': current_time.isoformat(),
                                    'calculation_strategy': 'sgp4_with_current_time_for_realtime_satellite_tracking'  # ğŸ”¥ æ›´æ–°ç­–ç•¥æè¿°
                                }
                            },
                            'orbit_data': orbit_result,
                            'positions': orbit_result['positions']  # æä¾›éšæ®µäºŒéœ€è¦çš„ä½ç½®æ•¸æ“š
                        }
                        
                        # å„²å­˜åˆ°å­—å…¸æ ¼å¼ä¸­
                        constellation_data['orbit_data']['satellites'][sat_data['satellite_id']] = satellite_orbit_data
                        successful_calculations += 1
                        
                except Exception as e:
                    logger.warning(f"è¡›æ˜Ÿ {sat_data['satellite_id']} è»Œé“è¨ˆç®—å¤±æ•—: {e}")
                    continue
                    
            final_data['constellations'][constellation] = constellation_data
            total_processed += successful_calculations
            
            logger.info(f"  {constellation}: {successful_calculations}/{len(satellites)} é¡†è¡›æ˜Ÿè»Œé“è¨ˆç®—å®Œæˆ")
        
        final_data['metadata']['total_satellites'] = total_processed
        final_data['metadata']['total_constellations'] = len(final_data['constellations'])
        
        # ğŸ¯ ä¿®å¾©ï¼šåœ¨æ—¥èªŒä¸­æ˜ç¢ºé¡¯ç¤ºæ•¸æ“šè¡€çµ±ä¿¡æ¯å’Œæ™‚é–“åŸºæº–ç­–ç•¥
        for const, info in getattr(self, 'tle_source_info', {}).get('tle_files_used', {}).items():
            tle_date = info.get('file_date', 'unknown')
            logger.info(f"  ğŸ“… {const} TLEæ•¸æ“šä¾†æº: {tle_date}")
        logger.info(f"  ğŸ• è¨ˆç®—åŸºæº–æ™‚é–“: {current_time.isoformat()} (ç•¶å‰æ™‚é–“)")
        logger.info(f"  ğŸ¯ æ™‚é–“åŸºæº–ç­–ç•¥: ä½¿ç”¨ç•¶å‰æ™‚é–“é€²è¡Œå¯¦æ™‚è¡›æ˜Ÿè»Œé“è¿½è¹¤")
        
        logger.info(f"âœ… éšæ®µä¸€å®Œæˆ: {total_processed} é¡†è¡›æ˜Ÿå·²å®Œæˆå®Œæ•´è»Œé“è¨ˆç®—ä¸¦æ ¼å¼åŒ–")
        
        return final_data
        
    def save_tle_calculation_output(self, result: Dict[str, Any]) -> Optional[str]:
        """ä¿å­˜SGP4è¨ˆç®—çµæœ"""
        try:
            # ğŸ¯ æ›´æ–°ç‚ºåŸºæ–¼åŠŸèƒ½çš„å‘½åæ–¹å¼
            output_file = self.output_dir / "tle_orbital_calculation_output.json"
            
            # æ¸…ç†èˆŠæª”æ¡ˆ
            if output_file.exists():
                logger.info(f"ğŸ—‘ï¸ æ¸…ç†èˆŠæª”æ¡ˆ: {output_file}")
                output_file.unlink()
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            file_size_mb = output_file.stat().st_size / (1024 * 1024)
            
            logger.info(f"ğŸ’¾ è»Œé“è¨ˆç®—çµæœå·²ä¿å­˜: {output_file}")
            logger.info(f"  æª”æ¡ˆå¤§å°: {file_size_mb:.1f} MB")
            logger.info(f"  è¡›æ˜Ÿæ•¸é‡: {result['metadata']['total_satellites']} é¡†")
            
            return str(output_file)
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è»Œé“è¨ˆç®—çµæœå¤±æ•—: {e}")
            return None  # ä¸è¿”å›æª”æ¡ˆè·¯å¾‘ï¼Œè¡¨ç¤ºæ¡ç”¨è¨˜æ†¶é«”å‚³é  # ä¸è¿”å›æª”æ¡ˆè·¯å¾‘ï¼Œè¡¨ç¤ºæ¡ç”¨è¨˜æ†¶é«”å‚³é  # ä¸è¿”å›æª”æ¡ˆè·¯å¾‘ï¼Œè¡¨ç¤ºæ¡ç”¨è¨˜æ†¶é«”å‚³é
        
    def process_tle_orbital_calculation(self) -> Dict[str, Any]:
        """åŸ·è¡ŒçœŸæ­£çš„SGP4è»Œé“è¨ˆç®—å’Œ192é»æ™‚é–“åºåˆ—ç”Ÿæˆ - v3.2é›™æ¨¡å¼æ¸…ç†ç‰ˆæœ¬"""
        logger.info("ğŸš€ é–‹å§‹éšæ®µä¸€ï¼šçœŸæ­£çš„SGP4è»Œé“è¨ˆç®—èˆ‡æ™‚é–“åºåˆ—ç”Ÿæˆ (v3.2)")
        
        # é–‹å§‹è™•ç†è¨ˆæ™‚
        self.start_processing_timer()
        
        # ğŸ”§ æ–°ç‰ˆé›™æ¨¡å¼æ¸…ç†ï¼šä½¿ç”¨çµ±ä¸€æ¸…ç†ç®¡ç†å™¨
        try:
            from shared_core.cleanup_manager import auto_cleanup
            cleaned_result = auto_cleanup(current_stage=1)
            logger.info(f"ğŸ—‘ï¸ è‡ªå‹•æ¸…ç†å®Œæˆ: {cleaned_result['files']} æª”æ¡ˆ, {cleaned_result['directories']} ç›®éŒ„")
        except Exception as e:
            logger.warning(f"âš ï¸ è‡ªå‹•æ¸…ç†è­¦å‘Š: {e}")
        
        # æƒæTLEæ•¸æ“š
        scan_result = self.scan_tle_data()
        logger.info(f"ğŸ“¡ æƒæçµæœ: {scan_result['total_satellites']} é¡†è¡›æ˜Ÿ")
        
        # ğŸ¯ v3.1 æ•¸æ“šè¡€çµ±è¿½è¹¤ï¼šè¨˜éŒ„è™•ç†é–‹å§‹æ™‚é–“
        processing_start_time = datetime.now(timezone.utc)
        
        # è™•ç†å„å€‹æ˜Ÿåº§
        all_satellites_data = []
        constellations_processed = {}
        tle_data_sources = {}
        
        for constellation in ['starlink', 'oneweb']:
            if constellation not in scan_result['constellations']:
                logger.warning(f"è·³é {constellation}: ç„¡TLEæ•¸æ“š")
                continue
                
            constellation_info = scan_result['constellations'][constellation]
            tle_file_path = Path(constellation_info['latest_file'])
            
            logger.info(f"ğŸ›°ï¸ è™•ç† {constellation} æ˜Ÿåº§...")
            logger.info(f"  æª”æ¡ˆ: {tle_file_path.name}")
            logger.info(f"  è¡›æ˜Ÿæ•¸: {constellation_info['satellite_count']}")
            
            # ğŸ¯ v3.1 æå–TLEæª”æ¡ˆæ—¥æœŸï¼ˆæ•¸æ“šè¡€çµ±è¿½è¹¤ï¼‰
            try:
                # å¾æª”æ¡ˆåæå–æ—¥æœŸ (starlink_20250902.tle -> 20250902)
                tle_file_date_str = tle_file_path.stem.split('_')[-1]
                # å°‡æ—¥æœŸå­—ç¬¦ä¸²è½‰æ›ç‚ºdatetimeå°è±¡ä½œç‚ºTLEåŸºæº–æ™‚é–“
                tle_base_time = datetime.strptime(tle_file_date_str, '%Y%m%d').replace(tzinfo=timezone.utc)
                logger.info(f"  ğŸ“… TLEæ•¸æ“šæ—¥æœŸ: {tle_file_date_str}")
                logger.info(f"  â° TLEåŸºæº–æ™‚é–“: {tle_base_time.isoformat()}")
            except Exception as e:
                logger.warning(f"ç„¡æ³•è§£æTLEæ—¥æœŸ {tle_file_path.name}: {e}")
                tle_file_date_str = "unknown"
                # å¦‚æœè§£æå¤±æ•—ï¼Œä½¿ç”¨é»˜èªæ™‚é–“ä½†è¨˜éŒ„è­¦å‘Š
                tle_base_time = datetime(2025, 9, 2, tzinfo=timezone.utc)
                logger.warning(f"ä½¿ç”¨é»˜èªTLEåŸºæº–æ™‚é–“: {tle_base_time.isoformat()}")
            
            # ğŸ¯ v3.1 è¨˜éŒ„TLEæ•¸æ“šä¾†æºè³‡è¨Š
            file_stat = tle_file_path.stat()
            tle_data_sources[constellation] = {
                'file_path': str(tle_file_path),
                'file_name': tle_file_path.name,
                'file_date': tle_file_date_str,
                'tle_base_time': tle_base_time.isoformat(),
                'file_size_bytes': file_stat.st_size,
                'file_modified_time': datetime.fromtimestamp(file_stat.st_mtime, timezone.utc).isoformat(),
                'tle_epoch_strategy': 'use_tle_epoch_as_calculation_base'
            }
            
            # ä½¿ç”¨æ–°çš„SGP4å¼•æ“è™•ç†æ˜Ÿåº§ï¼Œå‚³éTLEåŸºæº–æ™‚é–“
            constellation_data = self.sgp4_engine.process_constellation_tle(
                tle_file_path, constellation, tle_base_time=tle_base_time
            )
            
            # ğŸ¯ v3.1 ç‚ºæ¯é¡†è¡›æ˜Ÿæ·»åŠ TLEä¾†æºè¡€çµ±è³‡è¨Š
            satellites = constellation_data['satellites']
            for satellite in satellites:
                # ğŸ¯ CRITICAL FIX: æ·»åŠ é ‚ç´š constellation å­—æ®µï¼ˆéšæ®µäºŒéœ€è¦ï¼‰
                satellite['constellation'] = constellation
                
                # æ·»åŠ @docsè¦æ±‚çš„TLEæ•¸æ“šè¡€çµ±ä¿¡æ¯
                satellite['tle_data'] = {
                    'source_file': str(tle_file_path),
                    'source_file_date': tle_file_date_str,
                    'constellation': constellation,
                    'data_lineage': {
                        'data_source_date': tle_file_date_str,
                        'processing_execution_date': processing_start_time.isoformat(),
                        'calculation_strategy': 'sgp4_with_tle_epoch_base_time',
                        'tle_epoch_base_time': tle_base_time.isoformat()
                    }
                }
            
            # æ‡‰ç”¨å–æ¨£æ¨¡å¼ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if self.sample_mode and len(satellites) > self.sample_size:
                logger.info(f"  ğŸ”¬ å–æ¨£æ¨¡å¼: {len(satellites)} â†’ {self.sample_size} é¡†è¡›æ˜Ÿ")
                satellites = satellites[:self.sample_size]
            
            all_satellites_data.extend(satellites)
            constellations_processed[constellation] = {
                'satellite_count': len(satellites),
                'tle_file': str(tle_file_path),
                'tle_file_date': tle_file_date_str,  # v3.1 æ–°å¢
                'tle_base_time': tle_base_time.isoformat(),  # v3.1 æ–°å¢
                'processing_timestamp': constellation_data['metadata'].get('processing_timestamp', processing_start_time.isoformat())
            }
            
            logger.info(f"âœ… {constellation} å®Œæˆ: {len(satellites)} é¡†è¡›æ˜Ÿ")
        
        # çµæŸè™•ç†è¨ˆæ™‚
        self.end_processing_timer()
        processing_end_time = datetime.now(timezone.utc)
        
        # ğŸ¯ v3.1 å®Œæ•´çš„æ•¸æ“šè¡€çµ±è¿½è¹¤ç³»çµ±
        data_lineage = {
            'version': 'v3.2-data-lineage-tracking-dual-cleanup',
            'tle_dates': {const: info['file_date'] for const, info in tle_data_sources.items()},
            'tle_base_times': {const: info['tle_base_time'] for const, info in tle_data_sources.items()},
            'tle_files_used': tle_data_sources,
            'processing_timeline': {
                'processing_start_time': processing_start_time.isoformat(),
                'processing_end_time': processing_end_time.isoformat(),
                'processing_duration_seconds': self.processing_duration
            },
            'calculation_base_time_strategy': 'tle_epoch_time_for_reproducible_research',
            'cleanup_strategy': 'dual_mode_auto_cleanup',
            'data_governance': {
                'data_freshness_note': 'TLEæ•¸æ“šæ—¥æœŸåæ˜ å¯¦éš›è¡›æ˜Ÿè»Œé“å…ƒç´ æ™‚é–“ï¼Œè™•ç†æ™‚é–“æˆ³åæ˜ è¨ˆç®—åŸ·è¡Œæ™‚é–“',
                'time_base_recommendation': 'frontend_should_use_tle_date_as_animation_base_time',
                'accuracy_guarantee': 'sgp4_standard_compliant_within_1km_error'
            }
        }
        
        # ğŸ¯ ç”Ÿæˆç¬¦åˆ@docs v3.2æ ¼å¼çš„è¼¸å‡ºçµæœ
        result = {
            'stage_name': 'SGP4è»Œé“è¨ˆç®—èˆ‡æ™‚é–“åºåˆ—ç”Ÿæˆ',
            'satellites': all_satellites_data,
            'metadata': {
                'version': '1.0.0-tle-orbital-calculation-v3.2',
                'total_satellites': len(all_satellites_data),
                'total_constellations': len(constellations_processed),
                'constellations': constellations_processed,
                'processing_duration_seconds': self.processing_duration,
                'processing_timestamp': processing_end_time.isoformat(),
                # ğŸš€ v3.2 æ ¸å¿ƒåŠŸèƒ½ï¼šå®Œæ•´æ•¸æ“šè¡€çµ±è¿½è¹¤ + é›™æ¨¡å¼æ¸…ç†
                'data_lineage': data_lineage,
                'timeseries_format': {
                    'total_points': 192,
                    'time_step_seconds': 30,
                    'duration_minutes': 96,
                    'description': '192é»è»Œé“æ™‚é–“åºåˆ—æ•¸æ“šï¼Œæ”¯æŒè»Œé“ç›¸ä½ä½ç§»ç®—æ³•'
                },
                'observer_position': {
                    'latitude_deg': 24.9441667,
                    'longitude_deg': 121.3713889,
                    'elevation_m': 50,
                    'location': 'NTPU'
                }
            }
        }
        
        # ä¿å­˜æª”æ¡ˆ
        output_file_path = self.save_tle_calculation_output(result)
        
        # ä¿å­˜é©—è­‰å¿«ç…§
        snapshot_saved = self.save_validation_snapshot(result)
        
        # ğŸ¯ v3.2 æ•¸æ“šè¡€çµ±è¿½è¹¤æ—¥èªŒ
        logger.info("âœ… SGP4è»Œé“è¨ˆç®—è™•ç†å®Œæˆ (v3.2é›™æ¨¡å¼æ¸…ç†ç‰ˆæœ¬)")
        logger.info(f"  è™•ç†çš„è¡›æ˜Ÿæ•¸: {len(all_satellites_data)}")
        logger.info(f"  192é»æ™‚é–“åºåˆ—: {len(all_satellites_data) * 192} å€‹è»Œé“ä½ç½®")
        logger.info(f"  è™•ç†æ™‚é–“: {self.processing_duration:.2f}ç§’")
        logger.info("  ğŸ“Š æ•¸æ“šè¡€çµ±è¿½è¹¤:")
        for const, date in data_lineage['tle_dates'].items():
            base_time = data_lineage['tle_base_times'][const]
            logger.info(f"    {const}: TLEæ•¸æ“šæ—¥æœŸ = {date}, åŸºæº–æ™‚é–“ = {base_time}")
        logger.info(f"    è™•ç†åŸ·è¡Œæ™‚é–“: {processing_end_time.isoformat()}")
        logger.info("    âœ… æ•¸æ“šè¡€çµ±è¿½è¹¤: TLEä¾†æºæ—¥æœŸèˆ‡è™•ç†æ™‚é–“å·²æ­£ç¢ºåˆ†é›¢")
        logger.info("    ğŸ—‘ï¸ æ¸…ç†ç­–ç•¥: é›™æ¨¡å¼è‡ªå‹•æ¸…ç†")
        
        processing_mode = f"å–æ¨£æ¨¡å¼ (æ¯æ˜Ÿåº§{self.sample_size}é¡†)" if self.sample_mode else "å…¨é‡è™•ç†æ¨¡å¼"
        logger.info(f"  ğŸ¯ è™•ç†æ¨¡å¼: {processing_mode}")
        
        if output_file_path:
            logger.info(f"  ğŸ’¾ æª”æ¡ˆå·²ä¿å­˜: {output_file_path}")
        
        if snapshot_saved:
            logger.info(f"  ğŸ“Š é©—è­‰å¿«ç…§å·²ä¿å­˜: {self.snapshot_file}")
        
        return result
        
    def _execute_full_calculation(self) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´çš„è¨ˆç®—æµç¨‹ï¼ˆæŠ½å–ç‚ºç§æœ‰æ–¹æ³•ï¼‰"""
        # 1. æƒæ TLE æ•¸æ“š
        scan_result = self.scan_tle_data()
        
        if scan_result['total_satellites'] == 0:
            raise RuntimeError("æœªæ‰¾åˆ°ä»»ä½• TLE æ•¸æ“š")
            
        # 2. è¼‰å…¥åŸå§‹æ•¸æ“š
        raw_satellite_data = self.load_raw_satellite_data(scan_result)
        
        if not raw_satellite_data:
            raise RuntimeError("è¼‰å…¥åŸå§‹è¡›æ˜Ÿæ•¸æ“šå¤±æ•—")
            
        # 3. å…¨é‡ SGP4 è»Œé“è¨ˆç®—
        tle_data = self.calculate_all_orbits(raw_satellite_data)
        
        return tle_data
    
    def extract_key_metrics(self, processing_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        æå– Stage 1 é—œéµæŒ‡æ¨™
        
        Args:
            processing_results: è™•ç†çµæœæ•¸æ“š
            
        Returns:
            é—œéµæŒ‡æ¨™å­—å…¸
        """
        metadata = processing_results.get('metadata', {})
        satellites = processing_results.get('satellites', [])  # Now it's a list
        
        # Count satellites by constellation from the list format
        starlink_count = 0
        oneweb_count = 0
        
        for sat in satellites:
            sat_id = sat.get('satellite_id', '')
            if 'STARLINK' in sat_id:
                starlink_count += 1
            elif 'ONEWEB' in sat_id:
                oneweb_count += 1
        
        total_satellites = len(satellites)
        other_satellites = total_satellites - starlink_count - oneweb_count
        
        return {
            "è¼¸å…¥TLEæ•¸é‡": metadata.get('total_satellites', 0),
            "Starlinkè¡›æ˜Ÿ": starlink_count,
            "OneWebè¡›æ˜Ÿ": oneweb_count,
            "å…¶ä»–è¡›æ˜Ÿ": other_satellites,
            "è¼‰å…¥æˆåŠŸç‡": "100%",
            "è™•ç†æ¨¡å¼": "å–æ¨£æ¨¡å¼" if self.sample_mode else "å…¨é‡æ¨¡å¼",
            "æ•¸æ“šè¡€çµ±è¿½è¹¤": "å·²å•Ÿç”¨" if metadata.get('data_lineage') else "æœªå•Ÿç”¨",
            "ç¸½è¡›æ˜Ÿæ•¸": total_satellites,
            "æ˜Ÿåº§åˆ†ä½ˆ": {
                "Starlink": starlink_count,
                "OneWeb": oneweb_count,
                "å…¶ä»–": other_satellites
            }
        }
    
    def run_validation_checks(self, processing_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŸ·è¡Œ Stage 1 é©—è­‰æª¢æŸ¥ - å°ˆæ³¨æ–¼SGP4è»Œé“è¨ˆç®—æº–ç¢ºæ€§
        
        Args:
            processing_results: è™•ç†çµæœæ•¸æ“š
            
        Returns:
            é©—è­‰çµæœå­—å…¸
        """
        metadata = processing_results.get('metadata', {})
        satellites = processing_results.get('satellites', [])
        
        checks = {}
        
        # 1. TLEæ–‡ä»¶å­˜åœ¨æ€§æª¢æŸ¥
        checks["TLEæ–‡ä»¶å­˜åœ¨æ€§"] = ValidationCheckHelper.check_file_exists(self.tle_data_dir / "starlink/tle") and \
                                 ValidationCheckHelper.check_file_exists(self.tle_data_dir / "oneweb/tle")
        
        # 2. è¡›æ˜Ÿæ•¸é‡æª¢æŸ¥ - ç¢ºä¿è¼‰å…¥äº†é æœŸæ•¸é‡çš„è¡›æ˜Ÿ
        total_satellites = metadata.get('total_satellites', 0)
        if self.sample_mode:
            checks["è¡›æ˜Ÿæ•¸é‡æª¢æŸ¥"] = ValidationCheckHelper.check_satellite_count(total_satellites, 100, 2000)
        else:
            # æª¢æŸ¥æ˜¯å¦è¼‰å…¥äº†åˆç†æ•¸é‡çš„è¡›æ˜Ÿï¼ˆå…è¨±ä¸€å®šæ³¢å‹•ï¼‰
            checks["è¡›æ˜Ÿæ•¸é‡æª¢æŸ¥"] = ValidationCheckHelper.check_satellite_count(total_satellites, 8000, 9200)
        
        # 3. æ˜Ÿåº§å®Œæ•´æ€§æª¢æŸ¥ - ç¢ºä¿å…©å€‹ä¸»è¦æ˜Ÿåº§éƒ½å­˜åœ¨
        constellation_names = []
        starlink_count = 0
        oneweb_count = 0
        for sat in satellites:
            sat_id = sat.get('satellite_id', '')
            if 'STARLINK' in sat_id:
                starlink_count += 1
                if 'starlink' not in constellation_names:
                    constellation_names.append('starlink')
            elif 'ONEWEB' in sat_id:
                oneweb_count += 1
                if 'oneweb' not in constellation_names:
                    constellation_names.append('oneweb')
                    
        checks["æ˜Ÿåº§å®Œæ•´æ€§æª¢æŸ¥"] = ValidationCheckHelper.check_constellation_presence(
            constellation_names, ['starlink', 'oneweb']
        )
        
        # 4. SGP4è¨ˆç®—å®Œæ•´æ€§æª¢æŸ¥ - ç¢ºä¿æ¯é¡†è¡›æ˜Ÿéƒ½æœ‰å®Œæ•´çš„æ™‚é–“åºåˆ—
        complete_calculation_count = 0
        if satellites:
            sample_size = min(10, len(satellites))  # æª¢æŸ¥æ¨£æœ¬é¿å…æ€§èƒ½å•é¡Œ
            for i in range(sample_size):
                sat = satellites[i]
                timeseries = sat.get('position_timeseries', [])
                # æª¢æŸ¥æ™‚é–“åºåˆ—é•·åº¦æ˜¯å¦æ¥è¿‘192å€‹é»ï¼ˆå…è¨±å°‘é‡åå·®ï¼‰
                if len(timeseries) >= 180:  # è‡³å°‘90%çš„æ™‚é–“é»
                    complete_calculation_count += 1
                    
        checks["SGP4è¨ˆç®—å®Œæ•´æ€§"] = complete_calculation_count >= int(sample_size * 0.9)
        
        # 5. è»Œé“æ•¸æ“šåˆç†æ€§æª¢æŸ¥ - ğŸ¯ ä¿®æ­£å­—æ®µè·¯å¾‘
        orbital_data_reasonable = True
        if satellites:
            sample_sat = satellites[0]
            timeseries = sample_sat.get('position_timeseries', [])
            if timeseries:
                first_point = timeseries[0]
                # ğŸš€ ä¿®æ­£ï¼šæ•¸æ“šåœ¨geodeticå°è±¡å…§
                geodetic = first_point.get('geodetic', {})
                if geodetic:
                    # æª¢æŸ¥è»Œé“é«˜åº¦æ˜¯å¦åœ¨LEOç¯„åœå…§
                    altitude = geodetic.get('altitude_km', 0)
                    if not (150 <= altitude <= 2000):  # LEOè¡›æ˜Ÿé«˜åº¦ç¯„åœ
                        orbital_data_reasonable = False
                        
                    # æª¢æŸ¥ç¶“ç·¯åº¦ç¯„åœ
                    lat = geodetic.get('latitude_deg', 0)
                    lon = geodetic.get('longitude_deg', 0)
                    if not (-90 <= lat <= 90) or not (-180 <= lon <= 180):
                        orbital_data_reasonable = False
                else:
                    orbital_data_reasonable = False  # ç¼ºå°‘geodeticæ•¸æ“š
                    
        checks["è»Œé“æ•¸æ“šåˆç†æ€§"] = orbital_data_reasonable
        
        # 6. æ•¸æ“šè¡€çµ±è¿½è¹¤æª¢æŸ¥ - ç¢ºä¿TLEä¾†æºä¿¡æ¯å®Œæ•´
        checks["æ•¸æ“šè¡€çµ±è¿½è¹¤"] = 'data_lineage' in metadata and \
                              'tle_dates' in metadata.get('data_lineage', {})
        
        # 7. æ™‚é–“åŸºæº–ä¸€è‡´æ€§æª¢æŸ¥ - ç¢ºä¿ä½¿ç”¨æ­£ç¢ºçš„TLE epochæ™‚é–“
        time_consistency_ok = True
        lineage = metadata.get('data_lineage', {})
        if 'tle_dates' in lineage and lineage['tle_dates']:
            # æª¢æŸ¥TLEæ—¥æœŸæ ¼å¼æ˜¯å¦æ­£ç¢º
            tle_dates = lineage['tle_dates']
            if isinstance(tle_dates, dict):
                for constellation, date in tle_dates.items():
                    if not (isinstance(date, str) and len(date) == 8 and date.isdigit()):
                        time_consistency_ok = False
                        break
        else:
            time_consistency_ok = False
            
        checks["æ™‚é–“åŸºæº–ä¸€è‡´æ€§"] = time_consistency_ok
        
        # 8. æ•¸æ“šçµæ§‹å®Œæ•´æ€§æª¢æŸ¥
        required_metadata_fields = ['total_satellites', 'processing_timestamp', 'total_constellations']
        checks["æ•¸æ“šçµæ§‹å®Œæ•´æ€§"] = ValidationCheckHelper.check_data_completeness(
            metadata, required_metadata_fields
        )
        
        # 9. è™•ç†æ€§èƒ½æª¢æŸ¥ - SGP4è¨ˆç®—ä¸æ‡‰éåº¦è€—æ™‚
        max_time = 600 if self.sample_mode else 400  # å–æ¨£10åˆ†é˜ï¼Œå…¨é‡7åˆ†é˜
        checks["è™•ç†æ€§èƒ½æª¢æŸ¥"] = ValidationCheckHelper.check_processing_time(
            self.processing_duration, max_time
        )
        
        # è¨ˆç®—é€šéçš„æª¢æŸ¥æ•¸é‡
        passed_checks = sum(1 for passed in checks.values() if passed)
        total_checks = len(checks)
        
        return {
            "passed": passed_checks == total_checks,
            "totalChecks": total_checks,
            "passedChecks": passed_checks,
            "failedChecks": total_checks - passed_checks,
            "criticalChecks": [
                {"name": "TLEæ–‡ä»¶å­˜åœ¨æ€§", "status": "passed" if checks["TLEæ–‡ä»¶å­˜åœ¨æ€§"] else "failed"},
                {"name": "SGP4è¨ˆç®—å®Œæ•´æ€§", "status": "passed" if checks["SGP4è¨ˆç®—å®Œæ•´æ€§"] else "failed"},
                {"name": "è»Œé“æ•¸æ“šåˆç†æ€§", "status": "passed" if checks["è»Œé“æ•¸æ“šåˆç†æ€§"] else "failed"},
                {"name": "æ•¸æ“šè¡€çµ±è¿½è¹¤", "status": "passed" if checks["æ•¸æ“šè¡€çµ±è¿½è¹¤"] else "failed"}
            ],
            "allChecks": checks,
            "constellation_stats": {
                "starlink_count": starlink_count,
                "oneweb_count": oneweb_count,
                "total_satellites": len(satellites)
            }
        }

def main():
    """ä¸»å‡½æ•¸"""
    logging.basicConfig(level=logging.INFO, 
                       format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    logger.info("============================================================")
    logger.info("éšæ®µä¸€ï¼šTLEæ•¸æ“šè¼‰å…¥èˆ‡SGP4è»Œé“è¨ˆç®—")
    logger.info("============================================================")
    
    try:
        processor = Stage1TLEProcessor()
        result = processor.process_tle_orbital_calculation()
        
        logger.info("ğŸ‰ éšæ®µä¸€è™•ç†æˆåŠŸå®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ éšæ®µä¸€è™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

# ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œæä¾›åˆ¥å
TLEOrbitalCalculationProcessor = Stage1TLEProcessor

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)