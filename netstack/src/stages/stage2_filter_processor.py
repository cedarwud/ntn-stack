#!/usr/bin/env python3
"""
éšæ®µäºŒï¼šæ™ºèƒ½è¡›æ˜Ÿç¯©é¸è™•ç†å™¨ - åŸ·è¡Œå°è£å™¨

å®Œå…¨éµå¾ª @docs/satellite_data_preprocessing.md è¦ç¯„ï¼š
- æ¥æ”¶éšæ®µä¸€è¼¸å‡ºçš„å®Œæ•´è¡›æ˜Ÿè»Œé“æ•¸æ“š
- åŸ·è¡Œæ™ºèƒ½ç¯©é¸ï¼ˆæ˜Ÿåº§åˆ†é›¢ã€åœ°ç†ç¯©é¸ã€æ›æ‰‹è©•åˆ†ï¼‰
- è¼¸å‡ºç¯©é¸å¾Œçš„é«˜å“è³ªè¡›æ˜Ÿå€™é¸
"""

import os
import sys
import json
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Any, Optional

# æ·»åŠ å¿…è¦è·¯å¾‘
sys.path.insert(0, '/app/netstack')
sys.path.insert(0, '/app')

# å¼•ç”¨é‡æ–°çµ„ç¹”å¾Œçš„æ™ºèƒ½ç¯©é¸ç³»çµ±
from src.services.satellite.intelligent_filtering.unified_intelligent_filter import create_unified_intelligent_filter

logger = logging.getLogger(__name__)

class Stage2FilterProcessor:
    """éšæ®µäºŒï¼šæ™ºèƒ½è¡›æ˜Ÿç¯©é¸è™•ç†å™¨å°è£
    
    è·è²¬ï¼š
    1. è¼‰å…¥éšæ®µä¸€è¼¸å‡ºçš„å®Œæ•´è»Œé“æ•¸æ“š
    2. åŸ·è¡Œçµ±ä¸€æ™ºèƒ½ç¯©é¸æµç¨‹
    3. ä¿å­˜éšæ®µäºŒç¯©é¸çµæœ
    4. ç‚ºéšæ®µä¸‰æä¾›é«˜å“è³ªè¼¸å…¥
    """
    
    def __init__(self, observer_lat: float = 24.9441667, observer_lon: float = 121.3713889,
                 input_dir: str = "/app/data", output_dir: str = "/app/data"):
        self.observer_lat = observer_lat
        self.observer_lon = observer_lon
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # å‰µå»ºçµ±ä¸€æ™ºèƒ½ç¯©é¸ç³»çµ±
        self.filter_system = create_unified_intelligent_filter(observer_lat, observer_lon)
        
        logger.info("âœ… éšæ®µäºŒè™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  è¼¸å…¥ç›®éŒ„: {self.input_dir}")
        logger.info(f"  è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        logger.info(f"  è§€æ¸¬åº§æ¨™: ({self.observer_lat}Â°, {self.observer_lon}Â°)")
        
    def load_stage1_output(self, stage1_file: Optional[str] = None) -> Dict[str, Any]:
        """è¼‰å…¥éšæ®µä¸€è¼¸å‡ºæ•¸æ“š"""
        if stage1_file is None:
            stage1_file = self.input_dir / "stage1_tle_sgp4_output.json"
        else:
            stage1_file = Path(stage1_file)
            
        logger.info(f"ğŸ“¥ è¼‰å…¥éšæ®µä¸€æ•¸æ“š: {stage1_file}")
        
        if not stage1_file.exists():
            raise FileNotFoundError(f"éšæ®µä¸€è¼¸å‡ºæª”æ¡ˆä¸å­˜åœ¨: {stage1_file}")
            
        try:
            with open(stage1_file, 'r', encoding='utf-8') as f:
                stage1_data = json.load(f)
                
            # é©—è­‰æ•¸æ“šæ ¼å¼
            if 'constellations' not in stage1_data:
                raise ValueError("éšæ®µä¸€æ•¸æ“šç¼ºå°‘ constellations æ¬„ä½")
                
            total_satellites = 0
            for constellation_name, constellation_data in stage1_data['constellations'].items():
                satellites = constellation_data.get('satellites', [])
                total_satellites += len(satellites)
                logger.info(f"  {constellation_name}: {len(satellites)} é¡†è¡›æ˜Ÿ")
                
            logger.info(f"âœ… éšæ®µä¸€æ•¸æ“šè¼‰å…¥å®Œæˆ: ç¸½è¨ˆ {total_satellites} é¡†è¡›æ˜Ÿ")
            return stage1_data
            
        except Exception as e:
            logger.error(f"è¼‰å…¥éšæ®µä¸€æ•¸æ“šå¤±æ•—: {e}")
            raise
            
    def execute_intelligent_filtering(self, stage1_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œæ™ºèƒ½ç¯©é¸æµç¨‹"""
        logger.info("ğŸ¯ é–‹å§‹æ™ºèƒ½è¡›æ˜Ÿç¯©é¸...")
        
        # éšæ®µäºŒæ¡ç”¨å‹•æ…‹ç¯©é¸ - ä¸è¨­å›ºå®šæ•¸é‡é™åˆ¶ï¼Œä¾æ“šç¯©é¸æ¢ä»¶å‹•æ…‹æ±ºå®š
        # ç§»é™¤ç¡¬ç·¨ç¢¼æ•¸é‡ï¼Œè®“æ™ºèƒ½ç¯©é¸ç³»çµ±æ ¹æ“šå¯¦éš›æ¢ä»¶å‹•æ…‹ç¯©é¸
        selection_config = None  # ä½¿ç”¨å‹•æ…‹ç¯©é¸æ¨¡å¼
        
        try:
            # åŸ·è¡Œéšæ®µäºŒå°ˆç”¨ç¯©é¸æµç¨‹ï¼ˆä¸åŒ…å«ä¿¡è™Ÿå“è³ªå’Œäº‹ä»¶åˆ†æï¼‰
            filtered_result = self.filter_system.process_stage2_filtering_only(
                stage1_data, 
                selection_config
            )
            
            # é©—è­‰ç¯©é¸çµæœ
            validation = self.filter_system.validate_filtering_results(filtered_result)
            
            if not validation['overall_quality']:
                logger.warning("âš ï¸ ç¯©é¸çµæœå“è³ªæª¢æŸ¥æœªå®Œå…¨é€šé")
                for key, status in validation.items():
                    if not status:
                        logger.warning(f"   {key}: æœªé€šé")
            else:
                logger.info("âœ… ç¯©é¸çµæœå“è³ªæª¢æŸ¥å…¨éƒ¨é€šé")
            
            return filtered_result
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ç¯©é¸åŸ·è¡Œå¤±æ•—: {e}")
            raise
            
    def save_stage2_output(self, filtered_data: Dict[str, Any]) -> str:
        """ä¿å­˜éšæ®µäºŒè¼¸å‡ºæ•¸æ“š - v3.0 æ¸…ç†èˆŠæª”æ¡ˆç‰ˆæœ¬"""
        output_file = self.output_dir / "stage2_intelligent_filtered_output.json"
        
        # ğŸ—‘ï¸ æ¸…ç†èˆŠæª”æ¡ˆ - ç¢ºä¿è³‡æ–™ä¸€è‡´æ€§
        if output_file.exists():
            file_size = output_file.stat().st_size
            logger.info(f"ğŸ—‘ï¸ æ¸…ç†èˆŠéšæ®µäºŒè¼¸å‡ºæª”æ¡ˆ: {output_file}")
            logger.info(f"   èˆŠæª”æ¡ˆå¤§å°: {file_size / (1024*1024):.1f} MB")
            output_file.unlink()
            logger.info("âœ… èˆŠæª”æ¡ˆå·²åˆªé™¤")
        
        # æ·»åŠ éšæ®µäºŒå®Œæˆæ¨™è¨˜
        filtered_data['metadata'].update({
            'stage2_completion': 'intelligent_filtering_complete',
            'stage2_timestamp': datetime.now(timezone.utc).isoformat(),
            'ready_for_stage3': True,
            'file_generation': 'clean_regeneration'  # æ¨™è¨˜ç‚ºé‡æ–°ç”Ÿæˆ
        })
        
        # ğŸ’¾ ç”Ÿæˆæ–°çš„éšæ®µäºŒè¼¸å‡ºæª”æ¡ˆ
        logger.info(f"ğŸ’¾ ç”Ÿæˆæ–°çš„éšæ®µäºŒè¼¸å‡ºæª”æ¡ˆ: {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(filtered_data, f, indent=2, ensure_ascii=False)
            
        # æª¢æŸ¥æ–°æª”æ¡ˆå¤§å°
        new_file_size = output_file.stat().st_size
        logger.info(f"âœ… éšæ®µäºŒæ•¸æ“šå·²ä¿å­˜: {output_file}")
        logger.info(f"   æ–°æª”æ¡ˆå¤§å°: {new_file_size / (1024*1024):.1f} MB")
        logger.info(f"   åŒ…å«è¡›æ˜Ÿæ•¸: {filtered_data['metadata'].get('unified_filtering_results', {}).get('total_selected', 'unknown')}")
        
        return str(output_file)
        
    def process_stage2(self, stage1_file: Optional[str] = None, stage1_data: Optional[Dict[str, Any]] = None, 
                      save_output: bool = True) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´çš„éšæ®µäºŒè™•ç†æµç¨‹"""
        logger.info("ğŸš€ é–‹å§‹éšæ®µäºŒï¼šæ™ºèƒ½è¡›æ˜Ÿç¯©é¸")
        
        # 1. è¼‰å…¥éšæ®µä¸€æ•¸æ“šï¼ˆå„ªå…ˆä½¿ç”¨å…§å­˜æ•¸æ“šï¼‰
        if stage1_data is not None:
            logger.info("ğŸ“¥ ä½¿ç”¨æä¾›çš„éšæ®µä¸€å…§å­˜æ•¸æ“š")
            # é©—è­‰å…§å­˜æ•¸æ“šæ ¼å¼
            if 'constellations' not in stage1_data:
                raise ValueError("éšæ®µä¸€æ•¸æ“šç¼ºå°‘ constellations æ¬„ä½")
            total_satellites = 0
            for constellation_name, constellation_data in stage1_data['constellations'].items():
                satellites = constellation_data.get('orbit_data', {}).get('satellites', {})
                total_satellites += len(satellites)
                logger.info(f"  {constellation_name}: {len(satellites)} é¡†è¡›æ˜Ÿ")
            logger.info(f"âœ… éšæ®µä¸€å…§å­˜æ•¸æ“šé©—è­‰å®Œæˆ: ç¸½è¨ˆ {total_satellites} é¡†è¡›æ˜Ÿ")
        else:
            stage1_data = self.load_stage1_output(stage1_file)
        
        # 2. åŸ·è¡Œæ™ºèƒ½ç¯©é¸
        filtered_data = self.execute_intelligent_filtering(stage1_data)
        
        # 3. å¯é¸çš„è¼¸å‡ºç­–ç•¥
        output_file = None
        if save_output:
            output_file = self.save_stage2_output(filtered_data)
            logger.info(f"ğŸ’¾ éšæ®µäºŒæ•¸æ“šå·²ä¿å­˜åˆ°: {output_file}")
        else:
            logger.info("ğŸš€ éšæ®µäºŒä½¿ç”¨å…§å­˜å‚³éæ¨¡å¼ï¼Œæœªä¿å­˜æª”æ¡ˆ")
        
        logger.info("âœ… éšæ®µäºŒè™•ç†å®Œæˆ")
        # ç²å–ç¯©é¸çµæœçµ±è¨ˆ
        total_selected = filtered_data['metadata'].get('unified_filtering_results', {}).get('total_selected', 0)
        starlink_selected = filtered_data['metadata'].get('unified_filtering_results', {}).get('starlink_selected', 0)
        oneweb_selected = filtered_data['metadata'].get('unified_filtering_results', {}).get('oneweb_selected', 0)
        
        logger.info(f"  ç¯©é¸çš„è¡›æ˜Ÿæ•¸: {total_selected} (Starlink: {starlink_selected}, OneWeb: {oneweb_selected})")
        if output_file:
            logger.info(f"  è¼¸å‡ºæª”æ¡ˆ: {output_file}")
        
        return filtered_data

def main():
    """ä¸»å‡½æ•¸"""
    logging.basicConfig(level=logging.INFO, 
                       format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    logger.info("============================================================")
    logger.info("éšæ®µäºŒï¼šæ™ºèƒ½è¡›æ˜Ÿç¯©é¸")
    logger.info("============================================================")
    
    try:
        processor = Stage2FilterProcessor()
        result = processor.process_stage2()
        
        logger.info("ğŸ‰ éšæ®µäºŒè™•ç†æˆåŠŸå®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ éšæ®µäºŒè™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)