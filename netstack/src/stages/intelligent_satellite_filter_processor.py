#!/usr/bin/env python3
"""
æ™ºèƒ½è¡›æ˜Ÿç¯©é¸è™•ç†å™¨ - åŸ·è¡Œå°è£å™¨

å®Œå…¨éµå¾ª @docs/satellite_data_preprocessing.md è¦ç¯„ï¼š
- æ¥æ”¶è»Œé“è¨ˆç®—è¼¸å‡ºçš„å®Œæ•´è¡›æ˜Ÿè»Œé“æ•¸æ“š
- åŸ·è¡Œæ™ºèƒ½ç¯©é¸ï¼ˆæ˜Ÿåº§åˆ†é›¢ã€åœ°ç†ç¯©é¸ã€æ›æ‰‹è©•åˆ†ï¼‰
- è¼¸å‡ºç¯©é¸å¾Œçš„é«˜å“è³ªè¡›æ˜Ÿå€™é¸
"""

import os
import sys
import json
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Any, Optional

# æ·»åŠ å¿…è¦è·¯å¾‘
sys.path.insert(0, '/app/netstack')
sys.path.insert(0, '/app')

# å¼•ç”¨é‡æ–°çµ„ç¹”å¾Œçš„æ™ºèƒ½ç¯©é¸ç³»çµ±
from src.services.satellite.intelligent_filtering.unified_intelligent_filter import create_unified_intelligent_filter

logger = logging.getLogger(__name__)

class IntelligentSatelliteFilterProcessor:
    """æ™ºèƒ½è¡›æ˜Ÿç¯©é¸è™•ç†å™¨å°è£
    
    è·è²¬ï¼š
    1. è¼‰å…¥è»Œé“è¨ˆç®—è¼¸å‡ºçš„å®Œæ•´è»Œé“æ•¸æ“š
    2. åŸ·è¡Œçµ±ä¸€æ™ºèƒ½ç¯©é¸æµç¨‹
    3. ä¿å­˜æ™ºèƒ½ç¯©é¸çµæœ
    4. ç‚ºå¾ŒçºŒä¿¡è™Ÿåˆ†ææä¾›é«˜å“è³ªè¼¸å…¥
    """
    
    def __init__(self, observer_lat: float = 24.9441667, observer_lon: float = 121.3713889,
                 input_dir: str = "/app/data", output_dir: str = "/app/data"):
        self.observer_lat = observer_lat
        self.observer_lon = observer_lon
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # å‰µå»ºçµ±ä¸€æ™ºèƒ½ç¯©é¸ç³»çµ±
        self.filter_system = create_unified_intelligent_filter(observer_lat, observer_lon)
        
        logger.info("âœ… æ™ºèƒ½è¡›æ˜Ÿç¯©é¸è™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  è¼¸å…¥ç›®éŒ„: {self.input_dir}")
        logger.info(f"  è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        logger.info(f"  è§€æ¸¬åº§æ¨™: ({self.observer_lat}Â°, {self.observer_lon}Â°)")
        
    def load_orbital_calculation_output(self, orbital_file: Optional[str] = None) -> Dict[str, Any]:
        """è¼‰å…¥è»Œé“è¨ˆç®—è¼¸å‡ºæ•¸æ“š"""
        if orbital_file is None:
            orbital_file = self.input_dir / "tle_orbital_calculation_output.json"
        else:
            orbital_file = Path(orbital_file)
            
        logger.info(f"ğŸ“¥ è¼‰å…¥è»Œé“è¨ˆç®—æ•¸æ“š: {orbital_file}")
        
        if not orbital_file.exists():
            raise FileNotFoundError(f"è»Œé“è¨ˆç®—è¼¸å‡ºæª”æ¡ˆä¸å­˜åœ¨: {orbital_file}")
            
        try:
            with open(orbital_file, 'r', encoding='utf-8') as f:
                orbital_data = json.load(f)
                
            # é©—è­‰æ•¸æ“šæ ¼å¼
            if 'constellations' not in orbital_data:
                raise ValueError("è»Œé“è¨ˆç®—æ•¸æ“šç¼ºå°‘ constellations æ¬„ä½")
                
            total_satellites = 0
            for constellation_name, constellation_data in orbital_data['constellations'].items():
                satellites = constellation_data.get('satellites', [])
                total_satellites += len(satellites)
                logger.info(f"  {constellation_name}: {len(satellites)} é¡†è¡›æ˜Ÿ")
                
            logger.info(f"âœ… è»Œé“è¨ˆç®—æ•¸æ“šè¼‰å…¥å®Œæˆ: ç¸½è¨ˆ {total_satellites} é¡†è¡›æ˜Ÿ")
            return orbital_data
            
        except Exception as e:
            logger.error(f"è¼‰å…¥è»Œé“è¨ˆç®—æ•¸æ“šå¤±æ•—: {e}")
            raise
            
    def execute_intelligent_filtering(self, orbital_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œæ™ºèƒ½ç¯©é¸æµç¨‹"""
        logger.info("ğŸ¯ é–‹å§‹æ™ºèƒ½è¡›æ˜Ÿç¯©é¸...")
        
        # æ™ºèƒ½ç¯©é¸æ¡ç”¨å‹•æ…‹ç¯©é¸ - ä¸è¨­å›ºå®šæ•¸é‡é™åˆ¶ï¼Œä¾æ“šç¯©é¸æ¢ä»¶å‹•æ…‹æ±ºå®š
        # ç§»é™¤ç¡¬ç·¨ç¢¼æ•¸é‡ï¼Œè®“æ™ºèƒ½ç¯©é¸ç³»çµ±æ ¹æ“šå¯¦éš›æ¢ä»¶å‹•æ…‹ç¯©é¸
        selection_config = None  # ä½¿ç”¨å‹•æ…‹ç¯©é¸æ¨¡å¼
        
        try:
            # åŸ·è¡Œæ™ºèƒ½ç¯©é¸å°ˆç”¨æµç¨‹ï¼ˆä¸åŒ…å«ä¿¡è™Ÿå“è³ªå’Œäº‹ä»¶åˆ†æï¼‰
            filtered_result = self.filter_system.process_f2_filtering_only(
                orbital_data, 
                selection_config
            )
            
            # é©—è­‰ç¯©é¸çµæœ
            validation = self.filter_system.validate_filtering_results(filtered_result)
            
            if not validation['overall_quality']:
                logger.warning("âš ï¸ ç¯©é¸çµæœå“è³ªæª¢æŸ¥æœªå®Œå…¨é€šé")
                for key, status in validation.items():
                    if not status:
                        logger.warning(f"   {key}: æœªé€šé")
            else:
                logger.info("âœ… ç¯©é¸çµæœå“è³ªæª¢æŸ¥å…¨éƒ¨é€šé")
            
            return filtered_result
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ç¯©é¸åŸ·è¡Œå¤±æ•—: {e}")
            raise
            
    def save_intelligent_filtering_output(self, filtered_data: Dict[str, Any]) -> str:
        """ä¿å­˜æ™ºèƒ½ç¯©é¸è¼¸å‡ºæ•¸æ“š - v3.0 æ¸…ç†èˆŠæª”æ¡ˆç‰ˆæœ¬"""
        output_file = self.output_dir / "intelligent_filtered_output.json"
        
        # ğŸ—‘ï¸ æ¸…ç†èˆŠæª”æ¡ˆ - ç¢ºä¿è³‡æ–™ä¸€è‡´æ€§
        if output_file.exists():
            file_size = output_file.stat().st_size
            logger.info(f"ğŸ—‘ï¸ æ¸…ç†èˆŠæ™ºèƒ½ç¯©é¸è¼¸å‡ºæª”æ¡ˆ: {output_file}")
            logger.info(f"   èˆŠæª”æ¡ˆå¤§å°: {file_size / (1024*1024):.1f} MB")
            output_file.unlink()
            logger.info("âœ… èˆŠæª”æ¡ˆå·²åˆªé™¤")
        
        # æ·»åŠ æ™ºèƒ½ç¯©é¸å®Œæˆæ¨™è¨˜
        filtered_data['metadata'].update({
            'intelligent_filtering_completion': 'complete',
            'filtering_timestamp': datetime.now(timezone.utc).isoformat(),
            'ready_for_signal_analysis': True,
            'file_generation': 'clean_regeneration'  # æ¨™è¨˜ç‚ºé‡æ–°ç”Ÿæˆ
        })
        
        # ğŸ’¾ ç”Ÿæˆæ–°çš„æ™ºèƒ½ç¯©é¸è¼¸å‡ºæª”æ¡ˆ
        logger.info(f"ğŸ’¾ ç”Ÿæˆæ–°çš„æ™ºèƒ½ç¯©é¸è¼¸å‡ºæª”æ¡ˆ: {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(filtered_data, f, indent=2, ensure_ascii=False)
            
        # æª¢æŸ¥æ–°æª”æ¡ˆå¤§å°
        new_file_size = output_file.stat().st_size
        logger.info(f"âœ… æ™ºèƒ½ç¯©é¸æ•¸æ“šå·²ä¿å­˜: {output_file}")
        logger.info(f"   æ–°æª”æ¡ˆå¤§å°: {new_file_size / (1024*1024):.1f} MB")
        logger.info(f"   åŒ…å«è¡›æ˜Ÿæ•¸: {filtered_data['metadata'].get('unified_filtering_results', {}).get('total_selected', 'unknown')}")
        
        return str(output_file)
        
    def process_intelligent_filtering(self, orbital_file: Optional[str] = None, orbital_data: Optional[Dict[str, Any]] = None, 
                      save_output: bool = True) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´çš„æ™ºèƒ½ç¯©é¸è™•ç†æµç¨‹"""
        logger.info("ğŸš€ é–‹å§‹æ™ºèƒ½è¡›æ˜Ÿç¯©é¸è™•ç†")
        
        # 1. è¼‰å…¥è»Œé“è¨ˆç®—æ•¸æ“šï¼ˆå„ªå…ˆä½¿ç”¨å…§å­˜æ•¸æ“šï¼‰
        if orbital_data is not None:
            logger.info("ğŸ“¥ ä½¿ç”¨æä¾›çš„è»Œé“è¨ˆç®—å…§å­˜æ•¸æ“š")
            # é©—è­‰å…§å­˜æ•¸æ“šæ ¼å¼
            if 'constellations' not in orbital_data:
                raise ValueError("è»Œé“è¨ˆç®—æ•¸æ“šç¼ºå°‘ constellations æ¬„ä½")
            total_satellites = 0
            for constellation_name, constellation_data in orbital_data['constellations'].items():
                satellites = constellation_data.get('orbit_data', {}).get('satellites', {})
                total_satellites += len(satellites)
                logger.info(f"  {constellation_name}: {len(satellites)} é¡†è¡›æ˜Ÿ")
            logger.info(f"âœ… è»Œé“è¨ˆç®—å…§å­˜æ•¸æ“šé©—è­‰å®Œæˆ: ç¸½è¨ˆ {total_satellites} é¡†è¡›æ˜Ÿ")
        else:
            orbital_data = self.load_orbital_calculation_output(orbital_file)
        
        # 2. åŸ·è¡Œæ™ºèƒ½ç¯©é¸
        filtered_data = self.execute_intelligent_filtering(orbital_data)
        
        # 3. å¯é¸çš„è¼¸å‡ºç­–ç•¥
        output_file = None
        if save_output:
            output_file = self.save_intelligent_filtering_output(filtered_data)
            logger.info(f"ğŸ’¾ æ™ºèƒ½ç¯©é¸æ•¸æ“šå·²ä¿å­˜åˆ°: {output_file}")
        else:
            logger.info("ğŸš€ æ™ºèƒ½ç¯©é¸ä½¿ç”¨å…§å­˜å‚³éæ¨¡å¼ï¼Œæœªä¿å­˜æª”æ¡ˆ")
        
        logger.info("âœ… æ™ºèƒ½ç¯©é¸è™•ç†å®Œæˆ")
        # ç²å–ç¯©é¸çµæœçµ±è¨ˆ
        total_selected = filtered_data['metadata'].get('unified_filtering_results', {}).get('total_selected', 0)
        starlink_selected = filtered_data['metadata'].get('unified_filtering_results', {}).get('starlink_selected', 0)
        oneweb_selected = filtered_data['metadata'].get('unified_filtering_results', {}).get('oneweb_selected', 0)
        
        logger.info(f"  ç¯©é¸çš„è¡›æ˜Ÿæ•¸: {total_selected} (Starlink: {starlink_selected}, OneWeb: {oneweb_selected})")
        if output_file:
            logger.info(f"  è¼¸å‡ºæª”æ¡ˆ: {output_file}")
        
        return filtered_data

    def process_stage2(self, stage1_file: Optional[str] = None, stage1_data: Optional[Dict[str, Any]] = None, 
                      save_output: bool = True) -> Dict[str, Any]:
        """å‘å¾Œå…¼å®¹çš„éšæ®µè™•ç†æ–¹æ³• - é‡å®šå‘åˆ°æ™ºèƒ½ç¯©é¸è™•ç†æ–¹æ³•"""
        logger.warning("âš ï¸ process_stage2 å·²æ£„ç”¨ï¼Œè«‹ä½¿ç”¨ process_intelligent_filtering")
        return self.process_intelligent_filtering(stage1_file, stage1_data, save_output)

def main():
    """ä¸»å‡½æ•¸"""
    logging.basicConfig(level=logging.INFO, 
                       format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    logger.info("============================================================")
    logger.info("æ™ºèƒ½è¡›æ˜Ÿç¯©é¸è™•ç†")
    logger.info("============================================================")
    
    try:
        processor = IntelligentSatelliteFilterProcessor()
        result = processor.process_intelligent_filtering()
        
        logger.info("ğŸ‰ æ™ºèƒ½è¡›æ˜Ÿç¯©é¸è™•ç†æˆåŠŸå®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ™ºèƒ½è¡›æ˜Ÿç¯©é¸è™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)