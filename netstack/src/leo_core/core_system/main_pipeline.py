# ğŸ›°ï¸ Phase 1 ä¸»ç®¡é“åŸ·è¡Œå™¨
"""
Phase 1 Main Pipeline - å®Œæ•´æ ¸å¿ƒç³»çµ±åŸ·è¡Œæµç¨‹
åŠŸèƒ½: ä¸²æ¥F1â†’F2â†’F3â†’A1å®Œæ•´æµç¨‹ï¼Œå¯¦ç¾10-15/3-6é¡†è¡›æ˜Ÿå‹•æ…‹è¦†è“‹
"""

import asyncio
import logging
from datetime import datetime, timezone
from pathlib import Path
import json
import sys
import os

# æ·»åŠ ç•¶å‰è·¯å¾‘åˆ°ç³»çµ±è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

from tle_data_loader.tle_loader_engine import TLELoaderEngine
from satellite_filter_engine.satellite_filter_engine_v2 import SatelliteFilterEngineV2  
from signal_analyzer.threegpp_event_processor import A4A5D2EventProcessor
from dynamic_pool_planner.simulated_annealing_optimizer import SimulatedAnnealingOptimizer

class LEOCorePipeline:
    """LEO æ ¸å¿ƒç³»çµ±ç®¡é“åŸ·è¡Œå™¨"""
    
    def __init__(self, config: dict, output_dir: str = None):
        self.config = config
        self.logger = self._setup_logger()
        
        # ğŸ¯ åˆ†å±¤è¼¸å‡ºç­–ç•¥å¯¦ç¾ (è·¨å¹³å°å…¼å®¹)
        import tempfile
        import os
        
        if output_dir:
            # ğŸ”§ F3/A1æ°¸ä¹…æ•¸æ“šç›®éŒ„ - æ·»åŠ è·¨å¹³å°æª¢æ¸¬
            # æª¢æ¸¬æ˜¯å¦åœ¨å®¹å™¨ç’°å¢ƒä¸­ï¼ˆé€šéè·¯å¾‘å’Œç’°å¢ƒè®Šé‡é›™é‡æª¢æ¸¬ï¼‰
            is_container = (os.getenv('DOCKER_CONTAINER') == '1' or 
                          Path('/app').exists() or 
                          Path('/.dockerenv').exists())
            
            if is_container:
                # å®¹å™¨ç’°å¢ƒï¼šä½¿ç”¨å‚³å…¥çš„å®¹å™¨è·¯å¾‘
                self.output_dir = Path(output_dir)
            else:
                # ä¸»æ©Ÿç’°å¢ƒï¼šæª¢æ¸¬ä¸¦è½‰æ›ç‚ºæœ¬åœ°è·¯å¾‘
                if output_dir.startswith('/app/data') or output_dir.startswith('/tmp/'):
                    # å®¹å™¨è·¯å¾‘ï¼šè½‰æ›ç‚ºä¸»æ©Ÿé …ç›®ç›®éŒ„
                    project_root = Path.cwd().resolve()
                    self.output_dir = project_root / "data" / "leo_outputs"
                else:
                    # å·²ç¶“æ˜¯ä¸»æ©Ÿè·¯å¾‘ï¼šç›´æ¥ä½¿ç”¨
                    self.output_dir = Path(output_dir)
            
            # F1/F2è‡¨æ™‚è¼¸å‡ºç›®éŒ„ - ä½¿ç”¨è·¨å¹³å°è‡¨æ™‚ç›®éŒ„
            if is_container:
                # å®¹å™¨ç’°å¢ƒï¼šä½¿ç”¨å®¹å™¨å…§è‡¨æ™‚ç›®éŒ„
                self.temp_output_dir = Path("/tmp/leo_temporary_outputs")
            else:
                # ä¸»æ©Ÿç’°å¢ƒï¼šä½¿ç”¨ç³»çµ±è‡¨æ™‚ç›®éŒ„ + å­ç›®éŒ„
                system_temp = Path(tempfile.gettempdir())
                self.temp_output_dir = system_temp / "leo_temporary_outputs"
        else:
            # é»˜èªé…ç½®ï¼šä½¿ç”¨è·¨å¹³å°é»˜èªè·¯å¾‘
            # æª¢æ¸¬æ˜¯å¦åœ¨å®¹å™¨ç’°å¢ƒä¸­ï¼ˆé€šéè·¯å¾‘å’Œç’°å¢ƒè®Šé‡é›™é‡æª¢æ¸¬ï¼‰
            is_container = (os.getenv('DOCKER_CONTAINER') == '1' or 
                          Path('/app').exists() or 
                          Path('/.dockerenv').exists())
            
            if is_container:
                # å®¹å™¨ç’°å¢ƒï¼šä½¿ç”¨å®¹å™¨é è¨­è·¯å¾‘
                default_output = '/app/data'
                self.temp_output_dir = Path("/tmp/leo_temporary_outputs")
            else:
                # ä¸»æ©Ÿç’°å¢ƒï¼šä½¿ç”¨é …ç›®ç›®éŒ„ä¸‹çš„dataå­ç›®éŒ„
                project_root = Path.cwd().resolve()
                default_output = str(project_root / "data" / "leo_outputs")
                self.temp_output_dir = Path(tempfile.gettempdir()) / "leo_temporary_outputs"
            
            self.output_dir = Path(default_output)
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.temp_output_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"ğŸ¯ åˆ†å±¤è¼¸å‡ºç­–ç•¥:")
        self.logger.info(f"   F1/F2è‡¨æ™‚æ•¸æ“š: {self.temp_output_dir}")
        self.logger.info(f"   F3/A1æ°¸ä¹…æ•¸æ“š: {self.output_dir}")
        
        # ç®¡é“çµ±è¨ˆ
        self.pipeline_stats = {
            'start_time': None,
            'end_time': None,
            'total_duration_seconds': 0,
            'stages_completed': 0,
            'total_stages': 4,
            'stage_durations': {},
            'final_results': {}
        }
        
        # éšæ®µçµ„ä»¶
        self.tle_loader = None
        self.satellite_filter = None
        self.event_processor = None
        self.optimizer = None
    
    def _setup_logger(self):
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„å™¨"""
        logger = logging.getLogger('LEOCorePipeline')
        logger.setLevel(logging.INFO)
        
        # å‰µå»ºæ§åˆ¶å°è™•ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # å‰µå»ºæ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(formatter)
        
        # æ·»åŠ è™•ç†å™¨åˆ°è¨˜éŒ„å™¨
        if not logger.handlers:
            logger.addHandler(console_handler)
        
        return logger
    
    async def execute_complete_pipeline(self):
        """åŸ·è¡Œå®Œæ•´çš„Phase 1ç®¡é“"""
        
        # åˆå§‹åŒ–ç®¡é“çµ±è¨ˆ
        pipeline_start_time = datetime.now(timezone.utc)  # ğŸ”§ ä¿®å¾©ï¼šä½¿ç”¨datetimeä¸€è‡´æ€§
        self.pipeline_stats = {
            'start_time': pipeline_start_time,  # ğŸ”§ ä¿®å¾©ï¼šå­˜å„²datetimeå°è±¡
            'stages_completed': 0,
            'total_stages': 4,
            'stage_durations': {},
            'handover_events': []  # åˆå§‹åŒ–ï¼Œä¾›æœ€çµ‚å ±å‘Šä½¿ç”¨
        }
        
        try:
            self.logger.info("ğŸš€ LEOæ ¸å¿ƒç³»çµ±ç®¡é“åŸ·è¡Œé–‹å§‹")
            self.logger.info(f"   è¼¸å‡ºç›®éŒ„: {self.output_dir}")
            
            # Stage 1: TLE Loader - è¼‰å…¥å…¨é‡è¡›æ˜Ÿä¸¦è¨ˆç®—è»Œé“ä½ç½®
            stage1_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ›°ï¸ Stage 1: TLE Loader é–‹å§‹...")
            
            satellite_data, orbital_positions = await self._execute_stage1_tle_loading()
            
            stage1_duration = (datetime.now(timezone.utc) - stage1_start).total_seconds()
            self.pipeline_stats['stage_durations']['stage1_tle_loading'] = stage1_duration
            self.pipeline_stats['stages_completed'] += 1
            
            self.logger.info(f"âœ… Stage 1å®Œæˆ ({stage1_duration:.1f}ç§’)")
            
            # Stage 2: F2_Satellite_Filter - ç¯©é¸å€™é¸ä¸¦ä½¿ç”¨å…¨é‡è»Œé“ä½ç½®
            stage2_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ” Stage 2: F2_Satellite_Filter é–‹å§‹...")
            
            filtered_candidates, candidate_orbital_positions = await self._execute_stage2_satellite_filtering(satellite_data, orbital_positions)
            
            stage2_duration = (datetime.now(timezone.utc) - stage2_start).total_seconds()
            self.pipeline_stats['stage_durations']['stage2_filtering'] = stage2_duration
            self.pipeline_stats['stages_completed'] += 1
            
            self.logger.info(f"âœ… Stage 2å®Œæˆ ({stage2_duration:.1f}ç§’)")
            
            # Stage 3: F3_Signal_Analyzer - A4/A5/D2äº‹ä»¶åˆ†æ
            stage3_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ“Š Stage 3: F3_Signal_Analyzer é–‹å§‹...")
            
            handover_events = await self._execute_stage3_signal_analysis(filtered_candidates, candidate_orbital_positions)
            
            stage3_duration = (datetime.now(timezone.utc) - stage3_start).total_seconds()
            self.pipeline_stats['stage_durations']['stage3_signal_analysis'] = stage3_duration
            self.pipeline_stats['stages_completed'] += 1
            
            # å°‡handover_eventså­˜å„²åˆ°pipeline_statsä¸­ä¾›æœ€çµ‚å ±å‘Šä½¿ç”¨
            self.pipeline_stats['handover_events'] = handover_events
            
            self.logger.info(f"âœ… Stage 3å®Œæˆ ({stage3_duration:.1f}ç§’)")
            
            # Stage 4: A1_Dynamic_Pool_Planner - æ¨¡æ“¬é€€ç«æœ€ä½³åŒ–
            stage4_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ”¥ Stage 4: A1_Dynamic_Pool_Planner é–‹å§‹...")
            
            optimal_pools = await self._execute_stage4_pool_optimization(filtered_candidates, candidate_orbital_positions)
            
            stage4_duration = (datetime.now(timezone.utc) - stage4_start).total_seconds()
            self.pipeline_stats['stage_durations']['stage4_optimization'] = stage4_duration
            self.pipeline_stats['stages_completed'] += 1
            
            self.logger.info(f"âœ… Stage 4å®Œæˆ ({stage4_duration:.1f}ç§’)")
            
            # ç”Ÿæˆæœ€çµ‚å ±å‘Š - ä¿®å¾©åŒæ­¥/ç•°æ­¥ä¸åŒ¹é…å•é¡Œ
            self._generate_final_report(optimal_pools)
            
            # ğŸ”§ ä¿®å¾©ï¼šè¨ˆç®—ç¸½æ™‚é–“æ™‚ä½¿ç”¨ä¸€è‡´çš„datetimeå°è±¡
            pipeline_end_time = datetime.now(timezone.utc)
            self.pipeline_stats['end_time'] = pipeline_end_time
            self.pipeline_stats['total_duration_seconds'] = (
                pipeline_end_time - pipeline_start_time
            ).total_seconds()
            
            self.logger.info("ğŸ‰ LEOæ ¸å¿ƒç³»çµ±ç®¡é“åŸ·è¡Œå®Œæˆ!")
            self.logger.info(f"   ç¸½è€—æ™‚: {self.pipeline_stats['total_duration_seconds']:.1f}ç§’")
            self.logger.info(f"   å®Œæˆéšæ®µ: {self.pipeline_stats['stages_completed']}/{self.pipeline_stats['total_stages']}")
            
            return optimal_pools
            
        except Exception as e:
            self.logger.error(f"âŒ LEOæ ¸å¿ƒç³»çµ±ç®¡é“åŸ·è¡Œå¤±æ•—: {e}")
            raise
    
    async def _execute_stage1_tle_loading(self):
        """åŸ·è¡ŒStage 1: TLEæ•¸æ“šè¼‰å…¥"""
        
        # âœ… ä¿®æ­£ï¼šåˆå§‹åŒ–TLEè¼‰å…¥å™¨ï¼Œå‚³éå®Œæ•´é…ç½®ä»¥æ”¯æ´sample_limits
        self.tle_loader = TLELoaderEngine(
            config=self.config.get('tle_loader', {}),
            full_config=self.config  # å‚³éå®Œæ•´é…ç½®ä»¥è¨ªå•satellite_filter.sample_limits
        )
        await self.tle_loader.initialize()
        
        # è¼‰å…¥å…¨é‡è¡›æ˜Ÿæ•¸æ“š
        satellite_data = await self.tle_loader.load_full_satellite_data()
        
        # è¨˜éŒ„å…¨é‡è¡›æ˜Ÿæ•¸æ“š
        if satellite_data.get('starlink'):
            self.logger.info(f"   Starlinkè¡›æ˜Ÿ: {len(satellite_data['starlink'])}é¡†")
        if satellite_data.get('oneweb'):
            self.logger.info(f"   OneWebè¡›æ˜Ÿ: {len(satellite_data['oneweb'])}é¡†")
        
        total_satellites = sum(len(sats) for sats in satellite_data.values())
        self.logger.info(f"ğŸ“Š å…¨é‡è¡›æ˜Ÿç¸½è¨ˆ: {total_satellites}é¡†")
        
        # âœ… ä¿®æ­£: æŒ‰ç…§è¨ˆåŠƒï¼ŒStage 1æ‡‰è©²è¨ˆç®—å…¨é‡è¡›æ˜Ÿçš„è»Œé“ä½ç½®
        self.logger.info("ğŸ›°ï¸ é–‹å§‹è¨ˆç®—å…¨é‡è¡›æ˜Ÿè»Œé“ä½ç½®...")
        
        # âœ… æ”¶é›†**å…¨é‡**è¡›æ˜Ÿé€²è¡Œè»Œé“è¨ˆç®— (æŒ‰ç…§åŸå§‹æ¶æ§‹ä¿®æ­£)
        all_satellites = []
        for constellation_satellites in satellite_data.values():
            all_satellites.extend(constellation_satellites)
        
        if len(all_satellites) > 0:
            self.logger.info(f"ğŸ“Š å…¨é‡è¡›æ˜Ÿæ§‹æˆï¼šç¸½è¨ˆ{len(all_satellites)}é¡†è¡›æ˜Ÿ")
            self.logger.info(f"   åŒ…å«ï¼š{len(satellite_data.get('starlink', []))}é¡†Starlink + {len(satellite_data.get('oneweb', []))}é¡†OneWeb")
            self.logger.info(f"ğŸ“Š è¨ˆç®—å…¨é‡{len(all_satellites)}é¡†è¡›æ˜Ÿçš„è»Œé“ä½ç½®(200åˆ†é˜çµ±ä¸€æ™‚é–“ç¯„åœ)...")
            
            # ğŸ”§ ä½¿ç”¨200åˆ†é˜çµ±ä¸€æ™‚é–“ç¯„åœè¦†è“‹é›™æ˜Ÿåº§è»Œé“é€±æœŸ (Starlink 96åˆ†é˜ + OneWeb 109åˆ†é˜)
            time_range = self.config.get('tle_loader', {}).get('calculation_params', {}).get('time_range_minutes', 200)
            orbital_positions = await self.tle_loader.calculate_orbital_positions(
                all_satellites, time_range_minutes=time_range
            )
            self.logger.info(f"âœ… å…¨é‡è»Œé“ä½ç½®è¨ˆç®—å®Œæˆ: {len(orbital_positions)}é¡†è¡›æ˜Ÿ")
        else:
            self.logger.warning("âš ï¸ æ²’æœ‰è¡›æ˜Ÿæ•¸æ“šï¼Œè·³éè»Œé“ä½ç½®è¨ˆç®—")
            orbital_positions = {}
        
        # å°å‡ºStage 1çµæœ - F1ä½¿ç”¨è‡¨æ™‚ç›®éŒ„ï¼Œæ”¹ç‚ºæœ‰æ„ç¾©çš„æª”å
        tle_loading_output = self.temp_output_dir / "tle_loading_and_orbit_calculation_results.json"
        await self.tle_loader.export_load_statistics(str(tle_loading_output))
        
        self.logger.info(f"ğŸ“Š Stage 1çµ±è¨ˆ: è¼‰å…¥{self.tle_loader.load_statistics['total_satellites']}é¡†è¡›æ˜Ÿï¼Œè¨ˆç®—{len(orbital_positions)}é¡†è»Œé“")
        
        return satellite_data, orbital_positions
    
    async def _execute_stage2_satellite_filtering(self, satellite_data, orbital_positions):
        """åŸ·è¡ŒStage 2: è¡›æ˜Ÿç¯©é¸"""
        
        # åˆå§‹åŒ–ç¯©é¸å™¨ (v2 - å…­éšæ®µç¯©é¸ç®¡ç·š)
        self.satellite_filter = SatelliteFilterEngineV2(self.config.get('satellite_filter', {}))
        
        # âœ… ä¿®æ­£: å¾æœ‰è»Œé“æ•¸æ“šçš„è¡›æ˜Ÿä¸­é€²è¡Œæ™ºèƒ½ç¯©é¸
        self.logger.info(f"ğŸ” åŸºæ–¼{len(orbital_positions)}é¡†è¡›æ˜Ÿçš„è»Œé“ä½ç½®é€²è¡Œæ™ºèƒ½ç¯©é¸")
        
        # ğŸ”§ èª¿æ•´ï¼šåƒ…å¾æœ‰è»Œé“æ•¸æ“šçš„è¡›æ˜Ÿä¸­ç¯©é¸å€™é¸
        filtered_satellite_data = {}
        for constellation, satellites in satellite_data.items():
            # åªä¿ç•™æœ‰è»Œé“æ•¸æ“šçš„è¡›æ˜Ÿ
            filtered_sats = [sat for sat in satellites if sat.satellite_id in orbital_positions]
            filtered_satellite_data[constellation] = filtered_sats
            self.logger.info(f"   {constellation}: {len(filtered_sats)}é¡†è¡›æ˜Ÿæœ‰è»Œé“æ•¸æ“š")
        
        # âœ… ä¿®å¾©ï¼šå…¨é‡æ¨¡å¼ä½¿ç”¨é©åˆçš„ç¯©é¸ç­–ç•¥
        total_satellites = sum(len(sats) for sats in filtered_satellite_data.values())
        
        if total_satellites >= 8000:  # çœŸæ­£çš„å…¨é‡æ¨¡å¼
            self.logger.info(f"ğŸŒ å…¨é‡æ¨¡å¼ ({total_satellites}é¡† â‰¥ 8000)ï¼Œä½¿ç”¨å¯¬é¬†ç¯©é¸é¿å…éåº¦ç¯©é¸")
            # ä¿®æ”¹ç¯©é¸å™¨é…ç½®ç‚ºæ›´å¯¬é¬†çš„åƒæ•¸
            original_config = self.satellite_filter.config.copy()
            
            # èª¿æ•´ç‚ºå…¨é‡æ¨¡å¼é©ç”¨çš„å¯¬é¬†åƒæ•¸
            self.satellite_filter.config.update({
                'filtering_params': {
                    'geographic_threshold': 120.0,    # æ”¾å¯¬åœ°ç†ç¯„åœ
                    'min_score_threshold': 30.0,      # é™ä½è©•åˆ†é–€æª»
                    'rsrp_threshold_dbm': -120.0,     # æ”¾å¯¬RSRPé–€æª»
                    'max_candidates_per_constellation': 500  # å¢åŠ å€™é¸æ•¸ä¸Šé™
                }
            })
            
            # ä½¿ç”¨é–‹ç™¼æ¨¡å¼ç¯©é¸ï¼ˆè¼ƒå¯¬é¬†ï¼‰
            filtered_candidates = await self.satellite_filter.apply_development_filter(
                filtered_satellite_data, orbital_positions
            )
            
            # æ¢å¾©åŸå§‹é…ç½®
            self.satellite_filter.config = original_config
            
        elif total_satellites <= 200:
            self.logger.info(f"ğŸš€ é–‹ç™¼æ¨¡å¼ ({total_satellites}é¡† â‰¤ 200)ï¼Œä½¿ç”¨å¯¬é¬†ç¯©é¸")
            # ä½¿ç”¨é–‹ç™¼æ¨¡å¼ç¯©é¸
            filtered_candidates = await self.satellite_filter.apply_development_filter(
                filtered_satellite_data, orbital_positions
            )
        else:
            self.logger.info(f"ğŸ­ ç”Ÿç”¢æ¨¡å¼ ({total_satellites}é¡†)ï¼Œä½¿ç”¨å…­éšæ®µç¯©é¸")
            # æ‡‰ç”¨å…­éšæ®µç¶œåˆç¯©é¸
            filtered_candidates = await self.satellite_filter.apply_comprehensive_filter(
                filtered_satellite_data, orbital_positions
            )
        
        # å¾å…¨é‡è»Œé“ä½ç½®ä¸­æå–å€™é¸è¡›æ˜Ÿçš„è»Œé“æ•¸æ“š
        candidate_orbital_positions = {}
        candidate_satellites = []
        for candidates in filtered_candidates.values():
            candidate_satellites.extend(candidates)
        
        self.logger.info(f"ğŸ“Š ç¯©é¸çµæœ: {len(candidate_satellites)}é¡†å€™é¸è¡›æ˜Ÿ")
        
        # æå–å€™é¸è¡›æ˜Ÿçš„è»Œé“ä½ç½®æ•¸æ“š
        missing_orbital_data = []
        for candidate in candidate_satellites:
            satellite_id = candidate.satellite_id
            if satellite_id in orbital_positions:
                candidate_orbital_positions[satellite_id] = orbital_positions[satellite_id]
            else:
                missing_orbital_data.append(satellite_id)
        
        if missing_orbital_data:
            self.logger.warning(f"âš ï¸ {len(missing_orbital_data)}é¡†å€™é¸è¡›æ˜Ÿç¼ºå°‘è»Œé“æ•¸æ“š: {missing_orbital_data[:5]}...")
        
        # è¼¸å‡ºèª¿è©¦ä¿¡æ¯
        self.logger.info(f"ğŸ” èª¿è©¦ä¿¡æ¯ï¼š")
        self.logger.info(f"   å€™é¸è¡›æ˜Ÿæ•¸é‡: {len(candidate_satellites)}")
        self.logger.info(f"   æœ‰è»Œé“æ•¸æ“šçš„å€™é¸: {len(candidate_orbital_positions)}")
        if candidate_orbital_positions:
            sample_sat = list(candidate_orbital_positions.keys())[0]
            sample_positions = candidate_orbital_positions[sample_sat]
            self.logger.info(f"   æ¨£æœ¬è¡›æ˜Ÿ {sample_sat}: {len(sample_positions)}å€‹ä½ç½®é»")
            if sample_positions:
                self.logger.info(f"   æ¨£æœ¬ä½ç½®: ä»°è§’{sample_positions[0].elevation_deg:.1f}Â°")
        
        # å°å‡ºStage 2çµæœ - F2ä½¿ç”¨è‡¨æ™‚ç›®éŒ„ (1.1GBå¤§æ–‡ä»¶)ï¼Œæ”¹ç‚ºæœ‰æ„ç¾©çš„æª”å
        filtering_output = self.temp_output_dir / "satellite_filtering_and_candidate_selection_results.json"
        await self._export_stage2_enhanced_results(filtered_candidates, candidate_orbital_positions, str(filtering_output))
        
        total_candidates = sum(len(candidates) for candidates in filtered_candidates.values())
        self.logger.info(f"ğŸ“Š Stage 2çµ±è¨ˆ: ç¯©é¸å‡º{total_candidates}é¡†å€™é¸è¡›æ˜Ÿ")
        
        return filtered_candidates, candidate_orbital_positions

    async def _export_stage2_enhanced_results(self, 
                                        filtered_candidates: dict, 
                                        orbital_positions: dict, 
                                        output_path: str):
        """å°å‡ºStage 2å¢å¼·çµæœï¼ŒåŒ…å«è»Œé“ä½ç½®æ•¸æ“š"""
        try:
            export_data = {
                'filter_statistics': {
                    'input_satellites': len(self.tle_loader.tle_database) if hasattr(self, 'tle_loader') else 0,
                    'final_candidates': sum(len(candidates) for candidates in filtered_candidates.values()),
                    'starlink_candidates': len(filtered_candidates.get('starlink', [])),
                    'oneweb_candidates': len(filtered_candidates.get('oneweb', [])),
                    'geographic_filtered': 0,
                    'constellation_filtered': 0,
                    'filter_stages': {}
                },
                'filter_timestamp': datetime.now(timezone.utc).isoformat(),
                'observer_coordinates': {
                    'latitude': 24.9441667,
                    'longitude': 121.3713889,
                    'location_name': 'NTPU'
                },
                'candidates': {},
                'orbital_positions': {}  # æ–°å¢ï¼šè»Œé“ä½ç½®æ•¸æ“š
            }
            
            # å°å‡ºå€™é¸è¡›æ˜Ÿè©³ç´°ä¿¡æ¯
            for constellation, candidates in filtered_candidates.items():
                export_data['candidates'][constellation] = []
                
                for candidate in candidates:
                    candidate_data = {
                        'satellite_id': candidate.satellite_id,
                        'total_score': round(candidate.total_score, 2),
                        'geographic_relevance_score': round(candidate.geographic_relevance_score, 2),
                        'orbital_characteristics_score': round(candidate.orbital_characteristics_score, 2),
                        'signal_quality_score': round(candidate.signal_quality_score, 2),
                        'temporal_distribution_score': round(candidate.temporal_distribution_score, 2),
                        'scoring_rationale': candidate.scoring_rationale,
                        'is_selected': candidate.is_selected
                    }
                    
                    # âœ… æ–°å¢ï¼šå°å‡ºå¯è¦‹æ€§åˆ†ææ•¸æ“š
                    if hasattr(candidate, 'visibility_analysis') and candidate.visibility_analysis:
                        va = candidate.visibility_analysis
                        candidate_data['visibility_analysis'] = {
                            'total_visible_time_minutes': round(va.total_visible_time_minutes, 2),
                            'max_elevation_deg': round(va.max_elevation_deg, 2),
                            'visible_passes_count': va.visible_passes_count,
                            'avg_pass_duration_minutes': round(va.avg_pass_duration_minutes, 2),
                            'signal_strength_estimate_dbm': round(va.signal_strength_estimate_dbm, 2)
                        }
                        if va.best_elevation_time:
                            candidate_data['visibility_analysis']['best_elevation_time'] = va.best_elevation_time.isoformat() if hasattr(va.best_elevation_time, 'isoformat') else str(va.best_elevation_time)
                    
                    export_data['candidates'][constellation].append(candidate_data)
            
            # å°å‡ºè»Œé“ä½ç½®æ•¸æ“š
            for satellite_id, positions in orbital_positions.items():
                export_data['orbital_positions'][satellite_id] = []
                for position in positions:
                    export_data['orbital_positions'][satellite_id].append({
                        'timestamp': position.timestamp.isoformat(),
                        'latitude_deg': round(position.latitude_deg, 6),
                        'longitude_deg': round(position.longitude_deg, 6),
                        'altitude_km': round(position.altitude_km, 2),
                        'elevation_deg': round(position.elevation_deg, 2),
                        'azimuth_deg': round(position.azimuth_deg, 2),
                        'distance_km': round(position.distance_km, 2),
                        'velocity_km_s': round(position.velocity_km_s, 3)
                    })
            
            with open(output_path, 'w') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
                
            self.logger.info(f"ğŸ“Š Stage 2å¢å¼·çµæœå·²å°å‡ºè‡³: {output_path}")
            self.logger.info(f"   åŒ…å«è»Œé“ä½ç½®æ•¸æ“š: {len(orbital_positions)}é¡†è¡›æ˜Ÿ")
            
        except Exception as e:
            self.logger.error(f"âŒ Stage 2å¢å¼·çµæœå°å‡ºå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    async def _execute_stage3_signal_analysis(self, filtered_candidates, orbital_positions):
        """åŸ·è¡ŒStage 3: ä¿¡è™Ÿåˆ†æå’Œäº‹ä»¶æª¢æ¸¬"""
        
        # åˆå§‹åŒ–äº‹ä»¶è™•ç†å™¨
        self.event_processor = A4A5D2EventProcessor(self.config.get('event_processor', {}))
        
        # âœ… ä¿®å¾©ï¼šå¾filtered_candidateså’Œorbital_positionsç”ŸæˆSatelliteSignalDataæ™‚é–“è»¸
        self.logger.info("ğŸ”„ é–‹å§‹ç”Ÿæˆè¡›æ˜Ÿä¿¡è™Ÿæ•¸æ“šæ™‚é–“è»¸...")
        serving_timeline, neighbor_timelines = await self._generate_signal_timelines(
            filtered_candidates, orbital_positions
        )
        
        self.logger.info(f"ğŸ“Š æ™‚é–“è»¸ç”Ÿæˆå®Œæˆ:")
        self.logger.info(f"   æœå‹™è¡›æ˜Ÿæ™‚é–“è»¸: {len(serving_timeline)}å€‹æ™‚é–“é»")
        self.logger.info(f"   é„°å±…è¡›æ˜Ÿæ•¸é‡: {len(neighbor_timelines)}")
        
        # æª¢æ¸¬æ›æ‰‹äº‹ä»¶
        handover_events = await self.event_processor.process_handover_events(
            serving_timeline, neighbor_timelines, time_range_minutes=200
        )
        
        # åŒ¯å‡ºStage 3çµæœ - F3ä½¿ç”¨æ°¸ä¹…ç›®éŒ„ï¼Œæ”¹ç‚ºæœ‰æ„ç¾©çš„æª”å
        handover_analysis_output = self.output_dir / "handover_event_analysis_results.json"
        await self.event_processor.export_event_analysis(handover_events, str(handover_analysis_output))
        
        self.logger.info(f"ğŸ“Š Stage 3çµ±è¨ˆ: æª¢æ¸¬{len(handover_events)}å€‹æ›æ‰‹äº‹ä»¶")
        
        return handover_events
    
    async def _generate_signal_timelines(self, filtered_candidates, orbital_positions):
        """âœ… é—œéµä¿®å¾©ï¼šç”ŸæˆSatelliteSignalDataæ™‚é–“è»¸"""
        from signal_analyzer.threegpp_event_processor import SatelliteSignalData
        import math
        
        self.logger.info("ğŸ”„ é–‹å§‹orbital_positionsâ†’SatelliteSignalDataè½‰æ›...")
        
        # 1. é¸æ“‡æœå‹™è¡›æ˜Ÿï¼ˆå¾Starlinkä¸­é¸æ“‡è©•åˆ†æœ€é«˜çš„ï¼‰
        starlink_candidates = filtered_candidates.get('starlink', [])
        if not starlink_candidates:
            self.logger.warning("âš ï¸ æ²’æœ‰Starlinkå€™é¸è¡›æ˜Ÿï¼Œä½¿ç”¨OneWeb")
            starlink_candidates = filtered_candidates.get('oneweb', [])
        
        if not starlink_candidates:
            self.logger.error("âŒ æ²’æœ‰å€™é¸è¡›æ˜Ÿå¯ç”¨æ–¼ä¿¡è™Ÿåˆ†æ")
            return [], []
        
        # é¸æ“‡ç¸½è©•åˆ†æœ€é«˜çš„è¡›æ˜Ÿä½œç‚ºæœå‹™è¡›æ˜Ÿ
        serving_satellite = max(starlink_candidates, key=lambda s: s.total_score)
        serving_satellite_id = serving_satellite.satellite_id
        
        self.logger.info(f"ğŸ“¡ é¸æ“‡æœå‹™è¡›æ˜Ÿ: {serving_satellite_id} (è©•åˆ†: {serving_satellite.total_score:.2f})")
        
        # 2. ç²å–æœå‹™è¡›æ˜Ÿçš„è»Œé“ä½ç½®æ•¸æ“š
        if serving_satellite_id not in orbital_positions:
            self.logger.error(f"âŒ æœå‹™è¡›æ˜Ÿ {serving_satellite_id} ç¼ºå°‘è»Œé“æ•¸æ“š")
            return [], []
        
        serving_orbital_data = orbital_positions[serving_satellite_id]
        self.logger.info(f"ğŸ“Š æœå‹™è¡›æ˜Ÿè»Œé“æ•¸æ“š: {len(serving_orbital_data)}å€‹æ™‚é–“é»")
        
        # 3. ç”Ÿæˆæœå‹™è¡›æ˜Ÿæ™‚é–“è»¸
        serving_timeline = []
        for position in serving_orbital_data:
            # è¨ˆç®—ä¿¡è™Ÿåƒæ•¸
            signal_data = await self._create_satellite_signal_data(
                serving_satellite, position, "starlink" if "starlink" in serving_satellite_id.lower() else "oneweb"
            )
            serving_timeline.append(signal_data)
        
        # 4. é¸æ“‡é„°å±…è¡›æ˜Ÿï¼ˆæ’é™¤æœå‹™è¡›æ˜Ÿï¼Œé¸æ“‡å‰10å€‹è©•åˆ†æœ€é«˜çš„ï¼‰
        all_candidates = []
        for constellation_candidates in filtered_candidates.values():
            all_candidates.extend(constellation_candidates)
        
        # æ’é™¤æœå‹™è¡›æ˜Ÿï¼ŒæŒ‰è©•åˆ†æ’åº
        neighbor_candidates = [c for c in all_candidates if c.satellite_id != serving_satellite_id]
        neighbor_candidates.sort(key=lambda s: s.total_score, reverse=True)
        neighbor_candidates = neighbor_candidates[:10]  # é™åˆ¶é„°å±…æ•¸é‡
        
        self.logger.info(f"ğŸ‘¥ é¸æ“‡é„°å±…è¡›æ˜Ÿæ•¸é‡: {len(neighbor_candidates)}")
        
        # 5. ç”Ÿæˆé„°å±…è¡›æ˜Ÿæ™‚é–“è»¸
        neighbor_timelines = []
        for neighbor_candidate in neighbor_candidates:
            neighbor_id = neighbor_candidate.satellite_id
            
            if neighbor_id not in orbital_positions:
                self.logger.warning(f"âš ï¸ é„°å±…è¡›æ˜Ÿ {neighbor_id} ç¼ºå°‘è»Œé“æ•¸æ“š")
                continue
            
            neighbor_orbital_data = orbital_positions[neighbor_id]
            neighbor_timeline = []
            
            constellation = "starlink" if "starlink" in neighbor_id.lower() else "oneweb"
            
            for position in neighbor_orbital_data:
                signal_data = await self._create_satellite_signal_data(
                    neighbor_candidate, position, constellation
                )
                neighbor_timeline.append(signal_data)
            
            neighbor_timelines.append(neighbor_timeline)
        
        self.logger.info(f"âœ… æ™‚é–“è»¸ç”Ÿæˆå®Œæˆ:")
        self.logger.info(f"   æœå‹™è¡›æ˜Ÿæ™‚é–“è»¸: {len(serving_timeline)}å€‹æ™‚é–“é»")
        self.logger.info(f"   é„°å±…è¡›æ˜Ÿæ•¸é‡: {len(neighbor_timelines)}")
        
        return serving_timeline, neighbor_timelines
    
    async def _create_satellite_signal_data(self, satellite_candidate, orbital_position, constellation):
        """å‰µå»ºSatelliteSignalDataå°è±¡"""
        from signal_analyzer.threegpp_event_processor import SatelliteSignalData
        import math
        
        # åŸºæœ¬ä½ç½®ä¿¡æ¯
        satellite_id = satellite_candidate.satellite_id
        timestamp = orbital_position.timestamp
        latitude = orbital_position.latitude_deg
        longitude = orbital_position.longitude_deg
        altitude_km = orbital_position.altitude_km
        elevation_deg = orbital_position.elevation_deg
        azimuth_deg = orbital_position.azimuth_deg
        distance_km = orbital_position.distance_km
        
        # å‰µå»ºè‡¨æ™‚SatelliteSignalDataç”¨æ–¼RSRPè¨ˆç®—
        temp_signal_data = SatelliteSignalData(
            satellite_id=satellite_id,
            constellation=constellation,
            timestamp=timestamp,
            latitude=latitude,
            longitude=longitude,
            altitude_km=altitude_km,
            elevation_deg=elevation_deg,
            azimuth_deg=azimuth_deg,
            distance_km=distance_km,
            rsrp_dbm=0.0,  # è‡¨æ™‚å€¼
            rsrq_db=0.0,   # è‡¨æ™‚å€¼
            sinr_db=0.0,   # è‡¨æ™‚å€¼
            path_loss_db=0.0,  # è‡¨æ™‚å€¼
            doppler_shift_hz=0.0,  # è‡¨æ™‚å€¼
            propagation_delay_ms=0.0   # è‡¨æ™‚å€¼
        )
        
        # ä½¿ç”¨äº‹ä»¶è™•ç†å™¨è¨ˆç®—ç²¾ç¢ºRSRP
        rsrp_dbm = await self.event_processor.calculate_precise_rsrp(temp_signal_data)
        
        # è¨ˆç®—å…¶ä»–ä¿¡è™Ÿåƒæ•¸
        # RSRQ: åŸºæ–¼ä»°è§’å‹•æ…‹èª¿æ•´
        rsrq_db = -12.0 + (elevation_deg - 10) * 0.1  # -12dBåŸºæº–ï¼Œä»°è§’è¶Šé«˜è¶Šå¥½
        
        # SINR: åŸºæ–¼ä»°è§’å’Œè·é›¢
        sinr_db = 18.0 + (elevation_deg - 10) * 0.2 - (distance_km - 550) / 100  # 18dBåŸºæº–
        
        # è‡ªç”±ç©ºé–“è·¯å¾‘æè€—
        frequency_ghz = 12.0 if constellation == "starlink" else 20.0  # Ku/Kaé »æ®µ
        path_loss_db = 20 * math.log10(distance_km) + 20 * math.log10(frequency_ghz) + 32.45
        
        # å¤šæ™®å‹’é »ç§» (ç°¡åŒ–è¨ˆç®—)
        velocity_km_s = getattr(orbital_position, 'velocity_km_s', 7.8)  # LEOè¡›æ˜Ÿå…¸å‹é€Ÿåº¦
        doppler_shift_hz = frequency_ghz * 1e9 * velocity_km_s * 1000 / 299792458  # c = å…‰é€Ÿ
        
        # å‚³æ’­å»¶é²
        propagation_delay_ms = distance_km / 299.792458  # å…‰é€Ÿ km/ms
        
        # å‰µå»ºå®Œæ•´çš„SatelliteSignalData
        signal_data = SatelliteSignalData(
            satellite_id=satellite_id,
            constellation=constellation,
            timestamp=timestamp,
            latitude=latitude,
            longitude=longitude,
            altitude_km=altitude_km,
            elevation_deg=elevation_deg,
            azimuth_deg=azimuth_deg,
            distance_km=distance_km,
            rsrp_dbm=rsrp_dbm,
            rsrq_db=rsrq_db,
            sinr_db=sinr_db,
            path_loss_db=path_loss_db,
            doppler_shift_hz=doppler_shift_hz,
            propagation_delay_ms=propagation_delay_ms
        )
        
        return signal_data
    
    async def _execute_stage4_pool_optimization(self, filtered_candidates, orbital_positions):
        """åŸ·è¡ŒStage 4: å‹•æ…‹æ± æœ€ä½³åŒ–"""
        
        # åˆå§‹åŒ–æœ€ä½³åŒ–å™¨
        self.optimizer = SimulatedAnnealingOptimizer(self.config.get('optimizer', {}))
        
        # æº–å‚™å€™é¸æ•¸æ“š
        starlink_candidates = filtered_candidates.get('starlink', [])
        oneweb_candidates = filtered_candidates.get('oneweb', [])
        
        # åŸ·è¡Œæ¨¡æ“¬é€€ç«æœ€ä½³åŒ–
        optimal_solution = await self.optimizer.optimize_satellite_pools(
            starlink_candidates, oneweb_candidates, orbital_positions
        )
        
        # åŒ¯å‡ºStage 4çµæœ - A1ä½¿ç”¨æ°¸ä¹…ç›®éŒ„ï¼Œæ”¹ç‚ºæœ‰æ„ç¾©çš„æª”å
        pool_optimization_output = self.output_dir / "dynamic_satellite_pool_optimization_results.json"
        await self.optimizer.export_optimization_results(optimal_solution, str(pool_optimization_output))
        
        self.logger.info(f"ğŸ“Š Stage 4çµ±è¨ˆ: æœ€ä½³è§£åŒ…å«{optimal_solution.get_total_satellites()}é¡†è¡›æ˜Ÿ")
        self.logger.info(f"   Starlink: {len(optimal_solution.starlink_satellites)}é¡†")
        self.logger.info(f"   OneWeb: {len(optimal_solution.oneweb_satellites)}é¡†")
        self.logger.info(f"   å¯è¦‹æ€§åˆè¦: {optimal_solution.visibility_compliance:.1%}")
        
        return optimal_solution
    
    def _serialize_pipeline_stats(self):
        """åºåˆ—åŒ–pipelineçµ±è¨ˆä¸­çš„datetimeå°è±¡ç‚ºJSONå…¼å®¹æ ¼å¼"""
        import numpy as np
        
        def serialize_value(value):
            """éæ­¸åºåˆ—åŒ–å„ç¨®æ•¸æ“šé¡å‹"""
            if isinstance(value, datetime):
                return value.isoformat()
            elif isinstance(value, (np.bool_, bool)):
                return bool(value)  # ç¢ºä¿numpy booleanè½‰ç‚ºPython boolean
            elif isinstance(value, (np.integer, np.int64, np.int32)):
                return int(value)  # ç¢ºä¿numpyæ•´æ•¸è½‰ç‚ºPython int
            elif isinstance(value, (np.floating, np.float64, np.float32)):
                return float(value)  # ç¢ºä¿numpyæµ®é»æ•¸è½‰ç‚ºPython float
            elif isinstance(value, dict):
                return {k: serialize_value(v) for k, v in value.items()}
            elif isinstance(value, (list, tuple)):
                return [serialize_value(item) for item in value]
            elif hasattr(value, 'tolist'):  # numpy arrays
                return value.tolist()
            else:
                return value
        
        serialized = {}
        for key, value in self.pipeline_stats.items():
            serialized[key] = serialize_value(value)
        return serialized
    
    def _generate_final_report(self, optimal_pools):
        """ç”Ÿæˆå®Œæ•´çš„åŸ·è¡Œå ±å‘Š"""
        
        # ğŸ”§ ä¿®å¾©ï¼šä½¿ç”¨datetimeä¸€è‡´æ€§æ™‚é–“è¨ˆç®—
        current_time = datetime.now(timezone.utc)
        total_duration = (current_time - self.pipeline_stats['start_time']).total_seconds()
        
        final_report = {
            "leo_optimization_completion_report": {
                "timestamp": current_time.isoformat(),
                "pipeline_statistics": {
                    "start_time": self.pipeline_stats['start_time'].isoformat(),
                    "end_time": None,  # æœƒåœ¨æœ€å¾Œè¨­å®š
                    "total_duration_seconds": 0,  # æœƒåœ¨æœ€å¾Œè¨ˆç®—
                    "stages_completed": self.pipeline_stats['stages_completed'],
                    "total_stages": self.pipeline_stats['total_stages'],
                    "stage_durations": self.pipeline_stats['stage_durations'],
                    "final_results": {}  # å‘å¾Œå…¼å®¹
                },
                "final_results": {
                    "optimal_satellite_pools": {
                        "starlink_count": len(optimal_pools.starlink_satellites),
                        "oneweb_count": len(optimal_pools.oneweb_satellites), 
                        "total_count": optimal_pools.get_total_satellites(),
                        "visibility_compliance": float(optimal_pools.visibility_compliance),
                        "temporal_distribution": float(optimal_pools.temporal_distribution),
                        "signal_quality": float(optimal_pools.signal_quality)
                    },
                    "handover_events": {
                        "total_events": len(self.pipeline_stats.get('handover_events', [])),
                        "a4_events": len([e for e in self.pipeline_stats.get('handover_events', []) if e.event_type == 'A4']),
                        "a5_events": len([e for e in self.pipeline_stats.get('handover_events', []) if e.event_type == 'A5']),
                        "d2_events": len([e for e in self.pipeline_stats.get('handover_events', []) if e.event_type == 'D2'])
                    },
                    "compliance_check": {
                        "starlink_target_met": 10 <= len(optimal_pools.starlink_satellites) <= 100,
                        "oneweb_target_met": 3 <= len(optimal_pools.oneweb_satellites) <= 50,
                        "visibility_compliance_ok": optimal_pools.visibility_compliance >= 0.70,
                        "temporal_distribution_ok": optimal_pools.temporal_distribution >= 0.50,
                        "frontend_ready": True
                    }
                }
            }
        }
        
        # è¨­å®šæœ€çµ‚æ™‚é–“å’ŒæŒçºŒæ™‚é–“
        final_report["leo_optimization_completion_report"]["pipeline_statistics"]["end_time"] = current_time.isoformat()
        final_report["leo_optimization_completion_report"]["pipeline_statistics"]["total_duration_seconds"] = total_duration
        
        # å„²å­˜å ±å‘Š - ä½¿ç”¨æ–°çš„åŠŸèƒ½æè¿°æ€§æª”å
        final_report_path = self.output_dir / "leo_optimization_final_report.json"
        
        with open(final_report_path, 'w') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ğŸ“‹ æœ€çµ‚å ±å‘Šå·²ç”Ÿæˆ: {final_report_path}")
        
        # æª¢æŸ¥ç›®æ¨™é”æˆç‹€æ³
        unmet_targets = []
        if not final_report["leo_optimization_completion_report"]["final_results"]["compliance_check"]["starlink_target_met"]:
            unmet_targets.append('starlink_pool_size_ok')
        if not final_report["leo_optimization_completion_report"]["final_results"]["compliance_check"]["oneweb_target_met"]:
            unmet_targets.append('oneweb_pool_size_ok')
        if not final_report["leo_optimization_completion_report"]["final_results"]["compliance_check"]["visibility_compliance_ok"]:
            unmet_targets.append('visibility_compliance_ok')
        if not final_report["leo_optimization_completion_report"]["final_results"]["compliance_check"]["temporal_distribution_ok"]:
            unmet_targets.append('temporal_distribution_ok')
        
        # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ signal_qualityç´„æŸæª¢æŸ¥
        signal_quality_ok = optimal_pools.signal_quality >= 0.50  # å‡è¨­ä¿¡è™Ÿå“è³ªé–¾å€¼
        if not signal_quality_ok:
            unmet_targets.append('signal_quality_ok')
            
        if unmet_targets:
            self.logger.warning(f"âš ï¸ æœªæ»¿è¶³çš„ç´„æŸ: {unmet_targets}")
        
        return final_report

def create_default_config():
    """å‰µå»ºé è¨­é…ç½®"""
    return {
        'tle_loader': {
            'data_sources': {
                'starlink_tle_url': 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink',
                'oneweb_tle_url': 'https://celestrak.org/NORAD/elements/gp.php?GROUP=oneweb'
            },
            'calculation_params': {
                'time_range_minutes': 200,
                'time_resolution_seconds': 30
            }
        },
        'satellite_filter': {
            # ğŸ”¥ ç§»é™¤é è¨­sample_limits - è®“å…¨é‡æ¨¡å¼æˆç‚ºé è¨­è¡Œç‚º
            # sample_limitsåªåœ¨é–‹ç™¼æ¨¡å¼ä¸­æ˜ç¢ºæ·»åŠ 
            'filtering_params': {
                'geographic_threshold': 60.0,
                'min_score_threshold': 70.0
            },
            'ntpu_coordinates': {
                'latitude': 24.9441667,
                'longitude': 121.3713889
            }
        },
        'event_processor': {
            'event_thresholds': {
                'a4_neighbor_threshold_dbm': -100.0,
                'a5_serving_threshold_dbm': -110.0,
                'd2_serving_distance_km': 5000.0
            },
            'signal_params': {
                'frequency_ghz': 12.0,
                'tx_power_dbm': 43.0
            }
        },
        'optimizer': {
            'optimization_params': {
                'max_iterations': 5000,
                'initial_temperature': 1000.0,
                'cooling_rate': 0.95
            },
            'targets': {
                'starlink_pool_size': 8085,  # âœ… åŸºæ–¼æœ¬åœ°TLEæ•¸æ“šå¯¦éš›å€¼
                'oneweb_pool_size': 651,   # âœ… åŸºæ–¼æœ¬åœ°TLEæ•¸æ“šå¯¦éš›å€¼
                'starlink_visible_range': (10, 15),
                'oneweb_visible_range': (3, 6)
            }
        }
    }

async def main():
    """Phase 1ä¸»ç®¡é“åŸ·è¡Œå…¥å£"""
    
    print("ğŸ›°ï¸ LEOè¡›æ˜Ÿå‹•æ…‹æ± è¦åŠƒç³»çµ± - Phase 1åŸ·è¡Œå™¨")
    print("=" * 60)
    
    # å‰µå»ºé…ç½®
    config = create_default_config()
    
    # åˆå§‹åŒ–ç®¡é“
    pipeline = LEOCorePipeline(config)
    
    try:
        # åŸ·è¡Œå®Œæ•´ç®¡é“
        optimal_pools = await pipeline.execute_complete_pipeline()
        
        print("\nğŸ‰ Phase 1åŸ·è¡ŒæˆåŠŸ!")
        print(f"ğŸ“Š æœ€ä½³åŒ–çµæœ:")
        print(f"   Starlinkæ± : {len(optimal_pools.starlink_satellites)}é¡†")
        print(f"   OneWebæ± : {len(optimal_pools.oneweb_satellites)}é¡†")
        print(f"   å¯è¦‹æ€§åˆè¦: {optimal_pools.visibility_compliance:.1%}")
        print(f"   è¼¸å‡ºç›®éŒ„: {pipeline.output_dir}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Phase 1åŸ·è¡Œå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())