# ğŸ›°ï¸ Phase 1: TLEè¼‰å…¥å¼•æ“å¢å¼·ç‰ˆ
"""
Enhanced TLE Loader Engine - Phase 1è¦æ ¼å®Œæ•´å¯¦ç¾
åŠŸèƒ½: è¼‰å…¥8,735é¡†è¡›æ˜ŸTLEæ•¸æ“šï¼ŒSGP4ç²¾ç¢ºè»Œé“è¨ˆç®—ï¼Œæ•¸æ“šé©—è­‰
è¦æ ¼: 
- è¼‰å…¥æ™‚é–“ < 2åˆ†é˜
- è¨ˆç®—ç²¾åº¦ < 100m
- è¨˜æ†¶é«”ä½¿ç”¨ < 2GB  
- éŒ¯èª¤è™•ç† 90%+æˆåŠŸç‡
- æ™‚é–“è»¸: 200å€‹æ™‚é–“é»ï¼Œ30ç§’é–“éš”
ç‰ˆæœ¬: Phase 1.1 Enhanced
"""

import asyncio
import logging
import aiohttp
import re
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Tuple, NamedTuple
from dataclasses import dataclass
from pathlib import Path
import json
import numpy as np

# å˜—è©¦å°å…¥Skyfieldï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨ç°¡åŒ–è¨ˆç®—
try:
    from skyfield.api import load, EarthSatellite, Topos
    from skyfield.timelib import Time
    SKYFIELD_AVAILABLE = True
except ImportError:
    SKYFIELD_AVAILABLE = False
    logging.warning("âš ï¸ Skyfieldæœªå®‰è£ï¼Œå°‡ä½¿ç”¨ç°¡åŒ–è»Œé“è¨ˆç®—")

# Phase 1å¢å¼·æ¨¡çµ„å°å…¥
try:
    from .orbital_calculator import EnhancedOrbitalCalculator, SGP4Parameters, OrbitalState
    from .data_validator import EnhancedTLEValidator, ValidationLevel, ValidationResult
    ENHANCED_MODULES_AVAILABLE = True
except ImportError:
    ENHANCED_MODULES_AVAILABLE = False
    logging.warning("âš ï¸ Phase 1å¢å¼·æ¨¡çµ„æœªå®‰è£ï¼Œå°‡ä½¿ç”¨åŸºç¤åŠŸèƒ½")

@dataclass
class TLEData:
    """TLEæ•¸æ“šçµæ§‹"""
    satellite_id: str
    satellite_name: str
    line1: str
    line2: str
    epoch: datetime
    constellation: str
    
    # SGP4è»Œé“åƒæ•¸ (å¾TLEè§£æ)
    inclination_deg: float
    raan_deg: float
    eccentricity: float
    arg_perigee_deg: float
    mean_anomaly_deg: float
    mean_motion_revs_per_day: float
    
    # è¨ˆç®—å¾—å‡ºçš„åƒæ•¸
    semi_major_axis_km: float
    orbital_period_minutes: float
    apogee_altitude_km: float
    perigee_altitude_km: float
    
    # å…¼å®¹æ€§åˆ¥åå±¬æ€§
    @property
    def apogee_km(self) -> float:
        return self.apogee_altitude_km
    
    @property
    def perigee_km(self) -> float:
        return self.perigee_altitude_km

@dataclass 
class SatellitePosition:
    """è¡›æ˜Ÿä½ç½®æ•¸æ“š"""
    timestamp: datetime
    latitude_deg: float
    longitude_deg: float
    altitude_km: float
    elevation_deg: float
    azimuth_deg: float
    distance_km: float
    velocity_km_s: float

class EnhancedTLELoaderEngine:
    """Phase 1å¢å¼·TLEè¼‰å…¥å’ŒSGP4è¨ˆç®—å¼•æ“"""
    
    def __init__(self, config: Dict, full_config: Dict = None):
        self.config = config
        self.full_config = full_config or config  # ä¿å­˜å®Œæ•´é…ç½®ä»¥è¨ªå•å…¶ä»–æ¨¡çµ„è¨­å®š
        self.logger = logging.getLogger(__name__)
        
        # NTPUè§€æ¸¬é»åº§æ¨™
        self.observer_lat = 24.9441667
        self.observer_lon = 121.3713889
        self.observer_alt_m = 50.0  # NTPUæµ·æ‹”é«˜åº¦
        
        # Phase 1å¢å¼·çµ„ä»¶
        self.orbital_calculator = None
        self.data_validator = None
        
        # Phase 1æ€§èƒ½ç›®æ¨™
        self.phase1_targets = {
            'max_load_time_seconds': 120.0,       # <2åˆ†é˜è¼‰å…¥
            'max_calculation_accuracy_m': 100.0,  # <100ç±³ç²¾åº¦
            'max_memory_usage_gb': 2.0,           # <2GBè¨˜æ†¶é«”
            'min_success_rate': 0.90,             # 90%+æˆåŠŸç‡
            'time_points': 200,                   # 200å€‹æ™‚é–“é»
            'time_resolution_seconds': 30         # 30ç§’é–“éš”
        }
        
        # ğŸ”§ ä¿®å¾©ï¼šå‹•æ…‹æŸ¥æ‰¾æœ€æ–°æœ¬åœ°TLEæ•¸æ“šæ–‡ä»¶
        self.local_tle_sources = self._get_latest_local_tle_files()
        
        # âœ… æ–°å¢ï¼šå¾å®Œæ•´é…ç½®ä¸­è®€å–sample_limits
        self.sample_limits = {}
        if self.full_config and 'satellite_filter' in self.full_config:
            filter_config = self.full_config['satellite_filter']
            if 'sample_limits' in filter_config:
                self.sample_limits = filter_config['sample_limits']
                self.logger.info(f"ğŸ¯ æ¨£æœ¬é™åˆ¶é…ç½®: {self.sample_limits}")
        
        # è¼‰å…¥çµ±è¨ˆ
        self.load_statistics = {
            'total_satellites': 0,
            'starlink_count': 0,
            'oneweb_count': 0,
            'other_constellation_count': 0,
            'load_duration_seconds': 0.0,
            'calculation_duration_seconds': 0.0,
            'error_count': 0,
            'successful_tle_parsing': 0
        }
        
        # å…§éƒ¨æ•¸æ“šå­˜å„²
        self.tle_database: Dict[str, TLEData] = {}
        self.orbital_positions: Dict[str, List[SatellitePosition]] = {}
        
        # Skyfieldå°è±¡ (å¦‚æœå¯ç”¨)
        self.ts = None
        self.observer_location = None

    def _get_latest_local_tle_files(self) -> Dict[str, str]:
        """å‹•æ…‹æŸ¥æ‰¾æœ€æ–°çš„æœ¬åœ°TLEæ•¸æ“šæ–‡ä»¶"""
        # ğŸ”§ ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„æœ¬åœ°TLEæ•¸æ“šè·¯å¾‘
        tle_base_path = Path("/home/sat/ntn-stack/netstack/tle_data")
        latest_files = {}
        
        try:
            # æŸ¥æ‰¾ Starlink æœ€æ–°æ–‡ä»¶
            starlink_dir = tle_base_path / "starlink" / "tle"
            if starlink_dir.exists():
                starlink_files = list(starlink_dir.glob("starlink_*.tle"))
                if starlink_files:
                    latest_starlink = max(starlink_files, key=lambda f: f.stat().st_mtime)
                    latest_files['starlink'] = str(latest_starlink)
                    self.logger.info(f"ğŸ” æ‰¾åˆ°æœ€æ–°Starlink TLE: {latest_starlink.name}")
            
            # æŸ¥æ‰¾ OneWeb æœ€æ–°æ–‡ä»¶
            oneweb_dir = tle_base_path / "oneweb" / "tle"
            if oneweb_dir.exists():
                oneweb_files = list(oneweb_dir.glob("oneweb_*.tle"))
                if oneweb_files:
                    latest_oneweb = max(oneweb_files, key=lambda f: f.stat().st_mtime)
                    latest_files['oneweb'] = str(latest_oneweb)
                    self.logger.info(f"ğŸ” æ‰¾åˆ°æœ€æ–°OneWeb TLE: {latest_oneweb.name}")
            
            if not latest_files:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°TLEæ–‡ä»¶ï¼Œå°‡ä½¿ç”¨fallbackæ•¸æ“š")
                
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥æ‰¾æœ¬åœ°TLEæ–‡ä»¶å¤±æ•—: {e}")
            
        return latest_files
        
    async def initialize(self):
        """åˆå§‹åŒ–Phase 1å¢å¼·TLEè¼‰å…¥å¼•æ“"""
        self.logger.info("ğŸš€ åˆå§‹åŒ–Phase 1å¢å¼·TLEè¼‰å…¥å¼•æ“...")
        
        # åŸºç¤Skyfieldåˆå§‹åŒ–
        if SKYFIELD_AVAILABLE:
            try:
                self.ts = load.timescale()
                # å‰µå»ºNTPUè§€æ¸¬é»
                self.observer_location = Topos(
                    latitude_degrees=self.observer_lat,
                    longitude_degrees=self.observer_lon,
                    elevation_m=self.observer_alt_m
                )
                self.logger.info("âœ… Skyfield SGP4å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ Skyfieldåˆå§‹åŒ–å¤±æ•—: {e}")
                globals()['SKYFIELD_AVAILABLE'] = False
        
        # Phase 1å¢å¼·æ¨¡çµ„åˆå§‹åŒ–
        if ENHANCED_MODULES_AVAILABLE:
            try:
                # åˆå§‹åŒ–å¢å¼·è»Œé“è¨ˆç®—å™¨
                self.orbital_calculator = EnhancedOrbitalCalculator(
                    self.observer_lat, self.observer_lon, self.observer_alt_m
                )
                await self.orbital_calculator.initialize()
                
                # åˆå§‹åŒ–æ•¸æ“šé©—è­‰å™¨
                self.data_validator = EnhancedTLEValidator(ValidationLevel.ENHANCED)
                
                self.logger.info("âœ… Phase 1å¢å¼·æ¨¡çµ„åˆå§‹åŒ–æˆåŠŸ")
                self.logger.info(f"   - å¢å¼·è»Œé“è¨ˆç®—å™¨: ç²¾åº¦ç›®æ¨™ <{self.phase1_targets['max_calculation_accuracy_m']}m")
                self.logger.info(f"   - æ•¸æ“šé©—è­‰å™¨: ç›®æ¨™æˆåŠŸç‡ â‰¥{self.phase1_targets['min_success_rate']*100:.0f}%")
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ Phase 1å¢å¼·æ¨¡çµ„åˆå§‹åŒ–å¤±æ•—: {e}")
                globals()['ENHANCED_MODULES_AVAILABLE'] = False
        
        self.logger.info(f"ğŸ“ è§€æ¸¬é»: NTPU ({self.observer_lat:.6f}Â°N, {self.observer_lon:.6f}Â°E, {self.observer_alt_m}m)")
        self.logger.info(f"ğŸ¯ Phase 1ç›®æ¨™: è¼‰å…¥8,735é¡†è¡›æ˜Ÿï¼ŒSGP4ç²¾åº¦<100mï¼ŒæˆåŠŸç‡â‰¥90%")
    
    async def load_full_satellite_data(self) -> Dict[str, List[TLEData]]:
        """è¼‰å…¥å…¨é‡è¡›æ˜ŸTLEæ•¸æ“š"""
        self.logger.info("ğŸ“¡ é–‹å§‹è¼‰å…¥å…¨é‡è¡›æ˜ŸTLEæ•¸æ“š...")
        load_start_time = datetime.now(timezone.utc)
        
        satellite_data = {
            'starlink': [],
            'oneweb': [],
            'other_constellations': []
        }
        
        try:
            # ä¸¦è¡Œè¼‰å…¥å¤šå€‹æ˜Ÿåº§çš„æœ¬åœ°TLEæ•¸æ“š
            loading_tasks = []
            for constellation, local_path in self.local_tle_sources.items():
                task = self._load_local_constellation_tle(constellation, local_path)
                loading_tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰è¼‰å…¥ä»»å‹™å®Œæˆ
            constellation_results = await asyncio.gather(*loading_tasks, return_exceptions=True)
            
            # è™•ç†è¼‰å…¥çµæœ
            for constellation, result in zip(self.local_tle_sources.keys(), constellation_results):
                if isinstance(result, Exception):
                    self.logger.error(f"âŒ {constellation} TLEè¼‰å…¥å¤±æ•—: {result}")
                    self.load_statistics['error_count'] += 1
                    continue
                
                tle_list = result
                
                if constellation == 'starlink':
                    satellite_data['starlink'] = tle_list
                    self.load_statistics['starlink_count'] = len(tle_list)
                elif constellation == 'oneweb':
                    satellite_data['oneweb'] = tle_list  
                    self.load_statistics['oneweb_count'] = len(tle_list)
                else:
                    satellite_data['other_constellations'].extend(tle_list)
                    self.load_statistics['other_constellation_count'] += len(tle_list)
                
                # æ·»åŠ åˆ°å…§éƒ¨æ•¸æ“šåº«
                for tle_data in tle_list:
                    self.tle_database[tle_data.satellite_id] = tle_data
            
            # è¨ˆç®—ç¸½çµ±è¨ˆ
            self.load_statistics['total_satellites'] = (
                self.load_statistics['starlink_count'] + 
                self.load_statistics['oneweb_count'] + 
                self.load_statistics['other_constellation_count']
            )
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨fallbackæ•¸æ“š
            if self.load_statistics['total_satellites'] == 0:
                self.logger.warning("âš ï¸ ç¶²è·¯è¼‰å…¥å¤±æ•—ï¼Œä½¿ç”¨fallbackæ¸¬è©¦æ•¸æ“š...")
                return await self._load_fallback_data()
            
            load_duration = (datetime.now(timezone.utc) - load_start_time).total_seconds()
            self.load_statistics['load_duration_seconds'] = load_duration
            
            self.logger.info(f"âœ… TLEæ•¸æ“šè¼‰å…¥å®Œæˆ ({load_duration:.1f}ç§’)")
            self.logger.info(f"ğŸ“Š è¼‰å…¥çµ±è¨ˆ:")
            self.logger.info(f"   ç¸½è¡›æ˜Ÿæ•¸: {self.load_statistics['total_satellites']}é¡†")
            self.logger.info(f"   Starlink: {self.load_statistics['starlink_count']}é¡†")
            self.logger.info(f"   OneWeb: {self.load_statistics['oneweb_count']}é¡†")
            self.logger.info(f"   å…¶ä»–æ˜Ÿåº§: {self.load_statistics['other_constellation_count']}é¡†")
            
            return satellite_data
            
        except Exception as e:
            self.logger.error(f"âŒ å…¨é‡TLEæ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            self.logger.warning("âš ï¸ å˜—è©¦ä½¿ç”¨fallbackæ¸¬è©¦æ•¸æ“š...")
            return await self._load_fallback_data()
    
    async def _load_local_constellation_tle(self, constellation: str, local_path: str) -> List[TLEData]:
        """è¼‰å…¥æœ¬åœ°TLEæ•¸æ“šæ–‡ä»¶"""
        self.logger.info(f"ğŸ“‚ è¼‰å…¥{constellation}æœ¬åœ°TLEæ•¸æ“š: {local_path}")
        
        try:
            # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not Path(local_path).exists():
                raise FileNotFoundError(f"TLEæ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
            
            # è®€å–æœ¬åœ°TLEæ–‡ä»¶
            with open(local_path, 'r', encoding='utf-8') as f:
                tle_content = f.read()
            
            self.logger.info(f"ğŸ“‹ æœ¬åœ°TLEæ–‡ä»¶è¼‰å…¥æˆåŠŸ: {constellation}")
            
            # è§£æTLEæ•¸æ“š
            tle_list = self._parse_tle_content(tle_content, constellation)
            
            self.logger.info(f"âœ… {constellation}è¼‰å…¥{len(tle_list)}é¡†è¡›æ˜Ÿ")
            return tle_list
            
        except Exception as e:
            self.logger.error(f"âŒ {constellation}æœ¬åœ°TLEè¼‰å…¥å¤±æ•—: {e}")
            return []
    
    async def _load_constellation_tle(self, constellation: str, url: str) -> List[TLEData]:
        """è¼‰å…¥å–®å€‹æ˜Ÿåº§çš„TLEæ•¸æ“š"""
        self.logger.info(f"ğŸ”„ è¼‰å…¥{constellation}æ˜Ÿåº§TLEæ•¸æ“š...")
        
        try:
            # æª¢æŸ¥æ˜¯å¦æœ‰æœ¬åœ°ç·©å­˜
            cache_path = Path(f"/tmp/tle_cache_{constellation}.txt")
            tle_content = ""
            
            if cache_path.exists() and self._is_cache_valid(cache_path):
                # ä½¿ç”¨ç·©å­˜æ•¸æ“š
                with open(cache_path, 'r') as f:
                    tle_content = f.read()
                self.logger.info(f"ğŸ“‚ ä½¿ç”¨ç·©å­˜TLEæ•¸æ“š: {constellation}")
            else:
                # å¾ç¶²è·¯ä¸‹è¼‰
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
                        if response.status == 200:
                            tle_content = await response.text()
                            
                            # ä¿å­˜åˆ°ç·©å­˜
                            with open(cache_path, 'w') as f:
                                f.write(tle_content)
                            
                            self.logger.info(f"ğŸŒ ä¸‹è¼‰TLEæ•¸æ“šå®Œæˆ: {constellation}")
                        else:
                            raise Exception(f"HTTP {response.status}")
            
            # è§£æTLEæ•¸æ“š
            tle_list = self._parse_tle_content(tle_content, constellation)
            
            self.logger.info(f"âœ… {constellation}è¼‰å…¥{len(tle_list)}é¡†è¡›æ˜Ÿ")
            return tle_list
            
        except Exception as e:
            self.logger.error(f"âŒ {constellation} TLEè¼‰å…¥å¤±æ•—: {e}")
            return []
    
    def _is_cache_valid(self, cache_path: Path, max_age_hours: int = 6) -> bool:
        """æª¢æŸ¥TLEç·©å­˜æ˜¯å¦æœ‰æ•ˆ"""
        try:
            file_age = datetime.now(timezone.utc) - datetime.fromtimestamp(
                cache_path.stat().st_mtime, tz=timezone.utc
            )
            return file_age.total_seconds() < (max_age_hours * 3600)
        except:
            return False
    
    def _parse_tle_content(self, content: str, constellation: str) -> List[TLEData]:
        """è§£æTLEå…§å®¹"""
        tle_list = []
        lines = content.strip().split('\n')  # âœ… ä¿®å¾©ï¼šç§»é™¤å¤šé¤˜çš„åæ–œæ 
        
        # âœ… æª¢æŸ¥æ¨£æœ¬é™åˆ¶
        sample_limit = None
        if self.sample_limits:
            limit_key = f"{constellation}_sample"
            if limit_key in self.sample_limits:
                sample_limit = self.sample_limits[limit_key]
                self.logger.info(f"ğŸ¯ æ‡‰ç”¨æ¨£æœ¬é™åˆ¶: {constellation} = {sample_limit}é¡†")
        
        try:
            i = 0
            parsed_count = 0
            
            while i < len(lines) - 2:
                # âœ… æª¢æŸ¥æ˜¯å¦é”åˆ°æ¨£æœ¬é™åˆ¶
                if sample_limit is not None and parsed_count >= sample_limit:
                    self.logger.info(f"âœ… {constellation}é”åˆ°æ¨£æœ¬é™åˆ¶({sample_limit}é¡†)ï¼Œåœæ­¢è§£æ")
                    break
                
                # TLEæ ¼å¼: è¡›æ˜Ÿåç¨± + Line1 + Line2
                name_line = lines[i].strip()
                line1 = lines[i + 1].strip()
                line2 = lines[i + 2].strip()
                
                # é©—è­‰TLEæ ¼å¼
                if (line1.startswith('1 ') and line2.startswith('2 ') and 
                    len(line1) == 69 and len(line2) == 69):
                    
                    try:
                        tle_data = self._parse_single_tle(name_line, line1, line2, constellation)
                        tle_list.append(tle_data)
                        parsed_count += 1
                        self.load_statistics['successful_tle_parsing'] += 1
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ TLEè§£æå¤±æ•— {name_line}: {e}")
                        self.load_statistics['error_count'] += 1
                
                i += 3
        
        except Exception as e:
            self.logger.error(f"âŒ TLEå…§å®¹è§£æå¤±æ•—: {e}")
        
        # âœ… è¨˜éŒ„æ¨£æœ¬é™åˆ¶æ‡‰ç”¨çµæœ
        if sample_limit is not None:
            self.logger.info(f"ğŸ“Š {constellation}æ¨£æœ¬é™åˆ¶çµæœ: è§£æ{len(tle_list)}é¡† (é™åˆ¶:{sample_limit}é¡†)")
        else:
            self.logger.info(f"ğŸ“Š {constellation}å…¨é‡è§£æ: {len(tle_list)}é¡†è¡›æ˜Ÿ")
        
        return tle_list
    
    def _parse_single_tle(self, name: str, line1: str, line2: str, constellation: str) -> TLEData:
        """è§£æå–®å€‹TLEè¨˜éŒ„"""
        
        # å¾Line1æå–æ•¸æ“š
        satellite_number = int(line1[2:7])
        epoch_year = int(line1[18:20])
        epoch_day = float(line1[20:32])
        
        # å¾Line2æå–è»Œé“åƒæ•¸
        inclination = float(line2[8:16])
        raan = float(line2[17:25])
        eccentricity = float('0.' + line2[26:33])
        arg_perigee = float(line2[34:42])
        mean_anomaly = float(line2[43:51])
        mean_motion = float(line2[52:63])
        
        # è¨ˆç®—epochæ™‚é–“
        current_year = datetime.now(timezone.utc).year
        full_year = 2000 + epoch_year if epoch_year < 50 else 1900 + epoch_year
        epoch_date = datetime(full_year, 1, 1, tzinfo=timezone.utc) + timedelta(days=epoch_day - 1)
        
        # è¨ˆç®—è»Œé“åƒæ•¸
        semi_major_axis = (398600.4418 / (mean_motion * 2 * np.pi / 86400) ** 2) ** (1/3)
        orbital_period = 2 * np.pi * np.sqrt(semi_major_axis ** 3 / 398600.4418) / 60  # åˆ†é˜
        
        earth_radius = 6371.0  # km
        apogee_alt = semi_major_axis * (1 + eccentricity) - earth_radius
        perigee_alt = semi_major_axis * (1 - eccentricity) - earth_radius
        
        return TLEData(
            satellite_id=f"{constellation}_{satellite_number}",
            satellite_name=name.strip(),
            line1=line1,
            line2=line2,
            epoch=epoch_date,
            constellation=constellation,
            inclination_deg=inclination,
            raan_deg=raan,
            eccentricity=eccentricity,
            arg_perigee_deg=arg_perigee,
            mean_anomaly_deg=mean_anomaly,
            mean_motion_revs_per_day=mean_motion,
            semi_major_axis_km=semi_major_axis,
            orbital_period_minutes=orbital_period,
            apogee_altitude_km=apogee_alt,
            perigee_altitude_km=perigee_alt
        )
    
    async def calculate_orbital_positions(self, 
                                        satellites: List[TLEData], 
                                        time_range_minutes: int = 200) -> Dict[str, List[SatellitePosition]]:
        """è¨ˆç®—è¡›æ˜Ÿè»Œé“ä½ç½®"""
        self.logger.info(f"ğŸ§® é–‹å§‹è¨ˆç®—è»Œé“ä½ç½® ({len(satellites)}é¡†è¡›æ˜Ÿ, {time_range_minutes}åˆ†é˜)")
        
        if len(satellites) == 0:
            self.logger.warning("âš ï¸ æ²’æœ‰è¡›æ˜Ÿæ•¸æ“šé€²è¡Œè¨ˆç®—")
            return {}
            
        calc_start_time = datetime.now(timezone.utc)
        
        positions_database = {}
        
        try:
            # ğŸ“… æŒ‰ç…§@docsè¨­è¨ˆï¼š200å€‹æ™‚é–“é»ï¼Œ30ç§’é–“éš”ï¼Œç¸½è¨ˆ100åˆ†é˜
            start_time = datetime.now(timezone.utc)
            time_points = []
            self.logger.info(f"ğŸ• è»Œé“è¨ˆç®—æ™‚é–“çª—å£: {start_time.strftime('%Y-%m-%d %H:%M:%S UTC')} (è¦†è“‹{time_range_minutes}åˆ†é˜)")
            self.logger.info(f"ğŸ“ æ™‚é–“è§£æåº¦: 30ç§’é–“éš”ï¼Œ{time_range_minutes*2}å€‹æ™‚é–“é» (ç¬¦åˆ@docsè¨­è¨ˆ)")
            
            for i in range(0, time_range_minutes * 2):  # 30ç§’é–“éš”
                time_point = start_time + timedelta(seconds=i * 30)
                time_points.append(time_point)
            
            # æ‰¹é‡è¨ˆç®—è¡›æ˜Ÿä½ç½®
            calculation_tasks = []
            for satellite in satellites:
                task = self._calculate_satellite_positions(satellite, time_points)
                calculation_tasks.append(task)
            
            # ä¸¦è¡Œè¨ˆç®— (åˆ†æ‰¹è™•ç†é¿å…è¨˜æ†¶é«”éè¼‰)
            batch_size = 100  # å¢åŠ æ‰¹é‡å¤§å°ä»¥æé«˜è™•ç†æ•ˆç‡
            total_batches = (len(calculation_tasks) + batch_size - 1) // batch_size
            self.logger.info(f"ğŸ“Š åˆ†æ‰¹è™•ç†: {total_batches}æ‰¹æ¬¡ï¼Œæ¯æ‰¹{batch_size}é¡†è¡›æ˜Ÿ")
            
            for batch_idx in range(0, len(calculation_tasks), batch_size):
                batch = calculation_tasks[batch_idx:batch_idx + batch_size]
                results = await asyncio.gather(*batch, return_exceptions=True)
                
                current_batch_num = (batch_idx // batch_size) + 1
                self.logger.info(f"   è™•ç†æ‰¹æ¬¡ {current_batch_num}/{total_batches} ({len(batch)}é¡†è¡›æ˜Ÿ)")
                
                for j, result in enumerate(results):
                    if isinstance(result, Exception):
                        satellite_id = satellites[batch_idx + j].satellite_id
                        self.logger.warning(f"âš ï¸ {satellite_id}ä½ç½®è¨ˆç®—å¤±æ•—: {result}")
                        continue
                    
                    satellite_id, positions = result
                    positions_database[satellite_id] = positions
            
            calc_duration = (datetime.now(timezone.utc) - calc_start_time).total_seconds()
            self.load_statistics['calculation_duration_seconds'] = calc_duration
            
            self.logger.info(f"âœ… è»Œé“ä½ç½®è¨ˆç®—å®Œæˆ ({calc_duration:.1f}ç§’)")
            self.logger.info(f"ğŸ“Š è¨ˆç®—çµ±è¨ˆ:")
            self.logger.info(f"   è¨ˆç®—è¡›æ˜Ÿæ•¸: {len(positions_database)}")
            self.logger.info(f"   æ™‚é–“é»æ•¸: {len(time_points)}")
            self.logger.info(f"   ç¸½ä½ç½®æ•¸æ“šé»: {sum(len(pos) for pos in positions_database.values())}")
            
            # å­˜å„²åˆ°å…§éƒ¨è³‡æ–™åº«
            self.orbital_positions.update(positions_database)
            
            return positions_database
            
        except Exception as e:
            self.logger.error(f"âŒ è»Œé“ä½ç½®è¨ˆç®—å¤±æ•—: {e}")
            raise
    
    async def _calculate_satellite_positions(self, 
                                           satellite: TLEData, 
                                           time_points: List[datetime]) -> Tuple[str, List[SatellitePosition]]:
        """è¨ˆç®—å–®é¡†è¡›æ˜Ÿçš„ä½ç½®åºåˆ—"""
        
        positions = []
        
        try:
            if SKYFIELD_AVAILABLE:
                # ä½¿ç”¨Skyfieldé€²è¡Œç²¾ç¢ºè¨ˆç®—
                positions = await self._calculate_positions_skyfield(satellite, time_points)
            else:
                # ä½¿ç”¨ç°¡åŒ–SGP4è¨ˆç®—
                positions = await self._calculate_positions_simplified(satellite, time_points)
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ {satellite.satellite_id}ä½ç½®è¨ˆç®—å¤±æ•—: {e}")
        
        return satellite.satellite_id, positions
    
    async def _calculate_positions_skyfield(self, 
                                      satellite: TLEData, 
                                      time_points: List[datetime]) -> List[SatellitePosition]:
        """ä½¿ç”¨Skyfieldè¨ˆç®—ç²¾ç¢ºä½ç½®"""
        positions = []
        
        try:
            # å°å…¥Skyfieldçš„UTCæ™‚å€
            from skyfield.api import utc
            
            # å‰µå»ºè¡›æ˜Ÿå°è±¡
            earth_satellite = EarthSatellite(satellite.line1, satellite.line2, 
                                           satellite.satellite_name, self.ts)
            
            success_count = 0
            error_count = 0
            
            for i, time_point in enumerate(time_points):
                try:
                    # ç¢ºä¿æ™‚é–“é»æœ‰UTCæ™‚å€ - ä½¿ç”¨Skyfieldçš„utcå°è±¡
                    if time_point.tzinfo is None:
                        time_point = time_point.replace(tzinfo=utc)
                    elif time_point.tzinfo != utc:
                        time_point = time_point.astimezone(utc)
                    
                    # è½‰æ›ç‚ºSkyfieldæ™‚é–“ - ç›´æ¥å‚³éå¸¶æ™‚å€çš„datetime
                    t = self.ts.from_datetime(time_point)
                    
                    # è¨ˆç®—è¡›æ˜Ÿä½ç½®
                    geocentric = earth_satellite.at(t)
                    subpoint = geocentric.subpoint()
                    
                    # è¨ˆç®—ç›¸å°è§€æ¸¬è€…çš„ä½ç½® - ä¿®å¾©ï¼šæ­£ç¢ºè§£åŒ…altaz()çµæœ
                    difference = earth_satellite.at(t) - self.observer_location.at(t)
                    elevation, azimuth, distance = difference.altaz()
                    
                    # è¨ˆç®—é€Ÿåº¦
                    dt = 1.0 / 86400  # 1ç§’
                    t_plus = self.ts.from_datetime(time_point + timedelta(seconds=1))
                    pos_plus = earth_satellite.at(t_plus)
                    velocity_vector = (pos_plus.position.km - geocentric.position.km) / dt
                    velocity_magnitude = np.linalg.norm(velocity_vector)
                    
                    position = SatellitePosition(
                        timestamp=time_point,
                        latitude_deg=subpoint.latitude.degrees,
                        longitude_deg=subpoint.longitude.degrees,
                        altitude_km=subpoint.elevation.km,
                        elevation_deg=elevation.degrees,  # ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„elevationå°è±¡
                        azimuth_deg=azimuth.degrees,      # ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„azimuthå°è±¡
                        distance_km=distance.km,          # ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„distanceå°è±¡
                        velocity_km_s=velocity_magnitude
                    )
                    
                    positions.append(position)
                    success_count += 1
                    
                except Exception as e:
                    error_count += 1
                    if error_count <= 3:  # åªè¨˜éŒ„å‰3å€‹éŒ¯èª¤é¿å…æ—¥èªŒæ³›æ¿«
                        self.logger.warning(f"âš ï¸ {satellite.satellite_id} SGP4è¨ˆç®—æ™‚é–“é»{i} å¤±æ•—: {e}")
                    continue
            
            if success_count > 0:
                self.logger.debug(f"âœ… {satellite.satellite_id}: SGP4è¨ˆç®—æˆåŠŸ {success_count}/{len(time_points)} é»")
            else:
                self.logger.error(f"âŒ {satellite.satellite_id}: æ‰€æœ‰æ™‚é–“é»SGP4è¨ˆç®—å¤±æ•—")
                    
        except Exception as e:
            self.logger.error(f"âŒ {satellite.satellite_id} Skyfieldåˆå§‹åŒ–å¤±æ•—: {e}")
            
        return positions
    
    async def _calculate_positions_simplified(self, 
                                        satellite: TLEData, 
                                        time_points: List[datetime]) -> List[SatellitePosition]:
        """ç°¡åŒ–SGP4ä½ç½®è¨ˆç®—"""
        positions = []
        
        try:
            success_count = 0
            error_count = 0
            
            for i, time_point in enumerate(time_points):
                try:
                    # ç°¡åŒ–çš„è»Œé“è¨ˆç®—
                    time_since_epoch = (time_point - satellite.epoch).total_seconds()
                    mean_motion_rad_s = satellite.mean_motion_revs_per_day * 2 * np.pi / 86400
                    
                    # ç°¡åŒ–çš„å¹³å‡ç•°å¸¸è§’è¨ˆç®—
                    current_mean_anomaly = (satellite.mean_anomaly_deg + 
                                          np.degrees(mean_motion_rad_s * time_since_epoch)) % 360
                    
                    # ç°¡åŒ–çš„ä½ç½®è¨ˆç®— (å‡è¨­åœ“è»Œé“)
                    true_anomaly = current_mean_anomaly  # ç°¡åŒ–
                    
                    # åœ°å¿ƒåº§æ¨™
                    r = satellite.semi_major_axis_km
                    x = r * np.cos(np.radians(true_anomaly))
                    y = r * np.sin(np.radians(true_anomaly))
                    z = 0  # ç°¡åŒ–ç‚ºèµ¤é“å¹³é¢
                    
                    # ç°¡åŒ–çš„åœ°ç†åº§æ¨™è½‰æ›
                    latitude = np.degrees(np.arcsin(z / r)) if r > 0 else 0
                    longitude = np.degrees(np.arctan2(y, x))
                    altitude = r - 6371.0  # åœ°çƒåŠå¾‘
                    
                    # ç°¡åŒ–çš„è§€æ¸¬è€…ç›¸å°ä½ç½®
                    lat_diff = latitude - self.observer_lat
                    lon_diff = longitude - self.observer_lon
                    distance = np.sqrt(lat_diff**2 + lon_diff**2) * 111.32  # ç²—ç•¥è·é›¢
                    elevation = np.degrees(np.arctan2(altitude, distance)) if distance > 0 else 90.0
                    azimuth = np.degrees(np.arctan2(lon_diff, lat_diff))
                    
                    position = SatellitePosition(
                        timestamp=time_point,
                        latitude_deg=latitude,
                        longitude_deg=longitude,
                        altitude_km=altitude,
                        elevation_deg=elevation,
                        azimuth_deg=azimuth % 360,
                        distance_km=distance + altitude,
                        velocity_km_s=7.8  # å…¸å‹LEOé€Ÿåº¦
                    )
                    
                    positions.append(position)
                    success_count += 1
                    
                except Exception as e:
                    error_count += 1
                    if error_count <= 3:  # åªè¨˜éŒ„å‰3å€‹éŒ¯èª¤
                        self.logger.warning(f"âš ï¸ {satellite.satellite_id} ç°¡åŒ–è¨ˆç®—æ™‚é–“é»{i} å¤±æ•—: {e}")
                    continue
            
            if error_count > 0:
                self.logger.warning(f"âš ï¸ {satellite.satellite_id} ç°¡åŒ–è¨ˆç®—: {success_count}æˆåŠŸ/{error_count}å¤±æ•—")
            
            if success_count == 0:
                self.logger.error(f"âŒ {satellite.satellite_id}: ç°¡åŒ–è¨ˆç®—å®Œå…¨å¤±æ•—")
                self.logger.error(f"   è»Œé“åƒæ•¸: å‘¨æœŸ{satellite.orbital_period_minutes:.1f}min, é«˜åº¦{satellite.apogee_altitude_km:.0f}km")
                
        except Exception as e:
            self.logger.error(f"âŒ {satellite.satellite_id} ç°¡åŒ–è¨ˆç®—å¤±æ•—: {e}")
            
        return positions
    
    async def _load_fallback_data(self) -> Dict[str, List[TLEData]]:
        """è¼‰å…¥fallbackæ¸¬è©¦æ•¸æ“š"""
        try:
            from .fallback_test_data import create_fallback_tle_data, get_fallback_statistics
            
            self.logger.info("ğŸ“‚ è¼‰å…¥fallbackæ¸¬è©¦æ•¸æ“š...")
            
            # ç²å–fallbackæ•¸æ“š
            fallback_data = create_fallback_tle_data()
            fallback_stats = get_fallback_statistics()
            
            # æ›´æ–°çµ±è¨ˆ
            self.load_statistics.update(fallback_stats)
            
            # æ·»åŠ åˆ°å…§éƒ¨æ•¸æ“šåº«
            for constellation, satellites in fallback_data.items():
                for satellite in satellites:
                    self.tle_database[satellite.satellite_id] = satellite
            
            self.logger.info("âœ… Fallbackæ•¸æ“šè¼‰å…¥å®Œæˆ")
            self.logger.info(f"ğŸ“Š æ¸¬è©¦æ•¸æ“šçµ±è¨ˆ:")
            self.logger.info(f"   ç¸½è¡›æ˜Ÿæ•¸: {fallback_stats['total_satellites']}é¡†")
            self.logger.info(f"   Starlink: {fallback_stats['starlink_count']}é¡†")
            self.logger.info(f"   OneWeb: {fallback_stats['oneweb_count']}é¡†")
            self.logger.warning(f"âš ï¸ {fallback_stats['fallback_reason']}")
            
            return fallback_data
            
        except Exception as e:
            self.logger.error(f"âŒ Fallbackæ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            # è¿”å›ç©ºæ•¸æ“šä½†ä¸æ‹‹å‡ºç•°å¸¸ï¼Œè®“ç³»çµ±ç¹¼çºŒé‹è¡Œ
            return {
                'starlink': [],
                'oneweb': [],
                'other_constellations': []
            }
    
    async def export_load_statistics(self, output_path: str):
        """åŒ¯å‡ºè¼‰å…¥çµ±è¨ˆä¿¡æ¯"""
        try:
            export_data = {
                'f1_tle_loader_statistics': {
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'load_statistics': self.load_statistics,
                    'configuration': {
                        'observer_coordinates': {
                            'latitude': self.observer_lat,
                            'longitude': self.observer_lon,
                            'altitude_m': self.observer_alt_m
                        },
                        'local_tle_sources': self.local_tle_sources,
                        'skyfield_available': SKYFIELD_AVAILABLE
                    },
                    'constellation_breakdown': {
                        'starlink': {
                            'count': self.load_statistics['starlink_count'],
                            'percentage': self.load_statistics['starlink_count'] / max(1, self.load_statistics['total_satellites']) * 100
                        },
                        'oneweb': {
                            'count': self.load_statistics['oneweb_count'],
                            'percentage': self.load_statistics['oneweb_count'] / max(1, self.load_statistics['total_satellites']) * 100
                        },
                        'others': {
                            'count': self.load_statistics['other_constellation_count'],
                            'percentage': self.load_statistics['other_constellation_count'] / max(1, self.load_statistics['total_satellites']) * 100
                        }
                    }
                }
            }
            
            with open(output_path, 'w') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ğŸ“Š F1è¼‰å…¥çµ±è¨ˆå·²åŒ¯å‡ºè‡³: {output_path}")
            
        except Exception as e:
            self.logger.error(f"âŒ è¼‰å…¥çµ±è¨ˆåŒ¯å‡ºå¤±æ•—: {e}")
    

# ä½¿ç”¨ç¯„ä¾‹
async def main():
    """F1_TLE_Loaderä½¿ç”¨ç¯„ä¾‹"""
    
    config = {
        'tle_sources': {
            'starlink': 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle',
            'oneweb': 'https://celestrak.org/NORAD/elements/gp.php?GROUP=oneweb&FORMAT=tle'
        },
        'calculation_params': {
            'time_range_minutes': 200,
            'time_resolution_seconds': 30
        }
    }
    
    # åˆå§‹åŒ–TLEè¼‰å…¥å™¨
    tle_loader = TLELoaderEngine(config)
    await tle_loader.initialize()
    
    # è¼‰å…¥å…¨é‡è¡›æ˜Ÿæ•¸æ“š
    satellite_data = await tle_loader.load_full_satellite_data()
    
    # è¨ˆç®—è»Œé“ä½ç½® (é¸æ“‡å‰100é¡†é€²è¡Œæ¸¬è©¦)
    test_satellites = []
    if satellite_data.get('starlink'):
        test_satellites.extend(satellite_data['starlink'][:50])
    if satellite_data.get('oneweb'):
        test_satellites.extend(satellite_data['oneweb'][:50])
    
    orbital_positions = await tle_loader.calculate_orbital_positions(
        test_satellites, time_range_minutes=200
    )
    
    # åŒ¯å‡ºçµ±è¨ˆ
    await tle_loader.export_load_statistics('/tmp/f1_tle_loader_stats.json')
    
    print(f"âœ… F1_TLE_Loaderæ¸¬è©¦å®Œæˆ")
    print(f"   è¼‰å…¥è¡›æ˜Ÿæ•¸: {tle_loader.load_statistics['total_satellites']}")
    print(f"   è¨ˆç®—ä½ç½®æ•¸: {len(orbital_positions)}")

# å‘å¾Œå…¼å®¹æ€§åˆ¥å
TLELoaderEngine = EnhancedTLELoaderEngine

if __name__ == "__main__":
    asyncio.run(main())