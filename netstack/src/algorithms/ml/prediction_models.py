"""
Phase 3.2.2.3: ML é©…å‹•é æ¸¬æ¨¡å‹æ•´åˆå¯¦ç¾

å¯¦ç¾æ©Ÿå™¨å­¸ç¿’é©…å‹•çš„é æ¸¬æ¨¡å‹ç³»çµ±ï¼ŒåŒ…æ‹¬ï¼š
1. è¡›æ˜Ÿè»Œé“é æ¸¬å„ªåŒ–æ¨¡å‹
2. åˆ‡æ›æ±ºç­–é æ¸¬æ¨¡å‹
3. æœå‹™è³ªé‡é æ¸¬æ¨¡å‹
4. è² è¼‰é æ¸¬å’Œè³‡æºå„ªåŒ–æ¨¡å‹
5. ç•°å¸¸æª¢æ¸¬å’Œæ•…éšœé æ¸¬æ¨¡å‹

ç¬¦åˆæ¨™æº–ï¼š
- TensorFlow/PyTorch æ©Ÿå™¨å­¸ç¿’æ¡†æ¶
- scikit-learn å‚³çµ±æ©Ÿå™¨å­¸ç¿’ç®—æ³•
- Time Series Forecasting æ™‚é–“åºåˆ—é æ¸¬
- Online Learning åœ¨ç·šå­¸ç¿’æ©Ÿåˆ¶
- Model Versioning æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
"""

import asyncio
import logging
import numpy as np
import pandas as pd
import pickle
import json
import os
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any, Union, Callable
from enum import Enum
from datetime import datetime, timezone, timedelta
from collections import defaultdict, deque
import threading
import uuid
import time
import math

# ML framework imports
try:
    import sklearn
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.linear_model import LinearRegression, Ridge, Lasso
    from sklearn.neural_network import MLPRegressor
    from sklearn.svm import SVR
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    from sklearn.preprocessing import StandardScaler, MinMaxScaler
    from sklearn.model_selection import train_test_split, cross_val_score
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

logger = logging.getLogger(__name__)


class ModelType(Enum):
    """æ¨¡å‹é¡å‹"""
    ORBIT_PREDICTION = "orbit_prediction"          # è»Œé“é æ¸¬
    HANDOVER_DECISION = "handover_decision"        # åˆ‡æ›æ±ºç­–
    QOS_PREDICTION = "qos_prediction"              # æœå‹™è³ªé‡é æ¸¬
    LOAD_PREDICTION = "load_prediction"            # è² è¼‰é æ¸¬
    ANOMALY_DETECTION = "anomaly_detection"        # ç•°å¸¸æª¢æ¸¬
    RESOURCE_OPTIMIZATION = "resource_optimization" # è³‡æºå„ªåŒ–


class PredictionTarget(Enum):
    """é æ¸¬ç›®æ¨™"""
    SIGNAL_STRENGTH = "signal_strength"            # ä¿¡è™Ÿå¼·åº¦
    THROUGHPUT = "throughput"                      # ååé‡
    LATENCY = "latency"                           # å»¶é²
    PACKET_LOSS = "packet_loss"                   # ä¸ŸåŒ…ç‡
    HANDOVER_SUCCESS = "handover_success"         # åˆ‡æ›æˆåŠŸç‡
    SATELLITE_LOAD = "satellite_load"             # è¡›æ˜Ÿè² è¼‰
    ORBITAL_POSITION = "orbital_position"         # è»Œé“ä½ç½®
    DOPPLER_SHIFT = "doppler_shift"              # éƒ½åœå‹’é »ç§»


class TrainingStatus(Enum):
    """è¨“ç·´ç‹€æ…‹"""
    NOT_STARTED = "not_started"
    TRAINING = "training"
    COMPLETED = "completed"
    FAILED = "failed"
    UPDATING = "updating"


@dataclass
class TrainingData:
    """è¨“ç·´æ•¸æ“š"""
    feature_data: np.ndarray
    target_data: np.ndarray
    feature_names: List[str]
    target_name: str
    timestamp: datetime
    data_source: str
    quality_score: float = 1.0
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ModelMetrics:
    """æ¨¡å‹æŒ‡æ¨™"""
    mse: float = 0.0                    # å‡æ–¹èª¤å·®
    mae: float = 0.0                    # å¹³å‡çµ•å°èª¤å·®
    rmse: float = 0.0                   # å‡æ–¹æ ¹èª¤å·®
    r2_score: float = 0.0               # æ±ºå®šä¿‚æ•¸
    accuracy: float = 0.0               # æº–ç¢ºç‡ï¼ˆåˆ†é¡æ¨¡å‹ï¼‰
    precision: float = 0.0              # ç²¾ç¢ºç‡
    recall: float = 0.0                 # å¬å›ç‡
    f1_score: float = 0.0               # F1åˆ†æ•¸
    training_time_ms: float = 0.0       # è¨“ç·´æ™‚é–“
    inference_time_ms: float = 0.0      # æ¨ç†æ™‚é–“
    model_size_bytes: int = 0           # æ¨¡å‹å¤§å°
    last_updated: datetime = field(default_factory=lambda: datetime.now(timezone.utc))


@dataclass
class PredictionResult:
    """é æ¸¬çµæœ"""
    prediction_id: str
    model_id: str
    input_features: Dict[str, Any]
    predicted_value: Union[float, np.ndarray]
    confidence_score: float
    prediction_timestamp: datetime
    model_version: str
    feature_importance: Optional[Dict[str, float]] = None
    uncertainty_bounds: Optional[Tuple[float, float]] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


class MLPredictionModel:
    """æ©Ÿå™¨å­¸ç¿’é æ¸¬æ¨¡å‹åŸºé¡"""
    
    def __init__(self, model_id: str, model_type: ModelType, 
                 prediction_target: PredictionTarget):
        self.model_id = model_id
        self.model_type = model_type
        self.prediction_target = prediction_target
        self.version = "1.0.0"
        
        # æ¨¡å‹ç‹€æ…‹
        self.is_trained = False
        self.training_status = TrainingStatus.NOT_STARTED
        self.last_training_time: Optional[datetime] = None
        
        # æ¨¡å‹å°è±¡
        self.model = None
        self.scaler = StandardScaler() if SKLEARN_AVAILABLE else None
        
        # è¨“ç·´æ­·å²
        self.training_history: List[TrainingData] = []
        self.metrics_history: List[ModelMetrics] = []
        
        # é…ç½®
        self.config = {
            'retrain_threshold_samples': 1000,
            'retrain_threshold_accuracy_drop': 0.05,
            'feature_importance_threshold': 0.01,
            'prediction_confidence_threshold': 0.7,
            'max_training_data_size': 10000,
            'auto_retrain_enabled': True,
            'online_learning_enabled': False
        }
        
        # çµ±è¨ˆä¿¡æ¯
        self.stats = {
            'predictions_made': 0,
            'successful_predictions': 0,
            'training_sessions': 0,
            'total_training_time_ms': 0.0,
            'average_prediction_time_ms': 0.0,
            'data_points_processed': 0,
            'model_accuracy_trend': []
        }
        
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
    
    def initialize_model(self, **model_params):
        """åˆå§‹åŒ–æ©Ÿå™¨å­¸ç¿’æ¨¡å‹"""
        if not SKLEARN_AVAILABLE:
            raise RuntimeError("scikit-learn not available for ML models")
        
        try:
            # æ ¹æ“šé æ¸¬ç›®æ¨™é¸æ“‡åˆé©çš„æ¨¡å‹
            if self.prediction_target in [PredictionTarget.SIGNAL_STRENGTH, 
                                        PredictionTarget.THROUGHPUT,
                                        PredictionTarget.LATENCY]:
                # å›æ­¸æ¨¡å‹
                self.model = RandomForestRegressor(
                    n_estimators=model_params.get('n_estimators', 100),
                    max_depth=model_params.get('max_depth', 10),
                    random_state=42,
                    n_jobs=-1
                )
            
            elif self.prediction_target == PredictionTarget.HANDOVER_SUCCESS:
                # åˆ†é¡æ¨¡å‹ï¼ˆä½¿ç”¨å›æ­¸å™¨çš„é–¾å€¼æ–¹å¼ï¼‰
                self.model = GradientBoostingRegressor(
                    n_estimators=model_params.get('n_estimators', 100),
                    learning_rate=model_params.get('learning_rate', 0.1),
                    max_depth=model_params.get('max_depth', 6),
                    random_state=42
                )
            
            else:
                # é»˜èªä½¿ç”¨éš¨æ©Ÿæ£®æ—
                self.model = RandomForestRegressor(
                    n_estimators=100,
                    max_depth=10,
                    random_state=42,
                    n_jobs=-1
                )
            
            self.logger.info(f"âœ… æ¨¡å‹ {self.model_id} åˆå§‹åŒ–å®Œæˆ - é¡å‹: {type(self.model).__name__}")
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def train(self, training_data: TrainingData, 
                   validation_split: float = 0.2) -> ModelMetrics:
        """è¨“ç·´æ¨¡å‹"""
        if not SKLEARN_AVAILABLE:
            raise RuntimeError("scikit-learn not available for model training")
        
        start_time = time.time()
        self.training_status = TrainingStatus.TRAINING
        
        try:
            # æ•¸æ“šé è™•ç†
            X = training_data.feature_data
            y = training_data.target_data
            
            if X.shape[0] == 0 or y.shape[0] == 0:
                raise ValueError("è¨“ç·´æ•¸æ“šç‚ºç©º")
            
            # æ•¸æ“šæ¨™æº–åŒ–
            X_scaled = self.scaler.fit_transform(X)
            
            # åˆ†å‰²è¨“ç·´å’Œé©—è­‰æ•¸æ“š
            if validation_split > 0:
                X_train, X_val, y_train, y_val = train_test_split(
                    X_scaled, y, test_size=validation_split, random_state=42
                )
            else:
                X_train, y_train = X_scaled, y
                X_val, y_val = None, None
            
            # è¨“ç·´æ¨¡å‹
            self.model.fit(X_train, y_train)
            
            # è¨ˆç®—æŒ‡æ¨™
            metrics = ModelMetrics()
            
            if X_val is not None and y_val is not None:
                y_pred = self.model.predict(X_val)
                metrics.mse = mean_squared_error(y_val, y_pred)
                metrics.mae = mean_absolute_error(y_val, y_pred)
                metrics.rmse = np.sqrt(metrics.mse)
                metrics.r2_score = r2_score(y_val, y_pred)
            else:
                # ä½¿ç”¨è¨“ç·´æ•¸æ“šè¨ˆç®—æŒ‡æ¨™ï¼ˆä¸ç†æƒ³ä½†å¯ç”¨ï¼‰
                y_pred = self.model.predict(X_train)
                metrics.mse = mean_squared_error(y_train, y_pred)
                metrics.mae = mean_absolute_error(y_train, y_pred)
                metrics.rmse = np.sqrt(metrics.mse)
                metrics.r2_score = r2_score(y_train, y_pred)
            
            # è¨“ç·´æ™‚é–“
            training_time = (time.time() - start_time) * 1000
            metrics.training_time_ms = training_time
            
            # æ¨¡å‹å¤§å°ä¼°ç®—
            try:
                import sys
                metrics.model_size_bytes = sys.getsizeof(pickle.dumps(self.model))
            except:
                metrics.model_size_bytes = 0
            
            # æ›´æ–°ç‹€æ…‹
            self.is_trained = True
            self.training_status = TrainingStatus.COMPLETED
            self.last_training_time = datetime.now(timezone.utc)
            
            # è¨˜éŒ„è¨“ç·´æ­·å²
            self.training_history.append(training_data)
            if len(self.training_history) > self.config['max_training_data_size']:
                self.training_history = self.training_history[-self.config['max_training_data_size']:]
            
            self.metrics_history.append(metrics)
            
            # æ›´æ–°çµ±è¨ˆ
            self.stats['training_sessions'] += 1
            self.stats['total_training_time_ms'] += training_time
            self.stats['data_points_processed'] += X.shape[0]
            self.stats['model_accuracy_trend'].append(metrics.r2_score)
            
            self.logger.info(f"âœ… æ¨¡å‹ {self.model_id} è¨“ç·´å®Œæˆ - "
                           f"RÂ²: {metrics.r2_score:.4f}, "
                           f"RMSE: {metrics.rmse:.4f}, "
                           f"è¨“ç·´æ™‚é–“: {training_time:.1f}ms")
            
            return metrics
            
        except Exception as e:
            self.training_status = TrainingStatus.FAILED
            self.logger.error(f"âŒ æ¨¡å‹è¨“ç·´å¤±æ•—: {e}")
            raise
    
    async def predict(self, features: Dict[str, Any]) -> PredictionResult:
        """é€²è¡Œé æ¸¬"""
        if not self.is_trained:
            raise RuntimeError(f"æ¨¡å‹ {self.model_id} å°šæœªè¨“ç·´")
        
        start_time = time.time()
        
        try:
            # ç‰¹å¾µå‘é‡åŒ–
            feature_vector = self._vectorize_features(features)
            
            # æ•¸æ“šæ¨™æº–åŒ–
            if self.scaler:
                feature_vector_scaled = self.scaler.transform(feature_vector.reshape(1, -1))
            else:
                feature_vector_scaled = feature_vector.reshape(1, -1)
            
            # é æ¸¬
            prediction = self.model.predict(feature_vector_scaled)[0]
            
            # è¨ˆç®—ç½®ä¿¡åº¦ï¼ˆåŸºæ–¼ç‰¹å¾µé‡è¦æ€§å’Œæ­·å²æº–ç¢ºæ€§ï¼‰
            confidence = self._calculate_confidence(features, prediction)
            
            # è¨ˆç®—ä¸ç¢ºå®šæ€§é‚Šç•Œï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
            uncertainty_bounds = self._calculate_uncertainty_bounds(
                feature_vector_scaled, prediction
            )
            
            # ç‰¹å¾µé‡è¦æ€§
            feature_importance = self._get_feature_importance(features.keys())
            
            # å‰µå»ºé æ¸¬çµæœ
            result = PredictionResult(
                prediction_id=f"pred_{uuid.uuid4().hex[:8]}",
                model_id=self.model_id,
                input_features=features,
                predicted_value=float(prediction),
                confidence_score=confidence,
                prediction_timestamp=datetime.now(timezone.utc),
                model_version=self.version,
                feature_importance=feature_importance,
                uncertainty_bounds=uncertainty_bounds
            )
            
            # æ¨ç†æ™‚é–“
            inference_time = (time.time() - start_time) * 1000
            result.metadata['inference_time_ms'] = inference_time
            
            # æ›´æ–°çµ±è¨ˆ
            self.stats['predictions_made'] += 1
            if confidence >= self.config['prediction_confidence_threshold']:
                self.stats['successful_predictions'] += 1
            
            # æ›´æ–°å¹³å‡æ¨ç†æ™‚é–“
            total_predictions = self.stats['predictions_made']
            current_avg = self.stats['average_prediction_time_ms']
            self.stats['average_prediction_time_ms'] = \
                (current_avg * (total_predictions - 1) + inference_time) / total_predictions
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ é æ¸¬å¤±æ•—: {e}")
            raise
    
    def _vectorize_features(self, features: Dict[str, Any]) -> np.ndarray:
        """å°‡ç‰¹å¾µå­—å…¸è½‰æ›ç‚ºæ•¸å€¼å‘é‡"""
        try:
            # åŸºæœ¬ç‰¹å¾µåˆ—è¡¨ï¼ˆå¯æ ¹æ“šå…·é«”æ¨¡å‹æ“´å±•ï¼‰
            feature_order = [
                'signal_strength_dbm', 'elevation_angle', 'distance_km',
                'satellite_load', 'user_count', 'available_bandwidth_mbps',
                'current_throughput_mbps', 'current_latency_ms',
                'doppler_shift_hz', 'interference_level_db'
            ]
            
            vector = []
            for feature_name in feature_order:
                value = features.get(feature_name, 0.0)
                if isinstance(value, (int, float)):
                    vector.append(float(value))
                else:
                    vector.append(0.0)
            
            # å¦‚æœå‘é‡ç‚ºç©ºï¼Œæ·»åŠ é»˜èªç‰¹å¾µ
            if not vector:
                vector = [0.0] * 10  # 10å€‹é»˜èªç‰¹å¾µ
            
            return np.array(vector)
            
        except Exception as e:
            self.logger.error(f"âŒ ç‰¹å¾µå‘é‡åŒ–å¤±æ•—: {e}")
            # è¿”å›é»˜èªå‘é‡
            return np.zeros(10)
    
    def _calculate_confidence(self, features: Dict[str, Any], prediction: float) -> float:
        """è¨ˆç®—é æ¸¬ç½®ä¿¡åº¦"""
        try:
            # åŸºæ–¼æ­·å²æº–ç¢ºæ€§çš„åŸºç¤ç½®ä¿¡åº¦
            if self.metrics_history:
                latest_metrics = self.metrics_history[-1]
                base_confidence = max(0.1, min(0.9, latest_metrics.r2_score))
            else:
                base_confidence = 0.5
            
            # åŸºæ–¼ç‰¹å¾µè³ªé‡çš„èª¿æ•´
            feature_quality = self._assess_feature_quality(features)
            
            # åŸºæ–¼é æ¸¬å€¼åˆç†æ€§çš„èª¿æ•´
            prediction_reasonableness = self._assess_prediction_reasonableness(prediction)
            
            # ç¶œåˆç½®ä¿¡åº¦
            confidence = base_confidence * feature_quality * prediction_reasonableness
            
            return max(0.0, min(1.0, confidence))
            
        except Exception:
            return 0.5  # é»˜èªä¸­ç­‰ç½®ä¿¡åº¦
    
    def _assess_feature_quality(self, features: Dict[str, Any]) -> float:
        """è©•ä¼°ç‰¹å¾µè³ªé‡"""
        try:
            quality_score = 1.0
            
            # æª¢æŸ¥é—œéµç‰¹å¾µæ˜¯å¦å­˜åœ¨
            key_features = ['signal_strength_dbm', 'elevation_angle', 'distance_km']
            missing_key_features = sum(1 for f in key_features if f not in features)
            quality_score *= (1.0 - missing_key_features / len(key_features) * 0.3)
            
            # æª¢æŸ¥ç‰¹å¾µå€¼çš„åˆç†æ€§
            for feature_name, value in features.items():
                if not isinstance(value, (int, float)):
                    quality_score *= 0.9
                elif math.isnan(value) or math.isinf(value):
                    quality_score *= 0.8
                else:
                    # æª¢æŸ¥ç‰¹å¾µå€¼ç¯„åœ
                    if feature_name == 'signal_strength_dbm' and not (-150 <= value <= -30):
                        quality_score *= 0.9
                    elif feature_name == 'elevation_angle' and not (0 <= value <= 90):
                        quality_score *= 0.9
            
            return max(0.1, quality_score)
            
        except Exception:
            return 0.8  # é»˜èªè¼ƒé«˜è³ªé‡
    
    def _assess_prediction_reasonableness(self, prediction: float) -> float:
        """è©•ä¼°é æ¸¬å€¼åˆç†æ€§"""
        try:
            if math.isnan(prediction) or math.isinf(prediction):
                return 0.1
            
            # æ ¹æ“šé æ¸¬ç›®æ¨™æª¢æŸ¥åˆç†æ€§
            if self.prediction_target == PredictionTarget.SIGNAL_STRENGTH:
                if -150 <= prediction <= -30:
                    return 1.0
                else:
                    return 0.6
            elif self.prediction_target == PredictionTarget.THROUGHPUT:
                if 0 <= prediction <= 1000:  # 0-1000 Mbps
                    return 1.0
                else:
                    return 0.7
            elif self.prediction_target == PredictionTarget.LATENCY:
                if 0 <= prediction <= 5000:  # 0-5000 ms
                    return 1.0
                else:
                    return 0.7
            
            return 0.9  # é»˜èªé«˜åˆç†æ€§
            
        except Exception:
            return 0.8
    
    def _calculate_uncertainty_bounds(self, feature_vector: np.ndarray, 
                                    prediction: float) -> Optional[Tuple[float, float]]:
        """è¨ˆç®—ä¸ç¢ºå®šæ€§é‚Šç•Œ"""
        try:
            if hasattr(self.model, 'predict') and hasattr(self.model, 'estimators_'):
                # å°æ–¼éš¨æ©Ÿæ£®æ—ç­‰é›†æˆæ¨¡å‹ï¼Œä½¿ç”¨æ¨¹çš„é æ¸¬æ–¹å·®
                if hasattr(self.model, 'estimators_'):
                    tree_predictions = [tree.predict(feature_vector)[0] 
                                      for tree in self.model.estimators_]
                    std_dev = np.std(tree_predictions)
                    
                    # 95%ç½®ä¿¡å€é–“
                    lower_bound = prediction - 1.96 * std_dev
                    upper_bound = prediction + 1.96 * std_dev
                    
                    return (float(lower_bound), float(upper_bound))
            
            # åŸºæ–¼æ­·å²èª¤å·®çš„ç°¡å–®ä¼°ç®—
            if self.metrics_history:
                latest_metrics = self.metrics_history[-1]
                error_margin = latest_metrics.rmse * 1.96  # 95%ç½®ä¿¡å€é–“
                
                return (prediction - error_margin, prediction + error_margin)
            
            return None
            
        except Exception:
            return None
    
    def _get_feature_importance(self, feature_names: List[str]) -> Dict[str, float]:
        """ç²å–ç‰¹å¾µé‡è¦æ€§"""
        try:
            if hasattr(self.model, 'feature_importances_'):
                importances = self.model.feature_importances_
                
                # å‰µå»ºç‰¹å¾µé‡è¦æ€§å­—å…¸
                importance_dict = {}
                for i, importance in enumerate(importances):
                    if i < len(feature_names):
                        feature_name = list(feature_names)[i]
                        if importance >= self.config['feature_importance_threshold']:
                            importance_dict[feature_name] = float(importance)
                
                return importance_dict
            
            return {}
            
        except Exception:
            return {}
    
    async def update_model(self, new_data: TrainingData) -> bool:
        """å¢é‡æ›´æ–°æ¨¡å‹"""
        try:
            if not self.config['online_learning_enabled']:
                return False
            
            # å°æ–¼æ”¯æŒå¢é‡å­¸ç¿’çš„æ¨¡å‹ï¼Œé€²è¡Œåœ¨ç·šæ›´æ–°
            # é€™è£¡ç°¡åŒ–ç‚ºé‡æ–°è¨“ç·´ï¼ˆç”Ÿç”¢ç’°å¢ƒä¸­å¯ä»¥ä½¿ç”¨å¢é‡å­¸ç¿’ç®—æ³•ï¼‰
            
            # åˆä½µæ–°æ•¸æ“šå’Œæ­·å²æ•¸æ“š
            if self.training_history:
                # åˆä½µæœ€è¿‘çš„è¨“ç·´æ•¸æ“š
                recent_data = self.training_history[-5:]  # æœ€è¿‘5æ¬¡çš„æ•¸æ“š
                combined_features = []
                combined_targets = []
                
                for data in recent_data:
                    combined_features.append(data.feature_data)
                    combined_targets.append(data.target_data)
                
                combined_features.append(new_data.feature_data)
                combined_targets.append(new_data.target_data)
                
                # å‰µå»ºåˆä½µçš„è¨“ç·´æ•¸æ“š
                combined_training_data = TrainingData(
                    feature_data=np.vstack(combined_features),
                    target_data=np.hstack(combined_targets),
                    feature_names=new_data.feature_names,
                    target_name=new_data.target_name,
                    timestamp=datetime.now(timezone.utc),
                    data_source="incremental_update"
                )
                
                # é‡æ–°è¨“ç·´
                await self.train(combined_training_data, validation_split=0.1)
                
                self.logger.info(f"âœ… æ¨¡å‹ {self.model_id} å¢é‡æ›´æ–°å®Œæˆ")
                return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹å¢é‡æ›´æ–°å¤±æ•—: {e}")
            return False
    
    def save_model(self, file_path: str) -> bool:
        """ä¿å­˜æ¨¡å‹"""
        try:
            model_data = {
                'model_id': self.model_id,
                'model_type': self.model_type.value,
                'prediction_target': self.prediction_target.value,
                'version': self.version,
                'model': self.model,
                'scaler': self.scaler,
                'is_trained': self.is_trained,
                'last_training_time': self.last_training_time,
                'config': self.config,
                'stats': self.stats,
                'metrics_history': self.metrics_history[-10:]  # æœ€è¿‘10æ¬¡æŒ‡æ¨™
            }
            
            with open(file_path, 'wb') as f:
                pickle.dump(model_data, f)
            
            self.logger.info(f"âœ… æ¨¡å‹ {self.model_id} å·²ä¿å­˜åˆ° {file_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹ä¿å­˜å¤±æ•—: {e}")
            return False
    
    def load_model(self, file_path: str) -> bool:
        """åŠ è¼‰æ¨¡å‹"""
        try:
            with open(file_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model_id = model_data['model_id']
            self.model_type = ModelType(model_data['model_type'])
            self.prediction_target = PredictionTarget(model_data['prediction_target'])
            self.version = model_data['version']
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.is_trained = model_data['is_trained']
            self.last_training_time = model_data['last_training_time']
            self.config.update(model_data.get('config', {}))
            self.stats.update(model_data.get('stats', {}))
            self.metrics_history = model_data.get('metrics_history', [])
            
            self.logger.info(f"âœ… æ¨¡å‹ {self.model_id} å·²å¾ {file_path} åŠ è¼‰")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
            return False
    
    def get_model_info(self) -> Dict[str, Any]:
        """ç²å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'model_id': self.model_id,
            'model_type': self.model_type.value,
            'prediction_target': self.prediction_target.value,
            'version': self.version,
            'is_trained': self.is_trained,
            'training_status': self.training_status.value,
            'last_training_time': self.last_training_time.isoformat() if self.last_training_time else None,
            'model_class': type(self.model).__name__ if self.model else None,
            'config': self.config,
            'stats': self.stats,
            'latest_metrics': self.metrics_history[-1].__dict__ if self.metrics_history else None
        }


class MLPredictionEngine:
    """æ©Ÿå™¨å­¸ç¿’é æ¸¬å¼•æ“ç®¡ç†å™¨"""
    
    def __init__(self, engine_id: str = None):
        self.engine_id = engine_id or f"ml_engine_{uuid.uuid4().hex[:8]}"
        
        # æ¨¡å‹ç®¡ç†
        self.models: Dict[str, MLPredictionModel] = {}
        self.model_registry: Dict[ModelType, List[str]] = defaultdict(list)
        
        # é…ç½®
        self.config = {
            'auto_model_selection': True,
            'ensemble_predictions': False,
            'model_performance_threshold': 0.7,
            'retrain_schedule_hours': 24,
            'prediction_cache_enabled': True,
            'prediction_cache_ttl_seconds': 300
        }
        
        # é æ¸¬ç·©å­˜
        self.prediction_cache: Dict[str, Tuple[PredictionResult, datetime]] = {}
        
        # çµ±è¨ˆä¿¡æ¯
        self.stats = {
            'total_models': 0,
            'active_models': 0,
            'total_predictions': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'model_training_sessions': 0,
            'average_prediction_accuracy': 0.0
        }
        
        # ç·šç¨‹é–
        self.lock = threading.RLock()
        
        # é‹è¡Œç‹€æ…‹
        self.is_running = False
        self.maintenance_task: Optional[asyncio.Task] = None
        
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
    
    async def start_engine(self):
        """å•Ÿå‹•é æ¸¬å¼•æ“"""
        if self.is_running:
            return
        
        self.is_running = True
        
        # å•Ÿå‹•ç¶­è­·ä»»å‹™
        self.maintenance_task = asyncio.create_task(self._maintenance_loop())
        
        self.logger.info(f"ğŸš€ MLé æ¸¬å¼•æ“å·²å•Ÿå‹• - ID: {self.engine_id}")
    
    async def stop_engine(self):
        """åœæ­¢é æ¸¬å¼•æ“"""
        self.is_running = False
        
        if self.maintenance_task:
            self.maintenance_task.cancel()
            try:
                await self.maintenance_task
            except asyncio.CancelledError:
                pass
        
        self.logger.info("â¹ï¸ MLé æ¸¬å¼•æ“å·²åœæ­¢")
    
    def register_model(self, model: MLPredictionModel) -> bool:
        """è¨»å†Šæ¨¡å‹"""
        try:
            with self.lock:
                self.models[model.model_id] = model
                self.model_registry[model.model_type].append(model.model_id)
                self.stats['total_models'] += 1
                
                if model.is_trained:
                    self.stats['active_models'] += 1
            
            self.logger.info(f"âœ… æ¨¡å‹è¨»å†ŠæˆåŠŸ: {model.model_id} ({model.model_type.value})")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹è¨»å†Šå¤±æ•—: {e}")
            return False
    
    def unregister_model(self, model_id: str) -> bool:
        """è¨»éŠ·æ¨¡å‹"""
        try:
            with self.lock:
                if model_id in self.models:
                    model = self.models[model_id]
                    del self.models[model_id]
                    
                    # å¾è¨»å†Šè¡¨ä¸­ç§»é™¤
                    if model_id in self.model_registry[model.model_type]:
                        self.model_registry[model.model_type].remove(model_id)
                    
                    self.stats['total_models'] -= 1
                    if model.is_trained:
                        self.stats['active_models'] -= 1
                    
                    self.logger.info(f"âœ… æ¨¡å‹è¨»éŠ·æˆåŠŸ: {model_id}")
                    return True
                else:
                    self.logger.warning(f"âš ï¸ æ¨¡å‹æœªæ‰¾åˆ°: {model_id}")
                    return False
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹è¨»éŠ·å¤±æ•—: {e}")
            return False
    
    async def predict(self, model_id: str, features: Dict[str, Any], 
                     use_cache: bool = True) -> PredictionResult:
        """é€²è¡Œé æ¸¬"""
        try:
            # æª¢æŸ¥ç·©å­˜
            if use_cache and self.config['prediction_cache_enabled']:
                cache_key = f"{model_id}_{hash(str(sorted(features.items())))}"
                
                if cache_key in self.prediction_cache:
                    cached_result, cache_time = self.prediction_cache[cache_key]
                    cache_age = (datetime.now(timezone.utc) - cache_time).total_seconds()
                    
                    if cache_age < self.config['prediction_cache_ttl_seconds']:
                        self.stats['cache_hits'] += 1
                        return cached_result
                
                self.stats['cache_misses'] += 1
            
            # ç²å–æ¨¡å‹
            if model_id not in self.models:
                raise ValueError(f"æ¨¡å‹æœªæ‰¾åˆ°: {model_id}")
            
            model = self.models[model_id]
            
            # é€²è¡Œé æ¸¬
            result = await model.predict(features)
            
            # æ›´æ–°ç·©å­˜
            if use_cache and self.config['prediction_cache_enabled']:
                cache_key = f"{model_id}_{hash(str(sorted(features.items())))}"
                self.prediction_cache[cache_key] = (result, datetime.now(timezone.utc))
            
            # æ›´æ–°çµ±è¨ˆ
            self.stats['total_predictions'] += 1
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ é æ¸¬å¤±æ•—: {e}")
            raise
    
    async def predict_with_ensemble(self, model_type: ModelType, 
                                   prediction_target: PredictionTarget,
                                   features: Dict[str, Any]) -> PredictionResult:
        """ä½¿ç”¨é›†æˆæ–¹æ³•é€²è¡Œé æ¸¬"""
        try:
            # ç²å–ç›¸é—œæ¨¡å‹
            relevant_models = []
            for model_id in self.model_registry[model_type]:
                model = self.models.get(model_id)
                if model and model.is_trained and model.prediction_target == prediction_target:
                    relevant_models.append(model)
            
            if not relevant_models:
                raise ValueError(f"æ²’æœ‰å¯ç”¨çš„æ¨¡å‹é€²è¡Œé æ¸¬: {model_type.value}, {prediction_target.value}")
            
            if len(relevant_models) == 1:
                # åªæœ‰ä¸€å€‹æ¨¡å‹ï¼Œç›´æ¥é æ¸¬
                return await relevant_models[0].predict(features)
            
            # é›†æˆé æ¸¬
            predictions = []
            confidences = []
            
            for model in relevant_models:
                try:
                    result = await model.predict(features)
                    predictions.append(result.predicted_value)
                    confidences.append(result.confidence_score)
                except Exception as e:
                    self.logger.warning(f"âš ï¸ æ¨¡å‹ {model.model_id} é æ¸¬å¤±æ•—: {e}")
                    continue
            
            if not predictions:
                raise RuntimeError("æ‰€æœ‰æ¨¡å‹é æ¸¬éƒ½å¤±æ•—")
            
            # åŠ æ¬Šå¹³å‡é æ¸¬
            weights = np.array(confidences)
            weights = weights / weights.sum()  # æ­¸ä¸€åŒ–
            
            ensemble_prediction = np.average(predictions, weights=weights)
            ensemble_confidence = np.mean(confidences)
            
            # å‰µå»ºé›†æˆé æ¸¬çµæœ
            result = PredictionResult(
                prediction_id=f"ensemble_{uuid.uuid4().hex[:8]}",
                model_id=f"ensemble_{model_type.value}",
                input_features=features,
                predicted_value=float(ensemble_prediction),
                confidence_score=ensemble_confidence,
                prediction_timestamp=datetime.now(timezone.utc),
                model_version="ensemble_1.0",
                metadata={
                    'ensemble_size': len(predictions),
                    'individual_predictions': predictions,
                    'individual_confidences': confidences,
                    'model_ids': [m.model_id for m in relevant_models]
                }
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ é›†æˆé æ¸¬å¤±æ•—: {e}")
            raise
    
    async def train_model(self, model_id: str, training_data: TrainingData) -> ModelMetrics:
        """è¨“ç·´æŒ‡å®šæ¨¡å‹"""
        try:
            if model_id not in self.models:
                raise ValueError(f"æ¨¡å‹æœªæ‰¾åˆ°: {model_id}")
            
            model = self.models[model_id]
            
            # è¨“ç·´æ¨¡å‹
            metrics = await model.train(training_data)
            
            # æ›´æ–°çµ±è¨ˆ
            self.stats['model_training_sessions'] += 1
            
            # æ›´æ–°æ´»èºæ¨¡å‹è¨ˆæ•¸
            if model.is_trained:
                with self.lock:
                    self.stats['active_models'] = sum(
                        1 for m in self.models.values() if m.is_trained
                    )
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹è¨“ç·´å¤±æ•—: {e}")
            raise
    
    def get_best_model(self, model_type: ModelType, 
                      prediction_target: PredictionTarget) -> Optional[MLPredictionModel]:
        """ç²å–æœ€ä½³æ¨¡å‹"""
        try:
            candidates = []
            
            for model_id in self.model_registry[model_type]:
                model = self.models.get(model_id)
                if (model and model.is_trained and 
                    model.prediction_target == prediction_target):
                    candidates.append(model)
            
            if not candidates:
                return None
            
            # æ ¹æ“šæœ€æ–°æŒ‡æ¨™é¸æ“‡æœ€ä½³æ¨¡å‹
            best_model = max(candidates, key=lambda m: (
                m.metrics_history[-1].r2_score if m.metrics_history else 0.0
            ))
            
            return best_model
            
        except Exception as e:
            self.logger.error(f"âŒ ç²å–æœ€ä½³æ¨¡å‹å¤±æ•—: {e}")
            return None
    
    async def _maintenance_loop(self):
        """ç¶­è­·å¾ªç’°"""
        try:
            while self.is_running:
                await asyncio.sleep(3600)  # æ¯å°æ™‚æª¢æŸ¥ä¸€æ¬¡
                
                # æ¸…ç†éæœŸç·©å­˜
                await self._cleanup_cache()
                
                # æª¢æŸ¥æ¨¡å‹æ€§èƒ½
                await self._check_model_performance()
                
        except asyncio.CancelledError:
            self.logger.info("ğŸ”„ ç¶­è­·å¾ªç’°å·²å–æ¶ˆ")
        except Exception as e:
            self.logger.error(f"âŒ ç¶­è­·å¾ªç’°ç•°å¸¸: {e}")
    
    async def _cleanup_cache(self):
        """æ¸…ç†éæœŸç·©å­˜"""
        try:
            current_time = datetime.now(timezone.utc)
            expired_keys = []
            
            for cache_key, (result, cache_time) in self.prediction_cache.items():
                cache_age = (current_time - cache_time).total_seconds()
                if cache_age > self.config['prediction_cache_ttl_seconds']:
                    expired_keys.append(cache_key)
            
            for key in expired_keys:
                del self.prediction_cache[key]
            
            if expired_keys:
                self.logger.debug(f"ğŸ—‘ï¸ æ¸…ç†éæœŸç·©å­˜: {len(expired_keys)} å€‹")
                
        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç†ç·©å­˜å¤±æ•—: {e}")
    
    async def _check_model_performance(self):
        """æª¢æŸ¥æ¨¡å‹æ€§èƒ½"""
        try:
            for model in self.models.values():
                if model.is_trained and model.metrics_history:
                    latest_metrics = model.metrics_history[-1]
                    
                    # æª¢æŸ¥æ€§èƒ½æ˜¯å¦ä½æ–¼é–¾å€¼
                    if latest_metrics.r2_score < self.config['model_performance_threshold']:
                        self.logger.warning(
                            f"âš ï¸ æ¨¡å‹ {model.model_id} æ€§èƒ½è¼ƒä½: "
                            f"RÂ² = {latest_metrics.r2_score:.4f}"
                        )
                        
                        # å¯ä»¥åœ¨é€™è£¡è§¸ç™¼é‡æ–°è¨“ç·´æˆ–å…¶ä»–ç¶­è­·æ“ä½œ
                
        except Exception as e:
            self.logger.error(f"âŒ æª¢æŸ¥æ¨¡å‹æ€§èƒ½å¤±æ•—: {e}")
    
    def get_engine_status(self) -> Dict[str, Any]:
        """ç²å–å¼•æ“ç‹€æ…‹"""
        with self.lock:
            return {
                'engine_id': self.engine_id,
                'is_running': self.is_running,
                'total_models': self.stats['total_models'],
                'active_models': self.stats['active_models'],
                'total_predictions': self.stats['total_predictions'],
                'cache_hit_rate': (
                    self.stats['cache_hits'] / 
                    max(1, self.stats['cache_hits'] + self.stats['cache_misses'])
                ),
                'prediction_cache_size': len(self.prediction_cache),
                'registered_model_types': {
                    model_type.value: len(model_ids) 
                    for model_type, model_ids in self.model_registry.items()
                },
                'config': self.config,
                'stats': self.stats
            }


# === ä¾¿åˆ©å‡½æ•¸ ===

def create_ml_prediction_engine(engine_id: str = None) -> MLPredictionEngine:
    """å‰µå»ºMLé æ¸¬å¼•æ“"""
    engine = MLPredictionEngine(engine_id)
    logger.info(f"âœ… MLé æ¸¬å¼•æ“å‰µå»ºå®Œæˆ - ID: {engine.engine_id}")
    return engine


def create_orbit_prediction_model(model_id: str = None) -> MLPredictionModel:
    """å‰µå»ºè»Œé“é æ¸¬æ¨¡å‹"""
    model_id = model_id or f"orbit_pred_{uuid.uuid4().hex[:8]}"
    model = MLPredictionModel(
        model_id=model_id,
        model_type=ModelType.ORBIT_PREDICTION,
        prediction_target=PredictionTarget.ORBITAL_POSITION
    )
    
    if SKLEARN_AVAILABLE:
        model.initialize_model(n_estimators=150, max_depth=12)
    
    logger.info(f"âœ… è»Œé“é æ¸¬æ¨¡å‹å‰µå»ºå®Œæˆ - ID: {model_id}")
    return model


def create_handover_prediction_model(model_id: str = None) -> MLPredictionModel:
    """å‰µå»ºåˆ‡æ›é æ¸¬æ¨¡å‹"""
    model_id = model_id or f"handover_pred_{uuid.uuid4().hex[:8]}"
    model = MLPredictionModel(
        model_id=model_id,
        model_type=ModelType.HANDOVER_DECISION,
        prediction_target=PredictionTarget.HANDOVER_SUCCESS
    )
    
    if SKLEARN_AVAILABLE:
        model.initialize_model(n_estimators=100, learning_rate=0.1, max_depth=8)
    
    logger.info(f"âœ… åˆ‡æ›é æ¸¬æ¨¡å‹å‰µå»ºå®Œæˆ - ID: {model_id}")
    return model


def create_qos_prediction_model(model_id: str = None, 
                               target: PredictionTarget = PredictionTarget.THROUGHPUT) -> MLPredictionModel:
    """å‰µå»ºQoSé æ¸¬æ¨¡å‹"""
    model_id = model_id or f"qos_pred_{uuid.uuid4().hex[:8]}"
    model = MLPredictionModel(
        model_id=model_id,
        model_type=ModelType.QOS_PREDICTION,
        prediction_target=target
    )
    
    if SKLEARN_AVAILABLE:
        model.initialize_model(n_estimators=120, max_depth=10)
    
    logger.info(f"âœ… QoSé æ¸¬æ¨¡å‹å‰µå»ºå®Œæˆ - ID: {model_id} (ç›®æ¨™: {target.value})")
    return model


def create_sample_training_data(data_type: str = "orbit") -> TrainingData:
    """å‰µå»ºç¤ºä¾‹è¨“ç·´æ•¸æ“š"""
    np.random.seed(42)  # ç¢ºä¿å¯é‡ç¾æ€§
    
    if data_type == "orbit":
        # è»Œé“é æ¸¬è¨“ç·´æ•¸æ“š
        n_samples = 1000
        
        # ç‰¹å¾µï¼šæ™‚é–“ã€åˆå§‹ä½ç½®ã€é€Ÿåº¦ç­‰
        features = np.random.rand(n_samples, 6)  # 6å€‹ç‰¹å¾µ
        features[:, 0] = features[:, 0] * 6000  # æ™‚é–“ï¼ˆç§’ï¼‰
        features[:, 1:3] = (features[:, 1:3] - 0.5) * 180  # ç·¯åº¦ã€ç¶“åº¦
        features[:, 3] = features[:, 3] * 1000 + 500  # é«˜åº¦ï¼ˆ500-1500kmï¼‰
        features[:, 4:6] = features[:, 4:6] * 8  # é€Ÿåº¦åˆ†é‡
        
        # ç›®æ¨™ï¼šæœªä¾†ä½ç½®ï¼ˆç°¡åŒ–çš„è»Œé“æ¨¡å‹ï¼‰
        targets = features[:, 1] + 0.1 * features[:, 0] + np.random.normal(0, 0.1, n_samples)
        
        return TrainingData(
            feature_data=features,
            target_data=targets,
            feature_names=['time', 'lat', 'lon', 'alt', 'vel_x', 'vel_y'],
            target_name='future_lat',
            timestamp=datetime.now(timezone.utc),
            data_source='simulation'
        )
    
    elif data_type == "qos":
        # QoSé æ¸¬è¨“ç·´æ•¸æ“š
        n_samples = 800
        
        # ç‰¹å¾µï¼šä¿¡è™Ÿå¼·åº¦ã€è·é›¢ã€è² è¼‰ç­‰
        features = np.random.rand(n_samples, 8)
        features[:, 0] = -120 + features[:, 0] * 40  # ä¿¡è™Ÿå¼·åº¦ (-120 to -80 dBm)
        features[:, 1] = features[:, 1] * 50 + 10    # ä»°è§’ (10-60åº¦)
        features[:, 2] = features[:, 2] * 1000 + 500 # è·é›¢ (500-1500km)
        features[:, 3] = features[:, 3] * 0.8        # è² è¼‰ (0-0.8)
        features[:, 4] = features[:, 4] * 200        # ç”¨æˆ¶æ•¸ (0-200)
        features[:, 5] = features[:, 5] * 1000       # å¯ç”¨å¸¶å¯¬ (0-1000Mbps)
        features[:, 6] = features[:, 6] * 100        # ç•¶å‰ååé‡ (0-100Mbps)
        features[:, 7] = features[:, 7] * 500 + 50   # ç•¶å‰å»¶é² (50-550ms)
        
        # ç›®æ¨™ï¼šé æ¸¬ååé‡ï¼ˆåŸºæ–¼ç‰¹å¾µçš„è¤‡é›œé—œä¿‚ï¼‰
        targets = (
            50 + (features[:, 0] + 120) * 2 +  # ä¿¡è™Ÿå¼·åº¦å½±éŸ¿
            features[:, 1] * 0.5 +              # ä»°è§’å½±éŸ¿
            (1 - features[:, 3]) * 30 +         # è² è¼‰å½±éŸ¿ï¼ˆåå‘ï¼‰
            features[:, 5] * 0.1 +              # å¯ç”¨å¸¶å¯¬å½±éŸ¿
            np.random.normal(0, 5, n_samples)   # å™ªè²
        )
        targets = np.clip(targets, 0, 100)      # é™åˆ¶åœ¨åˆç†ç¯„åœ
        
        return TrainingData(
            feature_data=features,
            target_data=targets,
            feature_names=['signal_strength', 'elevation', 'distance', 'load', 
                         'users', 'available_bw', 'current_throughput', 'current_latency'],
            target_name='predicted_throughput',
            timestamp=datetime.now(timezone.utc),
            data_source='simulation'
        )
    
    else:
        raise ValueError(f"æœªçŸ¥çš„æ•¸æ“šé¡å‹: {data_type}")