#!/usr/bin/env python3
"""
Phase 4 åˆ†ä½ˆå¼è¨“ç·´ç³»çµ±ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨åˆ†ä½ˆå¼è¨“ç·´ç³»çµ±é€²è¡Œå¼·åŒ–å­¸ç¿’è¨“ç·´ï¼š
- å‰µå»ºè¨“ç·´é…ç½®
- å•Ÿå‹•åˆ†ä½ˆå¼è¨“ç·´
- ç›£æ§è¨“ç·´é€²åº¦
- ç®¡ç†è¨“ç·´æœƒè©±

Usage:
    python phase4_example.py
"""

import asyncio
import logging
import json
import time
from datetime import datetime
from typing import Dict, List, Optional, Any

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å°å…¥åˆ†ä½ˆå¼è¨“ç·´çµ„ä»¶
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from netstack_api.services.rl_training.distributed import (
    TrainingConfiguration,
    TrainingMode,
    TrainingPhase,
    TrainingMetrics
)


class Phase4Example:
    """Phase 4 åˆ†ä½ˆå¼è¨“ç·´ç³»çµ±ä½¿ç”¨ç¤ºä¾‹"""
    
    def __init__(self):
        self.examples = {}
        
    async def run_examples(self):
        """é‹è¡Œç¤ºä¾‹"""
        logger.info("ğŸš€ é–‹å§‹ Phase 4 åˆ†ä½ˆå¼è¨“ç·´ç³»çµ±ä½¿ç”¨ç¤ºä¾‹...")
        
        try:
            # ç¤ºä¾‹ 1: å–®ç¯€é» DQN è¨“ç·´
            await self.example_single_node_dqn()
            
            # ç¤ºä¾‹ 2: å¤šç¯€é» PPO è¨“ç·´
            await self.example_multi_node_ppo()
            
            # ç¤ºä¾‹ 3: è¯é‚¦å­¸ç¿’ SAC è¨“ç·´
            await self.example_federated_sac()
            
            # ç¤ºä¾‹ 4: åˆ†å±¤è¨“ç·´
            await self.example_hierarchical_training()
            
            # ç¤ºä¾‹ 5: è¨“ç·´æŒ‡æ¨™åˆ†æ
            await self.example_metrics_analysis()
            
            # ç”Ÿæˆç¤ºä¾‹å ±å‘Š
            self.generate_example_report()
            
        except Exception as e:
            logger.error(f"âŒ ç¤ºä¾‹é‹è¡Œå¤±æ•—: {e}")
            raise
    
    async def example_single_node_dqn(self):
        """ç¤ºä¾‹ 1: å–®ç¯€é» DQN è¨“ç·´"""
        logger.info("ğŸ¯ ç¤ºä¾‹ 1: å–®ç¯€é» DQN è¨“ç·´")
        
        try:
            # å‰µå»º DQN è¨“ç·´é…ç½®
            config = TrainingConfiguration(
                algorithm="DQN",
                environment="CartPole-v1",
                hyperparameters={
                    "learning_rate": 0.001,
                    "batch_size": 32,
                    "buffer_size": 10000,
                    "epsilon": 0.1,
                    "epsilon_decay": 0.995,
                    "epsilon_min": 0.01,
                    "gamma": 0.99,
                    "target_update_frequency": 100
                },
                training_mode=TrainingMode.SINGLE_NODE,
                max_nodes=1,
                min_nodes=1,
                resource_requirements={
                    "cpu": 2,
                    "memory": 4,
                    "gpu": 0
                },
                training_steps=10000,
                evaluation_frequency=1000,
                checkpoint_frequency=5000,
                timeout=3600,
                enable_fault_recovery=True
            )
            
            # é¡¯ç¤ºé…ç½®
            print(f"ğŸ“‹ DQN è¨“ç·´é…ç½®:")
            print(f"   ç®—æ³•: {config.algorithm}")
            print(f"   ç’°å¢ƒ: {config.environment}")
            print(f"   è¨“ç·´æ¨¡å¼: {config.training_mode.value}")
            print(f"   è¨“ç·´æ­¥æ•¸: {config.training_steps:,}")
            print(f"   å­¸ç¿’ç‡: {config.hyperparameters['learning_rate']}")
            print(f"   æ‰¹æ¬¡å¤§å°: {config.hyperparameters['batch_size']}")
            
            # æ¨¡æ“¬è¨“ç·´æœƒè©±å‰µå»º
            session_id = f"dqn_session_{int(time.time())}"
            print(f"ğŸ¯ æ¨¡æ“¬å‰µå»ºè¨“ç·´æœƒè©±: {session_id}")
            
            self.examples["single_node_dqn"] = {
                "config": config.to_dict(),
                "session_id": session_id,
                "description": "å–®ç¯€é» DQN è¨“ç·´ç¤ºä¾‹",
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info("âœ… å–®ç¯€é» DQN è¨“ç·´ç¤ºä¾‹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å–®ç¯€é» DQN è¨“ç·´ç¤ºä¾‹å¤±æ•—: {e}")
            raise
    
    async def example_multi_node_ppo(self):
        """ç¤ºä¾‹ 2: å¤šç¯€é» PPO è¨“ç·´"""
        logger.info("ğŸŒ ç¤ºä¾‹ 2: å¤šç¯€é» PPO è¨“ç·´")
        
        try:
            # å‰µå»º PPO å¤šç¯€é»è¨“ç·´é…ç½®
            config = TrainingConfiguration(
                algorithm="PPO",
                environment="LunarLander-v2",
                hyperparameters={
                    "learning_rate": 0.0003,
                    "batch_size": 64,
                    "buffer_size": 2048,
                    "epsilon": 0.2,
                    "value_loss_coef": 0.5,
                    "entropy_coef": 0.01,
                    "gamma": 0.99,
                    "gae_lambda": 0.95,
                    "ppo_epochs": 10
                },
                training_mode=TrainingMode.MULTI_NODE,
                max_nodes=4,
                min_nodes=2,
                resource_requirements={
                    "cpu": 4,
                    "memory": 8,
                    "gpu": 1
                },
                training_steps=50000,
                evaluation_frequency=5000,
                checkpoint_frequency=10000,
                timeout=7200,
                enable_fault_recovery=True
            )
            
            # é¡¯ç¤ºé…ç½®
            print(f"ğŸ“‹ PPO å¤šç¯€é»è¨“ç·´é…ç½®:")
            print(f"   ç®—æ³•: {config.algorithm}")
            print(f"   ç’°å¢ƒ: {config.environment}")
            print(f"   è¨“ç·´æ¨¡å¼: {config.training_mode.value}")
            print(f"   ç¯€é»ç¯„åœ: {config.min_nodes} - {config.max_nodes}")
            print(f"   è¨“ç·´æ­¥æ•¸: {config.training_steps:,}")
            print(f"   PPO è¼ªæ•¸: {config.hyperparameters['ppo_epochs']}")
            
            # æ¨¡æ“¬å¤šç¯€é»ä»»å‹™åˆ†é…
            session_id = f"ppo_session_{int(time.time())}"
            print(f"ğŸ¯ æ¨¡æ“¬å¤šç¯€é»ä»»å‹™åˆ†é…: {session_id}")
            
            # æ¨¡æ“¬ç¯€é»åˆ†é…
            nodes = [f"node_{i}" for i in range(config.max_nodes)]
            print(f"ğŸ“¡ æ¨¡æ“¬ç¯€é»åˆ†é…: {nodes}")
            
            self.examples["multi_node_ppo"] = {
                "config": config.to_dict(),
                "session_id": session_id,
                "nodes": nodes,
                "description": "å¤šç¯€é» PPO è¨“ç·´ç¤ºä¾‹",
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info("âœ… å¤šç¯€é» PPO è¨“ç·´ç¤ºä¾‹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å¤šç¯€é» PPO è¨“ç·´ç¤ºä¾‹å¤±æ•—: {e}")
            raise
    
    async def example_federated_sac(self):
        """ç¤ºä¾‹ 3: è¯é‚¦å­¸ç¿’ SAC è¨“ç·´"""
        logger.info("ğŸ¤ ç¤ºä¾‹ 3: è¯é‚¦å­¸ç¿’ SAC è¨“ç·´")
        
        try:
            # å‰µå»º SAC è¯é‚¦å­¸ç¿’é…ç½®
            config = TrainingConfiguration(
                algorithm="SAC",
                environment="Pendulum-v1",
                hyperparameters={
                    "learning_rate": 0.0003,
                    "batch_size": 256,
                    "buffer_size": 100000,
                    "tau": 0.005,
                    "alpha": 0.2,
                    "gamma": 0.99,
                    "target_update_interval": 1,
                    "gradient_steps": 1
                },
                training_mode=TrainingMode.FEDERATED,
                max_nodes=8,
                min_nodes=4,
                resource_requirements={
                    "cpu": 8,
                    "memory": 16,
                    "gpu": 2
                },
                training_steps=100000,
                evaluation_frequency=10000,
                checkpoint_frequency=20000,
                timeout=14400,
                enable_fault_recovery=True
            )
            
            # é¡¯ç¤ºé…ç½®
            print(f"ğŸ“‹ SAC è¯é‚¦å­¸ç¿’é…ç½®:")
            print(f"   ç®—æ³•: {config.algorithm}")
            print(f"   ç’°å¢ƒ: {config.environment}")
            print(f"   è¨“ç·´æ¨¡å¼: {config.training_mode.value}")
            print(f"   è¯é‚¦ç¯€é»: {config.max_nodes}")
            print(f"   è¨“ç·´æ­¥æ•¸: {config.training_steps:,}")
            print(f"   æº«åº¦åƒæ•¸: {config.hyperparameters['alpha']}")
            
            # æ¨¡æ“¬è¯é‚¦å­¸ç¿’æ¶æ§‹
            session_id = f"sac_federated_{int(time.time())}"
            print(f"ğŸ¯ æ¨¡æ“¬è¯é‚¦å­¸ç¿’æ¶æ§‹: {session_id}")
            
            # æ¨¡æ“¬åƒæ•¸æœå‹™å™¨å’Œå®¢æˆ¶ç«¯
            server_node = "parameter_server"
            client_nodes = [f"client_{i}" for i in range(config.max_nodes - 1)]
            
            print(f"ğŸ–¥ï¸  åƒæ•¸æœå‹™å™¨: {server_node}")
            print(f"ğŸ“± å®¢æˆ¶ç«¯ç¯€é»: {client_nodes}")
            
            self.examples["federated_sac"] = {
                "config": config.to_dict(),
                "session_id": session_id,
                "server_node": server_node,
                "client_nodes": client_nodes,
                "description": "è¯é‚¦å­¸ç¿’ SAC è¨“ç·´ç¤ºä¾‹",
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info("âœ… è¯é‚¦å­¸ç¿’ SAC è¨“ç·´ç¤ºä¾‹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ è¯é‚¦å­¸ç¿’ SAC è¨“ç·´ç¤ºä¾‹å¤±æ•—: {e}")
            raise
    
    async def example_hierarchical_training(self):
        """ç¤ºä¾‹ 4: åˆ†å±¤è¨“ç·´"""
        logger.info("ğŸ—ï¸ ç¤ºä¾‹ 4: åˆ†å±¤è¨“ç·´")
        
        try:
            # å‰µå»ºåˆ†å±¤è¨“ç·´é…ç½®
            config = TrainingConfiguration(
                algorithm="PPO",
                environment="MountainCar-v0",
                hyperparameters={
                    "learning_rate": 0.0003,
                    "batch_size": 128,
                    "buffer_size": 4096,
                    "epsilon": 0.2,
                    "gamma": 0.99,
                    "gae_lambda": 0.95,
                    "ppo_epochs": 8,
                    "clip_vloss": True
                },
                training_mode=TrainingMode.HIERARCHICAL,
                max_nodes=6,
                min_nodes=3,
                resource_requirements={
                    "cpu": 6,
                    "memory": 12,
                    "gpu": 1
                },
                training_steps=75000,
                evaluation_frequency=7500,
                checkpoint_frequency=15000,
                timeout=10800,
                enable_fault_recovery=True
            )
            
            # é¡¯ç¤ºé…ç½®
            print(f"ğŸ“‹ åˆ†å±¤è¨“ç·´é…ç½®:")
            print(f"   ç®—æ³•: {config.algorithm}")
            print(f"   ç’°å¢ƒ: {config.environment}")
            print(f"   è¨“ç·´æ¨¡å¼: {config.training_mode.value}")
            print(f"   å±¤æ¬¡ç¯€é»: {config.max_nodes}")
            print(f"   è¨“ç·´æ­¥æ•¸: {config.training_steps:,}")
            
            # æ¨¡æ“¬åˆ†å±¤æ¶æ§‹
            session_id = f"hierarchical_{int(time.time())}"
            print(f"ğŸ¯ æ¨¡æ“¬åˆ†å±¤æ¶æ§‹: {session_id}")
            
            # æ¨¡æ“¬ä¸»ç¯€é»å’Œå·¥ä½œç¯€é»
            master_node = "master_node"
            worker_nodes = [f"worker_{i}" for i in range(config.max_nodes - 1)]
            
            print(f"ğŸ‘‘ ä¸»ç¯€é»: {master_node}")
            print(f"ğŸ‘· å·¥ä½œç¯€é»: {worker_nodes}")
            
            self.examples["hierarchical_training"] = {
                "config": config.to_dict(),
                "session_id": session_id,
                "master_node": master_node,
                "worker_nodes": worker_nodes,
                "description": "åˆ†å±¤è¨“ç·´ç¤ºä¾‹",
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info("âœ… åˆ†å±¤è¨“ç·´ç¤ºä¾‹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ åˆ†å±¤è¨“ç·´ç¤ºä¾‹å¤±æ•—: {e}")
            raise
    
    async def example_metrics_analysis(self):
        """ç¤ºä¾‹ 5: è¨“ç·´æŒ‡æ¨™åˆ†æ"""
        logger.info("ğŸ“Š ç¤ºä¾‹ 5: è¨“ç·´æŒ‡æ¨™åˆ†æ")
        
        try:
            # æ¨¡æ“¬è¨“ç·´æŒ‡æ¨™
            session_id = "metrics_analysis_session"
            node_id = "analysis_node"
            
            # å‰µå»ºä¸€ç³»åˆ—è¨“ç·´æŒ‡æ¨™
            metrics_series = []
            for step in range(0, 1000, 100):
                # æ¨¡æ“¬è¨“ç·´é€²åº¦
                reward = 10 + step * 0.01 + (step % 300) * 0.05
                loss = 1.0 - step * 0.0008
                epsilon = max(0.01, 0.9 - step * 0.0009)
                
                metrics = TrainingMetrics(
                    session_id=session_id,
                    timestamp=datetime.now(),
                    node_id=node_id,
                    step=step,
                    episode_reward=reward,
                    episode_length=200 + step // 10,
                    loss=loss,
                    learning_rate=0.001,
                    epsilon=epsilon,
                    q_values=[reward * 0.8, reward * 0.9, reward * 1.0],
                    actor_loss=loss * 0.6,
                    critic_loss=loss * 0.4,
                    entropy=0.1 + step * 0.0001
                )
                
                metrics_series.append(metrics)
            
            # åˆ†ææŒ‡æ¨™
            print(f"ğŸ“Š è¨“ç·´æŒ‡æ¨™åˆ†æ:")
            print(f"   æœƒè©±ID: {session_id}")
            print(f"   ç¯€é»ID: {node_id}")
            print(f"   æŒ‡æ¨™æ•¸é‡: {len(metrics_series)}")
            print(f"   æ­¥é©Ÿç¯„åœ: {metrics_series[0].step} - {metrics_series[-1].step}")
            print(f"   åˆå§‹å›å ±: {metrics_series[0].episode_reward:.2f}")
            print(f"   æœ€çµ‚å›å ±: {metrics_series[-1].episode_reward:.2f}")
            print(f"   å›å ±æ”¹å–„: {metrics_series[-1].episode_reward - metrics_series[0].episode_reward:.2f}")
            
            # è¨ˆç®—çµ±è¨ˆä¿¡æ¯
            rewards = [m.episode_reward for m in metrics_series]
            losses = [m.loss for m in metrics_series]
            
            stats = {
                "avg_reward": sum(rewards) / len(rewards),
                "max_reward": max(rewards),
                "min_reward": min(rewards),
                "avg_loss": sum(losses) / len(losses),
                "max_loss": max(losses),
                "min_loss": min(losses),
                "improvement_rate": (rewards[-1] - rewards[0]) / len(rewards)
            }
            
            print(f"ğŸ“ˆ çµ±è¨ˆä¿¡æ¯:")
            print(f"   å¹³å‡å›å ±: {stats['avg_reward']:.2f}")
            print(f"   æœ€å¤§å›å ±: {stats['max_reward']:.2f}")
            print(f"   å¹³å‡æå¤±: {stats['avg_loss']:.4f}")
            print(f"   æ”¹å–„ç‡: {stats['improvement_rate']:.4f}")
            
            self.examples["metrics_analysis"] = {
                "session_id": session_id,
                "node_id": node_id,
                "metrics_count": len(metrics_series),
                "statistics": stats,
                "sample_metrics": [m.to_dict() for m in metrics_series[:3]],
                "description": "è¨“ç·´æŒ‡æ¨™åˆ†æç¤ºä¾‹",
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info("âœ… è¨“ç·´æŒ‡æ¨™åˆ†æç¤ºä¾‹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ è¨“ç·´æŒ‡æ¨™åˆ†æç¤ºä¾‹å¤±æ•—: {e}")
            raise
    
    def generate_example_report(self):
        """ç”Ÿæˆç¤ºä¾‹å ±å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆç¤ºä¾‹å ±å‘Š...")
        
        # ç”Ÿæˆå ±å‘Š
        report = {
            "example_summary": {
                "total_examples": len(self.examples),
                "example_date": datetime.now().isoformat(),
                "version": "Phase 4 v1.0.0"
            },
            "examples": self.examples,
            "system_info": {
                "python_version": "3.10+",
                "environment": "Phase 4 Development",
                "components_used": [
                    "TrainingConfiguration",
                    "TrainingMode",
                    "TrainingMetrics",
                    "DistributedTrainingManager"
                ]
            }
        }
        
        # ä¿å­˜å ±å‘Š
        report_file = f"/tmp/phase4_examples_report_{int(time.time())}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # é¡¯ç¤ºæ‘˜è¦
        print("\n" + "="*60)
        print("ğŸ¯ Phase 4 åˆ†ä½ˆå¼è¨“ç·´ç³»çµ±ä½¿ç”¨ç¤ºä¾‹å ±å‘Š")
        print("="*60)
        print(f"ç¤ºä¾‹ç¸½æ•¸: {len(self.examples)}")
        print(f"å ±å‘Šæ–‡ä»¶: {report_file}")
        print("="*60)
        
        # è©³ç´°ç¤ºä¾‹
        for example_name, example_data in self.examples.items():
            print(f"ğŸ“‹ {example_name}: {example_data['description']}")
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹å®Œæˆï¼Phase 4 åˆ†ä½ˆå¼è¨“ç·´ç³»çµ±ä½¿ç”¨ç¤ºä¾‹å±•ç¤ºå®Œæˆã€‚")
        print("ğŸ“– æŸ¥çœ‹å ±å‘Šæ–‡ä»¶ç²å–å®Œæ•´é…ç½®å’Œä½¿ç”¨è©³æƒ…ã€‚")
        
        logger.info(f"ğŸ“Š ç¤ºä¾‹å ±å‘Šå·²ä¿å­˜è‡³: {report_file}")


async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ Phase 4 åˆ†ä½ˆå¼è¨“ç·´ç³»çµ±ä½¿ç”¨ç¤ºä¾‹")
    print("="*60)
    
    # å‰µå»ºç¤ºä¾‹
    example = Phase4Example()
    
    try:
        # é‹è¡Œç¤ºä¾‹
        await example.run_examples()
        
    except Exception as e:
        logger.error(f"âŒ ç¤ºä¾‹é‹è¡Œå¤±æ•—: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    # é‹è¡Œç¤ºä¾‹
    exit_code = asyncio.run(main())
    exit(exit_code)
