#!/usr/bin/env python3
"""
NTN Stack å¯è§€æ¸¬æ€§çµ±ä¸€æ ¼å¼éƒ¨ç½²å·¥å…·

è‡ªå‹•åŒ–éƒ¨ç½²ç›£æ§æŒ‡æ¨™çµ±ä¸€æ ¼å¼ç³»çµ±ï¼ŒåŒ…å«é©—è­‰ã€é…ç½®å’Œå„€è¡¨æ¿è¨­ç½®
"""

import os
import sys
import yaml
import json
import argparse
import logging
import subprocess
import requests
from typing import Dict, List, Optional, Any
from pathlib import Path
import time

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class ObservabilityDeployer:
    """å¯è§€æ¸¬æ€§éƒ¨ç½²å™¨"""

    def __init__(self, config_path: str = "monitoring"):
        self.config_path = Path(config_path)
        self.prometheus_url = "http://localhost:9090"
        self.grafana_url = "http://localhost:3000"
        self.grafana_credentials = ("admin", "admin")

        logger.info(f"å¯è§€æ¸¬æ€§éƒ¨ç½²å™¨å·²åˆå§‹åŒ–ï¼Œé…ç½®è·¯å¾‘: {self.config_path}")

    def deploy_full_stack(self):
        """éƒ¨ç½²å®Œæ•´çš„å¯è§€æ¸¬æ€§ç³»çµ±"""
        logger.info("é–‹å§‹éƒ¨ç½²å®Œæ•´çš„å¯è§€æ¸¬æ€§ç³»çµ±")

        steps = [
            ("é©—è­‰é…ç½®æ–‡ä»¶", self.validate_configurations),
            ("éƒ¨ç½² Prometheus é…ç½®", self.deploy_prometheus_config),
            ("å•Ÿå‹•æŒ‡æ¨™é©—è­‰å™¨", self.run_metrics_validation),
            ("éƒ¨ç½² Grafana å„€è¡¨æ¿", self.deploy_grafana_dashboards),
            ("å•Ÿå‹•æŒ‡æ¨™æ¨¡æ“¬å™¨", self.start_metrics_simulator),
            ("åŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥", self.run_health_checks),
            ("ç”Ÿæˆéƒ¨ç½²å ±å‘Š", self.generate_deployment_report),
        ]

        results = {}
        for step_name, step_func in steps:
            logger.info(f"åŸ·è¡Œæ­¥é©Ÿ: {step_name}")
            try:
                result = step_func()
                results[step_name] = {"status": "success", "result": result}
                logger.info(f"âœ… {step_name} å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ {step_name} å¤±æ•—: {e}")
                results[step_name] = {"status": "failed", "error": str(e)}
                # æ±ºå®šæ˜¯å¦ç¹¼çºŒåŸ·è¡Œå¾ŒçºŒæ­¥é©Ÿ
                if step_name in ["é©—è­‰é…ç½®æ–‡ä»¶", "éƒ¨ç½² Prometheus é…ç½®"]:
                    logger.error("é—œéµæ­¥é©Ÿå¤±æ•—ï¼Œåœæ­¢éƒ¨ç½²")
                    break

        return results

    def validate_configurations(self):
        """é©—è­‰é…ç½®æ–‡ä»¶"""
        logger.info("é©—è­‰æŒ‡æ¨™å‘½åç©ºé–“å’Œæ¨™ç±¤è¦ç¯„")

        required_files = [
            "standards/metrics_namespace_spec.yaml",
            "standards/standard_labels_spec.yaml",
            "configs/prometheus_best_practices.yaml",
        ]

        missing_files = []
        for file_path in required_files:
            full_path = self.config_path / file_path
            if not full_path.exists():
                missing_files.append(str(full_path))

        if missing_files:
            raise FileNotFoundError(f"ç¼ºå°‘å¿…è¦çš„é…ç½®æ–‡ä»¶: {missing_files}")

        # é©—è­‰ YAML æ–‡ä»¶æ ¼å¼
        for file_path in required_files:
            full_path = self.config_path / file_path
            try:
                with open(full_path, "r", encoding="utf-8") as f:
                    yaml.safe_load(f)
                logger.debug(f"âœ… {file_path} æ ¼å¼æ­£ç¢º")
            except yaml.YAMLError as e:
                raise ValueError(f"YAML æ ¼å¼éŒ¯èª¤ {file_path}: {e}")

        return {"validated_files": len(required_files)}

    def deploy_prometheus_config(self):
        """éƒ¨ç½² Prometheus é…ç½®"""
        logger.info("ç”Ÿæˆ Prometheus é…ç½®æ–‡ä»¶")

        # è¼‰å…¥æœ€ä½³å¯¦è¸é…ç½®
        best_practices_file = (
            self.config_path / "configs/prometheus_best_practices.yaml"
        )
        with open(best_practices_file, "r", encoding="utf-8") as f:
            config_content = f.read()
        
        # æ›¿æ›ç’°å¢ƒè®Šæ•¸
        external_ip = os.getenv("EXTERNAL_IP", "127.0.0.1")
        config_content = config_content.replace("${EXTERNAL_IP}", external_ip)
        
        best_practices = yaml.safe_load(config_content)

        # ç”Ÿæˆå¯¦éš›çš„ prometheus.yml
        prometheus_config = {
            "global": best_practices["global"],
            "scrape_configs": best_practices["scrape_configs"],
            "rule_files": best_practices["rule_files"],
        }

        # å¯«å…¥é…ç½®æ–‡ä»¶
        output_file = self.config_path / "prometheus.yml"
        with open(output_file, "w", encoding="utf-8") as f:
            yaml.dump(
                prometheus_config, f, default_flow_style=False, allow_unicode=True
            )

        logger.info(f"Prometheus é…ç½®å·²ç”Ÿæˆ: {output_file}")

        # ç”Ÿæˆå‘Šè­¦è¦å‰‡æ–‡ä»¶
        self._generate_alert_rules(best_practices)

        return {"config_file": str(output_file)}

    def _generate_alert_rules(self, best_practices: Dict):
        """ç”Ÿæˆå‘Šè­¦è¦å‰‡æ–‡ä»¶"""
        alert_rules_dir = self.config_path / "alert_rules"
        alert_rules_dir.mkdir(exist_ok=True)

        if "alert_rules" in best_practices:
            for rule_group in best_practices["alert_rules"]:
                filename = f"{rule_group['name'].replace('.', '_')}.yml"
                rule_file = alert_rules_dir / filename

                rule_content = {"groups": [rule_group]}

                with open(rule_file, "w", encoding="utf-8") as f:
                    yaml.dump(
                        rule_content, f, default_flow_style=False, allow_unicode=True
                    )

                logger.debug(f"ç”Ÿæˆå‘Šè­¦è¦å‰‡æ–‡ä»¶: {rule_file}")

    def run_metrics_validation(self):
        """åŸ·è¡ŒæŒ‡æ¨™é©—è­‰"""
        logger.info("é‹è¡ŒæŒ‡æ¨™é©—è­‰å·¥å…·")

        validator_script = self.config_path / "tools/metrics_validator.py"
        if not validator_script.exists():
            raise FileNotFoundError(f"æŒ‡æ¨™é©—è­‰å™¨ä¸å­˜åœ¨: {validator_script}")

        # é‹è¡Œé©—è­‰å™¨
        cmd = [
            sys.executable,
            str(validator_script),
            "--config-dir",
            str(self.config_path / "standards"),
            "--prometheus-url",
            self.prometheus_url,
            "--output",
            str(self.config_path / "validation_report.txt"),
        ]

        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            if result.returncode == 0:
                logger.info("æŒ‡æ¨™é©—è­‰é€šé")
                return {"status": "passed", "output": result.stdout}
            else:
                logger.warning(f"æŒ‡æ¨™é©—è­‰ç™¼ç¾å•é¡Œ: {result.stderr}")
                return {
                    "status": "warnings",
                    "output": result.stdout,
                    "errors": result.stderr,
                }
        except subprocess.TimeoutExpired:
            raise TimeoutError("æŒ‡æ¨™é©—è­‰è¶…æ™‚")
        except Exception as e:
            raise RuntimeError(f"æŒ‡æ¨™é©—è­‰åŸ·è¡Œå¤±æ•—: {e}")

    def deploy_grafana_dashboards(self):
        """éƒ¨ç½² Grafana å„€è¡¨æ¿"""
        logger.info("éƒ¨ç½² Grafana å„€è¡¨æ¿")

        dashboard_file = self.config_path / "templates/grafana_dashboard_template.json"
        if not dashboard_file.exists():
            raise FileNotFoundError(f"å„€è¡¨æ¿æ¨¡æ¿ä¸å­˜åœ¨: {dashboard_file}")

        # è¼‰å…¥å„€è¡¨æ¿æ¨¡æ¿
        with open(dashboard_file, "r", encoding="utf-8") as f:
            dashboard_data = json.load(f)

        # å˜—è©¦éƒ¨ç½²åˆ° Grafana
        try:
            response = self._deploy_to_grafana(dashboard_data)
            return {"status": "deployed", "dashboard_id": response.get("id")}
        except Exception as e:
            logger.warning(f"ç„¡æ³•é€£æ¥åˆ° Grafanaï¼Œå„€è¡¨æ¿å·²æº–å‚™: {e}")
            return {"status": "prepared", "template_file": str(dashboard_file)}

    def _deploy_to_grafana(self, dashboard_data: Dict) -> Dict:
        """éƒ¨ç½²å„€è¡¨æ¿åˆ° Grafana"""
        url = f"{self.grafana_url}/api/dashboards/db"

        payload = {"dashboard": dashboard_data["dashboard"], "overwrite": True}

        response = requests.post(
            url, json=payload, auth=self.grafana_credentials, timeout=30
        )
        response.raise_for_status()

        result = response.json()
        logger.info(f"å„€è¡¨æ¿å·²éƒ¨ç½²åˆ° Grafana: {result.get('url')}")
        return result

    def start_metrics_simulator(self):
        """å•Ÿå‹•æŒ‡æ¨™æ¨¡æ“¬å™¨"""
        logger.info("å•Ÿå‹•æŒ‡æ¨™æ¨¡æ“¬å™¨ç”¨æ–¼æ¸¬è©¦")

        simulator_script = self.config_path / "tools/metrics_simulator.py"
        if not simulator_script.exists():
            raise FileNotFoundError(f"æŒ‡æ¨™æ¨¡æ“¬å™¨ä¸å­˜åœ¨: {simulator_script}")

        # æª¢æŸ¥æ˜¯å¦å·²æœ‰æ¨¡æ“¬å™¨åœ¨é‹è¡Œ
        try:
            response = requests.get("http://localhost:8000/metrics", timeout=5)
            if response.status_code == 200:
                logger.info("æŒ‡æ¨™æ¨¡æ“¬å™¨å·²åœ¨é‹è¡Œ")
                return {"status": "already_running", "port": 8000}
        except requests.RequestException:
            pass

        # å•Ÿå‹•æ¨¡æ“¬å™¨ (èƒŒæ™¯åŸ·è¡Œ)
        cmd = [
            sys.executable,
            str(simulator_script),
            "--num-uavs",
            "3",
            "--duration",
            "86400",  # 24å°æ™‚
            "--port",
            "8000",
            "--enable-anomalies",
        ]

        try:
            process = subprocess.Popen(
                cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
            )

            # ç­‰å¾…æ¨¡æ“¬å™¨å•Ÿå‹•
            time.sleep(3)

            # é©—è­‰æ¨¡æ“¬å™¨æ˜¯å¦æ­£å¸¸é‹è¡Œ
            response = requests.get("http://localhost:8000/metrics", timeout=10)
            if response.status_code == 200:
                logger.info("æŒ‡æ¨™æ¨¡æ“¬å™¨å·²æˆåŠŸå•Ÿå‹•")
                return {"status": "started", "pid": process.pid, "port": 8000}
            else:
                raise RuntimeError("æ¨¡æ“¬å™¨å•Ÿå‹•å¤±æ•—")

        except Exception as e:
            raise RuntimeError(f"ç„¡æ³•å•Ÿå‹•æŒ‡æ¨™æ¨¡æ“¬å™¨: {e}")

    def run_health_checks(self):
        """åŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥"""
        logger.info("åŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥")

        checks = {
            "prometheus": self._check_prometheus,
            "grafana": self._check_grafana,
            "metrics_simulator": self._check_metrics_simulator,
        }

        results = {}
        for check_name, check_func in checks.items():
            try:
                result = check_func()
                results[check_name] = {"status": "healthy", "details": result}
                logger.info(f"âœ… {check_name} å¥åº·æª¢æŸ¥é€šé")
            except Exception as e:
                results[check_name] = {"status": "unhealthy", "error": str(e)}
                logger.warning(f"âš ï¸ {check_name} å¥åº·æª¢æŸ¥å¤±æ•—: {e}")

        return results

    def _check_prometheus(self) -> Dict:
        """æª¢æŸ¥ Prometheus ç‹€æ…‹"""
        response = requests.get(
            f"{self.prometheus_url}/api/v1/query", params={"query": "up"}, timeout=10
        )
        response.raise_for_status()

        data = response.json()
        return {"targets": len(data["data"]["result"]), "status": "up"}

    def _check_grafana(self) -> Dict:
        """æª¢æŸ¥ Grafana ç‹€æ…‹"""
        response = requests.get(f"{self.grafana_url}/api/health", timeout=10)
        response.raise_for_status()

        return response.json()

    def _check_metrics_simulator(self) -> Dict:
        """æª¢æŸ¥æŒ‡æ¨™æ¨¡æ“¬å™¨ç‹€æ…‹"""
        response = requests.get("http://localhost:8000/metrics", timeout=10)
        response.raise_for_status()

        metrics_text = response.text
        metric_count = len(
            [
                line
                for line in metrics_text.split("\n")
                if line and not line.startswith("#")
            ]
        )

        return {"metrics_count": metric_count, "status": "generating"}

    def generate_deployment_report(self):
        """ç”Ÿæˆéƒ¨ç½²å ±å‘Š"""
        logger.info("ç”Ÿæˆéƒ¨ç½²å ±å‘Š")

        report = {
            "deployment_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "configuration": {
                "prometheus_url": self.prometheus_url,
                "grafana_url": self.grafana_url,
                "metrics_simulator_url": "http://localhost:8000",
            },
            "components": {
                "metrics_namespace": "å·²éƒ¨ç½²çµ±ä¸€å‘½åç©ºé–“è¦ç¯„",
                "standard_labels": "å·²éƒ¨ç½²æ¨™æº–æ¨™ç±¤é›†",
                "prometheus_config": "å·²ç”Ÿæˆæœ€ä½³å¯¦è¸é…ç½®",
                "grafana_dashboard": "å·²éƒ¨ç½²ç³»çµ±ç¸½è¦½å„€è¡¨æ¿",
                "metrics_validator": "å·²é›†æˆæŒ‡æ¨™é©—è­‰å·¥å…·",
                "metrics_simulator": "å·²å•Ÿå‹•æ¸¬è©¦æ•¸æ“šç”Ÿæˆå™¨",
            },
            "usage": {
                "metrics_validation": "python monitoring/tools/metrics_validator.py",
                "dashboard_access": f"{self.grafana_url}/d/ntn-stack-overview",
                "metrics_endpoint": "http://localhost:8000/metrics",
            },
        }

        # ä¿å­˜å ±å‘Š
        report_file = self.config_path / "deployment_report.json"
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logger.info(f"éƒ¨ç½²å ±å‘Šå·²ä¿å­˜: {report_file}")
        return report


def main():
    """ä¸»ç¨‹åº"""
    parser = argparse.ArgumentParser(description="NTN Stack å¯è§€æ¸¬æ€§çµ±ä¸€æ ¼å¼éƒ¨ç½²å·¥å…·")
    parser.add_argument(
        "--config-path", default="monitoring", help="é…ç½®æ–‡ä»¶è·¯å¾‘ (é»˜èª: monitoring)"
    )
    parser.add_argument(
        "--prometheus-url",
        default="http://localhost:9090",
        help="Prometheus æœå‹™å™¨ URL",
    )
    parser.add_argument(
        "--grafana-url", default="http://localhost:3000", help="Grafana æœå‹™å™¨ URL"
    )
    parser.add_argument(
        "--action",
        choices=["deploy", "validate", "health-check", "report"],
        default="deploy",
        help="åŸ·è¡Œå‹•ä½œ",
    )
    parser.add_argument("--verbose", action="store_true", help="è©³ç´°è¼¸å‡º")

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # å‰µå»ºéƒ¨ç½²å™¨
    deployer = ObservabilityDeployer(args.config_path)
    deployer.prometheus_url = args.prometheus_url
    deployer.grafana_url = args.grafana_url

    try:
        if args.action == "deploy":
            logger.info("é–‹å§‹å®Œæ•´éƒ¨ç½²")
            results = deployer.deploy_full_stack()

            # è¼¸å‡ºçµæœæ‘˜è¦
            success_count = sum(1 for r in results.values() if r["status"] == "success")
            total_count = len(results)

            logger.info(f"éƒ¨ç½²å®Œæˆ: {success_count}/{total_count} æ­¥é©ŸæˆåŠŸ")

            if success_count == total_count:
                logger.info("ğŸ‰ å¯è§€æ¸¬æ€§ç³»çµ±éƒ¨ç½²æˆåŠŸï¼")
                logger.info(f"å„€è¡¨æ¿åœ°å€: {args.grafana_url}/d/ntn-stack-overview")
                logger.info("æŒ‡æ¨™æ¨¡æ“¬å™¨åœ°å€: http://localhost:8000/metrics")
            else:
                logger.warning("éƒ¨åˆ†æ­¥é©Ÿå¤±æ•—ï¼Œè«‹æª¢æŸ¥æ—¥èªŒ")
                for step, result in results.items():
                    if result["status"] == "failed":
                        logger.error(f"  âŒ {step}: {result['error']}")

        elif args.action == "validate":
            deployer.validate_configurations()
            deployer.run_metrics_validation()
            logger.info("é©—è­‰å®Œæˆ")

        elif args.action == "health-check":
            results = deployer.run_health_checks()
            healthy_count = sum(1 for r in results.values() if r["status"] == "healthy")
            logger.info(f"å¥åº·æª¢æŸ¥å®Œæˆ: {healthy_count}/{len(results)} æœå‹™å¥åº·")

        elif args.action == "report":
            report = deployer.generate_deployment_report()
            print(json.dumps(report, indent=2, ensure_ascii=False))

    except Exception as e:
        logger.error(f"åŸ·è¡Œå¤±æ•—: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
