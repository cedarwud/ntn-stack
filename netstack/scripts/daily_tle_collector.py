#!/usr/bin/env python3
"""
Phase 3: 45å¤©æ­·å²æ•¸æ“šæ”¶é›†è‡ªå‹•åŒ–
æ¯æ—¥è‡ªå‹•æ”¶é›† TLE æ•¸æ“šï¼Œå»ºç«‹å®Œæ•´çš„ 45 å¤©æ•¸æ“šé›†
"""

import asyncio
import aiohttp
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import hashlib
import sys
import os

# æ·»åŠ è·¯å¾‘ä»¥å°å…¥ Phase 0 æ¨¡çµ„
sys.path.append('/app/src')
sys.path.append('/app')

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('daily_tle_collector.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DailyTLECollector:
    """45å¤©æ­·å²æ•¸æ“šæ”¶é›†å™¨"""
    
    def __init__(self, target_days: int = 45):
        self.target_days = target_days
        self.base_dir = Path("netstack/tle_data")
        self.backup_dir = self.base_dir / "backups"
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self.base_dir.mkdir(parents=True, exist_ok=True)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        # æ”¯æ´çš„æ˜Ÿåº§é…ç½®
        self.constellations = {
            'starlink': {
                'url': 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle',
                'backup_url': 'https://www.celestrak.com/NORAD/elements/starlink.txt'
            },
            'oneweb': {
                'url': 'https://celestrak.org/NORAD/elements/gp.php?GROUP=oneweb&FORMAT=tle',
                'backup_url': 'https://www.celestrak.com/NORAD/elements/oneweb.txt'
            }
        }
        
        self.session: Optional[aiohttp.ClientSession] = None
    
    async def __aenter__(self):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
            headers={'User-Agent': 'NTN-Stack/1.0 Research Tool'}
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
    
    def get_date_range(self) -> List[datetime]:
        """ç²å–éœ€è¦æ”¶é›†çš„æ—¥æœŸç¯„åœ"""
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=self.target_days - 1)
        
        dates = []
        current_date = start_date
        while current_date <= end_date:
            dates.append(datetime.combine(current_date, datetime.min.time()))
            current_date += timedelta(days=1)
        
        return dates
    
    def get_existing_data_status(self) -> Dict[str, Dict[str, bool]]:
        """æª¢æŸ¥ç¾æœ‰æ•¸æ“šç‹€æ…‹"""
        status = {}
        
        for constellation in self.constellations.keys():
            status[constellation] = {}
            
            # æª¢æŸ¥ TLE æ–‡ä»¶
            for date in self.get_date_range():
                date_str = date.strftime('%Y%m%d')
                tle_file = self.base_dir / constellation / f"{constellation}_{date_str}.tle"
                json_file = self.base_dir / constellation / f"{constellation}_{date_str}.json"
                
                status[constellation][date_str] = {
                    'tle_exists': tle_file.exists(),
                    'json_exists': json_file.exists(),
                    'tle_size': tle_file.stat().st_size if tle_file.exists() else 0,
                    'json_size': json_file.stat().st_size if json_file.exists() else 0
                }
        
        return status
    
    async def download_tle_data(self, constellation: str, url: str) -> Optional[str]:
        """ä¸‹è¼‰ TLE æ•¸æ“š"""
        try:
            logger.info(f"ğŸ“¡ ä¸‹è¼‰ {constellation} TLE æ•¸æ“š: {url}")
            
            async with self.session.get(url) as response:
                if response.status == 200:
                    content = await response.text()
                    
                    # é©—è­‰ TLE æ ¼å¼
                    if self.validate_tle_format(content):
                        logger.info(f"âœ… {constellation} TLE æ•¸æ“šä¸‹è¼‰æˆåŠŸ ({len(content)} å­—ç¬¦)")
                        return content
                    else:
                        logger.warning(f"âš ï¸ {constellation} TLE æ ¼å¼é©—è­‰å¤±æ•—")
                        return None
                else:
                    logger.error(f"âŒ {constellation} TLE ä¸‹è¼‰å¤±æ•—: HTTP {response.status}")
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ {constellation} TLE ä¸‹è¼‰ç•°å¸¸: {e}")
            return None
    
    def validate_tle_format(self, content: str) -> bool:
        """é©—è­‰ TLE æ ¼å¼"""
        lines = content.strip().split('\n')
        
        # åŸºæœ¬æª¢æŸ¥ï¼šæ‡‰è©²æœ‰è¡›æ˜Ÿåç¨±å’Œå…©è¡Œ TLE æ•¸æ“š
        if len(lines) < 3:
            return False
        
        # æª¢æŸ¥ TLE è¡Œæ ¼å¼
        tle_lines = [line for line in lines if line.startswith(('1 ', '2 '))]
        
        if len(tle_lines) < 2:
            return False
        
        # æª¢æŸ¥ç¬¬ä¸€è¡Œå’Œç¬¬äºŒè¡Œçš„æ ¼å¼
        for line in tle_lines[:2]:
            if len(line) != 69:  # TLE è¡Œæ‡‰è©²æ˜¯ 69 å€‹å­—ç¬¦
                return False
        
        return True
    
    def parse_tle_to_json(self, tle_content: str, constellation: str) -> Dict:
        """å°‡ TLE æ•¸æ“šè§£æç‚º JSON æ ¼å¼"""
        lines = tle_content.strip().split('\n')
        satellites = []
        
        i = 0
        while i < len(lines) - 2:
            if lines[i + 1].startswith('1 ') and lines[i + 2].startswith('2 '):
                satellite_name = lines[i].strip()
                line1 = lines[i + 1].strip()
                line2 = lines[i + 2].strip()
                
                # æå– NORAD ID
                norad_id = line1.split()[1].rstrip('U')
                
                satellites.append({
                    'name': satellite_name,
                    'norad_id': norad_id,
                    'line1': line1,
                    'line2': line2,
                    'constellation': constellation
                })
                
                i += 3
            else:
                i += 1
        
        return {
            'constellation': constellation,
            'collection_date': datetime.now().isoformat(),
            'satellite_count': len(satellites),
            'satellites': satellites
        }
    
    async def save_daily_data(self, constellation: str, date: datetime, tle_content: str) -> bool:
        """ä¿å­˜æ¯æ—¥æ•¸æ“š"""
        try:
            date_str = date.strftime('%Y%m%d')
            constellation_dir = self.base_dir / constellation
            constellation_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜ TLE æ–‡ä»¶
            tle_file = constellation_dir / f"{constellation}_{date_str}.tle"
            with open(tle_file, 'w', encoding='utf-8') as f:
                f.write(tle_content)
            
            # è½‰æ›ä¸¦ä¿å­˜ JSON æ–‡ä»¶
            json_data = self.parse_tle_to_json(tle_content, constellation)
            json_file = constellation_dir / f"{constellation}_{date_str}.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, indent=2, ensure_ascii=False)
            
            # å‰µå»ºå‚™ä»½
            backup_dir = self.backup_dir / constellation / date_str
            backup_dir.mkdir(parents=True, exist_ok=True)
            
            # è¨ˆç®—æ–‡ä»¶å“ˆå¸Œ
            tle_hash = hashlib.md5(tle_content.encode()).hexdigest()
            
            # ä¿å­˜å…ƒæ•¸æ“š
            metadata = {
                'constellation': constellation,
                'date': date.isoformat(),
                'tle_file': str(tle_file),
                'json_file': str(json_file),
                'satellite_count': json_data['satellite_count'],
                'file_hash': tle_hash,
                'file_size': len(tle_content)
            }
            
            metadata_file = backup_dir / 'metadata.json'
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ’¾ {constellation} {date_str} æ•¸æ“šä¿å­˜æˆåŠŸ ({json_data['satellite_count']} é¡†è¡›æ˜Ÿ)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ {constellation} {date_str} æ•¸æ“šä¿å­˜å¤±æ•—: {e}")
            return False
    
    async def collect_daily_data(self) -> Dict[str, int]:
        """æ¯æ—¥è‡ªå‹•æ”¶é›† TLE æ•¸æ“š"""
        logger.info(f"ğŸš€ é–‹å§‹æ”¶é›† {self.target_days} å¤©æ­·å² TLE æ•¸æ“š")
        
        results = {'success': 0, 'failed': 0, 'skipped': 0}
        existing_status = self.get_existing_data_status()
        
        today = datetime.now()
        
        for constellation, config in self.constellations.items():
            logger.info(f"ğŸ“¡ è™•ç† {constellation} æ˜Ÿåº§")
            
            # ä¸‹è¼‰ä»Šæ—¥æ•¸æ“š
            tle_content = await self.download_tle_data(constellation, config['url'])
            
            if not tle_content:
                # å˜—è©¦å‚™ç”¨ URL
                logger.info(f"ğŸ”„ å˜—è©¦å‚™ç”¨ URL: {config['backup_url']}")
                tle_content = await self.download_tle_data(constellation, config['backup_url'])
            
            if tle_content:
                # ä¿å­˜ä»Šæ—¥æ•¸æ“š
                if await self.save_daily_data(constellation, today, tle_content):
                    results['success'] += 1
                else:
                    results['failed'] += 1
            else:
                logger.error(f"âŒ {constellation} æ•¸æ“šä¸‹è¼‰å®Œå…¨å¤±æ•—")
                results['failed'] += 1
        
        logger.info(f"ğŸ“Š æ”¶é›†çµæœ: æˆåŠŸ {results['success']}, å¤±æ•— {results['failed']}, è·³é {results['skipped']}")
        return results
    
    def validate_45day_completeness(self) -> Dict:
        """é©—è­‰45å¤©æ•¸æ“šé›†å®Œæ•´æ€§"""
        logger.info("ğŸ” é©—è­‰ 45 å¤©æ•¸æ“šé›†å®Œæ•´æ€§")
        
        status = self.get_existing_data_status()
        report = {
            'target_days': self.target_days,
            'validation_date': datetime.now().isoformat(),
            'constellations': {},
            'overall_completeness': 0.0
        }
        
        total_expected = self.target_days * len(self.constellations)
        total_complete = 0
        
        for constellation, dates in status.items():
            constellation_complete = 0
            constellation_report = {
                'expected_days': self.target_days,
                'available_days': 0,
                'missing_dates': [],
                'incomplete_dates': [],
                'total_satellites': 0
            }
            
            for date_str, file_status in dates.items():
                if file_status['tle_exists'] and file_status['json_exists']:
                    if file_status['tle_size'] > 1000 and file_status['json_size'] > 100:
                        constellation_complete += 1
                        total_complete += 1
                    else:
                        constellation_report['incomplete_dates'].append(date_str)
                else:
                    constellation_report['missing_dates'].append(date_str)
            
            constellation_report['available_days'] = constellation_complete
            constellation_report['completeness'] = (constellation_complete / self.target_days) * 100
            
            report['constellations'][constellation] = constellation_report
            
            logger.info(f"ğŸ“Š {constellation}: {constellation_complete}/{self.target_days} å¤© ({constellation_report['completeness']:.1f}%)")
        
        report['overall_completeness'] = (total_complete / total_expected) * 100
        
        # ä¿å­˜é©—è­‰å ±å‘Š
        report_file = self.base_dir / 'completeness_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‹ æ•´é«”å®Œæ•´æ€§: {report['overall_completeness']:.1f}%")
        logger.info(f"ğŸ’¾ é©—è­‰å ±å‘Šå·²ä¿å­˜: {report_file}")
        
        return report

async def main():
    """ä¸»å‡½æ•¸"""
    async with DailyTLECollector(target_days=45) as collector:
        # æ”¶é›†ä»Šæ—¥æ•¸æ“š
        results = await collector.collect_daily_data()
        
        # é©—è­‰æ•¸æ“šå®Œæ•´æ€§
        completeness_report = collector.validate_45day_completeness()
        
        print(f"\nğŸ¯ æ”¶é›†çµæœæ‘˜è¦:")
        print(f"æˆåŠŸ: {results['success']}")
        print(f"å¤±æ•—: {results['failed']}")
        print(f"æ•´é«”å®Œæ•´æ€§: {completeness_report['overall_completeness']:.1f}%")

if __name__ == "__main__":
    asyncio.run(main())
