#!/usr/bin/env python3
"""
å¾éšæ®µå››é–‹å§‹åŸ·è¡Œå…­éšæ®µæ•¸æ“šè™•ç†
ä½¿ç”¨ç¾æœ‰çš„éšæ®µä¸‰è¼¸å‡ºæ•¸æ“š
"""

import sys
import os
import json
import time
import logging
from datetime import datetime, timezone
from pathlib import Path

# ç¢ºä¿èƒ½æ‰¾åˆ°æ¨¡çµ„
sys.path.insert(0, '/app')
sys.path.insert(0, '/app/src')

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def run_stages_4_to_6():
    """åŸ·è¡Œéšæ®µ4åˆ°éšæ®µ6çš„è™•ç†æµç¨‹"""
    
    print('ğŸš€ å…­éšæ®µæ•¸æ“šè™•ç†ç³»çµ± - éšæ®µ4åˆ°6 (ä¿®å¾©ç‰ˆ)')
    print('=' * 80)
    print(f'é–‹å§‹æ™‚é–“: {datetime.now(timezone.utc).isoformat()}')
    print('=' * 80)
    
    results = {}
    start_time = time.time()
    
    try:
        # è¼‰å…¥éšæ®µä¸‰çš„è¼¸å‡º
        print('\nğŸ“¥ è¼‰å…¥éšæ®µä¸‰è¼¸å‡ºæ•¸æ“š')
        print('-' * 60)
        
        stage3_file = '/app/data/signal_analysis_outputs/signal_event_analysis_output.json'
        with open(stage3_file, 'r', encoding='utf-8') as f:
            results['stage3'] = json.load(f)
        
        stage3_satellites = results['stage3']['metadata'].get('satellites_count', 0)
        print(f'âœ… éšæ®µä¸‰æ•¸æ“šè¼‰å…¥å®Œæˆ: {stage3_satellites} é¡†è¡›æ˜Ÿ')
        
        # éšæ®µå››ï¼šæ™‚é–“åºåˆ—é è™•ç†
        print('\nâ° éšæ®µå››ï¼šæ™‚é–“åºåˆ—é è™•ç†')
        print('-' * 60)
        
        from stages.timeseries_preprocessing_processor import TimeseriesPreprocessingProcessor
        stage4 = TimeseriesPreprocessingProcessor(
            input_dir='/app/data',
            output_dir='/app/data/timeseries_preprocessing_outputs'
        )
        
        # Stage 4 loads from file, specify correct path
        results['stage4'] = stage4.process_timeseries_preprocessing(
            signal_file='/app/data/signal_analysis_outputs/signal_event_analysis_output.json',
            save_output=True
        )
        
        if not results['stage4']:
            print('âŒ éšæ®µå››å¤±æ•—')
            return False
            
        ts_count = 0
        if 'conversion_statistics' in results['stage4']:
            ts_count = results['stage4']['conversion_statistics'].get('successful_conversions', 0)
        elif 'constellation_data' in results['stage4']:
            starlink_processed = results['stage4']['constellation_data']['starlink'].get('satellites_processed', 0)
            oneweb_processed = results['stage4']['constellation_data']['oneweb'].get('satellites_processed', 0)
            ts_count = starlink_processed + oneweb_processed
        
        print(f'âœ… éšæ®µå››å®Œæˆ: {ts_count} é¡†è¡›æ˜Ÿæ™‚é–“åºåˆ—')
        
        # éšæ®µäº”ï¼šæ•¸æ“šæ•´åˆ
        print('\nğŸ”„ éšæ®µäº”ï¼šæ•¸æ“šæ•´åˆ')
        print('-' * 60)
        
        # å˜—è©¦å…©ç¨®å°å…¥æ–¹å¼
        try:
            from stages.data_integration_processor import Stage5IntegrationProcessor, Stage5Config
            
            # å‰µå»ºé…ç½®
            stage5_config = Stage5Config(
                input_enhanced_timeseries_dir='/app/data',
                output_data_integration_dir='/app/data/data_integration_outputs',
                elevation_thresholds=[5, 10, 15]
            )
            
            stage5 = Stage5IntegrationProcessor(stage5_config)
            # ä½¿ç”¨enhanced_dataåƒæ•¸ï¼ˆæ ¹æ“šåŸå§‹ç¨‹å¼ç¢¼ï¼‰
            results['stage5'] = stage5.process_data_integration(
                enhanced_data=results['stage4'],
                save_output=True
            )
        except ImportError:
            # å¦‚æœä¸Šé¢çš„å°å…¥å¤±æ•—ï¼Œå˜—è©¦å¦ä¸€ç¨®æ–¹å¼
            from stages.data_integration_processor import Stage5IntegrationProcessor
            
            stage5 = Stage5IntegrationProcessor(
                input_dir='/app/data',
                output_dir='/app/data/data_integration_outputs'
            )
            # ä½¿ç”¨timeseries_dataåƒæ•¸
            results['stage5'] = stage5.process_data_integration(
                timeseries_data=results['stage4'],
                save_output=True
            )
        
        if not results['stage5']:
            print('âŒ éšæ®µäº”å¤±æ•—')
            return False
            
        integrated_count = results['stage5'].get('metadata', {}).get('total_satellites', 0)
        print(f'âœ… éšæ®µäº”å®Œæˆ: {integrated_count} é¡†è¡›æ˜Ÿæ•´åˆ')
        
        # éšæ®µå…­ï¼šå‹•æ…‹æ± è¦åŠƒ
        print('\nğŸ¯ éšæ®µå…­ï¼šå‹•æ…‹æ± è¦åŠƒ')
        print('-' * 60)
        
        from stages.enhanced_dynamic_pool_planner import EnhancedDynamicPoolPlanner
        
        stage6 = EnhancedDynamicPoolPlanner(
            input_dir='/app/data',
            output_dir='/app/data/dynamic_pool_planning_outputs'
        )
        
        # ä½¿ç”¨process_dynamic_pool_planningæ–¹æ³•
        results['stage6'] = stage6.process_dynamic_pool_planning(
            integrated_data=results['stage5'],
            save_output=True
        )
        
        if not results['stage6']:
            print('âŒ éšæ®µå…­å¤±æ•—')
            return False
            
        # æå–æœ€çµ‚çµæœ
        pool_data = results['stage6'].get('dynamic_satellite_pool', {})
        total_selected = pool_data.get('total_selected', 0)
        starlink_count = len(pool_data.get('starlink_satellites', []))
        oneweb_count = len(pool_data.get('oneweb_satellites', []))
        
        print(f'âœ… éšæ®µå…­å®Œæˆ: ç¸½è¨ˆ {total_selected} é¡†è¡›æ˜Ÿ')
        print(f'   - Starlink: {starlink_count} é¡†')
        print(f'   - OneWeb: {oneweb_count} é¡†')
        
        # ç”Ÿæˆæœ€çµ‚å ±å‘Š
        elapsed_time = time.time() - start_time
        print('\n' + '=' * 80)
        print('ğŸ“Š éšæ®µ4-6è™•ç†å®Œæˆç¸½çµ')
        print('=' * 80)
        print(f'âœ… éšæ®µ4-6æˆåŠŸå®Œæˆï¼')
        print(f'â±ï¸ ç¸½è€—æ™‚: {elapsed_time:.2f} ç§’ ({elapsed_time/60:.2f} åˆ†é˜)')
        print(f'ğŸ“Š æ•¸æ“šæµç¨‹:')
        print(f'   Stage 3: {stage3_satellites} é¡†è¡›æ˜Ÿï¼ˆå·²æœ‰ï¼‰')
        print(f'   Stage 4: {ts_count} é¡†è¡›æ˜Ÿæ™‚é–“åºåˆ—')
        print(f'   Stage 5: {integrated_count} é¡†è¡›æ˜Ÿæ•´åˆ')
        print(f'   Stage 6: {total_selected} é¡†è¡›æ˜Ÿæœ€çµ‚é¸æ“‡')
        print('=' * 80)
        
        # ä¿å­˜æœ€çµ‚å ±å‘Š
        final_report = {
            'execution_time': datetime.now(timezone.utc).isoformat(),
            'processing_time_seconds': elapsed_time,
            'stages_completed': 3,  # éšæ®µ4-6
            'pipeline_summary': {
                'stage3_loaded': stage3_satellites,
                'stage4_timeseries': ts_count,
                'stage5_integrated': integrated_count,
                'stage6_selected': total_selected
            },
            'final_satellite_pool': {
                'total': total_selected,
                'starlink': starlink_count,
                'oneweb': oneweb_count
            },
            'success': True
        }
        
        report_path = '/app/data/leo_optimization_stages_4_to_6_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
        
        print(f'\nâœ… éšæ®µ4-6å ±å‘Šå·²ä¿å­˜: {report_path}')
        
        return True
        
    except Exception as e:
        print(f'\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}')
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    success = run_stages_4_to_6()
    
    if success:
        return 0
    else:
        return 1

if __name__ == '__main__':
    sys.exit(main())