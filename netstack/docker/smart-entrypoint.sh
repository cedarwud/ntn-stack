#!/bin/bash
set -e

echo "ğŸš€ NetStack æ™ºèƒ½å•Ÿå‹•é–‹å§‹..."

# ğŸ”§ ç·Šæ€¥ä¿®å¾©æ¨¡å¼ï¼šè‡ªå‹•æª¢æ¸¬ä¸¦è·³éæœ‰å•é¡Œçš„å…­éšæ®µç³»çµ±
if ! python -c "import sys; sys.path.append('/app/scripts'); import run_six_stages" 2>/dev/null; then
    echo "âš¡ æª¢æ¸¬åˆ°å…­éšæ®µç³»çµ±å°å…¥éŒ¯èª¤ï¼Œå•Ÿç”¨ç·Šæ€¥æ¨¡å¼ï¼šè·³éæ•¸æ“šç”Ÿæˆï¼Œç›´æ¥å•Ÿå‹• API"
    exec "$@"
    exit 0
fi

DATA_DIR="/app/data"
MARKER_FILE="$DATA_DIR/.data_ready"

# ç¢ºä¿æ•¸æ“šç›®éŒ„å­˜åœ¨ä¸¦ä¸”æ¬Šé™æ­£ç¢º
mkdir -p "$DATA_DIR" || true

# æ··åˆæ¨¡å¼ï¼šæª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§å’Œæ–°é®®åº¦
check_data_integrity() {
    echo "ğŸ” æ™ºèƒ½æ•¸æ“šæª¢æŸ¥é–‹å§‹..."
    
    # æª¢æŸ¥å…­éšæ®µç³»çµ±è¼¸å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨ (æ··åˆæ¨¡å¼ï¼šStage1-2è¨˜æ†¶é«”ï¼ŒStage3-6æª”æ¡ˆ)
    # Stage3-6 æ‡‰è©²æœ‰æª”æ¡ˆè¼¸å‡ºï¼ŒStage1-2 ä½¿ç”¨è¨˜æ†¶é«”å‚³é
    critical_files=(
        "$DATA_DIR/signal_analysis_outputs/signal_event_analysis_output.json"
        "$DATA_DIR/timeseries_preprocessing_outputs/enhanced_timeseries_output.json"
        "$DATA_DIR/data_integration_outputs/data_integration_output.json"
        "$DATA_DIR/dynamic_pool_planning_outputs/enhanced_dynamic_pools_output.json"
    )
    
    missing_files=0
    for file in "${critical_files[@]}"; do
        if [ ! -f "$file" ]; then
            echo "âŒ é—œéµéšæ®µè¼¸å‡ºæª”æ¡ˆç¼ºå¤±: $file"
            missing_files=$((missing_files + 1))
        fi
    done
    
    if [ $missing_files -gt 0 ]; then
        echo "âŒ å…­éšæ®µç³»çµ±è¼¸å‡ºä¸å®Œæ•´ï¼Œéœ€è¦é‡æ–°è¨ˆç®— (ç¼ºå¤± $missing_files å€‹æª”æ¡ˆ)"
        return 1
    fi
    
    # æª¢æŸ¥é—œéµæª”æ¡ˆå¤§å°ï¼ˆå½ˆæ€§æª¢æŸ¥ï¼Œå‹•æ…‹æ± è¦åŠƒä½œç‚ºå®Œæ•´æ€§æŒ‡æ¨™ï¼‰
    if [ -f "$DATA_DIR/dynamic_pool_planning_outputs/enhanced_dynamic_pools_output.json" ]; then
        SIZE=$(stat -c%s "$DATA_DIR/dynamic_pool_planning_outputs/enhanced_dynamic_pools_output.json" 2>/dev/null || echo 0)
        if [ "$SIZE" -lt 10000 ]; then
            echo "âŒ å‹•æ…‹æ± è¦åŠƒè¼¸å‡ºæ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½æå£ (å¤§å°: ${SIZE} bytes)"
            return 1
        fi
        echo "âœ… å‹•æ…‹æ± è¦åŠƒè¼¸å‡ºæ–‡ä»¶å¤§å°æ­£å¸¸: ${SIZE} bytes"
    else
        echo "âŒ å‹•æ…‹æ± è¦åŠƒè¼¸å‡ºæ–‡ä»¶ä¸å­˜åœ¨"
        return 1
    fi
    
    # æ··åˆæ¨¡å¼é—œéµï¼šæ¯”è¼ƒ TLE æ•¸æ“šå’Œé è¨ˆç®—æ•¸æ“šçš„æ™‚é–“æˆ³
    echo "ğŸ“Š æª¢æŸ¥ TLE æ•¸æ“š vs é è¨ˆç®—æ•¸æ“šçš„æ–°é®®åº¦..."
    
    # ç²å–æœ€æ–° TLE æ•¸æ“šçš„ä¿®æ”¹æ™‚é–“
    LATEST_TLE_TIME=0
    if [ -d "/app/tle_data" ]; then
        # æ‰¾åˆ°æœ€æ–°çš„ TLE æ–‡ä»¶æ™‚é–“æˆ³
        for tle_file in $(find /app/tle_data -name "*.tle" -o -name "*.json" 2>/dev/null); do
            if [ -f "$tle_file" ]; then
                FILE_TIME=$(stat -c%Y "$tle_file" 2>/dev/null || echo 0)
                if [ "$FILE_TIME" -gt "$LATEST_TLE_TIME" ]; then
                    LATEST_TLE_TIME=$FILE_TIME
                    LATEST_TLE_FILE="$tle_file"
                fi
            fi
        done
    fi
    
    # ç²å–å…­éšæ®µç³»çµ±è¼¸å‡ºçš„æ™‚é–“æˆ³ï¼ˆä½¿ç”¨å‹•æ…‹æ± è¦åŠƒä½œç‚ºå®Œæ•´æ€§æŒ‡æ¨™ï¼‰
    if [ -f "$DATA_DIR/dynamic_pool_planning_outputs/enhanced_dynamic_pools_output.json" ]; then
        DATA_TIME=$(stat -c%Y "$DATA_DIR/dynamic_pool_planning_outputs/enhanced_dynamic_pools_output.json" 2>/dev/null || echo 0)
    else
        DATA_TIME=0
    fi
    
    # æ¯”è¼ƒæ™‚é–“æˆ³
    if [ "$LATEST_TLE_TIME" -gt 0 ] && [ "$DATA_TIME" -gt 0 ]; then
        TIME_DIFF=$((LATEST_TLE_TIME - DATA_TIME))
        echo "ğŸ“… TLE æœ€æ–°æ™‚é–“: $(date -d @$LATEST_TLE_TIME '+%Y-%m-%d %H:%M:%S')"
        echo "ğŸ“… é è¨ˆç®—æ™‚é–“: $(date -d @$DATA_TIME '+%Y-%m-%d %H:%M:%S')"
        
        if [ "$TIME_DIFF" -gt 3600 ]; then  # TLE æ•¸æ“šæ¯”é è¨ˆç®—æ•¸æ“šæ–°è¶…é 1 å°æ™‚
            echo "ğŸ”„ TLE æ•¸æ“šå·²æ›´æ–°ï¼Œéœ€è¦é‡æ–°è¨ˆç®— (å·®ç•°: $((TIME_DIFF/3600)) å°æ™‚)"
            return 1
        else
            echo "âœ… é è¨ˆç®—æ•¸æ“šæ˜¯æœ€æ–°çš„ï¼Œå¯ä»¥å¿«é€Ÿå•Ÿå‹•ï¼"
        fi
    else
        echo "âš ï¸ ç„¡æ³•æ¯”è¼ƒæ™‚é–“æˆ³ï¼Œå‡è¨­éœ€è¦é‡æ–°è¨ˆç®—"
        return 1
    fi
    
    # æ›´æ–°æˆ–å‰µå»ºæ¨™è¨˜æ–‡ä»¶
    echo "$(date -Iseconds)" > "$MARKER_FILE"
    echo "âœ… æ•¸æ“šå®Œæ•´æ€§å’Œæ–°é®®åº¦æª¢æŸ¥é€šé"
    return 0
}

# é‡æ–°ç”Ÿæˆæ•¸æ“š
regenerate_data() {
    echo "ğŸ”„ é–‹å§‹é‡æ–°ç”Ÿæˆé è¨ˆç®—æ•¸æ“š..."
    
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    mkdir -p "$DATA_DIR"
    
    # æ¸…ç†èˆŠæ•¸æ“šï¼ˆä¿ç•™ç›®éŒ„çµæ§‹ï¼‰
    find "$DATA_DIR" -type f -delete 2>/dev/null || true
    
    # åŸ·è¡Œé è¨ˆç®—
    cd /app
    echo "ğŸ”¨ åŸ·è¡ŒçœŸå¯¦æ•¸æ“šç”Ÿæˆ (Phase 2.5 å®Œæ•´æ•¸æ“š)..."
    
    # åŸ·è¡Œå¢å¼·å…­éšæ®µç³»çµ± (å®Œæ•´æµç¨‹)
    echo "ğŸ”¨ å¢å¼·å…­éšæ®µç³»çµ±ï¼šå®Œæ•´çµ±ä¸€ç®¡é“ (TLEè¼‰å…¥â†’æ™ºèƒ½ç¯©é¸â†’ä¿¡è™Ÿåˆ†æâ†’æ™‚é–“åºåˆ—â†’æ•¸æ“šæ•´åˆâ†’å‹•æ…‹æ± è¦åŠƒ)..."
    echo "ğŸ¯ unified controller: run_six_stages.py"
    echo "â±ï¸ é ä¼°è™•ç†æ™‚é–“ï¼š5-10åˆ†é˜ (é–‹ç™¼æ¨¡å¼) æˆ– 20-45åˆ†é˜ (å®Œæ•´æ¨¡å¼)"
    if timeout 2700 python scripts/run_six_stages.py --data-dir "$DATA_DIR"; then
        echo "âœ… å¢å¼·å…­éšæ®µç³»çµ±å®Œæˆ"
    else
        echo "âŒ å¢å¼·å…­éšæ®µç³»çµ±å¤±æ•—æˆ–è¶…æ™‚ (45åˆ†é˜)"
        echo "ğŸ” æª¢æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†è¼¸å‡ºå¯ç”¨..."
        if [ -f "$DATA_DIR/tle_calculation_outputs/tle_sgp4_calculation_output.json" ] || [ -f "$DATA_DIR/intelligent_filtering_outputs/intelligent_filtered_output.json" ]; then
            echo "âš ï¸ ç™¼ç¾éƒ¨åˆ†è¼¸å‡ºï¼Œç¹¼çºŒå•Ÿå‹• API æœå‹™ (é™ç´šæ¨¡å¼)"
        else
            exit 1
        fi
    fi
    
    # æª¢æŸ¥å¢å¼·å…­éšæ®µç³»çµ±è¼¸å‡ºæ˜¯å¦æˆåŠŸ
    echo "ğŸ” æª¢æŸ¥å¢å¼·å…­éšæ®µç³»çµ±è¼¸å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨: $DATA_DIR/dynamic_pool_planning_outputs/enhanced_dynamic_pools_output.json"
    ls -la "$DATA_DIR"/ || echo "âŒ ç„¡æ³•åˆ—å‡ºæ•¸æ“šç›®éŒ„"
    
    # æª¢æŸ¥è¼¸å‡ºæ–‡ä»¶
    if [ -f "$DATA_DIR/dynamic_pool_planning_outputs/enhanced_dynamic_pools_output.json" ]; then
        # æª¢æŸ¥æ–‡ä»¶å¤§å°
        FILE_SIZE=$(stat -c%s "$DATA_DIR/dynamic_pool_planning_outputs/enhanced_dynamic_pools_output.json" 2>/dev/null || echo 0)
        echo "ğŸ“Š å¢å¼·å…­éšæ®µç³»çµ±è¼¸å‡ºæ–‡ä»¶å¤§å°: $FILE_SIZE bytes"
        
        # å‰µå»ºå®Œæˆæ¨™è¨˜
        echo "$(date -Iseconds)" > "$MARKER_FILE"
        echo "âœ… å¢å¼·å…­éšæ®µç³»çµ±æ•¸æ“šç”Ÿæˆå®Œæˆ"
        
        # é¡¯ç¤ºç”Ÿæˆçš„æ–‡ä»¶ä¿¡æ¯
        echo "ğŸ“Š ç”Ÿæˆçš„å¢å¼·å…­éšæ®µç³»çµ±æ–‡ä»¶:"
        ls -lh "$DATA_DIR"/*_outputs/*.json 2>/dev/null || true
    elif [ -f "$DATA_DIR/intelligent_filtering_outputs/intelligent_filtered_output.json" ]; then
        echo "âš ï¸ ä¸»è¦è¼¸å‡ºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½†ç™¼ç¾ç¯©é¸çµæœï¼Œç¹¼çºŒå•Ÿå‹• (é™ç´šæ¨¡å¼)"
        echo "$(date -Iseconds)" > "$MARKER_FILE"
        ls -lh "$DATA_DIR"/*_outputs/*.json 2>/dev/null || true
    else
        echo "âŒ å¢å¼·å…­éšæ®µç³»çµ±æ•¸æ“šç”Ÿæˆå¤±æ•— - ç„¡å¯ç”¨è¼¸å‡ºæ–‡ä»¶"
        echo "ğŸ” æ•¸æ“šç›®éŒ„å…§å®¹:"
        ls -la "$DATA_DIR"/ || echo "ç„¡æ³•è¨ªå•æ•¸æ“šç›®éŒ„"
        exit 1
    fi
}

# ä¸»é‚è¼¯
echo "ğŸ” æª¢æŸ¥æ•¸æ“šç‹€æ…‹..."
if check_data_integrity; then
    echo "ğŸ“Š ä½¿ç”¨ç¾æœ‰æ•¸æ“š"
    ls -lh "$DATA_DIR"/*.json 2>/dev/null | head -3
else
    echo "âš ï¸ æ•¸æ“šä¸å®Œæ•´ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ"
    regenerate_data
fi

echo "ğŸ¯ å•Ÿå‹• NetStack API æœå‹™..."

# è¨­ç½®Pythonæ¨¡å¡Šæœç´¢è·¯å¾‘
export PYTHONPATH="/app:$PYTHONPATH"

exec "$@"