#!/bin/bash
set -e

echo "ğŸš€ NetStack é‹è¡Œæ™‚æ™ºèƒ½å•Ÿå‹•..."

DATA_DIR="/app/data"
BUILD_TIMESTAMP_FILE="$DATA_DIR/.build_timestamp"
BUILD_MODE_FILE="$DATA_DIR/.build_mode"

# è¨­ç½®Pythonæ¨¡å¡Šæœç´¢è·¯å¾‘
export PYTHONPATH="/app:/app/src:/app/netstack:$PYTHONPATH"

# æª¢æŸ¥æ˜¯å¦æœ‰å»ºæ§‹æ™‚é è™•ç†çš„æ•¸æ“š
check_build_time_data() {
    echo "ğŸ” æª¢æŸ¥å»ºæ§‹æ™‚é è™•ç†æ•¸æ“š..."
    
    # æª¢æŸ¥å»ºæ§‹æ¨™è¨˜æ–‡ä»¶
    if [ ! -f "$BUILD_MODE_FILE" ]; then
        echo "âŒ æœªæ‰¾åˆ°å»ºæ§‹æ¨¡å¼æ¨™è¨˜ï¼Œéœ€è¦é‹è¡Œæ™‚è™•ç†"
        return 1
    fi
    
    if [ ! -f "$BUILD_TIMESTAMP_FILE" ]; then
        echo "âŒ æœªæ‰¾åˆ°å»ºæ§‹æ™‚é–“æˆ³ï¼Œéœ€è¦é‹è¡Œæ™‚è™•ç†"
        return 1
    fi
    
    # æª¢æŸ¥é—œéµé è™•ç†æ–‡ä»¶
    critical_files=(
        "$DATA_DIR/dynamic_pool_planning_outputs/enhanced_dynamic_pools_output.json"
        "$DATA_DIR/data_integration_outputs/data_integration_output.json"
        "$DATA_DIR/timeseries_preprocessing_outputs/enhanced_timeseries_output.json"
        "$DATA_DIR/signal_analysis_outputs/signal_event_analysis_output.json"
    )
    
    missing_count=0
    for file in "${critical_files[@]}"; do
        if [ ! -f "$file" ]; then
            echo "âŒ ç¼ºå°‘é—œéµæ–‡ä»¶: $file"
            missing_count=$((missing_count + 1))
        fi
    done
    
    if [ $missing_count -gt 0 ]; then
        echo "âŒ é è™•ç†æ•¸æ“šä¸å®Œæ•´ï¼Œç¼ºå°‘ $missing_count å€‹é—œéµæ–‡ä»¶"
        return 1
    fi
    
    # æª¢æŸ¥æ•¸æ“šæ–°é®®åº¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
    build_time=$(cat "$BUILD_TIMESTAMP_FILE")
    echo "âœ… å»ºæ§‹æ™‚é è™•ç†æ•¸æ“šå®Œæ•´ä¸”å¯ç”¨"
    echo "   å»ºæ§‹æ™‚é–“: $build_time"
    echo "   æ•¸æ“šæ–‡ä»¶: $((4 - missing_count))/4 å®Œæ•´"
    
    return 0
}

# æ™ºèƒ½å¢é‡æ›´æ–°æª¢æŸ¥
check_incremental_update_needed() {
    echo "ğŸ”„ æª¢æŸ¥æ˜¯å¦éœ€è¦å¢é‡æ›´æ–°..."
    
    # æª¢æŸ¥TLEæ•¸æ“šæ˜¯å¦æ›´æ–°
    if [ -d "/app/tle_data" ]; then
        # æ‰¾åˆ°æœ€æ–°çš„TLEæ–‡ä»¶
        latest_tle=$(find /app/tle_data -name "*.tle" -type f -printf '%T@ %p\n' 2>/dev/null | sort -n | tail -1 | cut -d' ' -f2-)
        
        if [ -n "$latest_tle" ] && [ -f "$latest_tle" ]; then
            tle_time=$(stat -c%Y "$latest_tle" 2>/dev/null || echo 0)
            build_time_epoch=$(date -d "$(cat "$BUILD_TIMESTAMP_FILE")" +%s 2>/dev/null || echo 0)
            
            if [ "$tle_time" -gt "$build_time_epoch" ]; then
                echo "ğŸ”„ æª¢æ¸¬åˆ°TLEæ•¸æ“šæ›´æ–°ï¼Œå»ºè­°åŸ·è¡Œå¢é‡æ›´æ–°"
                return 0
            fi
        fi
    fi
    
    echo "âœ… æ•¸æ“šæ–°é®®ï¼Œç„¡éœ€å¢é‡æ›´æ–°"
    return 1
}

# åŸ·è¡Œå¢é‡æ›´æ–°
execute_incremental_update() {
    echo "ğŸ”„ åŸ·è¡Œæ™ºèƒ½å¢é‡æ›´æ–°..."
    
    # ä½¿ç”¨å¢é‡æ›´æ–°ç®¡ç†å™¨
    cd /app
    if python -c "
from shared_core.incremental_update_manager import IncrementalUpdateManager
manager = IncrementalUpdateManager()
update_needed = manager.detect_tle_changes()
if update_needed:
    manager.execute_incremental_update(update_needed)
    print('âœ… å¢é‡æ›´æ–°å®Œæˆ')
else:
    print('â„¹ï¸ ç„¡éœ€æ›´æ–°')
    "; then
        echo "âœ… æ™ºèƒ½å¢é‡æ›´æ–°å®Œæˆ"
        return 0
    else
        echo "âš ï¸ å¢é‡æ›´æ–°å¤±æ•—ï¼Œç¹¼çºŒä½¿ç”¨ç¾æœ‰æ•¸æ“š"
        return 1
    fi
}

# é‹è¡Œæ™‚ç·Šæ€¥é‡æ–°ç”Ÿæˆï¼ˆæœ€å¾Œæ‰‹æ®µï¼‰
emergency_regenerate() {
    echo "ğŸš¨ ç·Šæ€¥æ¨¡å¼ï¼šåŸ·è¡Œé‹è¡Œæ™‚å®Œæ•´é‡æ–°ç”Ÿæˆ..."
    
    echo "ğŸ§¹ æ¸…ç†æ‰€æœ‰èˆŠçš„å…­éšæ®µé è™•ç†æª”æ¡ˆ..."
    # æ¸…ç†æ‰€æœ‰éšæ®µçš„è¼¸å‡ºç›®éŒ„
    rm -rf "$DATA_DIR/tle_calculation_outputs" 2>/dev/null || true
    rm -rf "$DATA_DIR/orbital_calculation_outputs" 2>/dev/null || true
    rm -rf "$DATA_DIR/intelligent_filtering_outputs" 2>/dev/null || true
    rm -rf "$DATA_DIR/signal_analysis_outputs" 2>/dev/null || true
    rm -rf "$DATA_DIR/timeseries_preprocessing_outputs" 2>/dev/null || true
    rm -rf "$DATA_DIR/data_integration_outputs" 2>/dev/null || true
    rm -rf "$DATA_DIR/dynamic_pool_planning_outputs" 2>/dev/null || true
    rm -rf "$DATA_DIR/signal_cache" 2>/dev/null || true
    rm -f "$DATA_DIR/data_integration_output.json" 2>/dev/null || true
    rm -f "$DATA_DIR/leo_optimization_final_report.json" 2>/dev/null || true
    # æ¸…ç†æ‰€æœ‰å…¶ä»– JSON æ–‡ä»¶
    find "$DATA_DIR" -name "*.json" -type f -delete 2>/dev/null || true
    echo "âœ… èˆŠæª”æ¡ˆæ¸…ç†å®Œæˆ"
    
    # åŸ·è¡Œå®Œæ•´å…­éšæ®µè™•ç†
    cd /app
    if timeout 2700 python scripts/run_six_stages.py --data-dir "$DATA_DIR"; then
        echo "âœ… ç·Šæ€¥é‡æ–°ç”Ÿæˆå®Œæˆ"
        echo "$(date -Iseconds)" > "$DATA_DIR/.runtime_generation"
        return 0
    else
        echo "âŒ ç·Šæ€¥é‡æ–°ç”Ÿæˆå¤±æ•—"
        return 1
    fi
}

# ä¸»é‚è¼¯ï¼šæ™ºèƒ½å•Ÿå‹•æ±ºç­–
echo "ğŸ§  æ™ºèƒ½å•Ÿå‹•æ±ºç­–é–‹å§‹..."

if check_build_time_data; then
    echo "âœ… ä½¿ç”¨å»ºæ§‹æ™‚é è™•ç†æ•¸æ“š - å¿«é€Ÿå•Ÿå‹•æ¨¡å¼"
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦å¢é‡æ›´æ–°
    if check_incremental_update_needed; then
        execute_incremental_update || echo "âš ï¸ å¢é‡æ›´æ–°å¤±æ•—ï¼Œç¹¼çºŒä½¿ç”¨ç¾æœ‰æ•¸æ“š"
    fi
    
    startup_time="< 10ç§’"
    
elif [ -f "/app/data/.runtime_generation" ]; then
    echo "âœ… ä½¿ç”¨é‹è¡Œæ™‚ç”Ÿæˆæ•¸æ“š"
    startup_time="å·²å°±ç·’"
    
else
    echo "âš ï¸ ç„¡å¯ç”¨é è™•ç†æ•¸æ“šï¼ŒåŸ·è¡Œç·Šæ€¥é‡æ–°ç”Ÿæˆ..."
    if emergency_regenerate; then
        startup_time="45åˆ†é˜ (ç·Šæ€¥æ¨¡å¼)"
    else
        echo "âŒ æ‰€æœ‰æ•¸æ“šç”Ÿæˆæ–¹æ¡ˆéƒ½å¤±æ•—ï¼Œå•Ÿå‹•åŸºç¤APIæœå‹™"
        startup_time="åŸºç¤æ¨¡å¼"
    fi
fi

echo "ğŸ¯ NetStack API æœå‹™å•Ÿå‹•ä¸­..."
echo "   é ä¼°å•Ÿå‹•æ™‚é–“: $startup_time"
echo "   æ•¸æ“šæ¨¡å¼: $([ -f "$BUILD_MODE_FILE" ] && echo "å»ºæ§‹æ™‚é è™•ç†" || echo "é‹è¡Œæ™‚è™•ç†")"

# åŸ·è¡Œå¯¦éš›çš„æ‡‰ç”¨ç¨‹å¼
exec "$@"