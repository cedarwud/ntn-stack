#!/usr/bin/env python3
"""
Phase 0: Docker å»ºç½®æ™‚é è¨ˆç®—æ•¸æ“šç”Ÿæˆ
åœ¨å®¹å™¨å»ºç½®éŽç¨‹ä¸­åŸ·è¡Œè»Œé“é è¨ˆç®—ï¼Œç¢ºä¿å•Ÿå‹•æ™‚æ•¸æ“šå³æ™‚å¯ç”¨
"""

import sys
import os
import json
import time
import logging
from pathlib import Path
from datetime import datetime

# æ·»åŠ è·¯å¾‘
sys.path.append("/app/src")
sys.path.append("/app")

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def main():
    """ä¸»å»ºç½®å‡½æ•¸"""
    logger.info("ðŸš€ é–‹å§‹ Phase 0 é è¨ˆç®—æ•¸æ“šå»ºç½®")

    build_start_time = time.time()

    try:
        # å°Žå…¥ Phase 0 æ¨¡çµ„
        from src.services.satellite.coordinate_specific_orbit_engine import (
            CoordinateSpecificOrbitEngine,
        )
        from src.services.satellite.local_tle_loader import LocalTLELoader
        from src.services.satellite.ntpu_visibility_filter import NTPUVisibilityFilter

        # åˆå§‹åŒ–çµ„ä»¶
        logger.info("ðŸ“¡ åˆå§‹åŒ–è»Œé“è¨ˆç®—å¼•æ“Ž")
        # NTPU åº§æ¨™ (å°ç£æ–°åŒ—å¸‚)
        observer_lat = 24.94417
        observer_lon = 121.37139
        orbit_engine = CoordinateSpecificOrbitEngine(observer_lat, observer_lon)
        tle_loader = LocalTLELoader("tle_data")
        visibility_filter = NTPUVisibilityFilter()

        # è¼‰å…¥ TLE æ•¸æ“š
        logger.info("ðŸ“Š è¼‰å…¥ TLE æ•¸æ“š")
        starlink_collection = tle_loader.load_collected_data("starlink")
        oneweb_collection = tle_loader.load_collected_data("oneweb")

        # æå–å¯¦éš›çš„è¡›æ˜Ÿæ•¸æ“š
        starlink_data = {}
        oneweb_data = {}

        if starlink_collection and "daily_data" in starlink_collection:
            # å–æœ€æ–°ä¸€å¤©çš„æ•¸æ“š
            daily_data = starlink_collection["daily_data"]
            if daily_data and len(daily_data) > 0:
                latest_data = daily_data[-1]  # å–æœ€å¾Œä¸€å¤©çš„æ•¸æ“š
                if "satellites" in latest_data:
                    starlink_data = {
                        sat["norad_id"]: sat for sat in latest_data["satellites"]
                    }
                    logger.info(f"ðŸ“¡ è¼‰å…¥ Starlink æ•¸æ“š: {len(starlink_data)} é¡†è¡›æ˜Ÿ")

        if oneweb_collection and "daily_data" in oneweb_collection:
            # å–æœ€æ–°ä¸€å¤©çš„æ•¸æ“š
            daily_data = oneweb_collection["daily_data"]
            if daily_data and len(daily_data) > 0:
                latest_data = daily_data[-1]  # å–æœ€å¾Œä¸€å¤©çš„æ•¸æ“š
                if "satellites" in latest_data:
                    oneweb_data = {
                        sat["norad_id"]: sat for sat in latest_data["satellites"]
                    }
                    logger.info(f"ðŸ“¡ è¼‰å…¥ OneWeb æ•¸æ“š: {len(oneweb_data)} é¡†è¡›æ˜Ÿ")

        if not starlink_data and not oneweb_data:
            logger.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ° TLE æ•¸æ“šï¼Œä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")
            # å‰µå»ºæ¨¡æ“¬æ•¸æ“šç”¨æ–¼å»ºç½®
            starlink_data = {
                str(i): sat
                for i, sat in enumerate(create_mock_tle_data("starlink", 100))
            }
            oneweb_data = {
                str(i): sat for i, sat in enumerate(create_mock_tle_data("oneweb", 50))
            }

        # åŸ·è¡Œé è¨ˆç®—
        logger.info("âš™ï¸ åŸ·è¡Œè»Œé“é è¨ˆç®—")

        from datetime import datetime

        precomputed_data = {
            "metadata": {
                "generation_timestamp": datetime.now().isoformat(),
                "build_time_seconds": 0,  # ç¨å¾Œæ›´æ–°
                "data_source": "phase0_build",
                "computation_type": "real_constellation_data",
            },
            "observer_location": {
                "name": "NTPU",
                "lat": 24.94417,
                "lon": 121.37139,
                "alt": 50.0,
            },
            "constellations": {},
        }

        # è™•ç† Starlink
        if starlink_data:
            logger.info("ðŸ›°ï¸ è™•ç† Starlink æ•¸æ“š")
            starlink_results = {}
            for sat_id, sat_data in starlink_data.items():
                try:
                    sat_results = orbit_engine.compute_120min_orbital_cycle(
                        sat_data, datetime.now()
                    )
                    starlink_results[sat_id] = sat_results
                except Exception as e:
                    logger.warning(f"è·³éŽè¡›æ˜Ÿ {sat_id}: {e}")
            logger.info(f"âœ… Starlink è™•ç†å®Œæˆ: {len(starlink_results)} é¡†è¡›æ˜Ÿ")
            precomputed_data["constellations"]["starlink"] = {
                "name": "STARLINK",
                "orbit_data": {
                    "metadata": {
                        "start_time": datetime.now().isoformat(),
                        "duration_minutes": 120,
                        "time_step_seconds": 30,
                        "total_time_points": 240,
                        "observer_location": {
                            "lat": observer_lat,
                            "lon": observer_lon,
                            "alt": 50.0,
                            "name": "NTPU",
                        },
                    },
                    "satellites": starlink_results,
                },
            }

        # è™•ç† OneWeb
        if oneweb_data:
            logger.info("ðŸ›°ï¸ è™•ç† OneWeb æ•¸æ“š")
            oneweb_results = {}
            for sat_id, sat_data in oneweb_data.items():
                try:
                    sat_results = orbit_engine.compute_120min_orbital_cycle(
                        sat_data, datetime.now()
                    )
                    oneweb_results[sat_id] = sat_results
                except Exception as e:
                    logger.warning(f"è·³éŽè¡›æ˜Ÿ {sat_id}: {e}")
            logger.info(f"âœ… OneWeb è™•ç†å®Œæˆ: {len(oneweb_results)} é¡†è¡›æ˜Ÿ")
            precomputed_data["constellations"]["oneweb"] = {
                "name": "ONEWEB",
                "orbit_data": {
                    "metadata": {
                        "start_time": datetime.now().isoformat(),
                        "duration_minutes": 120,
                        "time_step_seconds": 30,
                        "total_time_points": 240,
                        "observer_location": {
                            "lat": observer_lat,
                            "lon": observer_lon,
                            "alt": 50.0,
                            "name": "NTPU",
                        },
                    },
                    "satellites": oneweb_results,
                },
            }

        # æ›´æ–°å»ºç½®æ™‚é–“
        build_duration = time.time() - build_start_time
        precomputed_data["metadata"]["build_time_seconds"] = round(build_duration, 2)

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        output_dir = Path("/app/data")
        output_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜é è¨ˆç®—æ•¸æ“šï¼ˆåŽŸå§‹ JSONï¼‰
        output_file = output_dir / "phase0_precomputed_orbits.json"
        logger.info(f"ðŸ’¾ ä¿å­˜é è¨ˆç®—æ•¸æ“š: {output_file}")

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(precomputed_data, f, indent=2, ensure_ascii=False)


        # ç”Ÿæˆå»ºç½®æ‘˜è¦
        summary = {
            "build_timestamp": datetime.now().isoformat(),
            "build_duration_seconds": build_duration,
            "total_constellations": len(precomputed_data["constellations"]),
            "total_satellites": sum(
                len(constellation.get("orbit_data", {}).get("satellites", {}))
                for constellation in precomputed_data["constellations"].values()
            ),
            "visible_satellites": sum(
                len([sat for sat in constellation.get("orbit_data", {}).get("satellites", {}).values() 
                     if not sat.get("satellite_info", {}).get("status") == "not_visible"])
                for constellation in precomputed_data["constellations"].values()
            ),
            "output_file_size_bytes": (
                output_file.stat().st_size if output_file.exists() else 0
            ),
            "status": "success",
        }

        summary_file = output_dir / "phase0_build_summary.json"
        with open(summary_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)

        # Phase 2: ç”Ÿæˆ D2/A4/A5 äº‹ä»¶è³‡æ–™
        logger.info("ðŸŽ¯ é–‹å§‹ Phase 2: D2/A4/A5 äº‹ä»¶æª¢æ¸¬")
        try:
            from src.services.satellite.handover_event_detector import HandoverEventDetector
            
            # åˆå§‹åŒ–äº‹ä»¶æª¢æ¸¬å™¨
            event_detector = HandoverEventDetector(scene_id="ntpu")
            
            # è™•ç†è»Œé“è³‡æ–™ç”Ÿæˆäº‹ä»¶
            events_data = event_detector.process_orbit_data(precomputed_data)
            
            # ä¿å­˜äº‹ä»¶è³‡æ–™
            events_dir = output_dir / "events"
            events_dir.mkdir(exist_ok=True)
            
            events_file = events_dir / "ntpu_handover_events.json"
            logger.info(f"ðŸ“‹ ä¿å­˜äº‹ä»¶è³‡æ–™: {events_file}")
            
            with open(events_file, "w", encoding="utf-8") as f:
                json.dump(events_data, f, indent=2, ensure_ascii=False)
            
            # æ›´æ–°æ‘˜è¦
            summary.update({
                "events_generated": True,
                "total_d2_events": events_data["statistics"]["total_d2_events"],
                "total_a4_events": events_data["statistics"]["total_a4_events"],
                "total_a5_events": events_data["statistics"]["total_a5_events"],
                "events_file_size_bytes": events_file.stat().st_size if events_file.exists() else 0
            })
            
            logger.info(f"ðŸŽ¯ äº‹ä»¶ç”Ÿæˆå®Œæˆ: D2={summary['total_d2_events']}, A4={summary['total_a4_events']}, A5={summary['total_a5_events']}")
            
        except Exception as e:
            logger.error(f"âŒ Phase 2 äº‹ä»¶æª¢æ¸¬å¤±æ•—: {e}")
            summary["events_generated"] = False
            summary["events_error"] = str(e)

        logger.info(f"âœ… Phase 0+2 å»ºç½®å®Œæˆï¼è€—æ™‚ {build_duration:.2f}s")
        logger.info(f"ðŸ“Š è™•ç†è¡›æ˜Ÿæ•¸: {summary['total_satellites']}")
        logger.info(f"ðŸ’¾ è»Œé“æª”æ¡ˆå¤§å°: {summary['output_file_size_bytes']:,} bytes")
        if summary.get("events_generated"):
            logger.info(f"ðŸŽ¯ äº‹ä»¶æª”æ¡ˆå¤§å°: {summary.get('events_file_size_bytes', 0):,} bytes")

        # è‡ªå‹•åŒæ­¥æ•¸æ“šåˆ°å‰ç«¯ (å¦‚æžœåœ¨é–‹ç™¼ç’°å¢ƒä¸­)
        try:
            import subprocess

            sync_script = (
                Path(__file__).parent.parent / "scripts" / "sync-netstack-data.sh"
            )
            if sync_script.exists():
                logger.info("ðŸ”„ è‡ªå‹•åŒæ­¥æ•¸æ“šåˆ°å‰ç«¯...")
                result = subprocess.run(
                    [str(sync_script)], capture_output=True, text=True, timeout=30
                )
                if result.returncode == 0:
                    logger.info("âœ… æ•¸æ“šåŒæ­¥åˆ°å‰ç«¯æˆåŠŸ")
                else:
                    logger.warning("âš ï¸ æ•¸æ“šåŒæ­¥åˆ°å‰ç«¯å¤±æ•—ï¼Œå¯æ‰‹å‹•é‹è¡ŒåŒæ­¥è…³æœ¬")
            else:
                logger.info("â„¹ï¸ åŒæ­¥è…³æœ¬ä¸å­˜åœ¨ï¼Œè·³éŽè‡ªå‹•åŒæ­¥")
        except Exception as sync_error:
            logger.warning(f"âš ï¸ è‡ªå‹•åŒæ­¥éŽç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {sync_error}")
            logger.info("ðŸ’¡ å¯ä»¥æ‰‹å‹•é‹è¡Œ: scripts/sync-netstack-data.sh")

        return True

    except Exception as e:
        logger.error(f"âŒ Phase 0 å»ºç½®å¤±æ•—: {e}")

        # å‰µå»ºéŒ¯èª¤å ±å‘Š
        error_report = {
            "build_timestamp": datetime.now().isoformat(),
            "build_duration_seconds": time.time() - build_start_time,
            "status": "failed",
            "error_message": str(e),
            "error_type": type(e).__name__,
        }

        output_dir = Path("/app/data")
        output_dir.mkdir(parents=True, exist_ok=True)

        error_file = output_dir / "phase0_build_error.json"
        with open(error_file, "w", encoding="utf-8") as f:
            json.dump(error_report, f, indent=2, ensure_ascii=False)

        return False


def create_mock_tle_data(constellation: str, count: int) -> list:
    """å‰µå»ºæ¨¡æ“¬ TLE æ•¸æ“šç”¨æ–¼å»ºç½®æ¸¬è©¦"""
    logger.info(f"ðŸ”§ å‰µå»º {constellation} æ¨¡æ“¬æ•¸æ“š ({count} é¡†è¡›æ˜Ÿ)")

    mock_data = []
    base_norad_id = 44713 if constellation == "starlink" else 47844

    for i in range(count):
        satellite = {
            "name": f"{constellation.upper()}-{i+1}",
            "norad_id": str(base_norad_id + i),
            "line1": f"1 {base_norad_id + i:05d}U 19074A   21001.00000000  .00000000  00000-0  00000-0 0  9990",
            "line2": f"2 {base_norad_id + i:05d}  53.0000 290.0000 0001000  90.0000 270.0000 15.50000000000010",
        }
        mock_data.append(satellite)

    return mock_data


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
