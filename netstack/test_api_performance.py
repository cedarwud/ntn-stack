#!/usr/bin/env python3
"""
API æ€§èƒ½æ¸¬è©¦
å®Œæˆ Phase 4.1 è¦æ±‚ï¼šæ¸¬è©¦ API çš„æ€§èƒ½æŒ‡æ¨™å’Œè² è¼‰èƒ½åŠ›
"""

import sys
import os
import time
import statistics
import requests
import concurrent.futures
import threading
from datetime import datetime, timezone
import json

sys.path.append('/home/sat/ntn-stack/netstack')

class APIPerformanceTester:
    """API æ€§èƒ½æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.base_url = "http://localhost:8000"
        self.test_results = {}
        
    def measure_response_time(self, endpoint, method='GET', payload=None, iterations=10):
        """æ¸¬é‡ API éŸ¿æ‡‰æ™‚é–“"""
        response_times = []
        success_count = 0
        
        for i in range(iterations):
            start_time = time.time()
            try:
                if method == 'GET':
                    response = requests.get(f"{self.base_url}{endpoint}", timeout=10)
                elif method == 'POST':
                    response = requests.post(f"{self.base_url}{endpoint}", json=payload, timeout=10)
                
                end_time = time.time()
                response_time = end_time - start_time
                
                if response.status_code == 200:
                    response_times.append(response_time)
                    success_count += 1
                    
            except Exception as e:
                print(f"    è«‹æ±‚ {i+1} å¤±æ•—: {e}")
        
        if response_times:
            return {
                'avg_response_time': statistics.mean(response_times),
                'min_response_time': min(response_times),
                'max_response_time': max(response_times),
                'median_response_time': statistics.median(response_times),
                'success_rate': success_count / iterations,
                'total_requests': iterations
            }
        else:
            return None
    
    def test_sib19_api_performance(self):
        """æ¸¬è©¦ SIB19 API æ€§èƒ½"""
        print("ğŸ” æ¸¬è©¦ SIB19 API æ€§èƒ½")
        
        endpoints = [
            '/api/sib19/current',
            '/api/sib19/history',
            '/api/sib19/validate'
        ]
        
        all_passed = True
        
        for endpoint in endpoints:
            print(f"  æ¸¬è©¦ç«¯é»: {endpoint}")
            result = self.measure_response_time(endpoint, iterations=20)
            
            if result:
                avg_time = result['avg_response_time']
                success_rate = result['success_rate']
                
                print(f"    å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_time:.3f}s")
                print(f"    æˆåŠŸç‡: {success_rate:.1%}")
                print(f"    éŸ¿æ‡‰æ™‚é–“ç¯„åœ: {result['min_response_time']:.3f}s - {result['max_response_time']:.3f}s")
                
                # æ€§èƒ½æ¨™æº–ï¼šå¹³å‡éŸ¿æ‡‰æ™‚é–“ < 0.5sï¼ŒæˆåŠŸç‡ > 95%
                if avg_time < 0.5 and success_rate > 0.95:
                    print(f"    âœ… {endpoint} æ€§èƒ½åˆæ ¼")
                else:
                    print(f"    âŒ {endpoint} æ€§èƒ½ä¸åˆæ ¼")
                    all_passed = False
            else:
                print(f"    âŒ {endpoint} æ¸¬è©¦å¤±æ•—")
                all_passed = False
        
        return all_passed
    
    def test_measurement_events_api_performance(self):
        """æ¸¬è©¦æ¸¬é‡äº‹ä»¶ API æ€§èƒ½"""
        print("ğŸ” æ¸¬è©¦æ¸¬é‡äº‹ä»¶ API æ€§èƒ½")
        
        events = ['A4', 'D1', 'D2', 'T1']
        all_passed = True
        
        for event in events:
            print(f"  æ¸¬è©¦äº‹ä»¶: {event}")
            
            # æ¸¬è©¦æ•¸æ“šç²å–æ€§èƒ½
            data_endpoint = f'/api/measurement-events/{event}/data'
            result = self.measure_response_time(data_endpoint, iterations=15)
            
            if result:
                avg_time = result['avg_response_time']
                success_rate = result['success_rate']
                
                print(f"    æ•¸æ“šç²å–å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_time:.3f}s")
                print(f"    æ•¸æ“šç²å–æˆåŠŸç‡: {success_rate:.1%}")
                
                # æ¸¬è©¦é…ç½®æ›´æ–°æ€§èƒ½
                config_payload = {
                    'event_type': event,
                    'config': {
                        'measurement_interval': 1000,
                        'reporting_interval': 5000
                    }
                }
                
                config_result = self.measure_response_time(
                    '/api/measurement-events/configure',
                    method='POST',
                    payload=config_payload,
                    iterations=10
                )
                
                if config_result:
                    config_avg_time = config_result['avg_response_time']
                    config_success_rate = config_result['success_rate']
                    
                    print(f"    é…ç½®æ›´æ–°å¹³å‡éŸ¿æ‡‰æ™‚é–“: {config_avg_time:.3f}s")
                    print(f"    é…ç½®æ›´æ–°æˆåŠŸç‡: {config_success_rate:.1%}")
                    
                    # æ€§èƒ½æ¨™æº–ï¼šæ•¸æ“šç²å– < 0.3sï¼Œé…ç½®æ›´æ–° < 0.2sï¼ŒæˆåŠŸç‡ > 95%
                    if (avg_time < 0.3 and config_avg_time < 0.2 and 
                        success_rate > 0.95 and config_success_rate > 0.95):
                        print(f"    âœ… {event} äº‹ä»¶ API æ€§èƒ½åˆæ ¼")
                    else:
                        print(f"    âŒ {event} äº‹ä»¶ API æ€§èƒ½ä¸åˆæ ¼")
                        all_passed = False
                else:
                    print(f"    âŒ {event} äº‹ä»¶é…ç½®æ¸¬è©¦å¤±æ•—")
                    all_passed = False
            else:
                print(f"    âŒ {event} äº‹ä»¶æ•¸æ“šæ¸¬è©¦å¤±æ•—")
                all_passed = False
        
        return all_passed
    
    def test_orbit_calculation_performance(self):
        """æ¸¬è©¦è»Œé“è¨ˆç®—æ€§èƒ½"""
        print("ğŸ” æ¸¬è©¦è»Œé“è¨ˆç®—æ€§èƒ½")
        
        # æ¸¬è©¦å–®æ¬¡è»Œé“è¨ˆç®—
        payload = {
            'tle_line1': '1 25544U 98067A   21001.00000000  .00002182  00000-0  40768-4 0  9990',
            'tle_line2': '2 25544  51.6461 339.2911 0002829  86.3372 273.9164 15.48919103123456',
            'prediction_time': datetime.now(timezone.utc).isoformat()
        }
        
        result = self.measure_response_time(
            '/api/orbit/calculate-position',
            method='POST',
            payload=payload,
            iterations=25
        )
        
        if result:
            avg_time = result['avg_response_time']
            success_rate = result['success_rate']
            
            print(f"  å–®æ¬¡è»Œé“è¨ˆç®—å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_time:.3f}s")
            print(f"  è»Œé“è¨ˆç®—æˆåŠŸç‡: {success_rate:.1%}")
            
            # æ¸¬è©¦æ‰¹é‡è»Œé“è¨ˆç®—
            batch_payload = {
                'satellites': [
                    {
                        'tle_line1': '1 25544U 98067A   21001.00000000  .00002182  00000-0  40768-4 0  9990',
                        'tle_line2': '2 25544  51.6461 339.2911 0002829  86.3372 273.9164 15.48919103123456'
                    },
                    {
                        'tle_line1': '1 43013U 17073A   21001.00000000  .00000000  00000-0  00000-0 0  9990',
                        'tle_line2': '2 43013   0.0000   0.0000 0000000   0.0000   0.0000  1.00000000000000'
                    }
                ],
                'prediction_time': datetime.now(timezone.utc).isoformat()
            }
            
            batch_result = self.measure_response_time(
                '/api/orbit/calculate-batch',
                method='POST',
                payload=batch_payload,
                iterations=10
            )
            
            if batch_result:
                batch_avg_time = batch_result['avg_response_time']
                batch_success_rate = batch_result['success_rate']
                
                print(f"  æ‰¹é‡è»Œé“è¨ˆç®—å¹³å‡éŸ¿æ‡‰æ™‚é–“: {batch_avg_time:.3f}s")
                print(f"  æ‰¹é‡è»Œé“è¨ˆç®—æˆåŠŸç‡: {batch_success_rate:.1%}")
                
                # æ€§èƒ½æ¨™æº–ï¼šå–®æ¬¡ < 0.1sï¼Œæ‰¹é‡ < 0.5sï¼ŒæˆåŠŸç‡ > 98%
                if (avg_time < 0.1 and batch_avg_time < 0.5 and 
                    success_rate > 0.98 and batch_success_rate > 0.98):
                    print("  âœ… è»Œé“è¨ˆç®—æ€§èƒ½åˆæ ¼")
                    return True
                else:
                    print("  âŒ è»Œé“è¨ˆç®—æ€§èƒ½ä¸åˆæ ¼")
                    return False
            else:
                print("  âŒ æ‰¹é‡è»Œé“è¨ˆç®—æ¸¬è©¦å¤±æ•—")
                return False
        else:
            print("  âŒ è»Œé“è¨ˆç®—æ¸¬è©¦å¤±æ•—")
            return False
    
    def test_concurrent_load(self):
        """æ¸¬è©¦ä¸¦ç™¼è² è¼‰"""
        print("ğŸ” æ¸¬è©¦ä¸¦ç™¼è² è¼‰")
        
        def make_concurrent_request(endpoint):
            """ç™¼é€ä¸¦ç™¼è«‹æ±‚"""
            try:
                start_time = time.time()
                response = requests.get(f"{self.base_url}{endpoint}", timeout=10)
                end_time = time.time()
                return {
                    'status_code': response.status_code,
                    'response_time': end_time - start_time,
                    'success': response.status_code == 200
                }
            except Exception as e:
                return {
                    'status_code': 0,
                    'response_time': 10.0,
                    'success': False,
                    'error': str(e)
                }
        
        # æ¸¬è©¦ä¸åŒä¸¦ç™¼ç´šåˆ¥
        concurrency_levels = [5, 10, 20, 50]
        endpoint = '/api/sib19/current'
        
        all_passed = True
        
        for concurrency in concurrency_levels:
            print(f"  æ¸¬è©¦ä¸¦ç™¼ç´šåˆ¥: {concurrency}")
            
            start_time = time.time()
            with concurrent.futures.ThreadPoolExecutor(max_workers=concurrency) as executor:
                futures = [executor.submit(make_concurrent_request, endpoint) for _ in range(concurrency)]
                results = [future.result() for future in futures]
            
            total_time = time.time() - start_time
            
            success_count = sum(1 for r in results if r['success'])
            success_rate = success_count / concurrency
            avg_response_time = statistics.mean([r['response_time'] for r in results if r['success']])
            throughput = concurrency / total_time
            
            print(f"    æˆåŠŸç‡: {success_rate:.1%} ({success_count}/{concurrency})")
            print(f"    å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_response_time:.3f}s")
            print(f"    ååé‡: {throughput:.1f} è«‹æ±‚/ç§’")
            print(f"    ç¸½è€—æ™‚: {total_time:.3f}s")
            
            # æ€§èƒ½æ¨™æº–ï¼šæˆåŠŸç‡ > 90%ï¼Œå¹³å‡éŸ¿æ‡‰æ™‚é–“ < 2s
            if success_rate > 0.9 and avg_response_time < 2.0:
                print(f"    âœ… ä¸¦ç™¼ç´šåˆ¥ {concurrency} æ¸¬è©¦é€šé")
            else:
                print(f"    âŒ ä¸¦ç™¼ç´šåˆ¥ {concurrency} æ¸¬è©¦å¤±æ•—")
                all_passed = False
        
        return all_passed
    
    def test_memory_and_cpu_usage(self):
        """æ¸¬è©¦è¨˜æ†¶é«”å’Œ CPU ä½¿ç”¨æƒ…æ³"""
        print("ğŸ” æ¸¬è©¦è¨˜æ†¶é«”å’Œ CPU ä½¿ç”¨æƒ…æ³")
        
        try:
            import psutil
            
            # ç²å–ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            
            print(f"  ç•¶å‰ CPU ä½¿ç”¨ç‡: {cpu_percent:.1f}%")
            print(f"  ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨ç‡: {memory.percent:.1f}%")
            print(f"  å¯ç”¨è¨˜æ†¶é«”: {memory.available / 1024 / 1024 / 1024:.1f} GB")
            
            # åŸ·è¡Œè² è¼‰æ¸¬è©¦ä¸¦ç›£æ§è³‡æºä½¿ç”¨
            print("  åŸ·è¡Œè² è¼‰æ¸¬è©¦...")
            
            def stress_test():
                for _ in range(50):
                    requests.get(f"{self.base_url}/api/sib19/current", timeout=5)
            
            # å•Ÿå‹•è² è¼‰æ¸¬è©¦
            with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
                futures = [executor.submit(stress_test) for _ in range(5)]
                
                # ç›£æ§è³‡æºä½¿ç”¨
                max_cpu = 0
                max_memory = 0
                
                for _ in range(10):
                    time.sleep(1)
                    cpu = psutil.cpu_percent()
                    mem = psutil.virtual_memory().percent
                    max_cpu = max(max_cpu, cpu)
                    max_memory = max(max_memory, mem)
                
                # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
                for future in futures:
                    future.result()
            
            print(f"  è² è¼‰æ¸¬è©¦æœŸé–“æœ€å¤§ CPU ä½¿ç”¨ç‡: {max_cpu:.1f}%")
            print(f"  è² è¼‰æ¸¬è©¦æœŸé–“æœ€å¤§è¨˜æ†¶é«”ä½¿ç”¨ç‡: {max_memory:.1f}%")
            
            # æ€§èƒ½æ¨™æº–ï¼šCPU < 80%ï¼Œè¨˜æ†¶é«” < 85%
            if max_cpu < 80 and max_memory < 85:
                print("  âœ… è³‡æºä½¿ç”¨æƒ…æ³æ­£å¸¸")
                return True
            else:
                print("  âŒ è³‡æºä½¿ç”¨æƒ…æ³ç•°å¸¸")
                return False
                
        except ImportError:
            print("  âš ï¸ psutil æœªå®‰è£ï¼Œè·³éè³‡æºç›£æ§æ¸¬è©¦")
            return True
        except Exception as e:
            print(f"  âŒ è³‡æºç›£æ§æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def run_all_tests(self):
        """é‹è¡Œæ‰€æœ‰æ€§èƒ½æ¸¬è©¦"""
        print("ğŸš€ é–‹å§‹ API æ€§èƒ½æ¸¬è©¦")
        print("=" * 60)
        
        tests = [
            ("SIB19 API æ€§èƒ½", self.test_sib19_api_performance),
            ("æ¸¬é‡äº‹ä»¶ API æ€§èƒ½", self.test_measurement_events_api_performance),
            ("è»Œé“è¨ˆç®—æ€§èƒ½", self.test_orbit_calculation_performance),
            ("ä¸¦ç™¼è² è¼‰æ¸¬è©¦", self.test_concurrent_load),
            ("è³‡æºä½¿ç”¨ç›£æ§", self.test_memory_and_cpu_usage)
        ]
        
        passed_tests = 0
        
        for test_name, test_func in tests:
            print(f"\nğŸ“‹ {test_name}")
            print("-" * 40)
            try:
                if test_func():
                    passed_tests += 1
                    self.test_results[test_name] = "PASS"
                    print(f"âœ… {test_name} æ¸¬è©¦é€šé")
                else:
                    self.test_results[test_name] = "FAIL"
                    print(f"âŒ {test_name} æ¸¬è©¦å¤±æ•—")
            except Exception as e:
                self.test_results[test_name] = f"ERROR: {e}"
                print(f"âŒ {test_name} æ¸¬è©¦éŒ¯èª¤: {e}")
        
        print("\n" + "=" * 60)
        print("ğŸ“Š API æ€§èƒ½æ¸¬è©¦çµæœçµ±è¨ˆ")
        print("=" * 60)
        print(f"ğŸ“ˆ ç¸½é«”é€šéç‡: {passed_tests}/{len(tests)} ({(passed_tests/len(tests)*100):.1f}%)")
        
        if passed_tests == len(tests):
            print("ğŸ‰ æ‰€æœ‰æ€§èƒ½æ¸¬è©¦é€šéï¼API æ€§èƒ½å„ªç§€ã€‚")
            return 0
        elif passed_tests >= len(tests) * 0.8:
            print("âœ… å¤§éƒ¨åˆ†æ€§èƒ½æ¸¬è©¦é€šéï¼ŒAPI æ€§èƒ½è‰¯å¥½ã€‚")
            return 0
        else:
            print("âš ï¸ å¤šé …æ€§èƒ½æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦æ€§èƒ½å„ªåŒ–ã€‚")
            return 1

def main():
    """ä¸»å‡½æ•¸"""
    tester = APIPerformanceTester()
    return tester.run_all_tests()

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
