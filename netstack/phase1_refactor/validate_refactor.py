#!/usr/bin/env python3
"""
Phase 1 é‡æ§‹é©—è­‰è…³æœ¬

åŠŸèƒ½:
1. é©—è­‰é‡æ§‹å¾Œçš„ Phase 1 æ¶æ§‹å®Œæ•´æ€§
2. ç¢ºèªç®—æ³•å’Œæ•¸æ“šä¾†æºç¬¦åˆ CLAUDE.md åŸå‰‡
3. æ¸¬è©¦å„å€‹æ¨¡çµ„çš„åŸºæœ¬åŠŸèƒ½

åŸ·è¡Œæ–¹å¼:
    python validate_refactor.py
"""

import os
import sys
import logging
import traceback
from pathlib import Path
from datetime import datetime, timezone

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def validate_directory_structure():
    """é©—è­‰ç›®éŒ„çµæ§‹"""
    logger.info("ğŸ” é©—è­‰ Phase 1 é‡æ§‹ç›®éŒ„çµæ§‹...")
    
    required_dirs = [
        "01_data_source",
        "02_orbit_calculation", 
        "03_processing_pipeline",
        "04_output_interface",
        "05_integration",
        "config",
        "docs",
        "migration"
    ]
    
    required_files = [
        "README.md",
        "01_data_source/tle_loader.py",
        "02_orbit_calculation/sgp4_engine.py",
        "03_processing_pipeline/phase1_coordinator.py",
        "docs/algorithm_specification.md",
        "migration/phase0_to_phase1_mapping.md"
    ]
    
    base_dir = Path(__file__).parent
    
    # æª¢æŸ¥ç›®éŒ„
    for dir_name in required_dirs:
        dir_path = base_dir / dir_name
        if dir_path.exists():
            logger.info(f"   âœ… ç›®éŒ„å­˜åœ¨: {dir_name}")
        else:
            logger.error(f"   âŒ ç›®éŒ„ç¼ºå¤±: {dir_name}")
            return False
    
    # æª¢æŸ¥æ–‡ä»¶
    for file_name in required_files:
        file_path = base_dir / file_name
        if file_path.exists():
            logger.info(f"   âœ… æª”æ¡ˆå­˜åœ¨: {file_name}")
        else:
            logger.error(f"   âŒ æª”æ¡ˆç¼ºå¤±: {file_name}")
            return False
    
    logger.info("âœ… ç›®éŒ„çµæ§‹é©—è­‰é€šé")
    return True

def validate_sgp4_availability():
    """é©—è­‰ SGP4 åº«å¯ç”¨æ€§"""
    logger.info("ğŸ” é©—è­‰ SGP4 åº«å¯ç”¨æ€§...")
    
    try:
        from sgp4.api import Satrec, jday
        from sgp4.earth_gravity import wgs72
        logger.info("   âœ… SGP4 å®˜æ–¹åº«å°å…¥æˆåŠŸ")
        
        # æ¸¬è©¦ SGP4 åŸºæœ¬åŠŸèƒ½
        line1 = "1 25544U 98067A   21001.00000000  .00001817  00000-0  41860-4 0  9990"
        line2 = "2 25544  51.6461 290.5094 0000597  91.8164 268.3516 15.48919103262509"
        
        satellite = Satrec.twoline2rv(line1, line2)
        if satellite is not None:
            logger.info("   âœ… SGP4 è¡›æ˜Ÿå°è±¡å‰µå»ºæˆåŠŸ")
            
            # æ¸¬è©¦è¨ˆç®—
            now = datetime.now(timezone.utc)
            jd, fr = jday(now.year, now.month, now.day, now.hour, now.minute, now.second)
            error, position, velocity = satellite.sgp4(jd, fr)
            
            if error == 0:
                logger.info("   âœ… SGP4 è»Œé“è¨ˆç®—æ¸¬è©¦é€šé")
                return True
            else:
                logger.error(f"   âŒ SGP4 è¨ˆç®—éŒ¯èª¤: {error}")
                return False
        else:
            logger.error("   âŒ SGP4 è¡›æ˜Ÿå°è±¡å‰µå»ºå¤±æ•—")
            return False
            
    except ImportError as e:
        logger.error(f"   âŒ SGP4 åº«å°å…¥å¤±æ•—: {e}")
        return False
    except Exception as e:
        logger.error(f"   âŒ SGP4 æ¸¬è©¦ç•°å¸¸: {e}")
        return False

def validate_module_imports():
    """é©—è­‰æ¨¡çµ„å°å…¥"""
    logger.info("ğŸ” é©—è­‰ Phase 1 æ¨¡çµ„å°å…¥...")
    
    base_dir = Path(__file__).parent
    sys.path.insert(0, str(base_dir))
    
    modules_to_test = [
        ("01_data_source.tle_loader", "TLELoader"),
        ("02_orbit_calculation.sgp4_engine", "SGP4Engine"),
        ("03_processing_pipeline.phase1_coordinator", "Phase1Coordinator")
    ]
    
    for module_name, class_name in modules_to_test:
        try:
            module = __import__(module_name, fromlist=[class_name])
            cls = getattr(module, class_name)
            logger.info(f"   âœ… æ¨¡çµ„å°å…¥æˆåŠŸ: {module_name}.{class_name}")
        except ImportError as e:
            logger.error(f"   âŒ æ¨¡çµ„å°å…¥å¤±æ•— {module_name}: {e}")
            return False
        except Exception as e:
            logger.error(f"   âŒ æ¨¡çµ„æ¸¬è©¦ç•°å¸¸ {module_name}: {e}")
            return False
    
    logger.info("âœ… æ¨¡çµ„å°å…¥é©—è­‰é€šé")
    return True

def validate_algorithm_compliance():
    """é©—è­‰ç®—æ³•ç¬¦åˆ CLAUDE.md åŸå‰‡"""
    logger.info("ğŸ” é©—è­‰ç®—æ³•ç¬¦åˆ CLAUDE.md åŸå‰‡...")
    
    # æª¢æŸ¥ç®—æ³•è¦æ ¼æ–‡æª”
    base_dir = Path(__file__).parent
    algo_spec_file = base_dir / "docs" / "algorithm_specification.md"
    
    if not algo_spec_file.exists():
        logger.error("   âŒ ç®—æ³•è¦æ ¼æ–‡æª”ä¸å­˜åœ¨")
        return False
    
    # è®€å–ç®—æ³•è¦æ ¼
    with open(algo_spec_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æª¢æŸ¥é—œéµåˆè¦è¦ç´ 
    compliance_checks = [
        ("SGP4 ç®—æ³•", "SGP4"),
        ("çœŸå¯¦æ•¸æ“š", "çœŸå¯¦æ•¸æ“š"),
        ("å®Œæ•´å¯¦ç¾", "å®Œæ•´å¯¦ç¾"), 
        ("ç±³ç´šç²¾åº¦", "ç±³ç´šç²¾åº¦"),
        ("ç¦æ­¢ç°¡åŒ–", "ç¦æ­¢"),
        ("CLAUDE.md åŸå‰‡", "CLAUDE.md")
    ]
    
    for check_name, keyword in compliance_checks:
        if keyword.lower() in content.lower():
            logger.info(f"   âœ… {check_name}: ç¬¦åˆè¦æ±‚")
        else:
            logger.warning(f"   âš ï¸  {check_name}: æ–‡æª”ä¸­æœªæ˜ç¢ºæåŠ")
    
    logger.info("âœ… ç®—æ³•åˆè¦æ€§é©—è­‰é€šé")
    return True

def validate_data_sources():
    """é©—è­‰æ•¸æ“šä¾†æºé…ç½®"""
    logger.info("ğŸ” é©—è­‰æ•¸æ“šä¾†æºé…ç½®...")
    
    # æª¢æŸ¥ TLE æ•¸æ“šç›®éŒ„ (å¦‚æœå­˜åœ¨)
    tle_dirs = [
        "/netstack/tle_data",
        "/home/sat/ntn-stack/netstack/tle_data"
    ]
    
    tle_found = False
    for tle_dir in tle_dirs:
        if Path(tle_dir).exists():
            logger.info(f"   âœ… TLE æ•¸æ“šç›®éŒ„å­˜åœ¨: {tle_dir}")
            
            # æª¢æŸ¥æ˜Ÿåº§å­ç›®éŒ„
            starlink_dir = Path(tle_dir) / "starlink"
            oneweb_dir = Path(tle_dir) / "oneweb"
            
            if starlink_dir.exists():
                tle_files = list(starlink_dir.glob("*.tle"))
                logger.info(f"   âœ… Starlink TLE æª”æ¡ˆ: {len(tle_files)} å€‹")
                tle_found = True
                
            if oneweb_dir.exists():
                tle_files = list(oneweb_dir.glob("*.tle"))
                logger.info(f"   âœ… OneWeb TLE æª”æ¡ˆ: {len(tle_files)} å€‹")
                tle_found = True
                
            break
    
    if not tle_found:
        logger.warning("   âš ï¸  TLE æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨ï¼Œé‹è¡Œæ™‚éœ€è¦ç¢ºä¿æ•¸æ“šå¯ç”¨")
    else:
        logger.info("âœ… æ•¸æ“šä¾†æºé©—è­‰é€šé")
    
    return True

def validate_phase2_interface():
    """é©—è­‰ Phase 2 æ¥å£æº–å‚™"""
    logger.info("ğŸ” é©—è­‰ Phase 2 æ¥å£æº–å‚™...")
    
    base_dir = Path(__file__).parent
    
    # æª¢æŸ¥æ¥å£æ–‡æª”
    expected_interface_files = [
        "04_output_interface",
        "migration/phase0_to_phase1_mapping.md"
    ]
    
    for item in expected_interface_files:
        path = base_dir / item
        if path.exists():
            logger.info(f"   âœ… Phase 2 æ¥å£æº–å‚™: {item}")
        else:
            logger.warning(f"   âš ï¸  Phase 2 æ¥å£é …ç›®ç¼ºå¤±: {item}")
    
    logger.info("âœ… Phase 2 æ¥å£é©—è­‰é€šé")
    return True

def generate_validation_report():
    """ç”Ÿæˆé©—è­‰å ±å‘Š"""
    logger.info("ğŸ“Š ç”Ÿæˆé©—è­‰å ±å‘Š...")
    
    timestamp = datetime.now().isoformat()
    
    report = {
        "validation_timestamp": timestamp,
        "phase1_refactor_status": "validation_complete",
        "validation_results": {
            "directory_structure": "âœ… PASS",
            "sgp4_availability": "âœ… PASS", 
            "module_imports": "âœ… PASS",
            "algorithm_compliance": "âœ… PASS",
            "data_sources": "âœ… PASS",
            "phase2_interface": "âœ… PASS"
        },
        "summary": {
            "total_checks": 6,
            "passed_checks": 6,
            "failed_checks": 0,
            "overall_status": "READY_FOR_INTEGRATION"
        },
        "next_steps": [
            "åŸ·è¡Œå®Œæ•´çš„ Phase 1 è™•ç†æµç¨‹æ¸¬è©¦",
            "é©—è­‰èˆ‡ç¾æœ‰ç³»çµ±çš„æ•´åˆ",
            "éƒ¨ç½² Phase 1 é‡æ§‹ç‰ˆæœ¬",
            "æ›´æ–°ç›¸é—œæ–‡æª”å’Œ API èªªæ˜"
        ]
    }
    
    base_dir = Path(__file__).parent
    report_file = base_dir / "validation_report.json"
    
    import json
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"âœ… é©—è­‰å ±å‘Šå·²ä¿å­˜: {report_file}")
    return report

def main():
    """ä¸»é©—è­‰æµç¨‹"""
    logger.info("ğŸš€ é–‹å§‹ Phase 1 é‡æ§‹é©—è­‰")
    logger.info("=" * 60)
    
    validation_steps = [
        ("ç›®éŒ„çµæ§‹", validate_directory_structure),
        ("SGP4 åº«å¯ç”¨æ€§", validate_sgp4_availability), 
        ("æ¨¡çµ„å°å…¥", validate_module_imports),
        ("ç®—æ³•åˆè¦æ€§", validate_algorithm_compliance),
        ("æ•¸æ“šä¾†æº", validate_data_sources),
        ("Phase 2 æ¥å£", validate_phase2_interface)
    ]
    
    passed = 0
    failed = 0
    
    for step_name, validation_func in validation_steps:
        try:
            logger.info(f"\nğŸ”„ åŸ·è¡Œé©—è­‰: {step_name}")
            if validation_func():
                passed += 1
            else:
                failed += 1
                logger.error(f"âŒ é©—è­‰å¤±æ•—: {step_name}")
        except Exception as e:
            failed += 1
            logger.error(f"âŒ é©—è­‰ç•°å¸¸ {step_name}: {e}")
            logger.error(traceback.format_exc())
    
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š Phase 1 é‡æ§‹é©—è­‰çµæœ")
    logger.info(f"   é€šé: {passed} / {len(validation_steps)}")
    logger.info(f"   å¤±æ•—: {failed} / {len(validation_steps)}")
    
    if failed == 0:
        logger.info("ğŸ‰ æ‰€æœ‰é©—è­‰é€šéï¼Phase 1 é‡æ§‹æº–å‚™å°±ç·’")
        generate_validation_report()
        return True
    else:
        logger.error("âŒ éƒ¨åˆ†é©—è­‰å¤±æ•—ï¼Œéœ€è¦ä¿®å¾©å¾Œå†æ¬¡é©—è­‰")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)