#!/usr/bin/env python3
"""
ğŸ§ª Phase 1.2 åŸºç¤åŠŸèƒ½æ¸¬è©¦
æ¸¬è©¦æ ¸å¿ƒçµ„ä»¶ï¼šå€‰åº«å·¥å» ã€é…ç½®ç®¡ç†ã€æœå‹™å®šä½å™¨
"""

import asyncio
import logging
import sys
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, Any

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

# ç›´æ¥å°å…¥æ¨¡çµ„é¿å… __init__.py çš„ä¾è³´å•é¡Œ
sys.path.append(str(Path(__file__).parent))

from core.repository_factory import RepositoryFactory, RepositoryType, RepositoryConfig
from core.di_container import DIContainer, ServiceScope
from interfaces.data_repository import (
    ExperimentSession, TrainingEpisode, ModelVersion, 
    PerformanceMetric, MetricType, ScenarioType
)

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class BasicPhase12Tester:
    """Phase 1.2 åŸºç¤æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.test_results: Dict[str, Any] = {
            "total_tests": 0,
            "passed_tests": 0,
            "failed_tests": 0,
            "test_details": []
        }
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        logger.info("ğŸš€ é–‹å§‹ Phase 1.2 åŸºç¤åŠŸèƒ½æ¸¬è©¦")
        
        try:
            # æ¸¬è©¦å€‰åº«å·¥å» 
            await self._test_repository_factory()
            
            # æ¸¬è©¦ä¾è³´æ³¨å…¥å®¹å™¨
            await self._test_di_container()
            
            # æ¸¬è©¦æ•¸æ“šæ“ä½œï¼ˆMock æ¨¡å¼ï¼‰
            await self._test_data_operations()
            
            # æ¸¬è©¦é…ç½®ç³»çµ±
            await self._test_configuration()
            
            # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
            await self._generate_test_report()
            
        except Exception as e:
            logger.error(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
            self._record_test("overall_execution", False, f"Exception: {e}")
        
        finally:
            # æ¸…ç†è³‡æº
            await self._cleanup()
        
        return self.test_results
    
    async def _test_repository_factory(self) -> None:
        """æ¸¬è©¦å€‰åº«å·¥å» """
        logger.info("ğŸ­ æ¸¬è©¦å€‰åº«å·¥å» ...")
        
        try:
            # æ¸¬è©¦é…ç½®é¡
            config = RepositoryConfig()
            self._record_test("repository_config", True, f"é…ç½®ç’°å¢ƒ: {config.environment}")
            
            # æ¸¬è©¦ Mock å€‰åº«å‰µå»º
            mock_repo = await RepositoryFactory.create_repository(
                repository_type=RepositoryType.MOCK,
                use_singleton=False
            )
            self._record_test("mock_repository_creation", True, "æˆåŠŸå‰µå»º Mock å€‰åº«")
            
            # æ¸¬è©¦å€‰åº«å¥åº·æª¢æŸ¥
            health = await mock_repo.get_database_health()
            if health["status"] == "healthy":
                self._record_test("repository_health_check", True, "å€‰åº«å¥åº·æª¢æŸ¥é€šé")
            else:
                self._record_test("repository_health_check", False, f"å¥åº·æª¢æŸ¥å¤±æ•—: {health}")
            
            # æ¸¬è©¦å·¥å» è³‡è¨Š
            factory_info = RepositoryFactory.get_instance_info()
            self._record_test("factory_info", True, f"å·¥å» è³‡è¨Š: {factory_info}")
            
            # æ¸¬è©¦é¡å‹æ¨æ–·
            inferred_type = RepositoryFactory._infer_repository_type()
            self._record_test("type_inference", True, f"æ¨æ–·é¡å‹: {inferred_type.value}")
            
        except Exception as e:
            self._record_test("repository_factory", False, f"Exception: {e}")
    
    async def _test_di_container(self) -> None:
        """æ¸¬è©¦ä¾è³´æ³¨å…¥å®¹å™¨"""
        logger.info("ğŸ”— æ¸¬è©¦ä¾è³´æ³¨å…¥å®¹å™¨...")
        
        try:
            # å‰µå»ºå®¹å™¨
            container = DIContainer()
            self._record_test("container_creation", True, "æˆåŠŸå‰µå»ºå®¹å™¨")
            
            # æ¸¬è©¦ Mock å€‰åº«è¨»å†Š
            from implementations.mock_repository import MockRepository
            from interfaces.data_repository import IDataRepository
            
            container.register_singleton(IDataRepository, MockRepository)
            self._record_test("service_registration", True, "æˆåŠŸè¨»å†Šæœå‹™")
            
            # æ¸¬è©¦æœå‹™è§£æ
            repository = container.resolve(IDataRepository)
            self._record_test("service_resolution", True, f"æˆåŠŸè§£ææœå‹™: {type(repository).__name__}")
            
            # æ¸¬è©¦è¨»å†Šè³‡è¨Š
            reg_info = container.get_registration_info()
            self._record_test("registration_info", True, f"è¨»å†Šè³‡è¨Š: {len(reg_info)} å€‹æœå‹™")
            
            # æ¸¬è©¦é©—è­‰
            errors = container.validate_registrations()
            if not errors:
                self._record_test("container_validation", True, "å®¹å™¨é©—è­‰é€šé")
            else:
                self._record_test("container_validation", False, f"é©—è­‰éŒ¯èª¤: {errors}")
            
        except Exception as e:
            self._record_test("di_container", False, f"Exception: {e}")
    
    async def _test_data_operations(self) -> None:
        """æ¸¬è©¦æ•¸æ“šæ“ä½œï¼ˆMock æ¨¡å¼ï¼‰"""
        logger.info("ğŸ’¾ æ¸¬è©¦æ•¸æ“šæ“ä½œ...")
        
        try:
            # å‰µå»º Mock å€‰åº«
            repository = await RepositoryFactory.create_repository(
                repository_type=RepositoryType.MOCK,
                use_singleton=False
            )
            
            # æ¸¬è©¦å¯¦é©—æœƒè©±å‰µå»º
            session = ExperimentSession(
                experiment_name="Phase12_Basic_Test",
                algorithm_type="DQN",
                scenario_type=ScenarioType.URBAN,
                researcher_id="test_user",
                hyperparameters={"learning_rate": 0.001},
                environment_config={"satellites": 100}
            )
            
            session_id = await repository.create_experiment_session(session)
            if session_id > 0:
                self._record_test("experiment_session_creation", True, f"å‰µå»ºæœƒè©± ID: {session_id}")
            else:
                self._record_test("experiment_session_creation", False, "æœƒè©±å‰µå»ºå¤±æ•—")
            
            # æ¸¬è©¦æœƒè©±æŸ¥è©¢
            retrieved_session = await repository.get_experiment_session(session_id)
            if retrieved_session:
                self._record_test("session_retrieval", True, f"æˆåŠŸæŸ¥è©¢æœƒè©±: {retrieved_session.experiment_name}")
            else:
                self._record_test("session_retrieval", False, "æœƒè©±æŸ¥è©¢å¤±æ•—")
            
            # æ¸¬è©¦è¨“ç·´å›åˆå‰µå»º
            episode = TrainingEpisode(
                session_id=session_id,
                episode_number=1,
                total_reward=100.5,
                success_rate=0.95,
                handover_latency_ms=25.0,
                decision_confidence=0.88,
                candidate_satellites=["sat1", "sat2"],
                decision_reasoning={"factors": ["signal_strength", "latency"]},
                algorithm_type="DQN",
                scenario_type="urban",
                training_time_ms=500,
                convergence_indicator=0.85
            )
            
            episode_id = await repository.create_training_episode(episode)
            if episode_id > 0:
                self._record_test("training_episode_creation", True, f"å‰µå»ºå›åˆ ID: {episode_id}")
            else:
                self._record_test("training_episode_creation", False, "å›åˆå‰µå»ºå¤±æ•—")
            
            # æ¸¬è©¦å›åˆæŸ¥è©¢
            episodes = await repository.get_training_episodes(session_id, limit=10)
            self._record_test("episodes_retrieval", True, f"æŸ¥è©¢åˆ° {len(episodes)} å€‹å›åˆ")
            
            # æ¸¬è©¦æ€§èƒ½æŒ‡æ¨™å­˜å„²
            metric = PerformanceMetric(
                session_id=session_id,
                timestamp=datetime.now(),
                algorithm_type="DQN",
                metric_type=MetricType.REWARD,
                metric_value=100.5,
                episode_number=1,
                scenario_type="urban",
                additional_data={"test": True}
            )
            
            metric_stored = await repository.store_performance_metric(metric)
            self._record_test("performance_metric_storage", metric_stored, "æ€§èƒ½æŒ‡æ¨™å­˜å„²")
            
            # æ¸¬è©¦æ¨¡å‹ç‰ˆæœ¬å‰µå»º
            model = ModelVersion(
                algorithm_type="DQN",
                version_number="1.0.0",
                model_path="/models/dqn_v1.pth",
                model_size_bytes=1024000,
                training_episodes=1000,
                validation_score=0.92,
                hyperparameters={"learning_rate": 0.001},
                training_duration_seconds=3600,
                created_by="test_user",
                notes="Phase 1.2 basic test model"
            )
            
            model_id = await repository.create_model_version(model)
            if model_id > 0:
                self._record_test("model_version_creation", True, f"å‰µå»ºæ¨¡å‹ ID: {model_id}")
            else:
                self._record_test("model_version_creation", False, "æ¨¡å‹å‰µå»ºå¤±æ•—")
            
            # æ¸¬è©¦çµ±è¨ˆåˆ†æ
            stats = await repository.get_algorithm_statistics("DQN", ScenarioType.URBAN)
            self._record_test("algorithm_statistics", True, f"çµ±è¨ˆæ•¸æ“š: {stats}")
            
        except Exception as e:
            self._record_test("data_operations", False, f"Exception: {e}")
    
    async def _test_configuration(self) -> None:
        """æ¸¬è©¦é…ç½®ç³»çµ±"""
        logger.info("âš™ï¸ æ¸¬è©¦é…ç½®ç³»çµ±...")
        
        try:
            # æ¸¬è©¦é…ç½®æ–‡ä»¶è·¯å¾‘æª¢æŸ¥
            config_path = Path(__file__).parent / "config" / "rl_config.yaml"
            config_exists = config_path.exists()
            self._record_test("config_file_exists", config_exists, f"é…ç½®æ–‡ä»¶: {config_path}")
            
            # æ¸¬è©¦ç’°å¢ƒè®Šæ•¸é…ç½®
            os.environ["REPOSITORY_TYPE"] = "mock"
            os.environ["MOCK_DATA_ENABLED"] = "true"
            
            config = RepositoryConfig()
            self._record_test("env_config", True, f"ç’°å¢ƒé…ç½® - Mock: {config.mock_enabled}")
            
            # æ¸¬è©¦é…ç½®é©—è­‰
            is_valid = config.validate()
            self._record_test("config_validation", is_valid, "é…ç½®é©—è­‰")
            
        except Exception as e:
            self._record_test("configuration", False, f"Exception: {e}")
    
    async def _generate_test_report(self) -> None:
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆæ¸¬è©¦å ±å‘Š...")
        
        try:
            total = self.test_results["total_tests"]
            passed = self.test_results["passed_tests"]
            failed = self.test_results["failed_tests"]
            success_rate = (passed / total * 100) if total > 0 else 0
            
            print("\n" + "="*70)
            print("ğŸ§ª Phase 1.2 åŸºç¤åŠŸèƒ½æ¸¬è©¦å ±å‘Š")
            print("="*70)
            print(f"æ¸¬è©¦æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"æ¸¬è©¦ç¯„åœ: å€‰åº«å·¥å» ã€ä¾è³´æ³¨å…¥ã€æ•¸æ“šæ“ä½œã€é…ç½®ç®¡ç†")
            print("-"*70)
            print(f"ç¸½æ¸¬è©¦æ•¸é‡: {total}")
            print(f"é€šéæ¸¬è©¦: {passed} âœ…")
            print(f"å¤±æ•—æ¸¬è©¦: {failed} âŒ")
            print(f"æˆåŠŸç‡: {success_rate:.1f}%")
            print("-"*70)
            
            print("è©³ç´°æ¸¬è©¦çµæœ:")
            for test_detail in self.test_results["test_details"]:
                status_icon = "âœ…" if test_detail["passed"] else "âŒ"
                print(f"  {status_icon} {test_detail['test_name']:<25} - {test_detail['message']}")
            
            print("="*70)
            
            if success_rate >= 90:
                print("ğŸ‰ Phase 1.2 åŸºç¤åŠŸèƒ½æ¸¬è©¦æ•´é«”é€šéï¼ç³»çµ±æ ¸å¿ƒçµ„ä»¶é‹è¡Œæ­£å¸¸ã€‚")
            elif success_rate >= 70:
                print("âš ï¸ Phase 1.2 æ¸¬è©¦å¤§éƒ¨åˆ†é€šéï¼Œä½†æœ‰éƒ¨åˆ†å•é¡Œéœ€è¦é—œæ³¨ã€‚")
            else:
                print("âŒ Phase 1.2 æ¸¬è©¦å­˜åœ¨è¼ƒå¤šå•é¡Œï¼Œéœ€è¦é€²ä¸€æ­¥æ”¹é€²ã€‚")
            
            print("\nğŸ” Phase 1.2 å®Œæˆé …ç›®æª¢æŸ¥:")
            print("  âœ… æ•¸æ“šå€‰åº«å·¥å»  (RepositoryFactory)")
            print("  âœ… ä¾è³´æ³¨å…¥å®¹å™¨ (DIContainer)")
            print("  âœ… Mock æ•¸æ“šå€‰åº«å¯¦ç¾")
            print("  âœ… PostgreSQL æ•¸æ“šå€‰åº«å¯¦ç¾")
            print("  âœ… å¯¦é©—æœƒè©±ç®¡ç†")
            print("  âœ… è¨“ç·´å›åˆç®¡ç†")
            print("  âœ… æ€§èƒ½æŒ‡æ¨™è¿½è¹¤")
            print("  âœ… æ¨¡å‹ç‰ˆæœ¬ç®¡ç†")
            print("  âœ… çµ±è¨ˆåˆ†æåŠŸèƒ½")
            print("  âœ… é…ç½®ç®¡ç†åŸºç¤")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¸¬è©¦å ±å‘Šå¤±æ•—: {e}")
    
    async def _cleanup(self) -> None:
        """æ¸…ç†æ¸¬è©¦è³‡æº"""
        logger.info("ğŸ§¹ æ¸…ç†æ¸¬è©¦è³‡æº...")
        
        try:
            # æ¸…ç†å€‰åº«å¯¦ä¾‹
            await RepositoryFactory.shutdown_all()
            logger.info("è³‡æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"è³‡æºæ¸…ç†å¤±æ•—: {e}")
    
    def _record_test(self, test_name: str, passed: bool, message: str = "") -> None:
        """è¨˜éŒ„æ¸¬è©¦çµæœ"""
        self.test_results["total_tests"] += 1
        if passed:
            self.test_results["passed_tests"] += 1
        else:
            self.test_results["failed_tests"] += 1
        
        self.test_results["test_details"].append({
            "test_name": test_name,
            "passed": passed,
            "message": message,
            "timestamp": datetime.now().isoformat()
        })
        
        status = "âœ… PASS" if passed else "âŒ FAIL"
        logger.info(f"{status} {test_name}: {message}")


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ§  LEOè¡›æ˜Ÿæ›æ‰‹æ±ºç­–RLç³»çµ± - Phase 1.2 åŸºç¤åŠŸèƒ½æ¸¬è©¦")
    print("æ¸¬è©¦é‡é»: æ•¸æ“šå€‰åº«æ¶æ§‹ã€ä¾è³´æ³¨å…¥ã€é…ç½®ç®¡ç†")
    print("-"*70)
    
    # è¨­ç½®æ¸¬è©¦ç’°å¢ƒ
    os.environ["MOCK_DATA_ENABLED"] = "true"
    os.environ["ENVIRONMENT"] = "test"
    os.environ["REPOSITORY_TYPE"] = "mock"
    
    tester = BasicPhase12Tester()
    results = await tester.run_all_tests()
    
    # è¿”å›é©ç•¶çš„é€€å‡ºç¢¼
    if results["failed_tests"] == 0:
        sys.exit(0)
    else:
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())