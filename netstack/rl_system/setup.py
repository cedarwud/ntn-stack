#!/usr/bin/env python3
"""
ğŸ§  NetStack RL ç³»çµ±è¨­ç½®è…³æœ¬

è‡ªå‹•åŒ–è¨­ç½®å’Œåˆå§‹åŒ–ä¸–ç•Œç´š LEO è¡›æ˜Ÿå¼·åŒ–å­¸ç¿’ç³»çµ±ã€‚
æ”¯æ´å®Œæ•´çš„é–‹ç™¼ç’°å¢ƒå»ºç½®å’Œé…ç½®ã€‚
"""

import os
import sys
import asyncio
import logging
import argparse
from pathlib import Path
from typing import Dict, Any, Optional

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from rl_system.core.di_container import DIContainer
from rl_system.core.service_locator import ServiceLocator
from rl_system.core.config_manager import ConfigDrivenAlgorithmManager, create_default_config
from rl_system.core.algorithm_factory import AlgorithmFactory

logger = logging.getLogger(__name__)


class RLSystemSetup:
    """RL ç³»çµ±è¨­ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_path: Optional[str] = None, environment: str = "development"):
        self.environment = environment
        self.config_path = Path(config_path) if config_path else Path("rl_system/config/default_config.yaml")
        self.container: Optional[DIContainer] = None
        self.algorithm_manager: Optional[ConfigDrivenAlgorithmManager] = None
        
        # è¨­ç½®æ—¥èªŒ
        self._setup_logging()
        
    def _setup_logging(self) -> None:
        """è¨­ç½®æ—¥èªŒç³»çµ±"""
        log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        logging.basicConfig(
            level=logging.INFO,
            format=log_format,
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler("setup.log")
            ]
        )
        
    async def setup_complete_system(self) -> bool:
        """è¨­ç½®å®Œæ•´çš„ RL ç³»çµ±"""
        try:
            logger.info("ğŸš€ é–‹å§‹è¨­ç½® NetStack RL ç³»çµ±...")
            
            # 1. å‰µå»ºå¿…è¦çš„ç›®éŒ„çµæ§‹
            await self._create_directory_structure()
            
            # 2. æª¢æŸ¥ä¸¦å‰µå»ºé…ç½®æ–‡ä»¶
            await self._setup_configuration()
            
            # 3. åˆå§‹åŒ–æ•¸æ“šåº«
            await self._setup_database()
            
            # 4. è¨­ç½®ä¾è³´æ³¨å…¥å®¹å™¨
            await self._setup_dependency_injection()
            
            # 5. è¨»å†Šç®—æ³•
            await self._register_algorithms()
            
            # 6. åˆå§‹åŒ–ç®—æ³•ç®¡ç†å™¨
            await self._setup_algorithm_manager()
            
            # 7. é©—è­‰ç³»çµ±é…ç½®
            await self._validate_system()
            
            # 8. é‹è¡Œå¥åº·æª¢æŸ¥
            await self._run_health_checks()
            
            logger.info("âœ… NetStack RL ç³»çµ±è¨­ç½®å®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç³»çµ±è¨­ç½®å¤±æ•—: {e}")
            return False
    
    async def _create_directory_structure(self) -> None:
        """å‰µå»ºå¿…è¦çš„ç›®éŒ„çµæ§‹"""
        logger.info("ğŸ“ å‰µå»ºç›®éŒ„çµæ§‹...")
        
        directories = [
            "rl_models",
            "exports", 
            "backups",
            "logs",
            "test_data",
            "temp",
            "rl_system/database/migrations",
            "rl_system/implementations/plugins"
        ]
        
        for directory in directories:
            dir_path = Path(directory)
            dir_path.mkdir(parents=True, exist_ok=True)
            logger.debug(f"å‰µå»ºç›®éŒ„: {dir_path}")
        
        logger.info("âœ… ç›®éŒ„çµæ§‹å‰µå»ºå®Œæˆ")
    
    async def _setup_configuration(self) -> None:
        """è¨­ç½®é…ç½®æ–‡ä»¶"""
        logger.info("âš™ï¸ è¨­ç½®é…ç½®æ–‡ä»¶...")
        
        if not self.config_path.exists():
            logger.info(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå‰µå»ºé è¨­é…ç½®: {self.config_path}")
            create_default_config(self.config_path)
        else:
            logger.info(f"ä½¿ç”¨ç¾æœ‰é…ç½®æ–‡ä»¶: {self.config_path}")
        
        # é©—è­‰é…ç½®æ–‡ä»¶
        try:
            import yaml
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info("âœ… é…ç½®æ–‡ä»¶é©—è­‰é€šé")
        except Exception as e:
            raise RuntimeError(f"é…ç½®æ–‡ä»¶é©—è­‰å¤±æ•—: {e}")
    
    async def _setup_database(self) -> None:
        """è¨­ç½®æ•¸æ“šåº«"""
        logger.info("ğŸ—„ï¸ è¨­ç½®æ•¸æ“šåº«...")
        
        try:
            # æª¢æŸ¥ PostgreSQL é€£æ¥
            await self._check_postgresql_connection()
            
            # é‹è¡Œæ•¸æ“šåº«é·ç§»
            await self._run_database_migrations()
            
            logger.info("âœ… æ•¸æ“šåº«è¨­ç½®å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"æ•¸æ“šåº«è¨­ç½®å¤±æ•—ï¼Œå°‡ä½¿ç”¨å…§å­˜å­˜å„²: {e}")
    
    async def _check_postgresql_connection(self) -> None:
        """æª¢æŸ¥ PostgreSQL é€£æ¥"""
        try:
            import asyncpg
            import yaml
            
            # å¾é…ç½®æ–‡ä»¶è®€å–æ•¸æ“šåº« URL
            with open(self.config_path, 'r') as f:
                config = yaml.safe_load(f)
            
            db_url = config.get('system', {}).get('database_url', '')
            if not db_url:
                raise ValueError("é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ•¸æ“šåº« URL")
            
            # å˜—è©¦é€£æ¥
            conn = await asyncpg.connect(db_url)
            await conn.close()
            logger.info("âœ… PostgreSQL é€£æ¥æˆåŠŸ")
            
        except ImportError:
            logger.warning("asyncpg æœªå®‰è£ï¼Œè·³é PostgreSQL æª¢æŸ¥")
        except Exception as e:
            raise RuntimeError(f"PostgreSQL é€£æ¥å¤±æ•—: {e}")
    
    async def _run_database_migrations(self) -> None:
        """é‹è¡Œæ•¸æ“šåº«é·ç§»"""
        logger.info("ğŸ“Š é‹è¡Œæ•¸æ“šåº«é·ç§»...")
        
        schema_file = Path("rl_system/database/schema.sql")
        if schema_file.exists():
            logger.info("æ‰¾åˆ°æ•¸æ“šåº«æ¶æ§‹æ–‡ä»¶ï¼Œæº–å‚™åŸ·è¡Œé·ç§»...")
            # é€™è£¡å¯ä»¥æ·»åŠ å¯¦éš›çš„é·ç§»é‚è¼¯
            logger.info("âœ… æ•¸æ“šåº«é·ç§»å®Œæˆ")
        else:
            logger.warning("æœªæ‰¾åˆ°æ•¸æ“šåº«æ¶æ§‹æ–‡ä»¶")
    
    async def _setup_dependency_injection(self) -> None:
        """è¨­ç½®ä¾è³´æ³¨å…¥å®¹å™¨"""
        logger.info("ğŸ”— è¨­ç½®ä¾è³´æ³¨å…¥å®¹å™¨...")
        
        # å‰µå»º DI å®¹å™¨
        self.container = DIContainer()
        
        # è¨»å†Šæ ¸å¿ƒæœå‹™ï¼ˆé€™è£¡ä½¿ç”¨æ¨¡æ“¬å¯¦ç¾ï¼‰
        await self._register_core_services()
        
        # åˆå§‹åŒ–æœå‹™å®šä½å™¨
        ServiceLocator.initialize(self.container)
        
        logger.info("âœ… ä¾è³´æ³¨å…¥å®¹å™¨è¨­ç½®å®Œæˆ")
    
    async def _register_core_services(self) -> None:
        """è¨»å†Šæ ¸å¿ƒæœå‹™"""
        logger.info("ğŸ“‹ è¨»å†Šæ ¸å¿ƒæœå‹™...")
        
        # é€™è£¡æœƒè¨»å†Šå¯¦éš›çš„æœå‹™å¯¦ç¾
        # ç¾åœ¨ä½¿ç”¨æ¨¡æ“¬å¯¦ç¾ä½œç‚ºæ¼”ç¤º
        
        from rl_system.interfaces.training_scheduler import ITrainingScheduler
        from rl_system.interfaces.performance_monitor import IPerformanceMonitor
        from rl_system.interfaces.data_repository import IDataRepository
        from rl_system.interfaces.model_manager import IModelManager
        
        # å‰µå»ºæ¨¡æ“¬å¯¦ç¾ï¼ˆå¯¦éš›é …ç›®ä¸­æ‡‰è©²ä½¿ç”¨çœŸå¯¦å¯¦ç¾ï¼‰
        class MockTrainingScheduler(ITrainingScheduler):
            async def submit_training_job(self, job): 
                return "mock_job_id"
            async def cancel_training_job(self, job_id): 
                return True
            async def get_job_status(self, job_id): 
                return {"status": "completed"}
            async def get_training_queue(self): 
                return []
            async def get_scheduler_status(self): 
                from rl_system.interfaces.training_scheduler import SchedulerStatus
                return SchedulerStatus(0, 0, 0, 0, 0.0, 0.0, None, 0.0, 0.0)
            async def set_scheduling_strategy(self, strategy): 
                return True
            async def set_resource_constraints(self, constraints): 
                return True
            async def pause_scheduler(self): 
                return True
            async def resume_scheduler(self): 
                return True
            async def shutdown_scheduler(self, wait_for_completion=True): 
                return True
        
        class MockPerformanceMonitor(IPerformanceMonitor):
            async def record_metric(self, metric): 
                return True
            async def record_metrics_batch(self, metrics): 
                return len(metrics)
            async def get_performance_summary(self, algorithm_name, metric_types=None, scenario_type=None, time_range=None): 
                return {}
            async def compare_with_baseline(self, our_algorithm, baseline_algorithm, metric_types, scenario_type=None): 
                return []
            async def analyze_convergence(self, algorithm_name, session_ids=None, convergence_threshold=0.95): 
                return []
            async def get_real_time_metrics(self, algorithm_name, time_window_minutes=5): 
                return {}
            async def export_metrics_for_paper(self, algorithm_names, metric_types, format_type="csv", include_statistical_tests=True): 
                return "mock_export_path"
            async def generate_performance_report(self, algorithm_names, report_type="comprehensive"): 
                return {}
            async def set_performance_alert(self, algorithm_name, metric_type, threshold, comparison_operator="less_than"): 
                return "mock_alert_id"
            async def get_trending_analysis(self, algorithm_name, metric_type, time_period_days=7): 
                return {}
        
        class MockDataRepository(IDataRepository):
            async def create_experiment_session(self, session): 
                return 1
            async def get_experiment_session(self, session_id): 
                return None
            async def update_experiment_session(self, session_id, updates): 
                return True
            async def delete_experiment_session(self, session_id): 
                return True
            async def query_experiment_sessions(self, filter_obj): 
                return []
            async def create_training_episode(self, episode): 
                return 1
            async def get_training_episodes(self, session_id, limit=None, offset=None): 
                return []
            async def get_latest_episode(self, session_id): 
                return None
            async def batch_create_episodes(self, episodes): 
                return len(episodes)
            async def store_performance_metric(self, metric): 
                return True
            async def batch_store_metrics(self, metrics): 
                return len(metrics)
            async def query_performance_metrics(self, algorithm_names, metric_types, start_time=None, end_time=None, scenario_type=None): 
                return []
            async def create_model_version(self, model): 
                return 1
            async def get_model_versions(self, algorithm_type, limit=None): 
                return []
            async def get_best_model(self, algorithm_type, metric="validation_score"): 
                return None
            async def get_algorithm_statistics(self, algorithm_name, scenario_type=None): 
                return {}
            async def get_convergence_analysis(self, session_ids, convergence_threshold=0.95): 
                return []
            async def compare_algorithms(self, algorithm_names, metric_types, scenario_type=None): 
                return {}
            async def backup_data(self, backup_path): 
                return True
            async def restore_data(self, backup_path): 
                return True
            async def cleanup_old_data(self, days_to_keep=30): 
                return 0
            async def get_database_health(self): 
                return {"status": "healthy"}
        
        class MockModelManager(IModelManager):
            async def register_model(self, metadata): 
                return "mock_model_id"
            async def get_model_metadata(self, model_id): 
                return None
            async def update_model_metadata(self, model_id, updates): 
                return True
            async def delete_model(self, model_id, force=False): 
                return True
            async def list_models(self, algorithm_name=None, scenario_type=None, status=None, limit=None): 
                return []
            async def validate_model(self, model_id, validation_dataset, validation_config=None): 
                from rl_system.interfaces.model_manager import ValidationReport, ValidationStatus
                return ValidationReport("val_id", model_id, ValidationStatus.PASSED, 0.9, {}, 10, 0, 1.0)
            async def get_validation_report(self, validation_id): 
                return None
            async def set_validation_pipeline(self, algorithm_name, validation_steps): 
                return True
            async def deploy_model(self, config): 
                return "mock_deployment_id"
            async def undeploy_model(self, deployment_id): 
                return True
            async def get_deployment_status(self, deployment_id): 
                return {"status": "deployed"}
            async def list_deployments(self, environment=None, status=None): 
                return []
            async def scale_deployment(self, deployment_id, replica_count): 
                return True
            async def start_ab_test(self, config): 
                return "mock_test_id"
            async def stop_ab_test(self, test_id): 
                return {"winner": "model_a"}
            async def get_ab_test_results(self, test_id): 
                return {}
            async def list_ab_tests(self, status=None): 
                return []
            async def monitor_model_performance(self, model_id, metrics, time_window_minutes=60): 
                return {}
            async def set_performance_alert(self, model_id, metric_name, threshold, alert_callback): 
                return "mock_alert_id"
            async def get_model_health(self, model_id): 
                return {"status": "healthy"}
            async def create_model_version(self, base_model_id, new_version, changes): 
                return "new_model_id"
            async def compare_model_versions(self, model_id_a, model_id_b, metrics): 
                return {}
            async def rollback_to_version(self, deployment_id, target_model_id): 
                return True
        
        # è¨»å†Šæœå‹™
        self.container.register_singleton(ITrainingScheduler, MockTrainingScheduler)
        self.container.register_singleton(IPerformanceMonitor, MockPerformanceMonitor)
        self.container.register_singleton(IDataRepository, MockDataRepository)
        self.container.register_singleton(IModelManager, MockModelManager)
        
        logger.info("âœ… æ ¸å¿ƒæœå‹™è¨»å†Šå®Œæˆ")
    
    async def _register_algorithms(self) -> None:
        """è¨»å†Šç®—æ³•å¯¦ç¾"""
        logger.info("ğŸ§® è¨»å†Šç®—æ³•å¯¦ç¾...")
        
        try:
            # è¨»å†Š DQN ç®—æ³•ï¼ˆå·²é€šéè£é£¾å™¨è‡ªå‹•è¨»å†Šï¼‰
            from rl_system.implementations.dqn_implementation import DQNAlgorithmImpl
            
            # æª¢æŸ¥ç®—æ³•æ˜¯å¦æˆåŠŸè¨»å†Š
            available_algorithms = AlgorithmFactory.get_available_algorithms()
            logger.info(f"å¯ç”¨ç®—æ³•: {available_algorithms}")
            
            if "DQN" in available_algorithms:
                logger.info("âœ… DQN ç®—æ³•è¨»å†ŠæˆåŠŸ")
            else:
                logger.warning("âŒ DQN ç®—æ³•è¨»å†Šå¤±æ•—")
            
            # å¯ä»¥åœ¨é€™è£¡è¨»å†Šæ›´å¤šç®—æ³•
            # from rl_system.implementations.ppo_implementation import PPOAlgorithmImpl
            # from rl_system.implementations.sac_implementation import SACAlgorithmImpl
            
        except Exception as e:
            logger.error(f"ç®—æ³•è¨»å†Šå¤±æ•—: {e}")
    
    async def _setup_algorithm_manager(self) -> None:
        """è¨­ç½®ç®—æ³•ç®¡ç†å™¨"""
        logger.info("ğŸ¯ è¨­ç½®ç®—æ³•ç®¡ç†å™¨...")
        
        try:
            self.algorithm_manager = ConfigDrivenAlgorithmManager(
                config_path=self.config_path,
                container=self.container
            )
            
            await self.algorithm_manager.initialize()
            
            logger.info("âœ… ç®—æ³•ç®¡ç†å™¨è¨­ç½®å®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç®—æ³•ç®¡ç†å™¨è¨­ç½®å¤±æ•—: {e}")
            raise
    
    async def _validate_system(self) -> None:
        """é©—è­‰ç³»çµ±é…ç½®"""
        logger.info("ğŸ” é©—è­‰ç³»çµ±é…ç½®...")
        
        # é©—è­‰æœå‹™è¨»å†Š
        validation_result = ServiceLocator.validate_services()
        if not validation_result["is_valid"]:
            logger.error(f"æœå‹™é©—è­‰å¤±æ•—: {validation_result['errors']}")
            raise RuntimeError("ç³»çµ±é…ç½®é©—è­‰å¤±æ•—")
        
        # é©—è­‰ç®—æ³•è¨»å†Š
        registry_stats = AlgorithmFactory.get_registry_stats()
        logger.info(f"ç®—æ³•è¨»å†Šçµ±è¨ˆ: {registry_stats}")
        
        if registry_stats["total_algorithms"] == 0:
            logger.warning("æœªç™¼ç¾å·²è¨»å†Šçš„ç®—æ³•")
        
        logger.info("âœ… ç³»çµ±é…ç½®é©—è­‰é€šé")
    
    async def _run_health_checks(self) -> None:
        """é‹è¡Œå¥åº·æª¢æŸ¥"""
        logger.info("ğŸ¥ é‹è¡Œå¥åº·æª¢æŸ¥...")
        
        try:
            # æª¢æŸ¥æœå‹™å®šä½å™¨å¥åº·ç‹€æ…‹
            health_status = ServiceLocator.get_health_status()
            logger.info(f"æœå‹™å®šä½å™¨ç‹€æ…‹: {health_status['status']}")
            
            # æª¢æŸ¥ç®—æ³•ç®¡ç†å™¨ç‹€æ…‹
            if self.algorithm_manager:
                manager_stats = self.algorithm_manager.get_manager_stats()
                logger.info(f"ç®—æ³•ç®¡ç†å™¨ç‹€æ…‹: å·²åŠ è¼‰ {manager_stats['loaded_instances']} å€‹ç®—æ³•å¯¦ä¾‹")
            
            # å˜—è©¦å‰µå»ºä¸€å€‹ç®—æ³•å¯¦ä¾‹
            try:
                from rl_system.interfaces.rl_algorithm import ScenarioType
                algorithm = AlgorithmFactory.create_algorithm("DQN", scenario_type=ScenarioType.URBAN)
                logger.info("âœ… ç®—æ³•å¯¦ä¾‹å‰µå»ºæ¸¬è©¦é€šé")
            except Exception as e:
                logger.warning(f"ç®—æ³•å¯¦ä¾‹å‰µå»ºæ¸¬è©¦å¤±æ•—: {e}")
            
            logger.info("âœ… å¥åº·æª¢æŸ¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
    
    async def cleanup(self) -> None:
        """æ¸…ç†è³‡æº"""
        logger.info("ğŸ§¹ æ¸…ç†ç³»çµ±è³‡æº...")
        
        try:
            if self.algorithm_manager:
                await self.algorithm_manager.shutdown()
            
            if self.container:
                # æ¸…ç†å®¹å™¨è³‡æºï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
                pass
            
            ServiceLocator.shutdown()
            
            logger.info("âœ… è³‡æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"è³‡æºæ¸…ç†å¤±æ•—: {e}")


async def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="NetStack RL ç³»çµ±è¨­ç½®")
    parser.add_argument("--config", help="é…ç½®æ–‡ä»¶è·¯å¾‘")
    parser.add_argument("--env", default="development", choices=["development", "testing", "production"],
                       help="é‹è¡Œç’°å¢ƒ")
    parser.add_argument("--skip-db", action="store_true", help="è·³éæ•¸æ“šåº«è¨­ç½®")
    parser.add_argument("--demo", action="store_true", help="é‹è¡Œæ¼”ç¤ºæ¨¡å¼")
    
    args = parser.parse_args()
    
    # å‰µå»ºè¨­ç½®ç®¡ç†å™¨
    setup_manager = RLSystemSetup(
        config_path=args.config,
        environment=args.env
    )
    
    try:
        # é‹è¡Œå®Œæ•´è¨­ç½®
        success = await setup_manager.setup_complete_system()
        
        if success:
            print("\nğŸ‰ NetStack RL ç³»çµ±è¨­ç½®æˆåŠŸï¼")
            print("\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:")
            print("1. æŸ¥çœ‹é…ç½®æ–‡ä»¶: rl_system/config/default_config.yaml")
            print("2. å•Ÿå‹• Web UI: python -m rl_system.web.app")
            print("3. é‹è¡Œ API æœå‹™å™¨: python -m rl_system.api.main")
            print("4. æŸ¥çœ‹æ–‡æª”: http://localhost:8000/api/v1/docs")
            
            if args.demo:
                print("\nğŸš€ å•Ÿå‹•æ¼”ç¤ºæ¨¡å¼...")
                await run_demo(setup_manager)
        else:
            print("\nâŒ ç³»çµ±è¨­ç½®å¤±æ•—ï¼Œè«‹æŸ¥çœ‹æ—¥èªŒç²å–è©³ç´°ä¿¡æ¯")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ¶ä¸­æ–·è¨­ç½®éç¨‹")
    except Exception as e:
        logger.error(f"è¨­ç½®éç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")
        sys.exit(1)
    finally:
        await setup_manager.cleanup()


async def run_demo(setup_manager: RLSystemSetup):
    """é‹è¡Œæ¼”ç¤ºæ¨¡å¼"""
    logger.info("ğŸ¬ é–‹å§‹æ¼”ç¤ºæ¨¡å¼...")
    
    try:
        from rl_system.interfaces.rl_algorithm import ScenarioType, TrainingConfig, PredictionContext
        from datetime import datetime
        
        # 1. å‰µå»ºç®—æ³•å¯¦ä¾‹
        print("\n1ï¸âƒ£ å‰µå»º DQN ç®—æ³•å¯¦ä¾‹...")
        dqn = AlgorithmFactory.create_algorithm("DQN", scenario_type=ScenarioType.URBAN)
        print(f"   âœ… ç®—æ³•: {dqn.get_name()} v{dqn.get_version()}")
        
        # 2. é‹è¡Œç°¡çŸ­è¨“ç·´
        print("\n2ï¸âƒ£ é‹è¡Œç°¡çŸ­è¨“ç·´æ¼”ç¤º...")
        training_config = TrainingConfig(
            episodes=10,
            batch_size=16,
            learning_rate=0.001,
            max_steps_per_episode=50
        )
        
        result = await dqn.train(training_config)
        print(f"   âœ… è¨“ç·´å®Œæˆ: æœ€çµ‚åˆ†æ•¸ = {result.final_score:.3f}")
        
        # 3. åŸ·è¡Œé æ¸¬
        print("\n3ï¸âƒ£ åŸ·è¡Œæ›æ‰‹æ±ºç­–é æ¸¬...")
        context = PredictionContext(
            satellite_positions=[
                {"lat": 40.7128, "lon": -74.0060, "altitude": 550000},
                {"lat": 40.7580, "lon": -73.9855, "altitude": 550000}
            ],
            ue_position={"lat": 40.7413, "lon": -73.9896},
            network_conditions={
                "signal_strength": -80,
                "latency": 25,
                "throughput": 100,
                "packet_loss": 0.01
            },
            current_serving_satellite=1,
            candidate_satellites=[1, 2, 3],
            timestamp=datetime.now()
        )
        
        decision = await dqn.predict(context)
        print(f"   âœ… æ±ºç­–å®Œæˆ: ç›®æ¨™è¡›æ˜Ÿ {decision.target_satellite_id}, ä¿¡å¿ƒåº¦ {decision.confidence_score:.3f}")
        
        # 4. é¡¯ç¤ºç³»çµ±çµ±è¨ˆ
        print("\n4ï¸âƒ£ ç³»çµ±çµ±è¨ˆè³‡è¨Š:")
        registry_stats = AlgorithmFactory.get_registry_stats()
        print(f"   ğŸ“Š å·²è¨»å†Šç®—æ³•: {registry_stats['total_algorithms']}")
        print(f"   ğŸƒ æ´»èºå¯¦ä¾‹: {registry_stats['active_instances']}")
        
        print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼ç³»çµ±é‹è¡Œæ­£å¸¸ã€‚")
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºæ¨¡å¼å¤±æ•—: {e}")


if __name__ == "__main__":
    asyncio.run(main())