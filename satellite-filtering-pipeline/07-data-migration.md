# æ•¸æ“šé·ç§»ç­–ç•¥

**æ–‡ä»¶ç‰ˆæœ¬**: 1.0.0  
**æœ€å¾Œæ›´æ–°**: 2025-08-01  
**é—œéµä»»å‹™**: æ•¸æ“šä½ç½®èª¿æ•´èˆ‡æ ¼å¼å‡ç´š

## ğŸ“‹ é·ç§»æ¦‚è¿°

### ä¸»è¦ç›®æ¨™
1. **æ•¸æ“šä½ç½®çµ±ä¸€** - å¾ `/data` é·ç§»è‡³ `/netstack/data`
2. **æ ¼å¼å‡ç´š** - æ”¯æ´åˆ†å±¤æ¨™è¨˜å’Œå¤šäº‹ä»¶é¡å‹
3. **å‘å¾Œå…¼å®¹** - ç¢ºä¿ç¾æœ‰ç³»çµ±æ­£å¸¸é‹è¡Œ
4. **é›¶åœæ©Ÿéƒ¨ç½²** - å¹³æ»‘éæ¸¡ç­–ç•¥

## ğŸ” ç¾ç‹€åˆ†æ

### ç•¶å‰æ•¸æ“šä½ç½®
```bash
/home/sat/ntn-stack/data/
â”œâ”€â”€ starlink_120min_timeseries.json      # 35MB
â”œâ”€â”€ starlink_120min_d2_enhanced.json     # 12MB
â”œâ”€â”€ oneweb_120min_timeseries.json        # 26MB
â”œâ”€â”€ oneweb_120min_d2_enhanced.json       # 8MB
â”œâ”€â”€ starlink_120min_timeseries_sgp4.json # 35MB
â””â”€â”€ oneweb_120min_timeseries_sgp4.json   # 26MB
```

### ç›®æ¨™ä½ç½®
```bash
/home/sat/ntn-stack/netstack/data/
â”œâ”€â”€ satellites/
â”‚   â”œâ”€â”€ filtered/                    # ç¯©é¸å¾Œçš„æ•¸æ“š
â”‚   â”‚   â”œâ”€â”€ tier1_satellites.json   # 20 é¡†
â”‚   â”‚   â”œâ”€â”€ tier2_satellites.json   # 80 é¡†
â”‚   â”‚   â””â”€â”€ tier3_satellites.json   # 500 é¡†
â”‚   â””â”€â”€ preprocessed/               # é è™•ç†æ•¸æ“š
â”‚       â”œâ”€â”€ unified_timeseries_v2.json
â”‚       â””â”€â”€ metadata.json
â”œâ”€â”€ layered_phase0/                 # ä¿ç•™ç¾æœ‰
â””â”€â”€ .migration_status              # é·ç§»ç‹€æ…‹è¿½è¹¤
```

## ğŸš€ é·ç§»æ­¥é©Ÿ

### Phase 1: æº–å‚™éšæ®µ

#### Step 1.1: æ•¸æ“šå‚™ä»½
```bash
#!/bin/bash
# backup_data.sh

BACKUP_DIR="/home/sat/ntn-stack/backups/$(date +%Y%m%d_%H%M%S)"
SOURCE_DIR="/home/sat/ntn-stack/data"
NETSTACK_DATA="/home/sat/ntn-stack/netstack/data"

echo "ğŸ”„ é–‹å§‹æ•¸æ“šå‚™ä»½..."

# å‰µå»ºå‚™ä»½ç›®éŒ„
mkdir -p "$BACKUP_DIR"

# å‚™ä»½ç¾æœ‰æ•¸æ“š
cp -r "$SOURCE_DIR" "$BACKUP_DIR/data_backup"
cp -r "$NETSTACK_DATA" "$BACKUP_DIR/netstack_data_backup"

# è¨ˆç®—æ ¡é©—å’Œ
find "$BACKUP_DIR" -type f -name "*.json" -exec md5sum {} \; > "$BACKUP_DIR/checksums.txt"

echo "âœ… å‚™ä»½å®Œæˆ: $BACKUP_DIR"
```

#### Step 1.2: å…¼å®¹æ€§æ¸¬è©¦
```python
# test_data_compatibility.py

def test_backward_compatibility():
    """æ¸¬è©¦æ•¸æ“šæ ¼å¼å‘å¾Œå…¼å®¹æ€§"""
    old_format = load_json("/data/starlink_120min_timeseries.json")
    new_format = convert_to_new_format(old_format)
    
    # é©—è­‰é—œéµå­—æ®µ
    assert 'positions' in new_format['satellites'][0]
    assert 'tier_labels' in new_format['satellites'][0]
    
    # æ¸¬è©¦ API å…¼å®¹æ€§
    response = test_api_with_old_format()
    assert response.status_code == 200
```

### Phase 2: æ•¸æ“šè½‰æ›

#### Step 2.1: æ ¼å¼å‡ç´šè…³æœ¬
```python
# migrate_data_format.py

class DataMigrator:
    def __init__(self):
        self.source_dir = "/home/sat/ntn-stack/data"
        self.target_dir = "/home/sat/ntn-stack/netstack/data"
        
    def migrate(self):
        """åŸ·è¡Œæ•¸æ“šé·ç§»"""
        # 1. è®€å–ç¾æœ‰æ•¸æ“š
        satellites = self._load_existing_data()
        
        # 2. åŸ·è¡Œä¸‰éšæ®µç¯©é¸
        filtered = self._apply_filtering_pipeline(satellites)
        
        # 3. è½‰æ›ç‚ºæ–°æ ¼å¼
        unified_data = self._convert_to_unified_format(filtered)
        
        # 4. ä¿å­˜åˆ°æ–°ä½ç½®
        self._save_migrated_data(unified_data)
        
        # 5. æ›´æ–°ç‹€æ…‹
        self._update_migration_status()
```

#### Step 2.2: æ–°æ•¸æ“šæ ¼å¼
```json
{
  "version": "2.0.0",
  "migration_info": {
    "migrated_at": "2025-08-15T10:00:00Z",
    "source_version": "1.0.0",
    "compatibility_mode": true
  },
  "satellites": [{
    "id": "STARLINK-1234",
    "tier_labels": ["tier_1", "tier_2", "tier_3"],
    "legacy_fields": {
      "positions": [...],  // ä¿ç•™èˆŠæ ¼å¼
      "visibility_data": [...]  // å…¼å®¹æ€§
    },
    "new_fields": {
      "orbital_data": {...},
      "signal_data": {...},
      "handover_events": {
        "d2": [...],
        "d1": [...],
        "a4": [...],
        "t1": [...]
      }
    }
  }]
}
```

### Phase 3: ç³»çµ±æ›´æ–°

#### Step 3.1: Docker é…ç½®æ›´æ–°
```dockerfile
# Dockerfile æ›´æ–°
FROM python:3.9-slim

# æ•¸æ“šç›®éŒ„èª¿æ•´
RUN mkdir -p /app/data/satellites/filtered \
             /app/data/satellites/preprocessed \
             /app/data/layered_phase0

# è¤‡è£½é·ç§»å¾Œçš„æ•¸æ“š
COPY ./netstack/data /app/data

# ç’°å¢ƒè®Šé‡æ›´æ–°
ENV DATA_PATH=/app/data
ENV LEGACY_SUPPORT=true
```

#### Step 3.2: API é©é…å±¤
```python
# api_adapter.py

class DataPathAdapter:
    """è™•ç†æ–°èˆŠæ•¸æ“šè·¯å¾‘çš„é©é…å™¨"""
    
    def __init__(self):
        self.new_path = "/app/data/satellites"
        self.legacy_path = "/app/data"
        self.compatibility_mode = os.getenv("LEGACY_SUPPORT", "true") == "true"
        
    def get_satellite_data(self, tier=None):
        """æ™ºèƒ½é¸æ“‡æ•¸æ“šæº"""
        # å„ªå…ˆä½¿ç”¨æ–°æ•¸æ“š
        if self._new_data_exists():
            return self._load_new_format(tier)
        
        # å›é€€åˆ°èˆŠæ•¸æ“š
        if self.compatibility_mode:
            logger.warning("Using legacy data format")
            return self._load_legacy_format()
        
        raise DataNotFoundError("No valid data source found")
```

### Phase 4: é©—è­‰èˆ‡åˆ‡æ›

#### Step 4.1: ä¸¦è¡Œé‹è¡Œæ¸¬è©¦
```bash
#!/bin/bash
# parallel_test.sh

echo "ğŸ”„ é–‹å§‹ä¸¦è¡Œæ¸¬è©¦..."

# å•Ÿå‹•ä½¿ç”¨èˆŠæ•¸æ“šçš„å¯¦ä¾‹
docker run -d --name old_system \
  -v /home/sat/ntn-stack/data:/app/data \
  -p 8080:8080 \
  netstack:legacy

# å•Ÿå‹•ä½¿ç”¨æ–°æ•¸æ“šçš„å¯¦ä¾‹
docker run -d --name new_system \
  -v /home/sat/ntn-stack/netstack/data:/app/data \
  -p 8081:8080 \
  netstack:v2

# åŸ·è¡Œå°æ¯”æ¸¬è©¦
python compare_results.py

# æ¸…ç†
docker stop old_system new_system
docker rm old_system new_system
```

#### Step 4.2: æµé‡åˆ‡æ›
```nginx
# nginx é…ç½®æ¼¸é€²å¼åˆ‡æ›
upstream backend {
    server old_system:8080 weight=90;  # 90% æµé‡
    server new_system:8080 weight=10;  # 10% æµé‡
}

# é€æ­¥èª¿æ•´æ¬Šé‡
# Day 1: 90/10
# Day 2: 70/30
# Day 3: 50/50
# Day 4: 30/70
# Day 5: 0/100
```

## ğŸ”§ å›æ»¾è¨ˆç•«

### å¿«é€Ÿå›æ»¾è…³æœ¬
```bash
#!/bin/bash
# rollback.sh

BACKUP_DIR=$1

if [ -z "$BACKUP_DIR" ]; then
    echo "Usage: ./rollback.sh <backup_directory>"
    exit 1
fi

echo "âš ï¸ é–‹å§‹å›æ»¾åˆ°: $BACKUP_DIR"

# åœæ­¢æœå‹™
make down

# æ¢å¾©æ•¸æ“š
rm -rf /home/sat/ntn-stack/data
rm -rf /home/sat/ntn-stack/netstack/data/satellites

cp -r "$BACKUP_DIR/data_backup" /home/sat/ntn-stack/data
cp -r "$BACKUP_DIR/netstack_data_backup/satellites" /home/sat/ntn-stack/netstack/data/

# æ¢å¾©é…ç½®
git checkout -- docker-compose.yml
git checkout -- Dockerfile

# é‡å•Ÿæœå‹™
make up

echo "âœ… å›æ»¾å®Œæˆ"
```

## ğŸ“Š é·ç§»æª¢æŸ¥æ¸…å–®

### é·ç§»å‰æª¢æŸ¥
- [ ] å®Œæ•´å‚™ä»½å®Œæˆ
- [ ] æ¸¬è©¦ç’°å¢ƒé©—è­‰é€šé
- [ ] å›æ»¾è…³æœ¬æ¸¬è©¦æˆåŠŸ
- [ ] åœ˜éšŠæˆå“¡çŸ¥æ‚‰è¨ˆç•«
- [ ] ç¶­è­·çª—å£å·²å®‰æ’

### é·ç§»ä¸­ç›£æ§
- [ ] æ•¸æ“šå®Œæ•´æ€§æ ¡é©—
- [ ] API éŸ¿æ‡‰æ™‚é–“æ­£å¸¸
- [ ] éŒ¯èª¤æ—¥èªŒç›£æ§
- [ ] è³‡æºä½¿ç”¨ç‡æ­£å¸¸
- [ ] ç”¨æˆ¶å½±éŸ¿è©•ä¼°

### é·ç§»å¾Œé©—è­‰
- [ ] æ‰€æœ‰ API ç«¯é»æ­£å¸¸
- [ ] 3D æ¸²æŸ“æ­£å¸¸é¡¯ç¤º
- [ ] åœ–è¡¨æ•¸æ“šæ­£ç¢º
- [ ] æ€§èƒ½æŒ‡æ¨™é”æ¨™
- [ ] ç„¡ç•°å¸¸éŒ¯èª¤æ—¥èªŒ

## ğŸš¨ ç‰¹æ®Šæ³¨æ„äº‹é …

### Docker Volume è™•ç†
```yaml
# docker-compose.yml æ›´æ–°
services:
  netstack-api:
    volumes:
      # æ–°æ•¸æ“šä½ç½®
      - ./netstack/data:/app/data
      # è‡¨æ™‚ä¿ç•™èˆŠä½ç½® (å…¼å®¹æœŸ)
      - ./data:/app/legacy_data:ro
```

### ç’°å¢ƒè®Šé‡é…ç½®
```bash
# .env æ–‡ä»¶
DATA_MIGRATION_MODE=progressive
LEGACY_DATA_PATH=/app/legacy_data
NEW_DATA_PATH=/app/data
COMPATIBILITY_PERIOD_DAYS=7
```

## ğŸ“… æ™‚é–“ç·š

| æ—¥æœŸ | éšæ®µ | é—œéµä»»å‹™ |
|------|------|----------|
| Day 1 | æº–å‚™ | å‚™ä»½ã€æ¸¬è©¦ç’°å¢ƒæº–å‚™ |
| Day 2 | è½‰æ› | æ•¸æ“šæ ¼å¼å‡ç´š |
| Day 3 | æ¸¬è©¦ | ä¸¦è¡Œé‹è¡Œæ¸¬è©¦ |
| Day 4-8 | æ¼¸é€²åˆ‡æ› | æµé‡é€æ­¥é·ç§» |
| Day 9 | æ¸…ç† | ç§»é™¤èˆŠæ•¸æ“šå’Œå…¼å®¹ä»£ç¢¼ |

## âœ… æˆåŠŸæ¨™æº–

1. **é›¶æ•¸æ“šä¸Ÿå¤±** - æ‰€æœ‰æ•¸æ“šå®Œæ•´é·ç§»
2. **é›¶åœæ©Ÿæ™‚é–“** - æœå‹™æŒçºŒå¯ç”¨
3. **æ€§èƒ½ä¸é™ç´š** - éŸ¿æ‡‰æ™‚é–“ç¶­æŒæˆ–æ”¹å–„
4. **å®Œå…¨å…¼å®¹** - ç¾æœ‰åŠŸèƒ½æ­£å¸¸é‹ä½œ
5. **å¯è¿½æº¯æ€§** - å®Œæ•´çš„é·ç§»æ—¥èªŒ

## ğŸ“š ç›¸é—œæ–‡ä»¶

- æ•¸æ“šæ¶æ§‹æ–‡æª”ï¼š`/docs/satellite_data_architecture.md`
- æ¸¬è©¦è¨ˆç•«ï¼š`08-validation-testing.md`
- API æ›´æ–°æŒ‡å—ï¼šå¾…å‰µå»º
