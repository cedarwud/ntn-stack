# é©—è­‰èˆ‡æ¸¬è©¦è¨ˆç•«

**æ–‡ä»¶ç‰ˆæœ¬**: 1.0.0  
**æœ€å¾Œæ›´æ–°**: 2025-08-01  
**æ¸¬è©¦è¦†è“‹**: å–®å…ƒæ¸¬è©¦ã€æ•´åˆæ¸¬è©¦ã€ç«¯åˆ°ç«¯æ¸¬è©¦ã€æ€§èƒ½æ¸¬è©¦

## ğŸ“‹ æ¸¬è©¦ç­–ç•¥æ¦‚è¿°

### æ¸¬è©¦é‡‘å­—å¡”
```
         /\
        /  \  ç«¯åˆ°ç«¯æ¸¬è©¦ (10%)
       /----\
      /      \  æ•´åˆæ¸¬è©¦ (30%)
     /--------\
    /          \  å–®å…ƒæ¸¬è©¦ (60%)
   /____________\
```

### æ¸¬è©¦åŸå‰‡
- **è‡ªå‹•åŒ–å„ªå…ˆ** - 95% æ¸¬è©¦è‡ªå‹•åŒ–
- **æŒçºŒæ•´åˆ** - æ¯æ¬¡æäº¤è§¸ç™¼æ¸¬è©¦
- **å¿«é€Ÿåé¥‹** - 10 åˆ†é˜å…§å®ŒæˆåŸºç¤æ¸¬è©¦
- **å…¨é¢è¦†è“‹** - ä»£ç¢¼è¦†è“‹ç‡ > 85%

## ğŸ§ª å–®å…ƒæ¸¬è©¦è¨ˆç•«

### ç¬¬ä¸€éšæ®µï¼šé›¶å®¹å¿ç¯©é¸å™¨
```python
# test_rl_optimized_filter.py

class TestRLOptimizedFilter:
    def test_parameter_validation(self):
        """æ¸¬è©¦åƒæ•¸å®Œæ•´æ€§é©—è­‰"""
        filter = RLOptimizedSatelliteFilter()
        
        # ç¼ºå°‘å¿…è¦åƒæ•¸
        invalid_sat = {"INCLINATION": 53.0}
        valid, reason = filter._validate_parameters(invalid_sat)
        assert not valid
        assert "Missing required parameter" in reason
        
    def test_physics_validation(self):
        """æ¸¬è©¦ç‰©ç†åˆç†æ€§é©—è­‰"""
        # æ¸¬è©¦ç•°å¸¸é›¢å¿ƒç‡
        sat_data = {
            "ECCENTRICITY": 0.5,  # å¤ªé«˜
            "MEAN_MOTION": 15.0
        }
        valid, reason = filter._validate_physics(sat_data)
        assert not valid
        
    def test_oneweb_acceptance(self):
        """ç¢ºä¿ OneWeb è¡›æ˜Ÿé€šéç¯©é¸"""
        oneweb_data = load_test_data("oneweb_sample.json")
        accepted, rejected = filter.filter_satellites(oneweb_data)
        assert len(accepted) == len(oneweb_data)
        assert len(rejected) == 0
```

### ç¬¬äºŒéšæ®µï¼šè»Œé“å¤šæ¨£æ€§ç¯©é¸
```python
# test_orbital_diversity.py

class TestOrbitalDiversityFilter:
    def test_raan_grouping(self):
        """æ¸¬è©¦ RAAN åˆ†ç¾¤ç®—æ³•"""
        satellites = generate_test_satellites(1000)
        filter = OrbitalDiversityFilter()
        groups = filter._group_by_orbital_plane(satellites)
        
        # æ‡‰è©²æœ‰ 36 å€‹çµ„ï¼ˆæ¯ 10 åº¦ä¸€çµ„ï¼‰
        assert len(groups) <= 36
        
        # æ¯çµ„å…§çš„ RAAN å·®ç•°æ‡‰å°æ–¼ 10 åº¦
        for group in groups.values():
            raans = [s['RA_OF_ASC_NODE'] for s in group]
            assert max(raans) - min(raans) < 10
            
    def test_temporal_coverage(self):
        """æ¸¬è©¦æ™‚é–“è¦†è“‹ç„¡ç©ºçª—"""
        selected = filter.select_diverse_satellites(satellites, 500)
        coverage_valid, msg = filter._analyze_temporal_coverage(selected)
        assert coverage_valid, f"Coverage gap found: {msg}"
```

### æ›æ‰‹äº‹ä»¶æª¢æ¸¬æ¸¬è©¦
```python
# test_handover_events.py

class TestHandoverEventDetection:
    def test_d2_event_detection(self):
        """æ¸¬è©¦ D2 äº‹ä»¶æª¢æ¸¬æº–ç¢ºæ€§"""
        detector = D2EventDetector()
        
        # å‰µå»ºæ¸¬è©¦å ´æ™¯ï¼šMRL è·é›¢äº¤å‰
        serving_mrl = [800, 900, 1100, 1200]  # éå¢
        target_mrl = [1200, 1000, 700, 600]   # éæ¸›
        
        events = detector.detect(serving_mrl, target_mrl, timestamps)
        assert len(events) == 1
        assert events[0]['timestamp'] == timestamps[2]  # äº¤å‰é»
        
    def test_t1_prediction_accuracy(self):
        """æ¸¬è©¦ T1 äº‹ä»¶é æ¸¬æº–ç¢ºæ€§"""
        detector = T1EventDetector()
        
        # æ¨¡æ“¬è¡›æ˜Ÿå³å°‡æ¶ˆå¤±çš„è»Œè·¡
        positions = simulate_satellite_pass(elevation_end=5)
        events = detector.detect(positions, ue_position, timestamps)
        
        # æ‡‰è©²åœ¨è¡›æ˜Ÿæ¶ˆå¤±å‰ 30 ç§’è§¸ç™¼
        assert len(events) > 0
        assert 25 <= events[0]['time_to_loss_seconds'] <= 35
```

## ğŸ”— æ•´åˆæ¸¬è©¦è¨ˆç•«

### API æ•´åˆæ¸¬è©¦
```python
# test_api_integration.py

class TestUnifiedAPI:
    @pytest.fixture
    def client(self):
        """æ¸¬è©¦å®¢æˆ¶ç«¯"""
        return TestClient(app)
        
    def test_tier_filtering(self, client):
        """æ¸¬è©¦åˆ†å±¤æŸ¥è©¢åŠŸèƒ½"""
        # Tier 1 æŸ¥è©¢
        response = client.get("/api/v1/satellites/unified/timeseries?tier=tier_1")
        assert response.status_code == 200
        data = response.json()
        assert len(data['satellites']) == 20
        
        # é©—è­‰å±¤ç´šåŒ…å«é—œä¿‚
        tier1_ids = {s['id'] for s in data['satellites']}
        
        # Tier 2 æ‡‰åŒ…å«æ‰€æœ‰ Tier 1
        response = client.get("/api/v1/satellites/unified/timeseries?tier=tier_2")
        tier2_data = response.json()
        tier2_ids = {s['id'] for s in tier2_data['satellites']}
        assert tier1_ids.issubset(tier2_ids)
        
    def test_backward_compatibility(self, client):
        """æ¸¬è©¦å‘å¾Œå…¼å®¹æ€§"""
        # èˆŠç‰ˆ API èª¿ç”¨
        response = client.get("/api/v1/satellites/precomputed/ntpu")
        assert response.status_code == 200
        
        # é©—è­‰èˆŠæ ¼å¼å­—æ®µå­˜åœ¨
        data = response.json()
        assert 'positions' in data['satellites'][0]
```

### æ•¸æ“šç®¡é“æ•´åˆæ¸¬è©¦
```python
# test_pipeline_integration.py

def test_full_pipeline():
    """æ¸¬è©¦å®Œæ•´çš„ç¯©é¸å’Œé è™•ç†ç®¡é“"""
    # 1. è¼‰å…¥åŸå§‹æ•¸æ“š
    raw_satellites = load_raw_tle_data()
    
    # 2. ç¬¬ä¸€éšæ®µç¯©é¸
    rl_filter = RLOptimizedSatelliteFilter()
    stage1_output = rl_filter.filter_satellites(raw_satellites)
    assert len(stage1_output) < 2500
    
    # 3. ç¬¬äºŒéšæ®µç¯©é¸
    diversity_filter = OrbitalDiversityFilter()
    stage2_output = diversity_filter.select_diverse_satellites(stage1_output, 500)
    assert 490 <= len(stage2_output) <= 510
    
    # 4. çµ±ä¸€é è™•ç†
    preprocessor = UnifiedSatellitePreprocessor()
    final_output = preprocessor.preprocess(stage2_output)
    
    # é©—è­‰è¼¸å‡ºæ ¼å¼
    assert 'metadata' in final_output
    assert 'satellites' in final_output
    assert all(event in final_output['satellites'][0]['handover_events'] 
              for event in ['d2', 'd1', 'a4', 't1'])
```

## ğŸš€ ç«¯åˆ°ç«¯æ¸¬è©¦

### 3D æ¸²æŸ“æ¸¬è©¦
```javascript
// test_3d_visualization.e2e.js

describe('3D Satellite Visualization', () => {
  it('should load only Tier 1 satellites', async () => {
    await page.goto('http://localhost:5173/3d-view');
    
    // ç­‰å¾… 3D å ´æ™¯è¼‰å…¥
    await page.waitForSelector('.cesium-viewer');
    
    // æª¢æŸ¥è¡›æ˜Ÿæ•¸é‡
    const satelliteCount = await page.evaluate(() => {
      return window.cesiumViewer.entities.values.length;
    });
    
    expect(satelliteCount).toBeLessThanOrEqual(20);
  });
  
  it('should show smooth transitions without lag', async () => {
    const startTime = Date.now();
    
    // æ¨¡æ“¬ 60 ç§’å‹•ç•«
    await page.evaluate(() => {
      window.cesiumViewer.clock.multiplier = 60;
    });
    
    await page.waitForTimeout(1000);
    
    // æª¢æŸ¥ FPS
    const fps = await page.evaluate(() => {
      return window.cesiumViewer.scene.frameState.fps;
    });
    
    expect(fps).toBeGreaterThan(30);
  });
});
```

### æ›æ‰‹äº‹ä»¶åœ–è¡¨æ¸¬è©¦
```javascript
// test_handover_charts.e2e.js

describe('Handover Event Charts', () => {
  it('should display all event types', async () => {
    await page.goto('http://localhost:5173/handover/charts');
    
    // æª¢æŸ¥æ‰€æœ‰äº‹ä»¶é¡å‹æ¨™ç±¤
    const eventTypes = await page.$$eval('.event-legend-item', 
      items => items.map(item => item.textContent)
    );
    
    expect(eventTypes).toContain('D2 Event');
    expect(eventTypes).toContain('D1 Event');
    expect(eventTypes).toContain('A4 Event');
    expect(eventTypes).toContain('T1 Event');
  });
});
```

## ğŸ“Š æ€§èƒ½æ¸¬è©¦

### è² è¼‰æ¸¬è©¦
```yaml
# k6_load_test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 100 },   // æ¼¸å¢åˆ° 100 ç”¨æˆ¶
    { duration: '5m', target: 100 },   // ç¶­æŒ 100 ç”¨æˆ¶
    { duration: '2m', target: 200 },   // å¢åŠ åˆ° 200 ç”¨æˆ¶
    { duration: '5m', target: 200 },   // ç¶­æŒ 200 ç”¨æˆ¶
    { duration: '2m', target: 0 },     // é™åˆ° 0
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95% è«‹æ±‚ < 500ms
    http_req_failed: ['rate<0.01'],   // éŒ¯èª¤ç‡ < 1%
  },
};

export default function() {
  // æ¸¬è©¦ä¸åŒ tier çš„æŸ¥è©¢
  const tier = ['tier_1', 'tier_2', 'tier_3'][Math.floor(Math.random() * 3)];
  const res = http.get(`http://localhost:8080/api/v1/satellites/unified/timeseries?tier=${tier}`);
  
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });
  
  sleep(1);
}
```

### è¨˜æ†¶é«”å£“åŠ›æ¸¬è©¦
```python
# memory_stress_test.py

def test_memory_usage():
    """æ¸¬è©¦è™•ç† 500 é¡†è¡›æ˜Ÿçš„è¨˜æ†¶é«”ä½¿ç”¨"""
    import psutil
    import os
    
    process = psutil.Process(os.getpid())
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # åŸ·è¡Œå®Œæ•´é è™•ç†
    preprocessor = UnifiedSatellitePreprocessor()
    satellites = load_test_satellites(500)
    
    for _ in range(10):  # é‡è¤‡ 10 æ¬¡
        result = preprocessor.preprocess(satellites)
        
    final_memory = process.memory_info().rss / 1024 / 1024
    memory_increase = final_memory - initial_memory
    
    assert memory_increase < 4000, f"Memory usage too high: {memory_increase}MB"
```

## ğŸ›¡ï¸ å®‰å…¨æ¸¬è©¦

### API å®‰å…¨æ¸¬è©¦
```python
# test_security.py

def test_sql_injection_protection():
    """æ¸¬è©¦ SQL æ³¨å…¥é˜²è­·"""
    malicious_params = [
        "'; DROP TABLE satellites; --",
        "1' OR '1'='1",
        "<script>alert('xss')</script>"
    ]
    
    for param in malicious_params:
        response = client.get(f"/api/v1/satellites/search?name={param}")
        assert response.status_code in [400, 422]  # Bad request
        assert "error" in response.json()

def test_rate_limiting():
    """æ¸¬è©¦é€Ÿç‡é™åˆ¶"""
    # å¿«é€Ÿç™¼é€ 100 å€‹è«‹æ±‚
    responses = []
    for _ in range(100):
        r = client.get("/api/v1/satellites/unified/timeseries")
        responses.append(r.status_code)
    
    # æ‡‰è©²æœ‰ä¸€äº›è«‹æ±‚è¢«é™æµ
    assert 429 in responses  # Too Many Requests
```

## ğŸ“ˆ æ¸¬è©¦æŒ‡æ¨™èˆ‡å ±å‘Š

### æ¸¬è©¦è¦†è“‹ç‡ç›®æ¨™
| æ¨¡çµ„ | ç›®æ¨™è¦†è“‹ç‡ | ç•¶å‰è¦†è“‹ç‡ |
|------|------------|------------|
| é›¶å®¹å¿ç¯©é¸å™¨ | 90% | - |
| è»Œé“å¤šæ¨£æ€§ç¯©é¸ | 85% | - |
| æ›æ‰‹äº‹ä»¶æª¢æ¸¬ | 90% | - |
| API ç«¯é» | 95% | - |
| å‰ç«¯çµ„ä»¶ | 80% | - |

### è‡ªå‹•åŒ–æ¸¬è©¦å ±å‘Š
```bash
#!/bin/bash
# generate_test_report.sh

# åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦ä¸¦ç”Ÿæˆå ±å‘Š
pytest --cov=. --cov-report=html --html=report.html
npm run test:coverage
k6 run k6_load_test.js --out json=load_test_results.json

# æ•´åˆå ±å‘Š
python consolidate_reports.py

# ç™¼é€åˆ°ç›£æ§ç³»çµ±
curl -X POST http://monitoring.internal/api/test-results \
  -H "Content-Type: application/json" \
  -d @consolidated_report.json
```

## ğŸ”„ æŒçºŒæ•´åˆé…ç½®

### GitHub Actions
```yaml
# .github/workflows/test.yml
name: Test Pipeline

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Run Unit Tests
      run: |
        python -m pytest tests/unit -v
        
    - name: Run Integration Tests
      run: |
        docker-compose up -d
        python -m pytest tests/integration -v
        
    - name: Run E2E Tests
      run: |
        npm run test:e2e
        
    - name: Performance Tests
      if: github.ref == 'refs/heads/main'
      run: |
        k6 run tests/performance/load_test.js
```

## âœ… æ¸¬è©¦å®Œæˆæ¨™æº–

### ç™¼å¸ƒå‰å¿…é ˆé€šé
- [ ] æ‰€æœ‰å–®å…ƒæ¸¬è©¦é€šé
- [ ] æ•´åˆæ¸¬è©¦ç„¡å¤±æ•—
- [ ] E2E æ¸¬è©¦å…¨éƒ¨ç¶ ç‡ˆ
- [ ] æ€§èƒ½æ¸¬è©¦é”æ¨™
- [ ] å®‰å…¨æƒæç„¡é«˜å±æ¼æ´
- [ ] ä»£ç¢¼è¦†è“‹ç‡ > 85%

### æ¸¬è©¦å ±å‘Šè¦æ±‚
- [ ] è‡ªå‹•ç”Ÿæˆæ¸¬è©¦å ±å‘Š
- [ ] åŒ…å«å¤±æ•—æ¡ˆä¾‹åˆ†æ
- [ ] æ€§èƒ½åŸºæº–å°æ¯”
- [ ] æ”¹é€²å»ºè­°

## ğŸ“š æ¸¬è©¦è³‡æº

- æ¸¬è©¦æ•¸æ“šé›†ï¼š`/tests/fixtures/`
- æ¸¬è©¦å·¥å…·ï¼špytest, jest, k6, cypress
- CI/CD å¹³å°ï¼šGitHub Actions
- ç›£æ§å¹³å°ï¼šGrafana + Prometheus
