"""
Phase 3 Stage 8: å³æ™‚æ€§èƒ½ç›£æ§å’Œå•é¡Œè­˜åˆ¥ç³»çµ±
å¯¦ç¾å¯¦æ™‚ç›£æ§ã€ç•°å¸¸æª¢æ¸¬å’Œè‡ªå‹•åŒ–å•é¡Œè­˜åˆ¥
"""
import asyncio
import json
import logging
import time
import statistics
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List, Optional, Any, Callable, Tuple
from collections import deque, defaultdict
import yaml

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AnomalyType(Enum):
    """ç•°å¸¸é¡å‹"""
    PERFORMANCE_DEGRADATION = "performance_degradation"
    ERROR_SPIKE = "error_spike"
    LATENCY_SPIKE = "latency_spike"
    RESOURCE_EXHAUSTION = "resource_exhaustion"
    SLA_VIOLATION = "sla_violation"
    HANDOVER_FAILURE = "handover_failure"
    TRAFFIC_ANOMALY = "traffic_anomaly"

class Severity(Enum):
    """åš´é‡ç¨‹åº¦"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ¨™"""
    timestamp: datetime
    service_name: str
    metric_name: str
    value: float
    labels: Dict[str, str] = field(default_factory=dict)
    
@dataclass
class Anomaly:
    """ç•°å¸¸äº‹ä»¶"""
    id: str
    type: AnomalyType
    severity: Severity
    service_name: str
    metric_name: str
    description: str
    current_value: float
    expected_value: float
    threshold: float
    detected_at: datetime
    resolved_at: Optional[datetime] = None
    impact_score: float = 0.0
    root_cause: Optional[str] = None
    
@dataclass
class AlertRule:
    """å‘Šè­¦è¦å‰‡"""
    name: str
    metric_pattern: str
    condition: str  # >, <, ==, anomaly_detection
    threshold: float
    severity: Severity
    window_minutes: int = 5
    min_samples: int = 10
    enabled: bool = True

class StatisticalAnalyzer:
    """çµ±è¨ˆåˆ†æå™¨"""
    
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.metric_windows: Dict[str, deque] = defaultdict(lambda: deque(maxlen=window_size))
        self.baseline_stats: Dict[str, Dict] = {}
        
    def add_metric(self, metric: PerformanceMetric):
        """æ·»åŠ æŒ‡æ¨™æ•¸æ“š"""
        key = f"{metric.service_name}.{metric.metric_name}"
        self.metric_windows[key].append((metric.timestamp, metric.value))
        
        # æ›´æ–°åŸºç·šçµ±è¨ˆ
        if len(self.metric_windows[key]) >= 10:
            values = [v for _, v in self.metric_windows[key]]
            self.baseline_stats[key] = {
                "mean": statistics.mean(values),
                "median": statistics.median(values),
                "stdev": statistics.stdev(values) if len(values) > 1 else 0,
                "min": min(values),
                "max": max(values),
                "p95": self._percentile(values, 95),
                "p99": self._percentile(values, 99)
            }
    
    def detect_anomaly(self, metric: PerformanceMetric) -> Optional[Tuple[bool, float, str]]:
        """æª¢æ¸¬ç•°å¸¸"""
        key = f"{metric.service_name}.{metric.metric_name}"
        
        if key not in self.baseline_stats:
            return None
        
        stats = self.baseline_stats[key]
        value = metric.value
        
        # Z-score ç•°å¸¸æª¢æ¸¬
        if stats["stdev"] > 0:
            z_score = abs(value - stats["mean"]) / stats["stdev"]
            if z_score > 3:  # 3-sigma è¦å‰‡
                anomaly_score = min(z_score / 3, 5.0)  # æ­£è¦åŒ–åˆ° 0-5
                reason = f"Z-scoreç•°å¸¸: {z_score:.2f} (é–¾å€¼: 3.0)"
                return True, anomaly_score, reason
        
        # ç™¾åˆ†ä½æ•¸ç•°å¸¸æª¢æ¸¬
        if value > stats["p99"]:
            anomaly_score = (value - stats["p99"]) / (stats["max"] - stats["p99"]) if stats["max"] > stats["p99"] else 1.0
            reason = f"è¶…éP99: {value:.2f} > {stats['p99']:.2f}"
            return True, min(anomaly_score * 2, 5.0), reason
        
        # è¶¨å‹¢ç•°å¸¸æª¢æ¸¬
        if len(self.metric_windows[key]) >= 10:
            recent_values = [v for _, v in list(self.metric_windows[key])[-10:]]
            if self._detect_trend_anomaly(recent_values):
                reason = "æª¢æ¸¬åˆ°è¶¨å‹¢ç•°å¸¸"
                return True, 2.0, reason
        
        return None
    
    def _percentile(self, values: List[float], percentile: int) -> float:
        """è¨ˆç®—ç™¾åˆ†ä½æ•¸"""
        sorted_values = sorted(values)
        k = (len(sorted_values) - 1) * percentile / 100
        f = int(k)
        c = k - f
        if f + 1 < len(sorted_values):
            return sorted_values[f] * (1 - c) + sorted_values[f + 1] * c
        else:
            return sorted_values[f]
    
    def _detect_trend_anomaly(self, values: List[float]) -> bool:
        """æª¢æ¸¬è¶¨å‹¢ç•°å¸¸"""
        if len(values) < 5:
            return False
        
        # æª¢æ¸¬æŒçºŒä¸Šå‡è¶¨å‹¢ï¼ˆå¯èƒ½è¡¨ç¤ºè³‡æºæ´©æ¼ï¼‰
        increasing_count = 0
        for i in range(1, len(values)):
            if values[i] > values[i-1]:
                increasing_count += 1
        
        # å¦‚æœ 80% ä»¥ä¸Šçš„æ•¸æ“šé»éƒ½åœ¨ä¸Šå‡ï¼Œè¦–ç‚ºç•°å¸¸
        if increasing_count / (len(values) - 1) > 0.8:
            return True
        
        # æª¢æ¸¬çªç„¶è®ŠåŒ–
        recent_avg = statistics.mean(values[-3:])
        earlier_avg = statistics.mean(values[:3])
        
        if abs(recent_avg - earlier_avg) / earlier_avg > 0.5:  # 50% è®ŠåŒ–
            return True
        
        return False

class RealtimePerformanceMonitor:
    """å³æ™‚æ€§èƒ½ç›£æ§å™¨"""
    
    def __init__(self, config_path: str):
        self.config = self._load_config(config_path)
        self.analyzer = StatisticalAnalyzer()
        self.alert_rules: List[AlertRule] = []
        self.active_anomalies: Dict[str, Anomaly] = {}
        self.metric_buffer: List[PerformanceMetric] = []
        self.is_monitoring = False
        
        # æ€§èƒ½æŒ‡æ¨™
        self.metrics_processed = 0
        self.anomalies_detected = 0
        self.alerts_triggered = 0
        
        # å›èª¿å‡½æ•¸
        self.anomaly_callbacks: List[Callable] = []
        self.alert_callbacks: List[Callable] = []
        
        # åˆå§‹åŒ–å‘Šè­¦è¦å‰‡
        self._initialize_alert_rules()
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """è¼‰å…¥é…ç½®"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.error(f"è¼‰å…¥é…ç½®å¤±æ•—: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """ç²å–é è¨­é…ç½®"""
        return {
            "monitoring": {
                "collection_interval": 5,
                "analysis_interval": 10,
                "anomaly_threshold": 2.0,
                "buffer_size": 1000
            },
            "sla_thresholds": {
                "error_rate": 0.001,
                "handover_latency_ms": 50.0,
                "handover_success_rate": 0.995,
                "response_time_ms": 100.0
            },
            "alert_rules": [
                {
                    "name": "high_error_rate",
                    "metric_pattern": "*.error_rate",
                    "condition": ">",
                    "threshold": 0.001,
                    "severity": "critical"
                },
                {
                    "name": "high_handover_latency",
                    "metric_pattern": "*.handover_latency_ms",
                    "condition": ">",
                    "threshold": 50.0,
                    "severity": "critical"
                }
            ]
        }
    
    def _initialize_alert_rules(self):
        """åˆå§‹åŒ–å‘Šè­¦è¦å‰‡"""
        rules_config = self.config.get("alert_rules", [])
        
        for rule_config in rules_config:
            rule = AlertRule(
                name=rule_config["name"],
                metric_pattern=rule_config["metric_pattern"],
                condition=rule_config["condition"],
                threshold=rule_config["threshold"],
                severity=Severity(rule_config.get("severity", "medium")),
                window_minutes=rule_config.get("window_minutes", 5),
                min_samples=rule_config.get("min_samples", 10),
                enabled=rule_config.get("enabled", True)
            )
            self.alert_rules.append(rule)
        
        logger.info(f"åˆå§‹åŒ– {len(self.alert_rules)} æ¢å‘Šè­¦è¦å‰‡")
    
    async def start_monitoring(self):
        """å•Ÿå‹•å³æ™‚ç›£æ§"""
        if self.is_monitoring:
            logger.warning("ç›£æ§å·²åœ¨é‹è¡Œ")
            return
        
        self.is_monitoring = True
        logger.info("ğŸš€ å•Ÿå‹•å³æ™‚æ€§èƒ½ç›£æ§ç³»çµ±")
        
        # å•Ÿå‹•ç›£æ§ä»»å‹™
        tasks = [
            asyncio.create_task(self._metric_collection_loop()),
            asyncio.create_task(self._analysis_loop()),
            asyncio.create_task(self._alert_processing_loop()),
            asyncio.create_task(self._anomaly_resolution_loop())
        ]
        
        try:
            await asyncio.gather(*tasks)
        except asyncio.CancelledError:
            logger.info("å³æ™‚ç›£æ§å·²åœæ­¢")
        finally:
            self.is_monitoring = False
    
    async def stop_monitoring(self):
        """åœæ­¢ç›£æ§"""
        logger.info("ğŸ›‘ åœæ­¢å³æ™‚æ€§èƒ½ç›£æ§")
        self.is_monitoring = False
    
    async def _metric_collection_loop(self):
        """æŒ‡æ¨™æ”¶é›†å¾ªç’°"""
        collection_config = self.config.get("monitoring", {})
        interval = collection_config.get("collection_interval", 5)
        
        while self.is_monitoring:
            try:
                # æ”¶é›†å„æœå‹™æŒ‡æ¨™
                metrics = await self._collect_realtime_metrics()
                
                for metric in metrics:
                    self.metric_buffer.append(metric)
                    self.analyzer.add_metric(metric)
                    self.metrics_processed += 1
                
                # é™åˆ¶ç·©è¡å€å¤§å°
                buffer_size = collection_config.get("buffer_size", 1000)
                if len(self.metric_buffer) > buffer_size:
                    self.metric_buffer = self.metric_buffer[-buffer_size:]
                
                await asyncio.sleep(interval)
                
            except Exception as e:
                logger.error(f"æŒ‡æ¨™æ”¶é›†å¤±æ•—: {e}")
                await asyncio.sleep(interval)
    
    async def _analysis_loop(self):
        """åˆ†æå¾ªç’°"""
        analysis_config = self.config.get("monitoring", {})
        interval = analysis_config.get("analysis_interval", 10)
        
        while self.is_monitoring:
            try:
                # åˆ†ææœ€è¿‘çš„æŒ‡æ¨™
                recent_metrics = self.metric_buffer[-100:] if len(self.metric_buffer) >= 100 else self.metric_buffer
                
                for metric in recent_metrics:
                    await self._analyze_metric(metric)
                
                # æª¢æŸ¥ SLA åˆè¦æ€§
                await self._check_sla_compliance()
                
                await asyncio.sleep(interval)
                
            except Exception as e:
                logger.error(f"æŒ‡æ¨™åˆ†æå¤±æ•—: {e}")
                await asyncio.sleep(interval)
    
    async def _alert_processing_loop(self):
        """å‘Šè­¦è™•ç†å¾ªç’°"""
        while self.is_monitoring:
            try:
                # è™•ç†æ´»èºç•°å¸¸
                for anomaly_id, anomaly in list(self.active_anomalies.items()):
                    await self._process_anomaly(anomaly)
                
                await asyncio.sleep(30)  # æ¯30ç§’è™•ç†ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"å‘Šè­¦è™•ç†å¤±æ•—: {e}")
                await asyncio.sleep(30)
    
    async def _anomaly_resolution_loop(self):
        """ç•°å¸¸è§£æ±ºå¾ªç’°"""
        while self.is_monitoring:
            try:
                # æª¢æŸ¥ç•°å¸¸æ˜¯å¦å·²è§£æ±º
                resolved_anomalies = []
                
                for anomaly_id, anomaly in self.active_anomalies.items():
                    if await self._check_anomaly_resolved(anomaly):
                        anomaly.resolved_at = datetime.now()
                        resolved_anomalies.append(anomaly_id)
                        logger.info(f"âœ… ç•°å¸¸å·²è§£æ±º: {anomaly.description}")
                
                # ç§»é™¤å·²è§£æ±ºçš„ç•°å¸¸
                for anomaly_id in resolved_anomalies:
                    del self.active_anomalies[anomaly_id]
                
                await asyncio.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"ç•°å¸¸è§£æ±ºæª¢æŸ¥å¤±æ•—: {e}")
                await asyncio.sleep(60)
    
    async def _collect_realtime_metrics(self) -> List[PerformanceMetric]:
        """æ”¶é›†å³æ™‚æŒ‡æ¨™"""
        metrics = []
        current_time = datetime.now()
        
        # æ¨¡æ“¬å¾å„æœå‹™æ”¶é›†æŒ‡æ¨™
        services = ["netstack", "simworld", "frontend", "gateway"]
        
        for service in services:
            # æ¨¡æ“¬æŒ‡æ¨™æ”¶é›†
            import random
            
            # HTTP æŒ‡æ¨™
            metrics.append(PerformanceMetric(
                timestamp=current_time,
                service_name=service,
                metric_name="error_rate",
                value=random.uniform(0.0001, 0.002),  # 0.01-0.2% éŒ¯èª¤ç‡
                labels={"service": service}
            ))
            
            metrics.append(PerformanceMetric(
                timestamp=current_time,
                service_name=service,
                metric_name="response_time_ms",
                value=random.uniform(20, 120),  # 20-120ms éŸ¿æ‡‰æ™‚é–“
                labels={"service": service}
            ))
            
            metrics.append(PerformanceMetric(
                timestamp=current_time,
                service_name=service,
                metric_name="throughput_rps",
                value=random.uniform(50, 500),  # 50-500 RPS
                labels={"service": service}
            ))
            
            # è³‡æºæŒ‡æ¨™
            metrics.append(PerformanceMetric(
                timestamp=current_time,
                service_name=service,
                metric_name="cpu_usage",
                value=random.uniform(0.2, 0.9),  # 20-90% CPU ä½¿ç”¨ç‡
                labels={"service": service}
            ))
            
            metrics.append(PerformanceMetric(
                timestamp=current_time,
                service_name=service,
                metric_name="memory_usage",
                value=random.uniform(0.3, 0.8),  # 30-80% è¨˜æ†¶é«”ä½¿ç”¨ç‡
                labels={"service": service}
            ))
        
        # NTN ç‰¹å®šæŒ‡æ¨™
        metrics.extend([
            PerformanceMetric(
                timestamp=current_time,
                service_name="ntn",
                metric_name="handover_latency_ms",
                value=random.uniform(25, 65),  # 25-65ms handover å»¶é²
                labels={"interface": "n2"}
            ),
            PerformanceMetric(
                timestamp=current_time,
                service_name="ntn",
                metric_name="handover_success_rate",
                value=random.uniform(0.993, 0.999),  # 99.3-99.9% æˆåŠŸç‡
                labels={"interface": "n2"}
            ),
            PerformanceMetric(
                timestamp=current_time,
                service_name="ntn",
                metric_name="active_ue_contexts",
                value=random.randint(5, 50),  # 5-50 æ´»èº UE
                labels={"interface": "n2"}
            )
        ])
        
        return metrics
    
    async def _analyze_metric(self, metric: PerformanceMetric):
        """åˆ†æå–®å€‹æŒ‡æ¨™"""
        # ç•°å¸¸æª¢æ¸¬
        anomaly_result = self.analyzer.detect_anomaly(metric)
        
        if anomaly_result:
            is_anomaly, anomaly_score, reason = anomaly_result
            if is_anomaly:
                await self._handle_anomaly_detection(metric, anomaly_score, reason)
        
        # è¦å‰‡åŒ¹é…
        for rule in self.alert_rules:
            if rule.enabled and self._match_rule(metric, rule):
                await self._trigger_alert(metric, rule)
    
    def _match_rule(self, metric: PerformanceMetric, rule: AlertRule) -> bool:
        """æª¢æŸ¥æŒ‡æ¨™æ˜¯å¦åŒ¹é…å‘Šè­¦è¦å‰‡"""
        # ç°¡å–®çš„æ¨¡å¼åŒ¹é…
        pattern = rule.metric_pattern.replace("*", "")
        metric_path = f"{metric.service_name}.{metric.metric_name}"
        
        if pattern not in metric_path:
            return False
        
        # æª¢æŸ¥æ¢ä»¶
        if rule.condition == ">":
            return metric.value > rule.threshold
        elif rule.condition == "<":
            return metric.value < rule.threshold
        elif rule.condition == "==":
            return abs(metric.value - rule.threshold) < 0.001
        
        return False
    
    async def _handle_anomaly_detection(self, metric: PerformanceMetric, anomaly_score: float, reason: str):
        """è™•ç†ç•°å¸¸æª¢æ¸¬"""
        anomaly_id = f"{metric.service_name}_{metric.metric_name}_{int(time.time())}"
        
        # ç¢ºå®šç•°å¸¸é¡å‹
        anomaly_type = self._classify_anomaly(metric)
        
        # ç¢ºå®šåš´é‡ç¨‹åº¦
        severity = self._determine_severity(metric, anomaly_score)
        
        # å‰µå»ºç•°å¸¸å°è±¡
        anomaly = Anomaly(
            id=anomaly_id,
            type=anomaly_type,
            severity=severity,
            service_name=metric.service_name,
            metric_name=metric.metric_name,
            description=f"{metric.service_name} {metric.metric_name} ç•°å¸¸: {reason}",
            current_value=metric.value,
            expected_value=self._get_expected_value(metric),
            threshold=self._get_threshold_for_metric(metric),
            detected_at=metric.timestamp,
            impact_score=anomaly_score
        )
        
        self.active_anomalies[anomaly_id] = anomaly
        self.anomalies_detected += 1
        
        logger.warning(f"ğŸš¨ æª¢æ¸¬åˆ°ç•°å¸¸: {anomaly.description} (è©•åˆ†: {anomaly_score:.2f})")
        
        # è§¸ç™¼å›èª¿
        for callback in self.anomaly_callbacks:
            try:
                await callback(anomaly)
            except Exception as e:
                logger.error(f"ç•°å¸¸å›èª¿åŸ·è¡Œå¤±æ•—: {e}")
    
    def _classify_anomaly(self, metric: PerformanceMetric) -> AnomalyType:
        """åˆ†é¡ç•°å¸¸é¡å‹"""
        if "error_rate" in metric.metric_name:
            return AnomalyType.ERROR_SPIKE
        elif "latency" in metric.metric_name or "response_time" in metric.metric_name:
            return AnomalyType.LATENCY_SPIKE
        elif "handover" in metric.metric_name:
            return AnomalyType.HANDOVER_FAILURE
        elif "cpu" in metric.metric_name or "memory" in metric.metric_name:
            return AnomalyType.RESOURCE_EXHAUSTION
        else:
            return AnomalyType.PERFORMANCE_DEGRADATION
    
    def _determine_severity(self, metric: PerformanceMetric, anomaly_score: float) -> Severity:
        """ç¢ºå®šåš´é‡ç¨‹åº¦"""
        # æª¢æŸ¥æ˜¯å¦é•å SLA
        sla_thresholds = self.config.get("sla_thresholds", {})
        
        if metric.metric_name == "error_rate" and metric.value > sla_thresholds.get("error_rate", 0.001):
            return Severity.CRITICAL
        elif metric.metric_name == "handover_latency_ms" and metric.value > sla_thresholds.get("handover_latency_ms", 50.0):
            return Severity.CRITICAL
        elif metric.metric_name == "handover_success_rate" and metric.value < sla_thresholds.get("handover_success_rate", 0.995):
            return Severity.CRITICAL
        
        # æ ¹æ“šç•°å¸¸è©•åˆ†ç¢ºå®šåš´é‡ç¨‹åº¦
        if anomaly_score >= 4.0:
            return Severity.CRITICAL
        elif anomaly_score >= 3.0:
            return Severity.HIGH
        elif anomaly_score >= 2.0:
            return Severity.MEDIUM
        else:
            return Severity.LOW
    
    def _get_expected_value(self, metric: PerformanceMetric) -> float:
        """ç²å–é æœŸå€¼"""
        key = f"{metric.service_name}.{metric.metric_name}"
        if key in self.analyzer.baseline_stats:
            return self.analyzer.baseline_stats[key]["mean"]
        return 0.0
    
    def _get_threshold_for_metric(self, metric: PerformanceMetric) -> float:
        """ç²å–æŒ‡æ¨™é–¾å€¼"""
        sla_thresholds = self.config.get("sla_thresholds", {})
        return sla_thresholds.get(metric.metric_name, 0.0)
    
    async def _trigger_alert(self, metric: PerformanceMetric, rule: AlertRule):
        """è§¸ç™¼å‘Šè­¦"""
        alert_data = {
            "rule_name": rule.name,
            "service": metric.service_name,
            "metric": metric.metric_name,
            "current_value": metric.value,
            "threshold": rule.threshold,
            "severity": rule.severity.value,
            "timestamp": metric.timestamp.isoformat()
        }
        
        self.alerts_triggered += 1
        logger.error(f"ğŸš¨ è§¸ç™¼å‘Šè­¦: {rule.name} - {metric.service_name}.{metric.metric_name} = {metric.value} (é–¾å€¼: {rule.threshold})")
        
        # è§¸ç™¼å‘Šè­¦å›èª¿
        for callback in self.alert_callbacks:
            try:
                await callback(alert_data)
            except Exception as e:
                logger.error(f"å‘Šè­¦å›èª¿åŸ·è¡Œå¤±æ•—: {e}")
    
    async def _check_sla_compliance(self):
        """æª¢æŸ¥ SLA åˆè¦æ€§"""
        sla_thresholds = self.config.get("sla_thresholds", {})
        
        # ç²å–æœ€è¿‘çš„æŒ‡æ¨™
        recent_metrics = self.metric_buffer[-50:] if len(self.metric_buffer) >= 50 else self.metric_buffer
        
        # æŒ‰æŒ‡æ¨™é¡å‹åˆ†çµ„
        metrics_by_type = defaultdict(list)
        for metric in recent_metrics:
            metrics_by_type[metric.metric_name].append(metric.value)
        
        # æª¢æŸ¥å„é … SLA
        sla_violations = []
        
        for metric_name, threshold in sla_thresholds.items():
            if metric_name in metrics_by_type:
                values = metrics_by_type[metric_name]
                
                if metric_name in ["error_rate", "handover_latency_ms", "response_time_ms"]:
                    # é€™äº›æŒ‡æ¨™éœ€è¦ä½æ–¼é–¾å€¼
                    avg_value = statistics.mean(values)
                    if avg_value > threshold:
                        sla_violations.append(f"{metric_name}: {avg_value:.4f} > {threshold}")
                
                elif metric_name in ["handover_success_rate"]:
                    # é€™äº›æŒ‡æ¨™éœ€è¦é«˜æ–¼é–¾å€¼
                    avg_value = statistics.mean(values)
                    if avg_value < threshold:
                        sla_violations.append(f"{metric_name}: {avg_value:.4f} < {threshold}")
        
        if sla_violations:
            logger.error(f"ğŸš¨ SLA é•è¦æª¢æ¸¬:")
            for violation in sla_violations:
                logger.error(f"  - {violation}")
    
    async def _process_anomaly(self, anomaly: Anomaly):
        """è™•ç†ç•°å¸¸"""
        # æ ¹ç•°å› åˆ†æ
        if not anomaly.root_cause:
            anomaly.root_cause = await self._analyze_root_cause(anomaly)
        
        # è¨ˆç®—æ¥­å‹™å½±éŸ¿
        anomaly.impact_score = await self._calculate_business_impact(anomaly)
    
    async def _analyze_root_cause(self, anomaly: Anomaly) -> str:
        """åˆ†ææ ¹æœ¬åŸå› """
        # ç°¡åŒ–çš„æ ¹å› åˆ†æ
        if anomaly.type == AnomalyType.ERROR_SPIKE:
            return "å¯èƒ½åŸå› : æœå‹™ç•°å¸¸ã€ç¶²è·¯å•é¡Œæˆ–è² è¼‰éé«˜"
        elif anomaly.type == AnomalyType.LATENCY_SPIKE:
            return "å¯èƒ½åŸå› : è³‡æºä¸è¶³ã€ç¶²è·¯å»¶é²æˆ–è³‡æ–™åº«æŸ¥è©¢ç·©æ…¢"
        elif anomaly.type == AnomalyType.HANDOVER_FAILURE:
            return "å¯èƒ½åŸå› : è¡›æ˜Ÿä¿¡è™Ÿå•é¡Œã€é…ç½®éŒ¯èª¤æˆ–ç®—æ³•ç¼ºé™·"
        elif anomaly.type == AnomalyType.RESOURCE_EXHAUSTION:
            return "å¯èƒ½åŸå› : è¨˜æ†¶é«”æ´©æ¼ã€CPU å¯†é›†å‹ä»»å‹™æˆ–è³‡æºé…ç½®ä¸è¶³"
        else:
            return "éœ€è¦é€²ä¸€æ­¥èª¿æŸ¥"
    
    async def _calculate_business_impact(self, anomaly: Anomaly) -> float:
        """è¨ˆç®—æ¥­å‹™å½±éŸ¿"""
        # åŸºç¤å½±éŸ¿è©•åˆ†
        base_impact = 0.0
        
        if anomaly.severity == Severity.CRITICAL:
            base_impact = 0.8
        elif anomaly.severity == Severity.HIGH:
            base_impact = 0.6
        elif anomaly.severity == Severity.MEDIUM:
            base_impact = 0.4
        else:
            base_impact = 0.2
        
        # æ ¹æ“šæœå‹™é‡è¦æ€§èª¿æ•´
        service_weights = {
            "netstack": 1.0,
            "simworld": 0.8,
            "frontend": 0.6,
            "gateway": 0.9
        }
        
        service_weight = service_weights.get(anomaly.service_name, 0.5)
        
        return min(base_impact * service_weight, 1.0)
    
    async def _check_anomaly_resolved(self, anomaly: Anomaly) -> bool:
        """æª¢æŸ¥ç•°å¸¸æ˜¯å¦å·²è§£æ±º"""
        # ç²å–æœ€è¿‘çš„ç›¸åŒæŒ‡æ¨™
        recent_metrics = [
            m for m in self.metric_buffer[-10:]
            if m.service_name == anomaly.service_name and m.metric_name == anomaly.metric_name
        ]
        
        if not recent_metrics:
            return False
        
        # æª¢æŸ¥æŒ‡æ¨™æ˜¯å¦å›åˆ°æ­£å¸¸ç¯„åœ
        recent_values = [m.value for m in recent_metrics]
        avg_recent = statistics.mean(recent_values)
        
        # æ ¹æ“šç•°å¸¸é¡å‹æª¢æŸ¥æ¢å¾©æ¢ä»¶
        if anomaly.type in [AnomalyType.ERROR_SPIKE, AnomalyType.LATENCY_SPIKE]:
            return avg_recent < anomaly.threshold
        elif anomaly.type == AnomalyType.HANDOVER_FAILURE:
            return avg_recent > anomaly.threshold  # handover_success_rate
        else:
            # æª¢æŸ¥æ˜¯å¦æ¥è¿‘é æœŸå€¼
            return abs(avg_recent - anomaly.expected_value) / anomaly.expected_value < 0.1
    
    def add_anomaly_callback(self, callback: Callable):
        """æ·»åŠ ç•°å¸¸å›èª¿"""
        self.anomaly_callbacks.append(callback)
    
    def add_alert_callback(self, callback: Callable):
        """æ·»åŠ å‘Šè­¦å›èª¿"""
        self.alert_callbacks.append(callback)
    
    def get_monitoring_status(self) -> Dict[str, Any]:
        """ç²å–ç›£æ§ç‹€æ…‹"""
        return {
            "is_monitoring": self.is_monitoring,
            "metrics_processed": self.metrics_processed,
            "anomalies_detected": self.anomalies_detected,
            "alerts_triggered": self.alerts_triggered,
            "active_anomalies": len(self.active_anomalies),
            "buffer_size": len(self.metric_buffer),
            "last_collection": datetime.now().isoformat()
        }
    
    def get_active_anomalies(self) -> List[Dict[str, Any]]:
        """ç²å–æ´»èºç•°å¸¸åˆ—è¡¨"""
        return [
            {
                "id": anomaly.id,
                "type": anomaly.type.value,
                "severity": anomaly.severity.value,
                "service": anomaly.service_name,
                "metric": anomaly.metric_name,
                "description": anomaly.description,
                "detected_at": anomaly.detected_at.isoformat(),
                "impact_score": anomaly.impact_score,
                "root_cause": anomaly.root_cause
            }
            for anomaly in self.active_anomalies.values()
        ]

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """å³æ™‚æ€§èƒ½ç›£æ§ç¤ºä¾‹"""
    
    # å‰µå»ºç›£æ§é…ç½®
    config = {
        "monitoring": {
            "collection_interval": 2,
            "analysis_interval": 5,
            "anomaly_threshold": 2.0
        },
        "sla_thresholds": {
            "error_rate": 0.001,
            "handover_latency_ms": 50.0,
            "handover_success_rate": 0.995,
            "response_time_ms": 100.0
        },
        "alert_rules": [
            {
                "name": "critical_error_rate",
                "metric_pattern": "*.error_rate",
                "condition": ">",
                "threshold": 0.001,
                "severity": "critical"
            },
            {
                "name": "sla_handover_latency",
                "metric_pattern": "*.handover_latency_ms", 
                "condition": ">",
                "threshold": 50.0,
                "severity": "critical"
            }
        ]
    }
    
    config_path = "/tmp/realtime_monitor_config.yaml"
    with open(config_path, "w", encoding="utf-8") as f:
        yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
    
    # åˆå§‹åŒ–ç›£æ§å™¨
    monitor = RealtimePerformanceMonitor(config_path)
    
    # æ·»åŠ å›èª¿å‡½æ•¸
    async def anomaly_handler(anomaly):
        print(f"ğŸš¨ ç•°å¸¸æª¢æ¸¬: {anomaly.description} (åš´é‡ç¨‹åº¦: {anomaly.severity.value})")
    
    async def alert_handler(alert):
        print(f"ğŸ”” å‘Šè­¦è§¸ç™¼: {alert['rule_name']} - {alert['metric']} = {alert['current_value']}")
    
    monitor.add_anomaly_callback(anomaly_handler)
    monitor.add_alert_callback(alert_handler)
    
    # å•Ÿå‹•ç›£æ§
    try:
        print("ğŸš€ å•Ÿå‹•å³æ™‚æ€§èƒ½ç›£æ§ç³»çµ±...")
        
        # é‹è¡Œç›£æ§ (ç¤ºä¾‹é‹è¡Œ 60 ç§’)
        monitoring_task = asyncio.create_task(monitor.start_monitoring())
        
        # ç­‰å¾…ä¸€æ®µæ™‚é–“å¾ŒæŸ¥çœ‹ç‹€æ…‹
        await asyncio.sleep(30)
        
        # æŸ¥çœ‹ç›£æ§ç‹€æ…‹
        status = monitor.get_monitoring_status()
        print(f"ç›£æ§ç‹€æ…‹: {json.dumps(status, ensure_ascii=False, indent=2)}")
        
        # æŸ¥çœ‹æ´»èºç•°å¸¸
        anomalies = monitor.get_active_anomalies()
        print(f"æ´»èºç•°å¸¸: {len(anomalies)} å€‹")
        for anomaly in anomalies:
            print(f"  - {anomaly['severity']}: {anomaly['description']}")
        
        # åœæ­¢ç›£æ§
        await monitor.stop_monitoring()
        monitoring_task.cancel()
        
    except KeyboardInterrupt:
        print("åœæ­¢ç›£æ§ç³»çµ±")
        await monitor.stop_monitoring()

if __name__ == "__main__":
    asyncio.run(main())