#!/usr/bin/env python3
"""
è«–æ–‡å¾©ç¾ç¶œåˆæ¸¬è©¦åŸ·è¡Œå™¨

çµ±ä¸€åŸ·è¡Œ 1.1 åˆ° 1.3 çš„æ‰€æœ‰æ¸¬è©¦ï¼Œç”Ÿæˆå®Œæ•´çš„è«–æ–‡å¾©ç¾å ±å‘Š

åŸ·è¡Œæ–¹å¼ (åœ¨ ntn-stack æ ¹ç›®éŒ„):
source venv/bin/activate
python paper/comprehensive/run_all_tests.py

æˆ–æŒ‡å®šç‰¹å®šéšæ®µ:
python paper/comprehensive/run_all_tests.py --stage 1.2
python paper/comprehensive/run_all_tests.py --stage 1.3
python paper/comprehensive/run_all_tests.py --stage all
"""

import sys
import os
import asyncio
import argparse
import subprocess
import json
import logging
from datetime import datetime
from typing import Dict, List, Any
import traceback

# æ·»åŠ  NetStack API è·¯å¾‘
sys.path.insert(0, "/home/sat/ntn-stack/netstack/netstack_api")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PaperReproductionTestRunner:
    """è«–æ–‡å¾©ç¾ç¶œåˆæ¸¬è©¦åŸ·è¡Œå™¨"""

    def __init__(self):
        self.test_results = {}
        self.start_time = None
        self.end_time = None
        self.base_path = "/home/sat/ntn-stack/paper"

        # æ¸¬è©¦éšæ®µå®šç¾© (ä¿®æ­£è·¯å¾‘)
        self.test_stages = {
            "1.1": {
                "name": "è¡›æ˜Ÿè»Œé“é æ¸¬æ¨¡çµ„æ•´åˆ",
                "script": f"{self.base_path}/1.1_satellite_orbit/test_tle_integration.py",
                "description": "NetStack â†” SimWorld TLE è³‡æ–™æ©‹æ¥",
            },
            "1.2": {
                "name": "åŒæ­¥æ¼”ç®—æ³• (Algorithm 1)",
                "script": f"{self.base_path}/1.2_synchronized_algorithm/test_algorithm_1.py",
                "description": "äºŒåˆ†æœå°‹æ›æ‰‹æ™‚é–“é æ¸¬ã€é€±æœŸæ€§æ›´æ–°æ©Ÿåˆ¶",
            },
            "1.3": {
                "name": "å¿«é€Ÿè¡›æ˜Ÿé æ¸¬æ¼”ç®—æ³• (Algorithm 2)",
                "script": f"{self.base_path}/1.3_fast_prediction/test_algorithm_2.py",
                "description": "åœ°ç†å€å¡ŠåŠƒåˆ†ã€UEå­˜å–ç­–ç•¥ç®¡ç†",
            },
        }

    async def run_stage_test(self, stage_id: str) -> Dict[str, Any]:
        """åŸ·è¡Œå–®å€‹éšæ®µçš„æ¸¬è©¦"""
        stage_info = self.test_stages[stage_id]

        print(f"\nğŸ”¬ åŸ·è¡Œ {stage_id} {stage_info['name']} æ¸¬è©¦...")
        print(f"ğŸ“ {stage_info['description']}")
        print("-" * 60)

        start_time = datetime.now()

        try:
            # ä½¿ç”¨ venv Python åŸ·è¡Œæ¸¬è©¦è…³æœ¬
            venv_python = "/home/sat/ntn-stack/venv/bin/python"
            script_path = stage_info["script"]

            # æª¢æŸ¥è…³æœ¬æ˜¯å¦å­˜åœ¨
            if not os.path.exists(script_path):
                raise FileNotFoundError(f"æ¸¬è©¦è…³æœ¬ä¸å­˜åœ¨: {script_path}")

            # åŸ·è¡Œæ¸¬è©¦è…³æœ¬
            process = await asyncio.create_subprocess_exec(
                venv_python,
                script_path,
                cwd="/home/sat/ntn-stack",
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )

            stdout, stderr = await process.communicate()

            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            # è§£æçµæœ
            success = process.returncode == 0
            output = stdout.decode("utf-8") if stdout else ""
            error_output = stderr.decode("utf-8") if stderr else ""

            # æå–æ¸¬è©¦çµ±è¨ˆ
            passed_tests, total_tests, success_rate = self._parse_test_output(output)

            result = {
                "stage_id": stage_id,
                "stage_name": stage_info["name"],
                "description": stage_info["description"],
                "success": success,
                "duration_seconds": duration,
                "passed_tests": passed_tests,
                "total_tests": total_tests,
                "success_rate": success_rate,
                "output": output,
                "error_output": error_output,
                "return_code": process.returncode,
            }

            if success:
                print(f"âœ… {stage_id} æ¸¬è©¦æˆåŠŸå®Œæˆ")
                print(
                    f"   é€šéæ¸¬è©¦: {passed_tests}/{total_tests} ({success_rate:.1f}%)"
                )
                print(f"   åŸ·è¡Œæ™‚é–“: {duration:.2f} ç§’")
            else:
                print(f"âŒ {stage_id} æ¸¬è©¦å¤±æ•—")
                print(f"   è¿”å›ç¢¼: {process.returncode}")
                if error_output:
                    print(f"   éŒ¯èª¤è¼¸å‡º: {error_output[:200]}...")

            return result

        except Exception as e:
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            error_msg = f"åŸ·è¡Œ {stage_id} æ¸¬è©¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
            print(f"âŒ {error_msg}")
            logger.error(error_msg, exc_info=True)

            return {
                "stage_id": stage_id,
                "stage_name": stage_info["name"],
                "description": stage_info["description"],
                "success": False,
                "duration_seconds": duration,
                "passed_tests": 0,
                "total_tests": 0,
                "success_rate": 0.0,
                "output": "",
                "error_output": str(e),
                "return_code": -1,
                "exception": traceback.format_exc(),
            }

    def _parse_test_output(self, output: str) -> tuple:
        """è§£ææ¸¬è©¦è¼¸å‡ºï¼Œæå–çµ±è¨ˆè³‡è¨Š"""
        passed_tests = 0
        total_tests = 0
        success_rate = 0.0

        try:
            lines = output.split("\n")
            for line in lines:
                if "ç¸½æ¸¬è©¦æ•¸:" in line:
                    total_tests = int(line.split(":")[1].strip())
                elif "é€šéæ¸¬è©¦:" in line:
                    passed_tests = int(line.split(":")[1].strip())
                elif "æˆåŠŸç‡:" in line and "%" in line:
                    success_rate = float(line.split(":")[1].replace("%", "").strip())
        except Exception as e:
            logger.warning(f"è§£ææ¸¬è©¦è¼¸å‡ºå¤±æ•—: {str(e)}")

        return passed_tests, total_tests, success_rate

    async def run_all_tests(self, stage_filter: str = "all") -> Dict[str, Any]:
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦æˆ–æŒ‡å®šéšæ®µçš„æ¸¬è©¦"""
        self.start_time = datetime.now()

        print("ğŸš€ é–‹å§‹åŸ·è¡Œè«–æ–‡å¾©ç¾ç¶œåˆæ¸¬è©¦")
        print("=" * 80)
        print(f"æ¸¬è©¦ç¯„åœ: {stage_filter}")
        print(f"é–‹å§‹æ™‚é–“: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æ¸¬è©¦ç’°å¢ƒ: venv Python ç’°å¢ƒ")
        print("=" * 80)

        # ç¢ºå®šè¦åŸ·è¡Œçš„éšæ®µ
        if stage_filter == "all":
            stages_to_run = list(self.test_stages.keys())
        else:
            stages_to_run = [stage_filter] if stage_filter in self.test_stages else []

        if not stages_to_run:
            raise ValueError(f"ç„¡æ•ˆçš„éšæ®µé¸æ“‡: {stage_filter}")

        # åŸ·è¡Œå„éšæ®µæ¸¬è©¦
        for stage_id in stages_to_run:
            stage_result = await self.run_stage_test(stage_id)
            self.test_results[stage_id] = stage_result

        self.end_time = datetime.now()

        # ç”Ÿæˆç¶œåˆå ±å‘Š
        comprehensive_report = self._generate_comprehensive_report()

        # è¼¸å‡ºå ±å‘Š
        self._print_comprehensive_summary(comprehensive_report)

        # ä¿å­˜å ±å‘Š
        await self._save_comprehensive_report(comprehensive_report)

        return comprehensive_report

    def _generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç¶œåˆæ¸¬è©¦å ±å‘Š"""
        total_duration = (self.end_time - self.start_time).total_seconds()

        # è¨ˆç®—ç¸½é«”çµ±è¨ˆ
        total_tests = sum(
            result.get("total_tests", 0) for result in self.test_results.values()
        )
        total_passed = sum(
            result.get("passed_tests", 0) for result in self.test_results.values()
        )
        successful_stages = sum(
            1 for result in self.test_results.values() if result.get("success", False)
        )
        total_stages = len(self.test_results)

        return {
            "test_execution_info": {
                "start_time": self.start_time.isoformat(),
                "end_time": self.end_time.isoformat(),
                "total_duration_seconds": total_duration,
                "test_environment": "venv Python Environment",
                "python_executable": "/home/sat/ntn-stack/venv/bin/python",
            },
            "overall_summary": {
                "total_stages": total_stages,
                "successful_stages": successful_stages,
                "failed_stages": total_stages - successful_stages,
                "stage_success_rate": (
                    f"{(successful_stages/total_stages*100):.1f}%"
                    if total_stages > 0
                    else "0%"
                ),
                "total_individual_tests": total_tests,
                "total_passed_tests": total_passed,
                "total_failed_tests": total_tests - total_passed,
                "overall_test_success_rate": (
                    f"{(total_passed/total_tests*100):.1f}%"
                    if total_tests > 0
                    else "0%"
                ),
            },
            "stage_results": self.test_results,
            "paper_reproduction_validation": self._validate_paper_reproduction(),
            "recommendations": self._generate_recommendations(),
        }

    def _validate_paper_reproduction(self) -> Dict[str, str]:
        """é©—è­‰è«–æ–‡å¾©ç¾ç‹€æ…‹"""
        validation = {
            "tle_integration": "âŒ æœªæ¸¬è©¦",
            "algorithm_1_implementation": "âŒ æœªæ¸¬è©¦",
            "algorithm_2_implementation": "âŒ æœªæ¸¬è©¦",
            "binary_search_precision": "âŒ æœªé©—è­‰",
            "geographical_block_division": "âŒ æœªé©—è­‰",
            "ue_access_strategy_management": "âŒ æœªé©—è­‰",
            "prediction_accuracy_target": "âŒ æœªé©—è­‰",
            "cross_container_communication": "âŒ æœªé©—è­‰",
        }

        # æª¢æŸ¥ 1.1 TLE æ•´åˆ
        if "1.1" in self.test_results and self.test_results["1.1"].get("success"):
            validation["tle_integration"] = "âœ… å·²å®Œæˆ"
            validation["cross_container_communication"] = "âœ… å·²é©—è­‰"

        # æª¢æŸ¥ 1.2 åŒæ­¥æ¼”ç®—æ³•
        if "1.2" in self.test_results and self.test_results["1.2"].get("success"):
            validation["algorithm_1_implementation"] = "âœ… å·²å¯¦ç¾"
            validation["binary_search_precision"] = "âœ… å·²é©—è­‰"

        # æª¢æŸ¥ 1.3 å¿«é€Ÿè¡›æ˜Ÿé æ¸¬æ¼”ç®—æ³•
        if "1.3" in self.test_results and self.test_results["1.3"].get("success"):
            validation["algorithm_2_implementation"] = "âœ… å·²å¯¦ç¾"
            validation["geographical_block_division"] = "âœ… å·²é©—è­‰"
            validation["ue_access_strategy_management"] = "âœ… å·²é©—è­‰"
            validation["prediction_accuracy_target"] = "âœ… å·²é©—è­‰"

        return validation

    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆå»ºè­°å’Œå¾ŒçºŒæ­¥é©Ÿ"""
        recommendations = []

        # æª¢æŸ¥å¤±æ•—çš„éšæ®µ
        failed_stages = [
            stage_id
            for stage_id, result in self.test_results.items()
            if not result.get("success", False)
        ]

        if failed_stages:
            recommendations.append(
                f"ğŸ”§ éœ€è¦ä¿®å¾©å¤±æ•—çš„æ¸¬è©¦éšæ®µ: {', '.join(failed_stages)}"
            )

        # æˆåŠŸæƒ…æ³çš„å¾ŒçºŒæ­¥é©Ÿ
        all_success = all(
            result.get("success", False) for result in self.test_results.values()
        )

        if all_success:
            recommendations.extend(
                [
                    "ğŸ¯ 1.1-1.3 éšæ®µå…¨éƒ¨é€šéï¼å¯ä»¥é–‹å§‹ä¸‹ä¸€éšæ®µï¼š1.4 UPF ä¿®æ”¹èˆ‡æ•´åˆ",
                    "ğŸ“Š å»ºè­°å»ºç«‹æŒçºŒæ•´åˆæ¸¬è©¦ç®¡é“",
                    "ğŸš€ å¯ä»¥é–‹å§‹æ•ˆèƒ½æœ€ä½³åŒ–å’Œå¯¦éš›å ´æ™¯æ¸¬è©¦",
                    "ğŸ“ å»ºè­°æ›´æ–° CLAUDE.md æ–‡æª”ä»¥åæ˜ ç•¶å‰å¯¦ç¾ç‹€æ…‹",
                ]
            )
        else:
            recommendations.append(
                "ğŸ“‹ å»ºè­°é€ä¸€æª¢æŸ¥å¤±æ•—çš„æ¸¬è©¦éšæ®µï¼Œç¢ºä¿è«–æ–‡å¾©ç¾çš„å®Œæ•´æ€§"
            )

        # æ•ˆèƒ½å»ºè­°
        total_duration = sum(
            result.get("duration_seconds", 0) for result in self.test_results.values()
        )
        if total_duration > 300:  # 5åˆ†é˜
            recommendations.append(
                f"âš¡ æ¸¬è©¦åŸ·è¡Œæ™‚é–“è¼ƒé•· ({total_duration:.1f}ç§’)ï¼Œè€ƒæ…®å„ªåŒ–æ¸¬è©¦æ•ˆèƒ½"
            )

        return recommendations

    def _print_comprehensive_summary(self, report: Dict[str, Any]):
        """åˆ—å°ç¶œåˆæ¸¬è©¦æ‘˜è¦"""
        print("\n" + "=" * 80)
        print("ğŸ¯ è«–æ–‡å¾©ç¾ç¶œåˆæ¸¬è©¦å ±å‘Š")
        print("=" * 80)

        # åŸ·è¡Œè³‡è¨Š
        exec_info = report["test_execution_info"]
        print(f"\nğŸ“Š åŸ·è¡Œè³‡è¨Š:")
        print(f"   é–‹å§‹æ™‚é–“: {exec_info['start_time']}")
        print(f"   çµæŸæ™‚é–“: {exec_info['end_time']}")
        print(f"   ç¸½åŸ·è¡Œæ™‚é–“: {exec_info['total_duration_seconds']:.1f} ç§’")
        print(f"   æ¸¬è©¦ç’°å¢ƒ: {exec_info['test_environment']}")

        # ç¸½é«”çµ±è¨ˆ
        summary = report["overall_summary"]
        print(f"\nğŸ“Š ç¸½é«”çµ±è¨ˆ:")
        print(
            f"   æ¸¬è©¦éšæ®µ: {summary['successful_stages']}/{summary['total_stages']} æˆåŠŸ ({summary['stage_success_rate']})"
        )
        print(
            f"   å€‹åˆ¥æ¸¬è©¦: {summary['total_passed_tests']}/{summary['total_individual_tests']} é€šé ({summary['overall_test_success_rate']})"
        )

        # éšæ®µè©³ç´°çµæœ
        print(f"\nğŸ“‹ éšæ®µè©³ç´°çµæœ:")
        for stage_id, result in self.test_results.items():
            status_emoji = "âœ…" if result["success"] else "âŒ"
            print(f"   {status_emoji} {stage_id} {result['stage_name']}")
            print(
                f"      æ¸¬è©¦é€šé: {result['passed_tests']}/{result['total_tests']} ({result['success_rate']:.1f}%)"
            )
            print(f"      åŸ·è¡Œæ™‚é–“: {result['duration_seconds']:.1f} ç§’")
            if not result["success"]:
                print(f"      å¤±æ•—åŸå› : è¿”å›ç¢¼ {result['return_code']}")

        # è«–æ–‡å¾©ç¾é©—è­‰
        print(f"\nğŸ“ è«–æ–‡å¾©ç¾é©—è­‰:")
        validation = report["paper_reproduction_validation"]
        for key, status in validation.items():
            feature_name = key.replace("_", " ").title()
            print(f"   {status} {feature_name}")

        # å»ºè­°
        recommendations = report["recommendations"]
        if recommendations:
            print(f"\nğŸ’¡ å»ºè­°å’Œå¾ŒçºŒæ­¥é©Ÿ:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")

        print("\n" + "=" * 80)

    async def _save_comprehensive_report(self, report: Dict[str, Any]):
        """ä¿å­˜ç¶œåˆæ¸¬è©¦å ±å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = (
            f"/home/sat/paper/comprehensive/paper_reproduction_report_{timestamp}.json"
        )

        # ç¢ºä¿å ±å‘Šç›®éŒ„å­˜åœ¨
        os.makedirs(os.path.dirname(report_filename), exist_ok=True)

        try:
            with open(report_filename, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)

            print(f"\nğŸ“„ è©³ç´°æ¸¬è©¦å ±å‘Šå·²ä¿å­˜è‡³: {report_filename}")
            logger.info(f"ç¶œåˆæ¸¬è©¦å ±å‘Šå·²ä¿å­˜: {report_filename}")

        except Exception as e:
            logger.error(f"ä¿å­˜ç¶œåˆæ¸¬è©¦å ±å‘Šå¤±æ•—: {str(e)}")


async def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="è«–æ–‡å¾©ç¾ç¶œåˆæ¸¬è©¦åŸ·è¡Œå™¨")
    parser.add_argument(
        "--stage",
        choices=["1.1", "1.2", "1.3", "all"],
        default="all",
        help="æŒ‡å®šè¦åŸ·è¡Œçš„æ¸¬è©¦éšæ®µ",
    )
    parser.add_argument("--verbose", action="store_true", help="å•Ÿç”¨è©³ç´°è¼¸å‡º")

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # å‰µå»ºæ¸¬è©¦åŸ·è¡Œå™¨
    runner = PaperReproductionTestRunner()

    try:
        # åŸ·è¡Œæ¸¬è©¦
        report = await runner.run_all_tests(stage_filter=args.stage)

        # æ ¹æ“šçµæœè¨­ç½®é€€å‡ºç¢¼
        all_success = all(
            result.get("success", False) for result in runner.test_results.values()
        )

        if all_success:
            print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦éšæ®µæˆåŠŸå®Œæˆï¼è«–æ–‡å¾©ç¾ç¬¬ä¸€éšæ®µ (1.1-1.3) é©—è­‰é€šéã€‚")
            sys.exit(0)
        else:
            print("\nâŒ éƒ¨åˆ†æ¸¬è©¦éšæ®µå¤±æ•—ï¼Œè«‹æª¢æŸ¥è©³ç´°å ±å‘Š")
            sys.exit(1)

    except KeyboardInterrupt:
        print("\nâš ï¸  æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
        sys.exit(130)
    except Exception as e:
        print(f"\nğŸ’¥ æ¸¬è©¦åŸ·è¡Œéç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {str(e)}")
        logger.error(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    # æª¢æŸ¥ Python ç‰ˆæœ¬
    if sys.version_info < (3, 7):
        print("âŒ éœ€è¦ Python 3.7 æˆ–æ›´é«˜ç‰ˆæœ¬")
        sys.exit(1)

    # æª¢æŸ¥æ˜¯å¦åœ¨æ­£ç¢ºçš„ç›®éŒ„
    if not os.path.exists("/home/sat/ntn-stack/netstack"):
        print("âŒ è«‹åœ¨ ntn-stack æ ¹ç›®éŒ„åŸ·è¡Œæ­¤è…³æœ¬")
        sys.exit(1)

    # é‹è¡Œä¸»å‡½æ•¸
    asyncio.run(main())
