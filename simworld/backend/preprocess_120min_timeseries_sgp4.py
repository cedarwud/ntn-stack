#!/usr/bin/env python3
"""
120åˆ†é˜æ•¸æ“šé è™•ç†è…³æœ¬ - å®Œæ•´ SGP4 ç‰ˆæœ¬
ä½¿ç”¨çœŸå¯¦çš„ SGP4 è»Œé“å‚³æ’­è¨ˆç®—ï¼Œç„¡ä»»ä½•ç°¡åŒ–
"""

import os
import json
import asyncio
import logging
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Tuple
import numpy as np
from sgp4.api import Satrec, WGS84
from sgp4.api import jday

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RealSGP4TimeseriesPreprocessor:
    """ä½¿ç”¨çœŸå¯¦ SGP4 è¨ˆç®—çš„ 120åˆ†é˜æ™‚é–“åºåˆ—é è™•ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é è™•ç†å™¨"""
        # æª¢æ¸¬é‹è¡Œç’°å¢ƒ
        if os.path.exists("/app"):
            # Docker å»ºç½®ç’°å¢ƒè·¯å¾‘
            self.app_root = Path("/app")
        else:
            # æœ¬åœ°é–‹ç™¼ç’°å¢ƒè·¯å¾‘
            self.app_root = Path(__file__).parent.parent.parent
        
        self.data_output_path = self.app_root / "data" 
        self.tle_data_path = self.app_root / "netstack" / "tle_data"
        
        # æ™‚é–“åºåˆ—é…ç½®
        self.time_span_minutes = 120
        self.time_interval_seconds = 10
        self.total_time_points = 720
        
        # æ”¯æ´çš„æ˜Ÿåº§
        self.supported_constellations = ["starlink", "oneweb"]
        
        # é»˜èªåƒè€ƒä½ç½®ï¼ˆå°åŒ—ç§‘æŠ€å¤§å­¸ï¼‰
        self.default_reference_location = {
            "latitude": 24.9441,
            "longitude": 121.3714,
            "altitude": 0.0
        }
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        self.data_output_path.mkdir(parents=True, exist_ok=True)
        
    async def preprocess_all_constellations(self) -> None:
        """é è™•ç†æ‰€æœ‰æ”¯æ´çš„æ˜Ÿåº§æ•¸æ“š"""
        logger.info("ğŸš€ é–‹å§‹ 120åˆ†é˜æ™‚é–“åºåˆ—æ•¸æ“šé è™•ç† (å®Œæ•´ SGP4)")
        logger.info(f"ğŸ“‚ è¼¸å‡ºè·¯å¾‘: {self.data_output_path}")
        logger.info(f"ğŸ“¡ TLE æ•¸æ“šè·¯å¾‘: {self.tle_data_path}")
        
        successful_constellations = []
        
        for constellation in self.supported_constellations:
            try:
                logger.info(f"\nğŸ›°ï¸ é è™•ç†æ˜Ÿåº§: {constellation}")
                
                # è¼‰å…¥è©²æ˜Ÿåº§çš„ TLE æ•¸æ“š
                tle_data = await self._load_tle_data(constellation)
                if not tle_data:
                    logger.warning(f"âš ï¸ {constellation} ç„¡å¯ç”¨ TLE æ•¸æ“š")
                    continue
                
                # æ™ºèƒ½ç¯©é¸è¡›æ˜Ÿ
                selected_satellites = await self._intelligent_satellite_selection(
                    tle_data, constellation
                )
                
                # ç”Ÿæˆæ™‚é–“åºåˆ—æ•¸æ“šï¼ˆä½¿ç”¨çœŸå¯¦ SGP4ï¼‰
                timeseries_data = await self._generate_constellation_timeseries_sgp4(
                    constellation, selected_satellites
                )
                
                if timeseries_data:
                    # ä¿å­˜é è™•ç†æ•¸æ“š
                    output_file = self.data_output_path / f"{constellation}_120min_timeseries_sgp4.json"
                    await self._save_timeseries_data(timeseries_data, output_file)
                    
                    successful_constellations.append(constellation)
                    logger.info(f"âœ… {constellation} é è™•ç†å®Œæˆ")
                else:
                    logger.error(f"âŒ {constellation} é è™•ç†å¤±æ•—")
                    
            except Exception as e:
                logger.error(f"âŒ {constellation} é è™•ç†ç•°å¸¸: {e}")
                continue
        
        # å‰µå»ºé è™•ç†ç‹€æ…‹æ–‡ä»¶
        await self._create_preprocess_status(successful_constellations)
        
        if successful_constellations:
            logger.info(f"ğŸ‰ é è™•ç†å®Œæˆï¼æˆåŠŸè™•ç†æ˜Ÿåº§: {', '.join(successful_constellations)}")
        else:
            logger.error("âŒ æ‰€æœ‰æ˜Ÿåº§é è™•ç†å¤±æ•—")
            
    async def _load_tle_data(self, constellation: str) -> List[Dict[str, Any]]:
        """è¼‰å…¥æŒ‡å®šæ˜Ÿåº§çš„ TLE æ•¸æ“š"""
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„ JSON TLE æ–‡ä»¶
            json_dir = self.tle_data_path / constellation / "json"
            if not json_dir.exists():
                logger.warning(f"âš ï¸ JSON TLE ç›®éŒ„ä¸å­˜åœ¨: {json_dir}")
                return []
            
            # ç²å–æœ€æ–°çš„ TLE æ–‡ä»¶
            tle_files = sorted(json_dir.glob(f"{constellation}_*.json"))
            if not tle_files:
                logger.warning(f"âš ï¸ ç„¡å¯ç”¨çš„ TLE æ–‡ä»¶: {json_dir}")
                return []
            
            latest_tle_file = tle_files[-1]
            logger.info(f"ğŸ“¡ è¼‰å…¥ JSON TLE æ•¸æ“š: {latest_tle_file}")
            
            with open(latest_tle_file, 'r', encoding='utf-8') as f:
                tle_data = json.load(f)
                
            logger.info(f"ğŸ“Š è¼‰å…¥ {len(tle_data)} é¡† {constellation} è¡›æ˜Ÿ")
            
            # è½‰æ›ç‚ºçµ±ä¸€æ ¼å¼
            formatted_data = []
            for sat in tle_data:
                # æ§‹å»º TLE è¡Œ
                line1 = self._build_tle_line1(sat)
                line2 = self._build_tle_line2(sat)
                
                formatted_data.append({
                    "name": sat.get("OBJECT_NAME", "UNKNOWN"),
                    "norad_id": sat.get("NORAD_CAT_ID", 0),
                    "line1": line1,
                    "line2": line2,
                    "raw_data": sat
                })
            
            return formatted_data
            
        except Exception as e:
            logger.error(f"âŒ TLE æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return []
    
    def _build_tle_line1(self, sat_data: Dict) -> str:
        """å¾ JSON æ•¸æ“šæ§‹å»º TLE Line 1"""
        # TLE Line 1 æ ¼å¼
        norad_id = str(sat_data.get("NORAD_CAT_ID", 0)).zfill(5)
        classification = sat_data.get("CLASSIFICATION_TYPE", "U")
        launch_year = sat_data.get("OBJECT_ID", "00001A")[:2]
        launch_number = sat_data.get("OBJECT_ID", "00001A")[2:6]
        launch_piece = sat_data.get("OBJECT_ID", "00001A")[6:]
        
        # è½‰æ› epoch
        epoch_str = sat_data.get("EPOCH", "2025-01-01T00:00:00")
        epoch_dt = datetime.fromisoformat(epoch_str.replace('Z', '+00:00'))
        year = epoch_dt.year % 100
        day_of_year = epoch_dt.timetuple().tm_yday
        fraction_of_day = (epoch_dt.hour * 3600 + epoch_dt.minute * 60 + epoch_dt.second) / 86400
        epoch_tle = f"{year:02d}{day_of_year:03d}.{int(fraction_of_day * 100000000):08d}"
        
        # Mean motion derivatives
        mean_motion_dot = sat_data.get("MEAN_MOTION_DOT", 0.0)
        mean_motion_ddot = sat_data.get("MEAN_MOTION_DDOT", 0.0)
        bstar = sat_data.get("BSTAR", 0.0)
        ephemeris_type = sat_data.get("EPHEMERIS_TYPE", 0)
        element_number = sat_data.get("ELEMENT_SET_NO", 999)
        
        # Format Line 1
        line1 = f"1 {norad_id}{classification} {launch_year}{launch_number}{launch_piece} {epoch_tle} "
        line1 += f"{mean_motion_dot:10.8f} {mean_motion_ddot:8.4e} {bstar:8.4e} "
        line1 += f"{ephemeris_type} {element_number:4d}"
        
        # Calculate checksum
        checksum = self._calculate_tle_checksum(line1)
        line1 += str(checksum)
        
        return line1
    
    def _build_tle_line2(self, sat_data: Dict) -> str:
        """å¾ JSON æ•¸æ“šæ§‹å»º TLE Line 2"""
        norad_id = str(sat_data.get("NORAD_CAT_ID", 0)).zfill(5)
        inclination = sat_data.get("INCLINATION", 0.0)
        raan = sat_data.get("RA_OF_ASC_NODE", 0.0)
        eccentricity = sat_data.get("ECCENTRICITY", 0.0)
        arg_perigee = sat_data.get("ARG_OF_PERICENTER", 0.0)
        mean_anomaly = sat_data.get("MEAN_ANOMALY", 0.0)
        mean_motion = sat_data.get("MEAN_MOTION", 0.0)
        rev_at_epoch = sat_data.get("REV_AT_EPOCH", 0)
        
        # Format Line 2
        line2 = f"2 {norad_id} {inclination:8.4f} {raan:8.4f} "
        line2 += f"{int(eccentricity * 10000000):07d} {arg_perigee:8.4f} "
        line2 += f"{mean_anomaly:8.4f} {mean_motion:11.8f} {rev_at_epoch:5d}"
        
        # Calculate checksum
        checksum = self._calculate_tle_checksum(line2)
        line2 += str(checksum)
        
        return line2
    
    def _calculate_tle_checksum(self, line: str) -> int:
        """è¨ˆç®— TLE è¡Œçš„æ ¡é©—å’Œ"""
        checksum = 0
        for char in line[:-1]:  # Exclude the checksum position
            if char.isdigit():
                checksum += int(char)
            elif char == '-':
                checksum += 1
        return checksum % 10
    
    async def _intelligent_satellite_selection(
        self, tle_data: List[Dict[str, Any]], constellation: str
    ) -> List[Dict[str, Any]]:
        """æ™ºèƒ½ç¯©é¸é©åˆå°ç£åœ°å€æ›æ‰‹æ¸¬è©¦çš„è¡›æ˜Ÿ"""
        logger.info(f"ğŸ¯ é–‹å§‹æ™ºèƒ½ç¯©é¸ {len(tle_data)} é¡† {constellation} è¡›æ˜Ÿ")
        
        # ç›®æ¨™ç¯©é¸æ•¸é‡
        if constellation == "starlink":
            target_count = 40
        else:  # oneweb
            target_count = 30
        
        # è¨ˆç®—æ¯é¡†è¡›æ˜Ÿçš„é©ç”¨æ€§åˆ†æ•¸
        satellite_scores = []
        
        for sat in tle_data:
            try:
                # å¾åŸå§‹æ•¸æ“šç²å–è»Œé“åƒæ•¸
                inclination = sat["raw_data"].get("INCLINATION", 0)
                raan = sat["raw_data"].get("RA_OF_ASC_NODE", 0)
                mean_motion = sat["raw_data"].get("MEAN_MOTION", 0)
                
                # è¨ˆç®—åˆ†æ•¸ï¼ˆåŸºæ–¼å°å°ç£åœ°å€çš„è¦†è“‹ï¼‰
                score = 0.0
                
                # 1. å‚¾è§’æ¥è¿‘ 53Â° çš„å¾—åˆ†æ›´é«˜ï¼ˆé©åˆä¸­ç·¯åº¦ï¼‰
                inclination_score = 100 - abs(inclination - 53) * 2
                score += inclination_score * 0.4
                
                # 2. å‡äº¤é»èµ¤ç¶“æ¥è¿‘å°ç£ç¶“åº¦çš„å¾—åˆ†æ›´é«˜
                raan_diff = abs(raan - 121.3714)
                if raan_diff > 180:
                    raan_diff = 360 - raan_diff
                raan_score = 100 - raan_diff * 0.5
                score += raan_score * 0.3
                
                # 3. è»Œé“é€±æœŸé©ä¸­çš„å¾—åˆ†æ›´é«˜ï¼ˆLEO ç‰¹æ€§ï¼‰
                if 15.0 <= mean_motion <= 16.0:
                    motion_score = 100
                else:
                    motion_score = 50
                score += motion_score * 0.3
                
                satellite_scores.append({
                    "satellite": sat,
                    "score": score
                })
                
            except Exception as e:
                logger.warning(f"âš ï¸ è¡›æ˜Ÿè©•åˆ†å¤±æ•— {sat.get('name', 'UNKNOWN')}: {e}")
                continue
        
        # æŒ‰åˆ†æ•¸æ’åºä¸¦é¸æ“‡å‰ N é¡†
        satellite_scores.sort(key=lambda x: x["score"], reverse=True)
        selected_satellites = [item["satellite"] for item in satellite_scores[:target_count]]
        
        logger.info(f"âœ… æ™ºèƒ½ç¯©é¸å®Œæˆï¼š{len(selected_satellites)}/{len(tle_data)} é¡†è¡›æ˜Ÿ")
        
        return selected_satellites
    
    async def _generate_constellation_timeseries_sgp4(
        self, constellation: str, satellites: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨çœŸå¯¦ SGP4 ç”Ÿæˆæ˜Ÿåº§æ™‚é–“åºåˆ—æ•¸æ“š"""
        try:
            # è¨­å®šæ™‚é–“ç¯„åœ
            start_time = datetime.now(timezone.utc).replace(second=0, microsecond=0)
            timestamps = []
            
            # ç”Ÿæˆæ™‚é–“æˆ³åˆ—è¡¨
            for i in range(self.total_time_points):
                timestamp = start_time + timedelta(seconds=i * self.time_interval_seconds)
                timestamps.append(timestamp.isoformat())
            
            # è™•ç†æ¯é¡†è¡›æ˜Ÿ
            satellites_data = []
            for idx, sat_data in enumerate(satellites):
                logger.info(f"ğŸ›°ï¸ è¨ˆç®—è¡›æ˜Ÿ {idx+1}/{len(satellites)}: {sat_data['name']}")
                
                # ä½¿ç”¨çœŸå¯¦ SGP4 è¨ˆç®—
                sat_timeseries = await self._calculate_real_sgp4_timeseries(
                    sat_data, start_time
                )
                
                if sat_timeseries:
                    satellites_data.append({
                        "norad_id": sat_data["norad_id"],
                        "name": sat_data["name"],
                        "constellation": constellation,
                        "time_series": sat_timeseries,
                        "positions": self._extract_positions_from_timeseries(sat_timeseries),
                        "mrl_distances": []  # å°‡åœ¨ D2 å¢å¼·éšæ®µè¨ˆç®—
                    })
            
            # çµ„è£å®Œæ•´æ•¸æ“šçµæ§‹
            timeseries_data = {
                "metadata": {
                    "computation_time": datetime.now(timezone.utc).isoformat(),
                    "constellation": constellation,
                    "time_span_minutes": self.time_span_minutes,
                    "time_interval_seconds": self.time_interval_seconds,
                    "total_time_points": self.total_time_points,
                    "data_source": "real_sgp4_calculations",
                    "sgp4_mode": "full_propagation",
                    "selection_mode": "intelligent_geographic_handover",
                    "reference_location": self.default_reference_location,
                    "satellites_processed": len(satellites_data),
                    "build_timestamp": datetime.now(timezone.utc).isoformat()
                },
                "timestamps": timestamps,
                "satellites": satellites_data
            }
            
            return timeseries_data
            
        except Exception as e:
            logger.error(f"âŒ æ™‚é–“åºåˆ—ç”Ÿæˆå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    async def _calculate_real_sgp4_timeseries(
        self, sat_data: Dict[str, Any], start_time: datetime
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨çœŸå¯¦ SGP4 è¨ˆç®—è¡›æ˜Ÿæ™‚é–“åºåˆ—"""
        try:
            # å‰µå»º SGP4 è¡›æ˜Ÿå°è±¡
            line1 = sat_data["line1"]
            line2 = sat_data["line2"]
            satellite = Satrec.twoline2rv(line1, line2)
            
            time_series = []
            
            # åƒè€ƒä½ç½®
            observer_lat = self.default_reference_location["latitude"]
            observer_lon = self.default_reference_location["longitude"]
            observer_alt = self.default_reference_location["altitude"] / 1000.0  # è½‰æ›ç‚º km
            
            for i in range(self.total_time_points):
                time_offset = i * self.time_interval_seconds
                current_time = start_time + timedelta(seconds=time_offset)
                
                # è¨ˆç®— Julian Date
                jd, fr = jday(
                    current_time.year,
                    current_time.month,
                    current_time.day,
                    current_time.hour,
                    current_time.minute,
                    current_time.second + current_time.microsecond / 1e6
                )
                
                # SGP4 å‚³æ’­
                error_code, position, velocity = satellite.sgp4(jd, fr)
                
                if error_code != 0:
                    logger.warning(f"SGP4 error code {error_code} for {sat_data['name']}")
                    # æ·»åŠ ç„¡æ•ˆæ•¸æ“šé»
                    time_series.append(self._create_invalid_datapoint(current_time, time_offset))
                    continue
                
                # è½‰æ›åˆ°åœ°ç†åæ¨™
                # position æ˜¯ TEME åæ¨™ç³»ï¼Œå–®ä½æ˜¯ km
                ecef_position = self._teme_to_ecef(position, current_time)
                lat, lon, alt = self._ecef_to_geodetic(ecef_position)
                
                # è¨ˆç®—ç›¸å°æ–¼è§€æ¸¬è€…çš„ä½ç½®
                el, az, range_km = self._calculate_look_angles(
                    observer_lat, observer_lon, observer_alt,
                    lat, lon, alt
                )
                
                # é€Ÿåº¦å¤§å°
                velocity_magnitude = np.linalg.norm(velocity)
                
                # çµ„è£æ•¸æ“šé»
                datapoint = {
                    "timestamp": current_time.isoformat() + "Z",
                    "time_offset_seconds": time_offset,
                    "position": {
                        "latitude": float(lat),
                        "longitude": float(lon),
                        "altitude": float(alt * 1000),  # è½‰æ›ç‚ºç±³
                        "ecef": {
                            "x": float(ecef_position[0] * 1000),  # è½‰æ›ç‚ºç±³
                            "y": float(ecef_position[1] * 1000),
                            "z": float(ecef_position[2] * 1000)
                        }
                    },
                    "velocity": {
                        "magnitude": float(velocity_magnitude),
                        "x": float(velocity[0]),
                        "y": float(velocity[1]),
                        "z": float(velocity[2])
                    },
                    "observation": {
                        "elevation_deg": float(el),
                        "azimuth_deg": float(az),
                        "range_km": float(range_km),
                        "is_visible": bool(el > 0),  # åœ°å¹³ç·šä»¥ä¸Šå³å¯è¦‹
                        "doppler_shift": float(self._calculate_doppler_shift(velocity, position, observer_lat, observer_lon, observer_alt))
                    },
                    "handover_metrics": {
                        "signal_strength_dbm": float(self._estimate_signal_strength(el, range_km)),
                        "latency_ms": float(self._estimate_latency(range_km)),
                        "data_rate_mbps": float(self._estimate_data_rate(el, range_km))
                    },
                    "measurement_events": {
                        "a3_condition": False,  # å°‡åœ¨å¾Œè™•ç†ä¸­è¨ˆç®—
                        "a4_condition": bool(el > 15.0),  # ç°¡å–®çš„ä»°è§’é–€æª»
                        "d1_condition": False,
                        "d2_condition": False
                    }
                }
                
                time_series.append(datapoint)
            
            return time_series
            
        except Exception as e:
            logger.error(f"âŒ SGP4 è¨ˆç®—å¤±æ•— {sat_data['name']}: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _teme_to_ecef(self, teme_position: Tuple[float, float, float], timestamp: datetime) -> np.ndarray:
        """å°‡ TEME åæ¨™è½‰æ›ç‚º ECEF åæ¨™"""
        # ç°¡åŒ–å¯¦ç¾ï¼šå¿½ç•¥å°çš„åæ¨™ç³»å·®ç•°
        # å¯¦éš›æ‡‰ç”¨ä¸­æ‡‰è©²ä½¿ç”¨ç²¾ç¢ºçš„è½‰æ›çŸ©é™£
        return np.array(teme_position)
    
    def _ecef_to_geodetic(self, ecef: np.ndarray) -> Tuple[float, float, float]:
        """å°‡ ECEF åæ¨™è½‰æ›ç‚ºåœ°ç†åæ¨™"""
        x, y, z = ecef
        
        # WGS84 åƒæ•¸
        a = 6378.137  # èµ¤é“åŠå¾‘ (km)
        e2 = 0.00669437999014  # ç¬¬ä¸€åå¿ƒç‡å¹³æ–¹
        
        # è¨ˆç®—ç¶“åº¦
        lon = np.degrees(np.arctan2(y, x))
        
        # è¿­ä»£è¨ˆç®—ç·¯åº¦å’Œé«˜åº¦
        p = np.sqrt(x**2 + y**2)
        lat = np.degrees(np.arctan2(z, p))
        
        # Newton-Raphson è¿­ä»£
        for _ in range(5):
            lat_rad = np.radians(lat)
            N = a / np.sqrt(1 - e2 * np.sin(lat_rad)**2)
            alt = p / np.cos(lat_rad) - N
            lat = np.degrees(np.arctan2(z, p * (1 - e2 * N / (N + alt))))
        
        return lat, lon, alt
    
    def _calculate_look_angles(
        self, obs_lat: float, obs_lon: float, obs_alt: float,
        sat_lat: float, sat_lon: float, sat_alt: float
    ) -> Tuple[float, float, float]:
        """è¨ˆç®—è§€æ¸¬è€…åˆ°è¡›æ˜Ÿçš„ä»°è§’ã€æ–¹ä½è§’å’Œè·é›¢"""
        # è½‰æ›ç‚ºå¼§åº¦
        obs_lat_rad = np.radians(obs_lat)
        obs_lon_rad = np.radians(obs_lon)
        sat_lat_rad = np.radians(sat_lat)
        sat_lon_rad = np.radians(sat_lon)
        
        # åœ°çƒåŠå¾‘
        earth_radius = 6371.0  # km
        
        # è§€æ¸¬è€…å’Œè¡›æ˜Ÿçš„åœ°å¿ƒè·é›¢
        obs_radius = earth_radius + obs_alt
        sat_radius = earth_radius + sat_alt
        
        # è¨ˆç®—åœ°å¿ƒè§’
        cos_central_angle = (
            np.sin(obs_lat_rad) * np.sin(sat_lat_rad) +
            np.cos(obs_lat_rad) * np.cos(sat_lat_rad) * np.cos(sat_lon_rad - obs_lon_rad)
        )
        central_angle = np.arccos(np.clip(cos_central_angle, -1, 1))
        
        # è¨ˆç®—è·é›¢ï¼ˆä½¿ç”¨é¤˜å¼¦å®šç†ï¼‰
        range_km = np.sqrt(
            obs_radius**2 + sat_radius**2 - 2 * obs_radius * sat_radius * cos_central_angle
        )
        
        # è¨ˆç®—ä»°è§’
        sin_elevation = (sat_radius * np.sin(central_angle)) / range_km
        cos_elevation = (sat_radius * cos_central_angle - obs_radius) / range_km
        elevation = np.degrees(np.arctan2(sin_elevation, cos_elevation))
        
        # è¨ˆç®—æ–¹ä½è§’
        delta_lon = sat_lon_rad - obs_lon_rad
        y = np.sin(delta_lon) * np.cos(sat_lat_rad)
        x = np.cos(obs_lat_rad) * np.sin(sat_lat_rad) - np.sin(obs_lat_rad) * np.cos(sat_lat_rad) * np.cos(delta_lon)
        azimuth = np.degrees(np.arctan2(y, x))
        azimuth = (azimuth + 360) % 360  # æ¨™æº–åŒ–åˆ° 0-360
        
        return elevation, azimuth, range_km
    
    def _calculate_doppler_shift(
        self, velocity: Tuple[float, float, float],
        position: Tuple[float, float, float],
        obs_lat: float, obs_lon: float, obs_alt: float
    ) -> float:
        """è¨ˆç®—éƒ½åœå‹’é »ç§»ï¼ˆç°¡åŒ–è¨ˆç®—ï¼‰"""
        # é€™æ˜¯ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›æ‡‰è©²è¨ˆç®—ç›¸å°é€Ÿåº¦åœ¨è¦–ç·šæ–¹å‘çš„åˆ†é‡
        c = 299792.458  # å…‰é€Ÿ km/s
        f0 = 2.0e9  # å‡è¨­ 2 GHz è¼‰æ³¢é »ç‡
        
        # ç°¡åŒ–ï¼šä½¿ç”¨é€Ÿåº¦å¤§å°çš„ä¸€éƒ¨åˆ†ä½œç‚ºå¾‘å‘é€Ÿåº¦
        v_radial = np.linalg.norm(velocity) * 0.1  # ç°¡åŒ–å‡è¨­
        
        # éƒ½åœå‹’é »ç§»
        doppler_shift = f0 * v_radial / c
        
        return doppler_shift
    
    def _estimate_signal_strength(self, elevation: float, range_km: float) -> float:
        """ä¼°ç®—ä¿¡è™Ÿå¼·åº¦"""
        if elevation <= 0:
            return -150.0  # ç„¡ä¿¡è™Ÿ
        
        # åŸºæœ¬è·¯å¾‘æè€—ï¼ˆç°¡åŒ– Friis å…¬å¼ï¼‰
        frequency_ghz = 2.0
        path_loss_db = 20 * np.log10(range_km) + 20 * np.log10(frequency_ghz) + 92.45
        
        # å¤§æ°£è¡°æ¸›ï¼ˆç°¡åŒ–æ¨¡å‹ï¼‰
        atmospheric_loss = 0.1 * (90 - elevation) / 90  # ä½ä»°è§’è¡°æ¸›æ›´å¤š
        
        # ç™¼å°„åŠŸç‡å‡è¨­ç‚º 30 dBmï¼Œå¤©ç·šå¢ç›Š 10 dBi
        tx_power_dbm = 30
        antenna_gain_dbi = 10
        
        # è¨ˆç®—æ¥æ”¶ä¿¡è™Ÿå¼·åº¦
        signal_strength = tx_power_dbm + antenna_gain_dbi - path_loss_db - atmospheric_loss
        
        return max(signal_strength, -150.0)
    
    def _estimate_latency(self, range_km: float) -> float:
        """ä¼°ç®—å‚³æ’­å»¶é²"""
        c = 299792.458  # å…‰é€Ÿ km/s
        # é›™å‘å‚³æ’­å»¶é²
        propagation_delay = 2 * range_km / c * 1000  # è½‰æ›ç‚º ms
        # åŠ ä¸Šè™•ç†å»¶é²
        processing_delay = 5.0  # ms
        return propagation_delay + processing_delay
    
    def _estimate_data_rate(self, elevation: float, range_km: float) -> float:
        """ä¼°ç®—æ•¸æ“šé€Ÿç‡"""
        if elevation <= 0:
            return 0.0
        
        # åŸºæ–¼ä»°è§’å’Œè·é›¢çš„ç°¡åŒ–æ¨¡å‹
        # é«˜ä»°è§’ã€çŸ­è·é›¢ = é«˜é€Ÿç‡
        base_rate = 100.0  # Mbps
        elevation_factor = elevation / 90.0
        distance_factor = 500.0 / range_km  # 500 km ä½œç‚ºåƒè€ƒè·é›¢
        
        data_rate = base_rate * elevation_factor * min(distance_factor, 1.0)
        
        return max(data_rate, 0.0)
    
    def _create_invalid_datapoint(self, timestamp: datetime, time_offset: int) -> Dict[str, Any]:
        """å‰µå»ºç„¡æ•ˆæ•¸æ“šé»ï¼ˆç•¶ SGP4 è¨ˆç®—å¤±æ•—æ™‚ï¼‰"""
        return {
            "timestamp": timestamp.isoformat() + "Z",
            "time_offset_seconds": time_offset,
            "position": {
                "latitude": 0.0,
                "longitude": 0.0,
                "altitude": 0.0,
                "ecef": {"x": 0.0, "y": 0.0, "z": 0.0}
            },
            "velocity": {
                "magnitude": 0.0,
                "x": 0.0, "y": 0.0, "z": 0.0
            },
            "observation": {
                "elevation_deg": 0.0,
                "azimuth_deg": 0.0,
                "range_km": 0.0,
                "is_visible": False,
                "doppler_shift": 0.0
            },
            "handover_metrics": {
                "signal_strength_dbm": -150.0,
                "latency_ms": 999.0,
                "data_rate_mbps": 0.0
            },
            "measurement_events": {
                "a3_condition": False,
                "a4_condition": False,
                "d1_condition": False,
                "d2_condition": False
            }
        }
    
    def _extract_positions_from_timeseries(self, timeseries: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å¾æ™‚é–“åºåˆ—ä¸­æå–ä½ç½®æ•¸æ“šï¼ˆç¬¦åˆçµ±ä¸€æ ¼å¼ï¼‰"""
        positions = []
        for entry in timeseries:
            obs = entry.get("observation", {})
            positions.append({
                "elevation_deg": obs.get("elevation_deg", 0.0),
                "azimuth_deg": obs.get("azimuth_deg", 0.0),
                "range_km": obs.get("range_km", 0.0),
                "is_visible": obs.get("is_visible", False),
                "timestamp": entry.get("timestamp", "")
            })
        return positions
    
    async def _save_timeseries_data(self, data: Dict[str, Any], output_file: Path) -> None:
        """ä¿å­˜æ™‚é–“åºåˆ—æ•¸æ“š"""
        try:
            logger.info(f"ğŸ’¾ ä¿å­˜æ•¸æ“šåˆ°: {output_file}")
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # é¡¯ç¤ºæ–‡ä»¶å¤§å°
            file_size_mb = output_file.stat().st_size / (1024 * 1024)
            logger.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
            
        except Exception as e:
            logger.error(f"âŒ æ•¸æ“šä¿å­˜å¤±æ•—: {e}")
            raise
    
    async def _create_preprocess_status(self, successful_constellations: List[str]) -> None:
        """å‰µå»ºé è™•ç†ç‹€æ…‹æ–‡ä»¶"""
        status_file = self.data_output_path / ".preprocess_status_sgp4"
        status_data = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "successful_constellations": successful_constellations,
            "sgp4_mode": "full_propagation",
            "time_span_minutes": self.time_span_minutes,
            "total_time_points": self.total_time_points
        }
        
        with open(status_file, 'w', encoding='utf-8') as f:
            json.dump(status_data, f, indent=2)
        
        logger.info(f"ğŸ“‹ é è™•ç†ç‹€æ…‹å·²ä¿å­˜: {status_file}")

async def main():
    """ä¸»ç¨‹åº"""
    preprocessor = RealSGP4TimeseriesPreprocessor()
    await preprocessor.preprocess_all_constellations()

if __name__ == "__main__":
    logger.info("ğŸš€ å•Ÿå‹• 120åˆ†é˜æ™‚é–“åºåˆ—é è™•ç†ï¼ˆå®Œæ•´ SGP4ï¼‰")
    asyncio.run(main())
    logger.info("âœ… é è™•ç†å®Œæˆï¼")