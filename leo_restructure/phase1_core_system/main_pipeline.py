# ğŸ›°ï¸ Phase 1 ä¸»ç®¡é“åŸ·è¡Œå™¨
"""
Phase 1 Main Pipeline - å®Œæ•´æ ¸å¿ƒç³»çµ±åŸ·è¡Œæµç¨‹
åŠŸèƒ½: ä¸²æ¥F1â†’F2â†’F3â†’A1å®Œæ•´æµç¨‹ï¼Œå¯¦ç¾10-15/3-6é¡†è¡›æ˜Ÿå‹•æ…‹è¦†è“‹
"""

import asyncio
import logging
from datetime import datetime, timezone
from pathlib import Path
import json
import sys
import os

# æ·»åŠ ç•¶å‰è·¯å¾‘åˆ°ç³»çµ±è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

from f1_tle_loader.tle_loader_engine import TLELoaderEngine
from f2_satellite_filter.satellite_filter_engine_v2 import SatelliteFilterEngineV2  
from f3_signal_analyzer.a4_a5_d2_event_processor import A4A5D2EventProcessor
from a1_dynamic_pool_planner.simulated_annealing_optimizer import SimulatedAnnealingOptimizer

class Phase1Pipeline:
    """Phase 1 å®Œæ•´ç®¡é“åŸ·è¡Œå™¨"""
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = self._setup_logger()
        
        # è¼¸å‡ºç›®éŒ„
        self.output_dir = Path("/tmp/phase1_outputs")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç®¡é“çµ±è¨ˆ
        self.pipeline_stats = {
            'start_time': None,
            'end_time': None,
            'total_duration_seconds': 0,
            'stages_completed': 0,
            'total_stages': 4,
            'stage_durations': {},
            'final_results': {}
        }
        
        # éšæ®µçµ„ä»¶
        self.tle_loader = None
        self.satellite_filter = None
        self.event_processor = None
        self.optimizer = None
    
    def _setup_logger(self):
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„å™¨"""
        logger = logging.getLogger('Phase1Pipeline')
        logger.setLevel(logging.INFO)
        
        # å‰µå»ºæ§åˆ¶å°è™•ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # å‰µå»ºæ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(formatter)
        
        # æ·»åŠ è™•ç†å™¨åˆ°è¨˜éŒ„å™¨
        if not logger.handlers:
            logger.addHandler(console_handler)
        
        return logger
    
    async def execute_complete_pipeline(self):
        """åŸ·è¡Œå®Œæ•´çš„Phase 1ç®¡é“"""
        self.logger.info("ğŸš€ å•Ÿå‹•Phase 1å®Œæ•´ç®¡é“åŸ·è¡Œ...")
        self.pipeline_stats['start_time'] = datetime.now(timezone.utc)
        
        try:
            # Stage 1: F1_TLE_Loader - è¼‰å…¥8,735é¡†è¡›æ˜ŸTLEæ•¸æ“š
            stage1_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ“¡ Stage 1: F1_TLE_Loader é–‹å§‹...")
            
            satellite_data, orbital_positions = await self._execute_stage1_tle_loading()
            
            stage1_duration = (datetime.now(timezone.utc) - stage1_start).total_seconds()
            self.pipeline_stats['stage_durations']['stage1_tle_loading'] = stage1_duration
            self.pipeline_stats['stages_completed'] += 1
            
            self.logger.info(f"âœ… Stage 1å®Œæˆ ({stage1_duration:.1f}ç§’)")
            
            # Stage 2: F2_Satellite_Filter - ç¯©é¸å€™é¸ä¸¦ä½¿ç”¨å…¨é‡è»Œé“ä½ç½®
            stage2_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ” Stage 2: F2_Satellite_Filter é–‹å§‹...")
            
            filtered_candidates, candidate_orbital_positions = await self._execute_stage2_satellite_filtering(satellite_data, orbital_positions)
            
            stage2_duration = (datetime.now(timezone.utc) - stage2_start).total_seconds()
            self.pipeline_stats['stage_durations']['stage2_filtering'] = stage2_duration
            self.pipeline_stats['stages_completed'] += 1
            
            self.logger.info(f"âœ… Stage 2å®Œæˆ ({stage2_duration:.1f}ç§’)")
            
            # Stage 3: F3_Signal_Analyzer - A4/A5/D2äº‹ä»¶åˆ†æ
            stage3_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ“Š Stage 3: F3_Signal_Analyzer é–‹å§‹...")
            
            handover_events = await self._execute_stage3_signal_analysis(filtered_candidates, candidate_orbital_positions)
            
            stage3_duration = (datetime.now(timezone.utc) - stage3_start).total_seconds()
            self.pipeline_stats['stage_durations']['stage3_signal_analysis'] = stage3_duration
            self.pipeline_stats['stages_completed'] += 1
            
            self.logger.info(f"âœ… Stage 3å®Œæˆ ({stage3_duration:.1f}ç§’)")
            
            # Stage 4: A1_Dynamic_Pool_Planner - æ¨¡æ“¬é€€ç«æœ€ä½³åŒ–
            stage4_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ”¥ Stage 4: A1_Dynamic_Pool_Planner é–‹å§‹...")
            
            optimal_pools = await self._execute_stage4_pool_optimization(filtered_candidates, candidate_orbital_positions)
            
            stage4_duration = (datetime.now(timezone.utc) - stage4_start).total_seconds()
            self.pipeline_stats['stage_durations']['stage4_optimization'] = stage4_duration
            self.pipeline_stats['stages_completed'] += 1
            
            self.logger.info(f"âœ… Stage 4å®Œæˆ ({stage4_duration:.1f}ç§’)")
            
            # ç”Ÿæˆæœ€çµ‚å ±å‘Š
            await self._generate_final_report(optimal_pools, handover_events)
            
            self.pipeline_stats['end_time'] = datetime.now(timezone.utc)
            self.pipeline_stats['total_duration_seconds'] = (
                self.pipeline_stats['end_time'] - self.pipeline_stats['start_time']
            ).total_seconds()
            
            self.logger.info("ğŸ‰ Phase 1ç®¡é“åŸ·è¡Œå®Œæˆ!")
            self.logger.info(f"   ç¸½è€—æ™‚: {self.pipeline_stats['total_duration_seconds']:.1f}ç§’")
            self.logger.info(f"   å®Œæˆéšæ®µ: {self.pipeline_stats['stages_completed']}/{self.pipeline_stats['total_stages']}")
            
            return optimal_pools
            
        except Exception as e:
            self.logger.error(f"âŒ Phase 1ç®¡é“åŸ·è¡Œå¤±æ•—: {e}")
            raise
    
    async def _execute_stage1_tle_loading(self):
        """åŸ·è¡ŒStage 1: TLEæ•¸æ“šè¼‰å…¥"""
        
        # åˆå§‹åŒ–TLEè¼‰å…¥å™¨
        self.tle_loader = TLELoaderEngine(self.config.get('tle_loader', {}))
        await self.tle_loader.initialize()
        
        # è¼‰å…¥å…¨é‡è¡›æ˜Ÿæ•¸æ“š
        satellite_data = await self.tle_loader.load_full_satellite_data()
        
        # è¨˜éŒ„å…¨é‡è¡›æ˜Ÿæ•¸æ“š
        if satellite_data.get('starlink'):
            self.logger.info(f"   Starlinkè¡›æ˜Ÿ: {len(satellite_data['starlink'])}é¡†")
        if satellite_data.get('oneweb'):
            self.logger.info(f"   OneWebè¡›æ˜Ÿ: {len(satellite_data['oneweb'])}é¡†")
        
        total_satellites = sum(len(sats) for sats in satellite_data.values())
        self.logger.info(f"ğŸ“Š å…¨é‡è¡›æ˜Ÿç¸½è¨ˆ: {total_satellites}é¡†")
        
        # âœ… ä¿®æ­£: æŒ‰ç…§è¨ˆåŠƒï¼ŒStage 1æ‡‰è©²è¨ˆç®—å…¨é‡è¡›æ˜Ÿçš„è»Œé“ä½ç½®
        self.logger.info("ğŸ§® é–‹å§‹è¨ˆç®—å…¨é‡è¡›æ˜Ÿè»Œé“ä½ç½®...")
        
        # âœ… æ”¶é›†**å…¨é‡**è¡›æ˜Ÿé€²è¡Œè»Œé“è¨ˆç®— (æŒ‰ç…§åŸå§‹æ¶æ§‹ä¿®æ­£)
        all_satellites = []
        for constellation_satellites in satellite_data.values():
            all_satellites.extend(constellation_satellites)
        
        if len(all_satellites) > 0:
            self.logger.info(f"ğŸ“Š å…¨é‡è¡›æ˜Ÿæ§‹æˆï¼šç¸½è¨ˆ{len(all_satellites)}é¡†è¡›æ˜Ÿ")
            self.logger.info(f"   åŒ…å«ï¼š{len(satellite_data.get('starlink', []))}é¡†Starlink + {len(satellite_data.get('oneweb', []))}é¡†OneWeb")
            self.logger.info(f"ğŸ“Š è¨ˆç®—å…¨é‡{len(all_satellites)}é¡†è¡›æ˜Ÿçš„è»Œé“ä½ç½®(96åˆ†é˜è»Œé“é€±æœŸ)...")
            
            # ğŸ”§ ä½¿ç”¨96åˆ†é˜è¦†è“‹Starlinkå®Œæ•´è»Œé“é€±æœŸ
            orbital_positions = await self.tle_loader.calculate_orbital_positions(
                all_satellites, time_range_minutes=96
            )
            self.logger.info(f"âœ… å…¨é‡è»Œé“ä½ç½®è¨ˆç®—å®Œæˆ: {len(orbital_positions)}é¡†è¡›æ˜Ÿ")
        else:
            self.logger.warning("âš ï¸ æ²’æœ‰è¡›æ˜Ÿæ•¸æ“šï¼Œè·³éè»Œé“ä½ç½®è¨ˆç®—")
            orbital_positions = {}
        
        # åŒ¯å‡ºStage 1çµæœ
        stage1_output = self.output_dir / "stage1_tle_loading_results.json"
        await self.tle_loader.export_load_statistics(str(stage1_output))
        
        self.logger.info(f"ğŸ“Š Stage 1çµ±è¨ˆ: è¼‰å…¥{self.tle_loader.load_statistics['total_satellites']}é¡†è¡›æ˜Ÿï¼Œè¨ˆç®—{len(orbital_positions)}é¡†è»Œé“")
        
        return satellite_data, orbital_positions
    
    async def _execute_stage2_satellite_filtering(self, satellite_data, orbital_positions):
        """åŸ·è¡ŒStage 2: è¡›æ˜Ÿç¯©é¸"""
        
        # åˆå§‹åŒ–ç¯©é¸å™¨ (v2 - å…­éšæ®µç¯©é¸ç®¡ç·š)
        self.satellite_filter = SatelliteFilterEngineV2(self.config.get('satellite_filter', {}))
        
        # âœ… ä¿®æ­£: å¾æœ‰è»Œé“æ•¸æ“šçš„è¡›æ˜Ÿä¸­é€²è¡Œæ™ºèƒ½ç¯©é¸
        self.logger.info(f"ğŸ” åŸºæ–¼{len(orbital_positions)}é¡†è¡›æ˜Ÿçš„è»Œé“ä½ç½®é€²è¡Œæ™ºèƒ½ç¯©é¸")
        
        # ğŸ”§ èª¿æ•´ï¼šåƒ…å¾æœ‰è»Œé“æ•¸æ“šçš„è¡›æ˜Ÿä¸­ç¯©é¸å€™é¸
        filtered_satellite_data = {}
        for constellation, satellites in satellite_data.items():
            # åªä¿ç•™æœ‰è»Œé“æ•¸æ“šçš„è¡›æ˜Ÿ
            filtered_sats = [sat for sat in satellites if sat.satellite_id in orbital_positions]
            filtered_satellite_data[constellation] = filtered_sats
            self.logger.info(f"   {constellation}: {len(filtered_sats)}é¡†è¡›æ˜Ÿæœ‰è»Œé“æ•¸æ“š")
        
        # æ‡‰ç”¨å…­éšæ®µç¶œåˆç¯©é¸ - éœ€è¦è»Œé“ä½ç½®æ•¸æ“š
        filtered_candidates = await self.satellite_filter.apply_comprehensive_filter(
            filtered_satellite_data, orbital_positions
        )
        
        # å¾å…¨é‡è»Œé“ä½ç½®ä¸­æå–å€™é¸è¡›æ˜Ÿçš„è»Œé“æ•¸æ“š
        candidate_orbital_positions = {}
        candidate_satellites = []
        for candidates in filtered_candidates.values():
            candidate_satellites.extend(candidates)
        
        self.logger.info(f"ğŸ“Š ç¯©é¸çµæœ: {len(candidate_satellites)}é¡†å€™é¸è¡›æ˜Ÿ")
        
        # æå–å€™é¸è¡›æ˜Ÿçš„è»Œé“ä½ç½®æ•¸æ“š
        missing_orbital_data = []
        for candidate in candidate_satellites:
            satellite_id = candidate.satellite_id
            if satellite_id in orbital_positions:
                candidate_orbital_positions[satellite_id] = orbital_positions[satellite_id]
            else:
                missing_orbital_data.append(satellite_id)
        
        if missing_orbital_data:
            self.logger.warning(f"âš ï¸ {len(missing_orbital_data)}é¡†å€™é¸è¡›æ˜Ÿç¼ºå°‘è»Œé“æ•¸æ“š: {missing_orbital_data[:5]}...")
        
        # è¼¸å‡ºèª¿è©¦ä¿¡æ¯
        self.logger.info(f"ğŸ” èª¿è©¦ä¿¡æ¯ï¼š")
        self.logger.info(f"   å€™é¸è¡›æ˜Ÿæ•¸é‡: {len(candidate_satellites)}")
        self.logger.info(f"   æœ‰è»Œé“æ•¸æ“šçš„å€™é¸: {len(candidate_orbital_positions)}")
        if candidate_orbital_positions:
            sample_sat = list(candidate_orbital_positions.keys())[0]
            sample_positions = candidate_orbital_positions[sample_sat]
            self.logger.info(f"   æ¨£æœ¬è¡›æ˜Ÿ {sample_sat}: {len(sample_positions)}å€‹ä½ç½®é»")
            if sample_positions:
                self.logger.info(f"   æ¨£æœ¬ä½ç½®: ä»°è§’{sample_positions[0].elevation_deg:.1f}Â°")
        
        # å°å‡ºStage 2çµæœ - å¢å¼·ç‰ˆåŒ…å«è»Œé“ä½ç½®æ•¸æ“š
        stage2_output = self.output_dir / "stage2_filtering_results.json"
        await self._export_stage2_enhanced_results(filtered_candidates, candidate_orbital_positions, str(stage2_output))
        
        total_candidates = sum(len(candidates) for candidates in filtered_candidates.values())
        self.logger.info(f"ğŸ“Š Stage 2çµ±è¨ˆ: ç¯©é¸å‡º{total_candidates}é¡†å€™é¸è¡›æ˜Ÿ")
        
        return filtered_candidates, candidate_orbital_positions

    async def _export_stage2_enhanced_results(self, 
                                        filtered_candidates: dict, 
                                        orbital_positions: dict, 
                                        output_path: str):
        """å°å‡ºStage 2å¢å¼·çµæœï¼ŒåŒ…å«è»Œé“ä½ç½®æ•¸æ“š"""
        try:
            export_data = {
                'filter_statistics': {
                    'input_satellites': len(self.tle_loader.tle_database) if hasattr(self, 'tle_loader') else 0,
                    'final_candidates': sum(len(candidates) for candidates in filtered_candidates.values()),
                    'starlink_candidates': len(filtered_candidates.get('starlink', [])),
                    'oneweb_candidates': len(filtered_candidates.get('oneweb', [])),
                    'geographic_filtered': 0,
                    'constellation_filtered': 0,
                    'filter_stages': {}
                },
                'filter_timestamp': datetime.now(timezone.utc).isoformat(),
                'observer_coordinates': {
                    'latitude': 24.9441667,
                    'longitude': 121.3713889,
                    'location_name': 'NTPU'
                },
                'candidates': {},
                'orbital_positions': {}  # æ–°å¢ï¼šè»Œé“ä½ç½®æ•¸æ“š
            }
            
            # å°å‡ºå€™é¸è¡›æ˜Ÿè©³ç´°ä¿¡æ¯
            for constellation, candidates in filtered_candidates.items():
                export_data['candidates'][constellation] = []
                
                for candidate in candidates:
                    export_data['candidates'][constellation].append({
                        'satellite_id': candidate.satellite_id,
                        'total_score': round(candidate.total_score, 2),
                        'geographic_relevance_score': round(candidate.geographic_relevance_score, 2),
                        'orbital_characteristics_score': round(candidate.orbital_characteristics_score, 2),
                        'signal_quality_score': round(candidate.signal_quality_score, 2),
                        'temporal_distribution_score': round(candidate.temporal_distribution_score, 2),
                        'scoring_rationale': candidate.scoring_rationale,
                        'is_selected': candidate.is_selected
                    })
            
            # å°å‡ºè»Œé“ä½ç½®æ•¸æ“š
            for satellite_id, positions in orbital_positions.items():
                export_data['orbital_positions'][satellite_id] = []
                for position in positions:
                    export_data['orbital_positions'][satellite_id].append({
                        'timestamp': position.timestamp.isoformat(),
                        'latitude_deg': round(position.latitude_deg, 6),
                        'longitude_deg': round(position.longitude_deg, 6),
                        'altitude_km': round(position.altitude_km, 2),
                        'elevation_deg': round(position.elevation_deg, 2),
                        'azimuth_deg': round(position.azimuth_deg, 2),
                        'distance_km': round(position.distance_km, 2),
                        'velocity_km_s': round(position.velocity_km_s, 3)
                    })
            
            with open(output_path, 'w') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
                
            self.logger.info(f"ğŸ“Š Stage 2å¢å¼·çµæœå·²å°å‡ºè‡³: {output_path}")
            self.logger.info(f"   åŒ…å«è»Œé“ä½ç½®æ•¸æ“š: {len(orbital_positions)}é¡†è¡›æ˜Ÿ")
            
        except Exception as e:
            self.logger.error(f"âŒ Stage 2å¢å¼·çµæœå°å‡ºå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    async def _execute_stage3_signal_analysis(self, filtered_candidates, orbital_positions):
        """åŸ·è¡ŒStage 3: ä¿¡è™Ÿåˆ†æå’Œäº‹ä»¶æª¢æ¸¬"""
        
        # åˆå§‹åŒ–äº‹ä»¶è™•ç†å™¨
        self.event_processor = A4A5D2EventProcessor(self.config.get('event_processor', {}))
        
        # æ¨¡æ“¬æœå‹™è¡›æ˜Ÿå’Œé„°å±…è¡›æ˜Ÿæ™‚é–“è»¸
        # å¯¦éš›å¯¦ç¾éœ€è¦åŸºæ–¼filtered_candidateså’Œorbital_positionsç”Ÿæˆ
        serving_timeline = []  # TODO: å¾filtered_candidatesç”Ÿæˆ
        neighbor_timelines = []  # TODO: å¾filtered_candidatesç”Ÿæˆ
        
        # æª¢æ¸¬æ›æ‰‹äº‹ä»¶
        handover_events = await self.event_processor.process_handover_events(
            serving_timeline, neighbor_timelines, time_range_minutes=200
        )
        
        # åŒ¯å‡ºStage 3çµæœ
        stage3_output = self.output_dir / "stage3_event_analysis_results.json"
        await self.event_processor.export_event_analysis(handover_events, str(stage3_output))
        
        self.logger.info(f"ğŸ“Š Stage 3çµ±è¨ˆ: æª¢æ¸¬{len(handover_events)}å€‹æ›æ‰‹äº‹ä»¶")
        
        return handover_events
    
    async def _execute_stage4_pool_optimization(self, filtered_candidates, orbital_positions):
        """åŸ·è¡ŒStage 4: å‹•æ…‹æ± æœ€ä½³åŒ–"""
        
        # åˆå§‹åŒ–æœ€ä½³åŒ–å™¨
        self.optimizer = SimulatedAnnealingOptimizer(self.config.get('optimizer', {}))
        
        # æº–å‚™å€™é¸æ•¸æ“š
        starlink_candidates = filtered_candidates.get('starlink', [])
        oneweb_candidates = filtered_candidates.get('oneweb', [])
        
        # åŸ·è¡Œæ¨¡æ“¬é€€ç«æœ€ä½³åŒ–
        optimal_solution = await self.optimizer.optimize_satellite_pools(
            starlink_candidates, oneweb_candidates, orbital_positions
        )
        
        # åŒ¯å‡ºStage 4çµæœ
        stage4_output = self.output_dir / "stage4_optimization_results.json"
        await self.optimizer.export_optimization_results(optimal_solution, str(stage4_output))
        
        self.logger.info(f"ğŸ“Š Stage 4çµ±è¨ˆ: æœ€ä½³è§£åŒ…å«{optimal_solution.get_total_satellites()}é¡†è¡›æ˜Ÿ")
        self.logger.info(f"   Starlink: {len(optimal_solution.starlink_satellites)}é¡†")
        self.logger.info(f"   OneWeb: {len(optimal_solution.oneweb_satellites)}é¡†")
        self.logger.info(f"   å¯è¦‹æ€§åˆè¦: {optimal_solution.visibility_compliance:.1%}")
        
        return optimal_solution
    
    def _serialize_pipeline_stats(self):
        """åºåˆ—åŒ–pipelineçµ±è¨ˆä¸­çš„datetimeå°è±¡ç‚ºJSONå…¼å®¹æ ¼å¼"""
        serialized = {}
        for key, value in self.pipeline_stats.items():
            if isinstance(value, datetime):
                serialized[key] = value.isoformat()
            elif isinstance(value, dict):
                # éæ­¸è™•ç†åµŒå¥—çš„å­—å…¸
                serialized[key] = {}
                for sub_key, sub_value in value.items():
                    if isinstance(sub_value, datetime):
                        serialized[key][sub_key] = sub_value.isoformat()
                    else:
                        serialized[key][sub_key] = sub_value
            else:
                serialized[key] = value
        return serialized
    
    async def _generate_final_report(self, optimal_pools, handover_events):
        """ç”Ÿæˆæœ€çµ‚å ±å‘Š"""
        
        # åºåˆ—åŒ–pipeline_statsä¸­çš„datetimeå°è±¡
        serialized_stats = self._serialize_pipeline_stats()
        
        final_report = {
            'phase1_completion_report': {
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'pipeline_statistics': serialized_stats,
                'final_results': {
                    'optimal_satellite_pools': {
                        'starlink_count': len(optimal_pools.starlink_satellites),
                        'oneweb_count': len(optimal_pools.oneweb_satellites),
                        'total_count': optimal_pools.get_total_satellites(),
                        'visibility_compliance': optimal_pools.visibility_compliance,
                        'temporal_distribution': optimal_pools.temporal_distribution,
                        'signal_quality': optimal_pools.signal_quality
                    },
                    'handover_events': {
                        'total_events': len(handover_events),
                        'a4_events': len([e for e in handover_events if e.event_type.value == 'A4']),
                        'a5_events': len([e for e in handover_events if e.event_type.value == 'A5']),
                        'd2_events': len([e for e in handover_events if e.event_type.value == 'D2'])
                    },
                    'compliance_check': {
                        'starlink_target_met': 10 <= len(optimal_pools.starlink_satellites) <= 15,  # ç°¡åŒ–æª¢æŸ¥
                        'oneweb_target_met': 3 <= len(optimal_pools.oneweb_satellites) <= 6,      # ç°¡åŒ–æª¢æŸ¥
                        'visibility_compliance_ok': optimal_pools.visibility_compliance >= 0.90,
                        'temporal_distribution_ok': optimal_pools.temporal_distribution >= 0.70,
                        'frontend_ready': True
                    }
                }
            }
        }
        
        # è¨˜éŒ„æœ€çµ‚çµæœåˆ°çµ±è¨ˆ
        self.pipeline_stats['final_results'] = final_report['phase1_completion_report']['final_results']
        
        # åŒ¯å‡ºæœ€çµ‚å ±å‘Š
        final_report_path = self.output_dir / "phase1_final_report.json"
        with open(final_report_path, 'w') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ğŸ“‹ æœ€çµ‚å ±å‘Šå·²ç”Ÿæˆ: {final_report_path}")
        
        # æª¢æŸ¥ç›®æ¨™é”æˆæƒ…æ³
        compliance = final_report['phase1_completion_report']['final_results']['compliance_check']
        all_targets_met = all(compliance.values())
        
        if all_targets_met:
            self.logger.info("ğŸ¯ âœ… æ‰€æœ‰ç›®æ¨™å‡å·²é”æˆ!")
            self.logger.info("   âœ… Starlinkç›®æ¨™: 10-15é¡†å¯è¦‹")
            self.logger.info("   âœ… OneWebç›®æ¨™: 3-6é¡†å¯è¦‹")
            self.logger.info("   âœ… å¯è¦‹æ€§åˆè¦: â‰¥90%")
            self.logger.info("   âœ… æ™‚ç©ºåˆ†ä½ˆ: â‰¥70%")
            self.logger.info("   âœ… å‰ç«¯å°±ç·’: æ”¯æ´ç«‹é«”åœ–æ¸²æŸ“")
        else:
            failed_targets = [k for k, v in compliance.items() if not v]
            self.logger.warning(f"âš ï¸ æœªé”æˆç›®æ¨™: {failed_targets}")

def create_default_config():
    """å‰µå»ºé è¨­é…ç½®"""
    return {
        'tle_loader': {
            'data_sources': {
                'starlink_tle_url': 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink',
                'oneweb_tle_url': 'https://celestrak.org/NORAD/elements/gp.php?GROUP=oneweb'
            },
            'calculation_params': {
                'time_range_minutes': 200,
                'time_resolution_seconds': 30
            }
        },
        'satellite_filter': {
            'filtering_params': {
                'geographic_threshold': 60.0,
                'min_score_threshold': 70.0
            },
            'ntpu_coordinates': {
                'latitude': 24.9441667,
                'longitude': 121.3713889
            }
        },
        'event_processor': {
            'event_thresholds': {
                'a4_neighbor_threshold_dbm': -100.0,
                'a5_serving_threshold_dbm': -110.0,
                'd2_serving_distance_km': 5000.0
            },
            'signal_params': {
                'frequency_ghz': 12.0,
                'tx_power_dbm': 43.0
            }
        },
        'optimizer': {
            'optimization_params': {
                'max_iterations': 5000,
                'initial_temperature': 1000.0,
                'cooling_rate': 0.95
            },
            'targets': {
                'starlink_pool_size': 8085,  # âœ… åŸºæ–¼æœ¬åœ°TLEæ•¸æ“šå¯¦éš›å€¼
                'oneweb_pool_size': 651,   # âœ… åŸºæ–¼æœ¬åœ°TLEæ•¸æ“šå¯¦éš›å€¼
                'starlink_visible_range': (10, 15),
                'oneweb_visible_range': (3, 6)
            }
        }
    }

async def main():
    """Phase 1ä¸»ç®¡é“åŸ·è¡Œå…¥å£"""
    
    print("ğŸ›°ï¸ LEOè¡›æ˜Ÿå‹•æ…‹æ± è¦åŠƒç³»çµ± - Phase 1åŸ·è¡Œå™¨")
    print("=" * 60)
    
    # å‰µå»ºé…ç½®
    config = create_default_config()
    
    # åˆå§‹åŒ–ç®¡é“
    pipeline = Phase1Pipeline(config)
    
    try:
        # åŸ·è¡Œå®Œæ•´ç®¡é“
        optimal_pools = await pipeline.execute_complete_pipeline()
        
        print("\nğŸ‰ Phase 1åŸ·è¡ŒæˆåŠŸ!")
        print(f"ğŸ“Š æœ€ä½³åŒ–çµæœ:")
        print(f"   Starlinkæ± : {len(optimal_pools.starlink_satellites)}é¡†")
        print(f"   OneWebæ± : {len(optimal_pools.oneweb_satellites)}é¡†")
        print(f"   å¯è¦‹æ€§åˆè¦: {optimal_pools.visibility_compliance:.1%}")
        print(f"   è¼¸å‡ºç›®éŒ„: {pipeline.output_dir}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Phase 1åŸ·è¡Œå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())