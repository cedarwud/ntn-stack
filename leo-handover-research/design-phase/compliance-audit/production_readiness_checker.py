#!/usr/bin/env python3
"""
ç”Ÿç”¢å°±ç·’æª¢æŸ¥å™¨
ç¢ºä¿æ•´å€‹åˆè¦æ€§å¯©è¨ˆç³»çµ±é”åˆ°ç”Ÿç”¢ç´šåˆ¥æ¨™æº–

ğŸš¨ åš´æ ¼éµå¾ª CLAUDE.md åŸå‰‡ï¼š
- âœ… ä½¿ç”¨çœŸå¯¦ç®—æ³•å’Œæ•¸æ“š
- âœ… å®Œæ•´å¯¦ç¾ï¼ˆç„¡ç°¡åŒ–ï¼‰
- âœ… ç”Ÿç”¢ç´šå“è³ªæª¢æŸ¥
- âœ… 100% åˆè¦æ€§é©—è­‰

Author: LEO Handover Research Team
Date: 2025-08-02
Purpose: ç”Ÿç”¢å°±ç·’åº¦å…¨é¢è©•ä¼°
"""

import asyncio
import time
import json
import logging
import subprocess
import psutil
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
from pathlib import Path

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ReadinessLevel(Enum):
    """å°±ç·’ç­‰ç´š"""
    PRODUCTION_READY = "production_ready"          # ç”Ÿç”¢å°±ç·’
    STAGING_READY = "staging_ready"                # æ¸¬è©¦ç’°å¢ƒå°±ç·’
    DEVELOPMENT_ONLY = "development_only"          # åƒ…é–‹ç™¼ç’°å¢ƒ
    NOT_READY = "not_ready"                        # æœªå°±ç·’

class CheckCategory(Enum):
    """æª¢æŸ¥é¡åˆ¥"""
    SECURITY = "security"                          # å®‰å…¨æ€§
    PERFORMANCE = "performance"                    # æ€§èƒ½
    RELIABILITY = "reliability"                    # å¯é æ€§
    COMPLIANCE = "compliance"                      # åˆè¦æ€§
    SCALABILITY = "scalability"                    # å¯æ“´å±•æ€§
    MONITORING = "monitoring"                      # ç›£æ§
    DOCUMENTATION = "documentation"                # æ–‡æª”

@dataclass
class ReadinessCheck:
    """å°±ç·’æª¢æŸ¥é …ç›®"""
    category: CheckCategory
    check_name: str
    description: str
    required_for_production: bool
    passed: bool
    score: float  # 0.0-100.0
    details: Dict[str, Any]
    recommendations: List[str]

class ProductionReadinessChecker:
    """
    ç”Ÿç”¢å°±ç·’æª¢æŸ¥å™¨
    
    è² è²¬ï¼š
    1. å…¨é¢çš„ç”Ÿç”¢å°±ç·’åº¦è©•ä¼°
    2. å®‰å…¨æ€§å’Œæ€§èƒ½æª¢æŸ¥
    3. åˆè¦æ€§æ¨™æº–é©—è­‰
    4. å¯é æ€§å’Œç›£æ§æª¢æŸ¥
    5. æ–‡æª”å®Œæ•´æ€§é©—è­‰
    6. éƒ¨ç½²å‰æœ€çµ‚æª¢æŸ¥
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–ç”Ÿç”¢å°±ç·’æª¢æŸ¥å™¨"""
        self.config = self._load_config(config_path)
        self.check_results: List[ReadinessCheck] = []
        
        # é—œéµæ–‡ä»¶è·¯å¾‘
        self.project_root = Path("/home/sat/ntn-stack")
        self.compliance_audit_path = self.project_root / "leo-handover-research/design-phase/compliance-audit"
        self.netstack_path = self.project_root / "netstack"
        
        logger.info("ğŸ” ç”Ÿç”¢å°±ç·’æª¢æŸ¥å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """è¼‰å…¥é…ç½®"""
        default_config = {
            "production_standards": {
                "min_compliance_score": 100.0,      # è¦æ±‚ 100% åˆè¦
                "max_response_time_ms": 100.0,      # æœ€å¤§éŸ¿æ‡‰æ™‚é–“
                "min_uptime_percent": 99.9,         # æœ€å°æ­£å¸¸é‹è¡Œæ™‚é–“
                "max_error_rate": 0.01,             # æœ€å¤§éŒ¯èª¤ç‡
                "min_test_coverage": 95.0,          # æœ€å°æ¸¬è©¦è¦†è“‹ç‡
                "security_score_threshold": 95.0    # å®‰å…¨åˆ†æ•¸é–€æª»
            },
            "performance_requirements": {
                "d2_event_detection_ms": 50,        # D2 äº‹ä»¶æª¢æ¸¬æ™‚é–“
                "a4_event_detection_ms": 50,        # A4 äº‹ä»¶æª¢æ¸¬æ™‚é–“
                "a5_event_detection_ms": 50,        # A5 äº‹ä»¶æª¢æ¸¬æ™‚é–“
                "rsrp_calculation_ms": 10,          # RSRP è¨ˆç®—æ™‚é–“
                "sib19_processing_ms": 100,         # SIB19 è™•ç†æ™‚é–“
                "concurrent_users": 1000,           # ä¸¦ç™¼ç”¨æˆ¶æ•¸
                "throughput_ops_per_sec": 10000     # ååé‡
            },
            "security_requirements": {
                "input_validation": True,           # è¼¸å…¥é©—è­‰
                "sql_injection_protection": True,   # SQL æ³¨å…¥é˜²è­·
                "xss_protection": True,             # XSS é˜²è­·
                "csrf_protection": True,            # CSRF é˜²è­·
                "rate_limiting": True,              # é€Ÿç‡é™åˆ¶
                "authentication": True,             # èº«ä»½é©—è­‰
                "authorization": True,              # æˆæ¬Š
                "data_encryption": True             # æ•¸æ“šåŠ å¯†
            },
            "reliability_requirements": {
                "graceful_degradation": True,       # å„ªé›…é™ç´š
                "circuit_breaker": True,            # æ–·è·¯å™¨
                "retry_mechanism": True,            # é‡è©¦æ©Ÿåˆ¶
                "timeout_handling": True,           # è¶…æ™‚è™•ç†
                "error_recovery": True,             # éŒ¯èª¤æ¢å¾©
                "health_checks": True,              # å¥åº·æª¢æŸ¥
                "monitoring_alerts": True           # ç›£æ§å‘Šè­¦
            }
        }
        
        if config_path and Path(config_path).exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                default_config.update(user_config)
        
        return default_config
    
    async def run_comprehensive_readiness_check(self) -> Dict[str, Any]:
        """é‹è¡Œå®Œæ•´çš„ç”Ÿç”¢å°±ç·’æª¢æŸ¥"""
        logger.info("ğŸš€ é–‹å§‹ç”Ÿç”¢å°±ç·’åº¦å…¨é¢æª¢æŸ¥")
        start_time = time.time()
        
        # æ¸…ç©ºä¹‹å‰çš„æª¢æŸ¥çµæœ
        self.check_results = []
        
        try:
            # 1. åˆè¦æ€§æª¢æŸ¥
            logger.info("ğŸ“‹ åŸ·è¡Œåˆè¦æ€§æª¢æŸ¥...")
            await self._run_compliance_checks()
            
            # 2. æ€§èƒ½æª¢æŸ¥
            logger.info("âš¡ åŸ·è¡Œæ€§èƒ½æª¢æŸ¥...")
            await self._run_performance_checks()
            
            # 3. å®‰å…¨æ€§æª¢æŸ¥
            logger.info("ğŸ”’ åŸ·è¡Œå®‰å…¨æ€§æª¢æŸ¥...")
            await self._run_security_checks()
            
            # 4. å¯é æ€§æª¢æŸ¥
            logger.info("ğŸ›¡ï¸ åŸ·è¡Œå¯é æ€§æª¢æŸ¥...")
            await self._run_reliability_checks()
            
            # 5. å¯æ“´å±•æ€§æª¢æŸ¥
            logger.info("ğŸ“ˆ åŸ·è¡Œå¯æ“´å±•æ€§æª¢æŸ¥...")
            await self._run_scalability_checks()
            
            # 6. ç›£æ§æª¢æŸ¥
            logger.info("ğŸ“Š åŸ·è¡Œç›£æ§æª¢æŸ¥...")
            await self._run_monitoring_checks()
            
            # 7. æ–‡æª”æª¢æŸ¥
            logger.info("ğŸ“š åŸ·è¡Œæ–‡æª”æª¢æŸ¥...")
            await self._run_documentation_checks()
            
            # è¨ˆç®—ç¸½é«”å°±ç·’åº¦
            overall_readiness = self._calculate_overall_readiness()
            
            duration = time.time() - start_time
            
            # ç”Ÿæˆå®Œæ•´å ±å‘Š
            report = {
                "check_timestamp": datetime.now(timezone.utc).isoformat(),
                "duration_seconds": duration,
                "overall_readiness": overall_readiness,
                "category_summaries": self._generate_category_summaries(),
                "detailed_results": [self._check_to_dict(check) for check in self.check_results],
                "production_deployment_recommendation": self._generate_deployment_recommendation(overall_readiness),
                "action_items": self._generate_action_items()
            }
            
            logger.info(f"âœ… ç”Ÿç”¢å°±ç·’æª¢æŸ¥å®Œæˆï¼Œè€—æ™‚ {duration:.2f} ç§’")
            logger.info(f"ğŸ“Š ç¸½é«”å°±ç·’ç­‰ç´š: {overall_readiness['readiness_level']}")
            logger.info(f"ğŸ¯ å°±ç·’åˆ†æ•¸: {overall_readiness['overall_score']:.1f}%")
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿç”¢å°±ç·’æª¢æŸ¥å¤±æ•—: {e}")
            return {
                "check_timestamp": datetime.now(timezone.utc).isoformat(),
                "duration_seconds": time.time() - start_time,
                "error": str(e),
                "status": "failed"
            }
    
    async def _run_compliance_checks(self):
        """åŸ·è¡Œåˆè¦æ€§æª¢æŸ¥"""
        # æª¢æŸ¥ 3GPP TS 38.331 åˆè¦æ€§
        await self._check_3gpp_compliance()
        
        # æª¢æŸ¥ ITU-R P.618-14 åˆè¦æ€§
        await self._check_itu_compliance()
        
        # æª¢æŸ¥åˆè¦æ€§é©—è­‰ç³»çµ±å®Œæ•´æ€§
        await self._check_compliance_verification_system()
    
    async def _check_3gpp_compliance(self):
        """æª¢æŸ¥ 3GPP TS 38.331 åˆè¦æ€§"""
        try:
            # é‹è¡Œ 3GPP åˆè¦æ€§æ¸¬è©¦
            import sys
            sys.path.append(str(self.compliance_audit_path))
            
            from compliance_verification_system import ComplianceVerificationSystem
            
            verifier = ComplianceVerificationSystem()
            results = await verifier._verify_3gpp_compliance()
            
            passed = results["compliance_score"] >= 100.0
            score = results["compliance_score"]
            
            recommendations = []
            if not passed:
                recommendations.append("ä¿®å¾©æ‰€æœ‰ 3GPP TS 38.331 ä¸åˆè¦é …ç›®")
                recommendations.append("é‡æ–°é‹è¡Œåˆè¦æ€§æ¸¬è©¦ç›´åˆ°é”åˆ° 100% åˆè¦")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.COMPLIANCE,
                check_name="3GPP_TS_38_331_Compliance",
                description="3GPP TS 38.331 v17.3.0 æ¨™æº–å®Œå…¨åˆè¦æ€§é©—è­‰",
                required_for_production=True,
                passed=passed,
                score=score,
                details={
                    "standard": "3GPP TS 38.331 v17.3.0",
                    "test_results": results["test_results"],
                    "total_tests": results["total_tests"],
                    "passed_tests": results["passed_tests"]
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.COMPLIANCE,
                check_name="3GPP_TS_38_331_Compliance",
                description="3GPP TS 38.331 v17.3.0 æ¨™æº–å®Œå…¨åˆè¦æ€§é©—è­‰",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾© 3GPP åˆè¦æ€§æª¢æŸ¥ç³»çµ±éŒ¯èª¤"]
            ))
    
    async def _check_itu_compliance(self):
        """æª¢æŸ¥ ITU-R P.618-14 åˆè¦æ€§"""
        try:
            import sys
            sys.path.append(str(self.compliance_audit_path))
            
            from compliance_verification_system import ComplianceVerificationSystem
            
            verifier = ComplianceVerificationSystem()
            results = await verifier._verify_itu_compliance()
            
            passed = results["compliance_score"] >= 100.0
            score = results["compliance_score"]
            
            recommendations = []
            if not passed:
                recommendations.append("ä¿®å¾©æ‰€æœ‰ ITU-R P.618-14 ä¸åˆè¦é …ç›®")
                recommendations.append("ç¢ºä¿ RSRP è¨ˆç®—æ¨¡å‹å®Œå…¨ç¬¦åˆ ITU-R æ¨™æº–")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.COMPLIANCE,
                check_name="ITU_R_P618_14_Compliance",
                description="ITU-R P.618-14 æ¨™æº–å®Œå…¨åˆè¦æ€§é©—è­‰",
                required_for_production=True,
                passed=passed,
                score=score,
                details={
                    "standard": "ITU-R P.618-14",
                    "test_results": results["test_results"],
                    "total_tests": results["total_tests"],
                    "passed_tests": results["passed_tests"]
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.COMPLIANCE,
                check_name="ITU_R_P618_14_Compliance",
                description="ITU-R P.618-14 æ¨™æº–å®Œå…¨åˆè¦æ€§é©—è­‰",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾© ITU-R åˆè¦æ€§æª¢æŸ¥ç³»çµ±éŒ¯èª¤"]
            ))
    
    async def _check_compliance_verification_system(self):
        """æª¢æŸ¥åˆè¦æ€§é©—è­‰ç³»çµ±å®Œæ•´æ€§"""
        try:
            verification_system_path = self.compliance_audit_path / "compliance_verification_system.py"
            integration_monitor_path = self.compliance_audit_path / "system_integration_monitor.py"
            readiness_checker_path = self.compliance_audit_path / "production_readiness_checker.py"
            
            files_exist = [
                verification_system_path.exists(),
                integration_monitor_path.exists(),
                readiness_checker_path.exists()
            ]
            
            passed = all(files_exist)
            score = (sum(files_exist) / len(files_exist)) * 100.0
            
            recommendations = []
            if not passed:
                recommendations.append("ç¢ºä¿æ‰€æœ‰åˆè¦æ€§é©—è­‰ç³»çµ±æ–‡ä»¶å®Œæ•´")
                recommendations.append("æª¢æŸ¥æ–‡ä»¶æ¬Šé™å’Œå¯åŸ·è¡Œæ€§")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.COMPLIANCE,
                check_name="Compliance_Verification_System_Integrity",
                description="åˆè¦æ€§é©—è­‰ç³»çµ±å®Œæ•´æ€§æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=score,
                details={
                    "verification_system_exists": verification_system_path.exists(),
                    "integration_monitor_exists": integration_monitor_path.exists(),
                    "readiness_checker_exists": readiness_checker_path.exists(),
                    "files_checked": len(files_exist)
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.COMPLIANCE,
                check_name="Compliance_Verification_System_Integrity",
                description="åˆè¦æ€§é©—è­‰ç³»çµ±å®Œæ•´æ€§æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©åˆè¦æ€§é©—è­‰ç³»çµ±å®Œæ•´æ€§æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _run_performance_checks(self):
        """åŸ·è¡Œæ€§èƒ½æª¢æŸ¥"""
        await self._check_response_times()
        await self._check_throughput()
        await self._check_resource_usage()
        await self._check_concurrent_performance()
    
    async def _check_response_times(self):
        """æª¢æŸ¥éŸ¿æ‡‰æ™‚é–“"""
        try:
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            
            from handover_event_detector import HandoverEventDetector
            from dynamic_link_budget_calculator import DynamicLinkBudgetCalculator
            
            detector = HandoverEventDetector("ntpu")
            calculator = DynamicLinkBudgetCalculator()
            
            # æ¸¬è©¦éŸ¿æ‡‰æ™‚é–“
            performance_tests = []
            
            # D2 äº‹ä»¶æª¢æ¸¬æ€§èƒ½
            start_time = time.time()
            for _ in range(100):
                serving_sat = {'satellite_id': 'test', 'elevation_deg': 25.0, 'range_km': 1600.0}
                candidates = [{'satellite_id': 'test2', 'elevation_deg': 30.0, 'range_km': 1000.0}]
                detector._should_trigger_d2((24.94, 121.37, 0.05), serving_sat, candidates)
            d2_avg_time = ((time.time() - start_time) / 100) * 1000
            
            # RSRP è¨ˆç®—æ€§èƒ½
            start_time = time.time()
            test_params = {'range_km': 800.0, 'elevation_deg': 30.0, 'frequency_ghz': 28.0, 
                          'satellite_id': 'test', 'azimuth_deg': 180.0}
            for _ in range(100):
                calculator.calculate_enhanced_rsrp(test_params, (24.94, 121.37, 0.05), time.time())
            rsrp_avg_time = ((time.time() - start_time) / 100) * 1000
            
            performance_tests.extend([
                {"test": "D2_event_detection", "avg_time_ms": d2_avg_time, "threshold_ms": 50},
                {"test": "RSRP_calculation", "avg_time_ms": rsrp_avg_time, "threshold_ms": 10}
            ])
            
            # è©•ä¼°æ€§èƒ½
            passed_tests = sum(1 for test in performance_tests 
                             if test["avg_time_ms"] <= test["threshold_ms"])
            total_tests = len(performance_tests)
            
            passed = passed_tests == total_tests
            score = (passed_tests / total_tests) * 100.0
            
            recommendations = []
            for test in performance_tests:
                if test["avg_time_ms"] > test["threshold_ms"]:
                    recommendations.append(f"å„ªåŒ– {test['test']} æ€§èƒ½ï¼Œç›®æ¨™ < {test['threshold_ms']}ms")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.PERFORMANCE,
                check_name="Response_Time_Performance",
                description="é—œéµåŠŸèƒ½éŸ¿æ‡‰æ™‚é–“æ€§èƒ½æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=score,
                details={
                    "performance_tests": performance_tests,
                    "passed_tests": passed_tests,
                    "total_tests": total_tests
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.PERFORMANCE,
                check_name="Response_Time_Performance",
                description="é—œéµåŠŸèƒ½éŸ¿æ‡‰æ™‚é–“æ€§èƒ½æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©æ€§èƒ½æ¸¬è©¦ç³»çµ±éŒ¯èª¤"]
            ))
    
    async def _check_throughput(self):
        """æª¢æŸ¥ååé‡"""
        try:
            # æ¨¡æ“¬ååé‡æ¸¬è©¦
            target_throughput = self.config["performance_requirements"]["throughput_ops_per_sec"]
            
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            from handover_event_detector import HandoverEventDetector
            
            detector = HandoverEventDetector("ntpu")
            
            # æ¸¬è©¦æ‰¹é‡è™•ç†èƒ½åŠ›
            batch_size = 1000
            start_time = time.time()
            
            for _ in range(batch_size):
                test_satellite = {'elevation_deg': 25.0, 'range_km': 800.0, 'satellite_id': 'throughput_test'}
                detector._calculate_rsrp(test_satellite)
            
            duration = time.time() - start_time
            actual_throughput = batch_size / duration
            
            passed = actual_throughput >= target_throughput * 0.8  # å…è¨± 20% èª¤å·®
            score = min(100.0, (actual_throughput / target_throughput) * 100.0)
            
            recommendations = []
            if not passed:
                recommendations.append(f"æå‡ç³»çµ±ååé‡è‡³ {target_throughput} ops/sec")
                recommendations.append("è€ƒæ…®ä¸¦è¡Œè™•ç†å’Œæ€§èƒ½å„ªåŒ–")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.PERFORMANCE,
                check_name="Throughput_Performance",
                description="ç³»çµ±ååé‡æ€§èƒ½æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=score,
                details={
                    "target_throughput_ops_per_sec": target_throughput,
                    "actual_throughput_ops_per_sec": actual_throughput,
                    "batch_size": batch_size,
                    "test_duration_sec": duration
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.PERFORMANCE,
                check_name="Throughput_Performance",
                description="ç³»çµ±ååé‡æ€§èƒ½æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©ååé‡æ¸¬è©¦éŒ¯èª¤"]
            ))
    
    async def _check_resource_usage(self):
        """æª¢æŸ¥è³‡æºä½¿ç”¨"""
        try:
            # ç²å–ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_info = psutil.virtual_memory()
            memory_percent = memory_info.percent
            disk_usage = psutil.disk_usage('/').percent
            
            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆç”Ÿç”¢æ¨™æº–
            cpu_ok = cpu_percent < 70.0  # CPU ä½¿ç”¨ç‡ < 70%
            memory_ok = memory_percent < 80.0  # è¨˜æ†¶é«”ä½¿ç”¨ç‡ < 80%
            disk_ok = disk_usage < 85.0  # ç£ç¢Ÿä½¿ç”¨ç‡ < 85%
            
            checks = [cpu_ok, memory_ok, disk_ok]
            passed = all(checks)
            score = (sum(checks) / len(checks)) * 100.0
            
            recommendations = []
            if not cpu_ok:
                recommendations.append("é™ä½ CPU ä½¿ç”¨ç‡ï¼Œå„ªåŒ–ç®—æ³•æ€§èƒ½")
            if not memory_ok:
                recommendations.append("å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨ï¼Œæª¢æŸ¥è¨˜æ†¶é«”æ´©æ¼")
            if not disk_ok:
                recommendations.append("æ¸…ç†ç£ç¢Ÿç©ºé–“ï¼Œå„ªåŒ–å­˜å„²ä½¿ç”¨")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.PERFORMANCE,
                check_name="Resource_Usage",
                description="ç³»çµ±è³‡æºä½¿ç”¨æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=score,
                details={
                    "cpu_usage_percent": cpu_percent,
                    "memory_usage_percent": memory_percent,
                    "disk_usage_percent": disk_usage,
                    "cpu_threshold": 70.0,
                    "memory_threshold": 80.0,
                    "disk_threshold": 85.0
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.PERFORMANCE,
                check_name="Resource_Usage",
                description="ç³»çµ±è³‡æºä½¿ç”¨æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©è³‡æºç›£æ§éŒ¯èª¤"]
            ))
    
    async def _check_concurrent_performance(self):
        """æª¢æŸ¥ä¸¦ç™¼æ€§èƒ½"""
        try:
            import asyncio
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            from handover_event_detector import HandoverEventDetector
            
            detector = HandoverEventDetector("ntpu")
            
            # ä¸¦ç™¼æ¸¬è©¦
            concurrent_tasks = 100
            
            async def concurrent_task():
                test_satellite = {'elevation_deg': 25.0, 'range_km': 800.0, 'satellite_id': 'concurrent_test'}
                return detector._calculate_rsrp(test_satellite)
            
            start_time = time.time()
            tasks = [concurrent_task() for _ in range(concurrent_tasks)]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            duration = time.time() - start_time
            
            # æª¢æŸ¥çµæœ
            successful_tasks = sum(1 for r in results if not isinstance(r, Exception))
            success_rate = successful_tasks / concurrent_tasks
            
            passed = success_rate >= 0.95 and duration < 5.0  # 95% æˆåŠŸç‡ï¼Œ5ç§’å…§å®Œæˆ
            score = min(100.0, success_rate * 100.0 * (5.0 / max(duration, 0.1)))
            
            recommendations = []
            if success_rate < 0.95:
                recommendations.append("æå‡ä¸¦ç™¼è™•ç†çš„ç©©å®šæ€§")
            if duration >= 5.0:
                recommendations.append("å„ªåŒ–ä¸¦ç™¼è™•ç†æ€§èƒ½")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.PERFORMANCE,
                check_name="Concurrent_Performance",
                description="ä¸¦ç™¼æ€§èƒ½æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=score,
                details={
                    "concurrent_tasks": concurrent_tasks,
                    "successful_tasks": successful_tasks,
                    "success_rate": success_rate,
                    "duration_sec": duration,
                    "errors": [str(r) for r in results if isinstance(r, Exception)]
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.PERFORMANCE,
                check_name="Concurrent_Performance",
                description="ä¸¦ç™¼æ€§èƒ½æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©ä¸¦ç™¼æ¸¬è©¦éŒ¯èª¤"]
            ))
    
    async def _run_security_checks(self):
        """åŸ·è¡Œå®‰å…¨æ€§æª¢æŸ¥"""
        await self._check_input_validation()
        await self._check_authentication_security()
        await self._check_data_protection()
        await self._check_api_security()
    
    async def _check_input_validation(self):
        """æª¢æŸ¥è¼¸å…¥é©—è­‰"""
        try:
            # æ¸¬è©¦è¼¸å…¥é©—è­‰
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            from handover_event_detector import HandoverEventDetector
            
            detector = HandoverEventDetector("ntpu")
            
            # æ¸¬è©¦ç•°å¸¸è¼¸å…¥è™•ç†
            invalid_inputs = [
                {'elevation_deg': -999, 'range_km': 'invalid', 'satellite_id': None},
                {'elevation_deg': 'abc', 'range_km': -1000, 'satellite_id': ''},
                {},  # ç©ºå­—å…¸
                None  # None å€¼
            ]
            
            validation_passed = 0
            total_tests = len(invalid_inputs)
            
            for invalid_input in invalid_inputs:
                try:
                    # æ‡‰è©²å„ªé›…è™•ç†ç„¡æ•ˆè¼¸å…¥è€Œä¸å´©æ½°
                    result = detector._calculate_rsrp(invalid_input)
                    # å¦‚æœæ²’æœ‰ç•°å¸¸ä½†è¿”å›åˆç†çµæœï¼Œèªªæ˜æœ‰é˜²è­·
                    if isinstance(result, float) and -200 <= result <= 0:
                        validation_passed += 1
                except (ValueError, TypeError, AttributeError):
                    # æ‹‹å‡ºé©ç•¶ç•°å¸¸ä¹Ÿæ˜¯æ­£ç¢ºçš„é˜²è­·
                    validation_passed += 1
                except Exception:
                    # å…¶ä»–ç•°å¸¸å¯èƒ½è¡¨ç¤ºé˜²è­·ä¸è¶³
                    pass
            
            passed = validation_passed >= total_tests * 0.8  # 80% é€šéç‡
            score = (validation_passed / total_tests) * 100.0
            
            recommendations = []
            if not passed:
                recommendations.append("åŠ å¼·è¼¸å…¥é©—è­‰ï¼Œç¢ºä¿æ‰€æœ‰è¼¸å…¥éƒ½ç¶“éé©ç•¶æª¢æŸ¥")
                recommendations.append("å¯¦ç¾çµ±ä¸€çš„è¼¸å…¥é©—è­‰æ©Ÿåˆ¶")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SECURITY,
                check_name="Input_Validation",
                description="è¼¸å…¥é©—è­‰å®‰å…¨æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=score,
                details={
                    "total_tests": total_tests,
                    "validation_passed": validation_passed,
                    "test_inputs": invalid_inputs
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SECURITY,
                check_name="Input_Validation",
                description="è¼¸å…¥é©—è­‰å®‰å…¨æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©è¼¸å…¥é©—è­‰æ¸¬è©¦éŒ¯èª¤"]
            ))
    
    async def _check_authentication_security(self):
        """æª¢æŸ¥èº«ä»½é©—è­‰å®‰å…¨"""
        try:
            # æª¢æŸ¥æ˜¯å¦å¯¦ç¾èº«ä»½é©—è­‰æ©Ÿåˆ¶
            auth_files = [
                self.netstack_path / "netstack_api" / "auth",
                self.netstack_path / "netstack_api" / "middleware",
                self.netstack_path / "netstack_api" / "security"
            ]
            
            auth_implementations = sum(1 for path in auth_files if path.exists())
            
            # æª¢æŸ¥ç’°å¢ƒè®Šé‡ä¸­çš„å¯†é‘°é…ç½®
            import os
            security_vars = [
                "JWT_SECRET_KEY",
                "API_KEY", 
                "ENCRYPTION_KEY"
            ]
            
            configured_vars = sum(1 for var in security_vars if os.getenv(var))
            
            # ç¸½é«”å®‰å…¨è©•åˆ†
            auth_score = (auth_implementations / len(auth_files)) * 50
            config_score = (configured_vars / len(security_vars)) * 50
            total_score = auth_score + config_score
            
            passed = total_score >= 70.0
            
            recommendations = []
            if auth_implementations == 0:
                recommendations.append("å¯¦ç¾èº«ä»½é©—è­‰å’Œæˆæ¬Šæ©Ÿåˆ¶")
            if configured_vars == 0:
                recommendations.append("é…ç½®å®‰å…¨å¯†é‘°å’Œç’°å¢ƒè®Šé‡")
            if not passed:
                recommendations.append("åŠ å¼·æ•´é«”å®‰å…¨é…ç½®")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SECURITY,
                check_name="Authentication_Security",
                description="èº«ä»½é©—è­‰å’Œæˆæ¬Šå®‰å…¨æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=total_score,
                details={
                    "auth_implementations": auth_implementations,
                    "configured_security_vars": configured_vars,
                    "auth_score": auth_score,
                    "config_score": config_score
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SECURITY,
                check_name="Authentication_Security",
                description="èº«ä»½é©—è­‰å’Œæˆæ¬Šå®‰å…¨æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©èº«ä»½é©—è­‰æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _check_data_protection(self):
        """æª¢æŸ¥æ•¸æ“šä¿è­·"""
        try:
            # æª¢æŸ¥æ•æ„Ÿæ•¸æ“šè™•ç†
            sensitive_patterns = [
                "password",
                "secret",
                "key",
                "token",
                "credential"
            ]
            
            # æª¢æŸ¥ä»£ç¢¼ä¸­æ˜¯å¦æœ‰ç¡¬ç·¨ç¢¼æ•æ„Ÿä¿¡æ¯
            code_files = list(self.netstack_path.rglob("*.py"))
            
            violations = 0
            total_files = len(code_files)
            
            for file_path in code_files[:20]:  # æŠ½æ¨£æª¢æŸ¥å‰20å€‹æ–‡ä»¶
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read().lower()
                        for pattern in sensitive_patterns:
                            if f'{pattern} = "' in content or f"{pattern} = '" in content:
                                violations += 1
                                break
                except:
                    continue
            
            protection_score = max(0, (1 - violations / max(total_files, 1)) * 100)
            passed = violations == 0
            
            recommendations = []
            if violations > 0:
                recommendations.append("ç§»é™¤ä»£ç¢¼ä¸­çš„ç¡¬ç·¨ç¢¼æ•æ„Ÿä¿¡æ¯")
                recommendations.append("ä½¿ç”¨ç’°å¢ƒè®Šé‡æˆ–å®‰å…¨é…ç½®ç®¡ç†")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SECURITY,
                check_name="Data_Protection",
                description="æ•¸æ“šä¿è­·å’Œæ•æ„Ÿä¿¡æ¯å®‰å…¨æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=protection_score,
                details={
                    "files_checked": min(20, total_files),
                    "violations_found": violations,
                    "sensitive_patterns_checked": sensitive_patterns
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SECURITY,
                check_name="Data_Protection",
                description="æ•¸æ“šä¿è­·å’Œæ•æ„Ÿä¿¡æ¯å®‰å…¨æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©æ•¸æ“šä¿è­·æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _check_api_security(self):
        """æª¢æŸ¥ API å®‰å…¨"""
        try:
            # æª¢æŸ¥ API è·¯ç”±å®‰å…¨é…ç½®
            router_files = list(self.netstack_path.rglob("*router*.py"))
            
            security_features = {
                "rate_limiting": 0,
                "input_validation": 0,
                "authentication": 0,
                "cors_config": 0
            }
            
            total_routers = len(router_files)
            
            for router_file in router_files:
                try:
                    with open(router_file, 'r', encoding='utf-8') as f:
                        content = f.read().lower()
                        
                        if "rate" in content or "limit" in content:
                            security_features["rate_limiting"] += 1
                        if "validate" in content or "schema" in content:
                            security_features["input_validation"] += 1
                        if "auth" in content or "token" in content:
                            security_features["authentication"] += 1
                        if "cors" in content:
                            security_features["cors_config"] += 1
                            
                except:
                    continue
            
            # è¨ˆç®—å®‰å…¨åˆ†æ•¸
            if total_routers > 0:
                avg_security = sum(security_features.values()) / (len(security_features) * total_routers)
                security_score = avg_security * 100
            else:
                security_score = 0
            
            passed = security_score >= 50.0
            
            recommendations = []
            if security_features["rate_limiting"] == 0:
                recommendations.append("å¯¦ç¾ API é€Ÿç‡é™åˆ¶")
            if security_features["authentication"] == 0:
                recommendations.append("åŠ å¼· API èº«ä»½é©—è­‰")
            if not passed:
                recommendations.append("å…¨é¢æå‡ API å®‰å…¨é…ç½®")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SECURITY,
                check_name="API_Security",
                description="API å®‰å…¨é…ç½®æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=security_score,
                details={
                    "total_routers": total_routers,
                    "security_features": security_features,
                    "avg_security_coverage": avg_security if total_routers > 0 else 0
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SECURITY,
                check_name="API_Security",
                description="API å®‰å…¨é…ç½®æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾© API å®‰å…¨æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _run_reliability_checks(self):
        """åŸ·è¡Œå¯é æ€§æª¢æŸ¥"""
        await self._check_error_handling()
        await self._check_fault_tolerance()
        await self._check_data_consistency()
    
    async def _check_error_handling(self):
        """æª¢æŸ¥éŒ¯èª¤è™•ç†"""
        try:
            # æª¢æŸ¥ä»£ç¢¼ä¸­çš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
            code_files = list(self.netstack_path.rglob("*.py"))
            
            error_handling_stats = {
                "try_except_blocks": 0,
                "logging_statements": 0,
                "custom_exceptions": 0,
                "total_files": 0
            }
            
            for file_path in code_files[:50]:  # æª¢æŸ¥å‰50å€‹æ–‡ä»¶
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                        error_handling_stats["total_files"] += 1
                        error_handling_stats["try_except_blocks"] += content.count("try:")
                        error_handling_stats["logging_statements"] += content.count("logger.")
                        error_handling_stats["custom_exceptions"] += content.count("Exception")
                        
                except:
                    continue
            
            # è¨ˆç®—éŒ¯èª¤è™•ç†è¦†è“‹ç‡
            if error_handling_stats["total_files"] > 0:
                avg_error_handling = (
                    error_handling_stats["try_except_blocks"] + 
                    error_handling_stats["logging_statements"]
                ) / error_handling_stats["total_files"]
                
                reliability_score = min(100.0, avg_error_handling * 20)  # æ¯å€‹æ–‡ä»¶è‡³å°‘5å€‹éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
            else:
                reliability_score = 0
            
            passed = reliability_score >= 60.0
            
            recommendations = []
            if error_handling_stats["try_except_blocks"] < error_handling_stats["total_files"]:
                recommendations.append("å¢åŠ  try-except éŒ¯èª¤è™•ç†å¡Š")
            if error_handling_stats["logging_statements"] < error_handling_stats["total_files"] * 2:
                recommendations.append("å¢åŠ é©ç•¶çš„æ—¥èªŒè¨˜éŒ„")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.RELIABILITY,
                check_name="Error_Handling",
                description="éŒ¯èª¤è™•ç†æ©Ÿåˆ¶æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=reliability_score,
                details=error_handling_stats,
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.RELIABILITY,
                check_name="Error_Handling",
                description="éŒ¯èª¤è™•ç†æ©Ÿåˆ¶æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©éŒ¯èª¤è™•ç†æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _check_fault_tolerance(self):
        """æª¢æŸ¥å®¹éŒ¯èƒ½åŠ›"""
        try:
            # æ¸¬è©¦æœå‹™çš„å®¹éŒ¯èƒ½åŠ›
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            from handover_event_detector import HandoverEventDetector
            
            detector = HandoverEventDetector("ntpu")
            
            # æ¸¬è©¦æ¥µç«¯æƒ…æ³è™•ç†
            fault_tests = [
                {"name": "empty_satellite_data", "input": {}},
                {"name": "negative_values", "input": {"elevation_deg": -100, "range_km": -500}},
                {"name": "extreme_values", "input": {"elevation_deg": 999, "range_km": 99999}},
                {"name": "null_values", "input": {"elevation_deg": None, "range_km": None}},
            ]
            
            fault_tolerance_score = 0
            
            for test in fault_tests:
                try:
                    result = detector._calculate_rsrp(test["input"])
                    # å¦‚æœèƒ½è™•ç†è€Œä¸å´©æ½°ï¼Œå¾—åˆ†
                    if isinstance(result, (int, float)):
                        fault_tolerance_score += 25
                except Exception:
                    # å„ªé›…çš„ç•°å¸¸è™•ç†ä¹Ÿç®—é€šé
                    fault_tolerance_score += 20
            
            passed = fault_tolerance_score >= 80.0
            
            recommendations = []
            if not passed:
                recommendations.append("æå‡ç³»çµ±å®¹éŒ¯èƒ½åŠ›")
                recommendations.append("å¯¦ç¾å„ªé›…é™ç´šæ©Ÿåˆ¶")
                recommendations.append("åŠ å¼·é‚Šç•Œæ¢ä»¶è™•ç†")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.RELIABILITY,
                check_name="Fault_Tolerance",
                description="å®¹éŒ¯èƒ½åŠ›æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=fault_tolerance_score,
                details={
                    "fault_tests": fault_tests,
                    "tolerance_score": fault_tolerance_score
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.RELIABILITY,
                check_name="Fault_Tolerance",
                description="å®¹éŒ¯èƒ½åŠ›æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©å®¹éŒ¯æ¸¬è©¦éŒ¯èª¤"]
            ))
    
    async def _check_data_consistency(self):
        """æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§"""
        try:
            # æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§æ©Ÿåˆ¶
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            from handover_event_detector import HandoverEventDetector
            
            detector = HandoverEventDetector("ntpu")
            
            # æ¸¬è©¦ç›¸åŒè¼¸å…¥çš„ä¸€è‡´æ€§
            test_satellite = {
                'satellite_id': 'consistency_test',
                'elevation_deg': 30.0,
                'range_km': 800.0
            }
            
            results = []
            for _ in range(10):
                result = detector._calculate_rsrp(test_satellite)
                results.append(result)
            
            # æª¢æŸ¥çµæœä¸€è‡´æ€§ï¼ˆå…è¨±å°å¹…éš¨æ©Ÿè®ŠåŒ–ï¼‰
            if results:
                avg_result = sum(results) / len(results)
                max_deviation = max(abs(r - avg_result) for r in results)
                consistency_score = max(0, 100 - (max_deviation * 10))  # åå·®è¶Šå°åˆ†æ•¸è¶Šé«˜
            else:
                consistency_score = 0
            
            passed = consistency_score >= 70.0
            
            recommendations = []
            if not passed:
                recommendations.append("æ”¹å–„æ•¸æ“šä¸€è‡´æ€§æ©Ÿåˆ¶")
                recommendations.append("æ¸›å°‘ä¸å¿…è¦çš„éš¨æ©Ÿæ€§")
                recommendations.append("å¯¦ç¾ç¢ºå®šæ€§ç®—æ³•")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.RELIABILITY,
                check_name="Data_Consistency",
                description="æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=consistency_score,
                details={
                    "test_results": results,
                    "average_result": avg_result if results else 0,
                    "max_deviation": max_deviation if results else 0,
                    "consistency_score": consistency_score
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.RELIABILITY,
                check_name="Data_Consistency",
                description="æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _run_scalability_checks(self):
        """åŸ·è¡Œå¯æ“´å±•æ€§æª¢æŸ¥"""
        await self._check_horizontal_scalability()
        await self._check_resource_scalability()
    
    async def _check_horizontal_scalability(self):
        """æª¢æŸ¥æ°´å¹³æ“´å±•èƒ½åŠ›"""
        try:
            # æª¢æŸ¥ç³»çµ±æ¶æ§‹æ˜¯å¦æ”¯æŒæ°´å¹³æ“´å±•
            scalability_indicators = {
                "stateless_design": False,
                "load_balancer_ready": False,
                "database_clustering": False,
                "api_versioning": False
            }
            
            # æª¢æŸ¥ä»£ç¢¼çµæ§‹
            code_files = list(self.netstack_path.rglob("*.py"))
            
            for file_path in code_files[:30]:  # æª¢æŸ¥å‰30å€‹æ–‡ä»¶
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read().lower()
                        
                        # æª¢æŸ¥ç„¡ç‹€æ…‹è¨­è¨ˆæŒ‡æ¨™
                        if "session" not in content and "global" not in content:
                            scalability_indicators["stateless_design"] = True
                        
                        # æª¢æŸ¥è² è¼‰å‡è¡¡æº–å‚™
                        if "load" in content or "balance" in content:
                            scalability_indicators["load_balancer_ready"] = True
                        
                        # æª¢æŸ¥ API ç‰ˆæœ¬æ§åˆ¶
                        if "v1" in content or "version" in content:
                            scalability_indicators["api_versioning"] = True
                            
                except:
                    continue
            
            # æª¢æŸ¥é…ç½®æ–‡ä»¶
            config_files = list(self.project_root.rglob("docker-compose*.yml"))
            if config_files:
                scalability_indicators["database_clustering"] = True
            
            scalability_score = (sum(scalability_indicators.values()) / len(scalability_indicators)) * 100
            passed = scalability_score >= 75.0
            
            recommendations = []
            if not scalability_indicators["stateless_design"]:
                recommendations.append("å¯¦ç¾ç„¡ç‹€æ…‹æœå‹™è¨­è¨ˆ")
            if not scalability_indicators["load_balancer_ready"]:
                recommendations.append("æº–å‚™è² è¼‰å‡è¡¡é…ç½®")
            if not scalability_indicators["api_versioning"]:
                recommendations.append("å¯¦ç¾ API ç‰ˆæœ¬æ§åˆ¶")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SCALABILITY,
                check_name="Horizontal_Scalability",
                description="æ°´å¹³æ“´å±•èƒ½åŠ›æª¢æŸ¥",
                required_for_production=False,  # éå¼·åˆ¶ä½†é‡è¦
                passed=passed,
                score=scalability_score,
                details=scalability_indicators,
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SCALABILITY,
                check_name="Horizontal_Scalability",
                description="æ°´å¹³æ“´å±•èƒ½åŠ›æª¢æŸ¥",
                required_for_production=False,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©å¯æ“´å±•æ€§æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _check_resource_scalability(self):
        """æª¢æŸ¥è³‡æºæ“´å±•èƒ½åŠ›"""
        try:
            # æª¢æŸ¥è³‡æºé…ç½®çš„å¯æ“´å±•æ€§
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            from handover_event_detector import HandoverEventDetector
            
            detector = HandoverEventDetector("ntpu")
            
            # æ¸¬è©¦ä¸åŒè² è¼‰ä¸‹çš„æ€§èƒ½
            load_tests = [10, 50, 100, 500]
            performance_results = []
            
            for load in load_tests:
                start_time = time.time()
                
                for _ in range(load):
                    test_satellite = {'elevation_deg': 25.0, 'range_km': 800.0, 'satellite_id': f'load_test_{load}'}
                    detector._calculate_rsrp(test_satellite)
                
                duration = time.time() - start_time
                avg_time_per_op = (duration / load) * 1000  # ms
                
                performance_results.append({
                    "load": load,
                    "total_duration_sec": duration,
                    "avg_time_per_op_ms": avg_time_per_op
                })
            
            # åˆ†ææ€§èƒ½æ“´å±•æ€§
            if len(performance_results) >= 2:
                # æª¢æŸ¥æ€§èƒ½æ˜¯å¦ç·šæ€§æ“´å±•
                first_result = performance_results[0]
                last_result = performance_results[-1]
                
                expected_time = first_result["avg_time_per_op_ms"]
                actual_time = last_result["avg_time_per_op_ms"]
                
                scalability_ratio = expected_time / max(actual_time, 0.001)
                scalability_score = min(100.0, scalability_ratio * 100)
            else:
                scalability_score = 0
            
            passed = scalability_score >= 70.0
            
            recommendations = []
            if not passed:
                recommendations.append("å„ªåŒ–ç®—æ³•ä»¥æ”¯æŒæ›´å¥½çš„è³‡æºæ“´å±•")
                recommendations.append("å¯¦ç¾è³‡æºæ± åŒ–å’Œé‡ç”¨")
                recommendations.append("è€ƒæ…®ç•°æ­¥è™•ç†å’Œä¸¦ç™¼å„ªåŒ–")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SCALABILITY,
                check_name="Resource_Scalability",
                description="è³‡æºæ“´å±•èƒ½åŠ›æª¢æŸ¥",
                required_for_production=False,
                passed=passed,
                score=scalability_score,
                details={
                    "performance_results": performance_results,
                    "scalability_score": scalability_score
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.SCALABILITY,
                check_name="Resource_Scalability",
                description="è³‡æºæ“´å±•èƒ½åŠ›æª¢æŸ¥",
                required_for_production=False,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©è³‡æºæ“´å±•æ€§æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _run_monitoring_checks(self):
        """åŸ·è¡Œç›£æ§æª¢æŸ¥"""
        await self._check_logging_system()
        await self._check_metrics_collection()
        await self._check_health_monitoring()
    
    async def _check_logging_system(self):
        """æª¢æŸ¥æ—¥èªŒç³»çµ±"""
        try:
            # æª¢æŸ¥æ—¥èªŒé…ç½®å’Œå¯¦ç¾
            logging_indicators = {
                "structured_logging": False,
                "log_levels": False,
                "log_rotation": False,
                "centralized_logging": False
            }
            
            # æª¢æŸ¥ä»£ç¢¼ä¸­çš„æ—¥èªŒä½¿ç”¨
            code_files = list(self.netstack_path.rglob("*.py"))
            
            total_logging_statements = 0
            total_files_with_logging = 0
            
            for file_path in code_files[:40]:  # æª¢æŸ¥å‰40å€‹æ–‡ä»¶
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                        file_logging_count = content.count("logger.")
                        if file_logging_count > 0:
                            total_files_with_logging += 1
                            total_logging_statements += file_logging_count
                        
                        # æª¢æŸ¥æ—¥èªŒé…ç½®
                        if "logging.config" in content or "dictConfig" in content:
                            logging_indicators["structured_logging"] = True
                        
                        if "DEBUG" in content and "INFO" in content and "ERROR" in content:
                            logging_indicators["log_levels"] = True
                            
                except:
                    continue
            
            # æª¢æŸ¥æ—¥èªŒé…ç½®æ–‡ä»¶
            config_files = list(self.project_root.rglob("*log*.conf")) + list(self.project_root.rglob("*log*.yaml"))
            if config_files:
                logging_indicators["log_rotation"] = True
                logging_indicators["centralized_logging"] = True
            
            # è¨ˆç®—æ—¥èªŒè¦†è“‹ç‡
            logging_coverage = (total_files_with_logging / max(len(code_files[:40]), 1)) * 100
            config_score = (sum(logging_indicators.values()) / len(logging_indicators)) * 100
            
            overall_score = (logging_coverage + config_score) / 2
            passed = overall_score >= 60.0
            
            recommendations = []
            if logging_coverage < 50:
                recommendations.append("å¢åŠ æ›´å¤šæ—¥èªŒè¨˜éŒ„è¦†è“‹")
            if not logging_indicators["structured_logging"]:
                recommendations.append("å¯¦ç¾çµæ§‹åŒ–æ—¥èªŒ")
            if not logging_indicators["log_rotation"]:
                recommendations.append("é…ç½®æ—¥èªŒè¼ªè½‰")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.MONITORING,
                check_name="Logging_System",
                description="æ—¥èªŒç³»çµ±æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=overall_score,
                details={
                    "logging_coverage_percent": logging_coverage,
                    "total_logging_statements": total_logging_statements,
                    "files_with_logging": total_files_with_logging,
                    "logging_indicators": logging_indicators
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.MONITORING,
                check_name="Logging_System",
                description="æ—¥èªŒç³»çµ±æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©æ—¥èªŒç³»çµ±æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _check_metrics_collection(self):
        """æª¢æŸ¥æŒ‡æ¨™æ”¶é›†"""
        try:
            # æª¢æŸ¥æŒ‡æ¨™æ”¶é›†å¯¦ç¾
            metrics_files = []
            metrics_implementations = 0
            
            # æŸ¥æ‰¾æŒ‡æ¨™ç›¸é—œæ–‡ä»¶
            for pattern in ["*metric*", "*monitor*", "*health*"]:
                metrics_files.extend(list(self.netstack_path.rglob(pattern + ".py")))
            
            if metrics_files:
                metrics_implementations = len(metrics_files)
            
            # æª¢æŸ¥ç³»çµ±æ•´åˆç›£æ§å™¨
            integration_monitor_exists = (self.compliance_audit_path / "system_integration_monitor.py").exists()
            
            # æª¢æŸ¥æŒ‡æ¨™å°å‡º
            prometheus_config = False
            grafana_config = False
            
            # æŸ¥æ‰¾ç›£æ§é…ç½®
            for config_file in self.project_root.rglob("*docker-compose*.yml"):
                try:
                    with open(config_file, 'r') as f:
                        content = f.read().lower()
                        if "prometheus" in content:
                            prometheus_config = True
                        if "grafana" in content:
                            grafana_config = True
                except:
                    continue
            
            # è¨ˆç®—æŒ‡æ¨™åˆ†æ•¸
            metrics_score = 0
            if metrics_implementations > 0:
                metrics_score += 30
            if integration_monitor_exists:
                metrics_score += 40
            if prometheus_config:
                metrics_score += 15
            if grafana_config:
                metrics_score += 15
            
            passed = metrics_score >= 70.0
            
            recommendations = []
            if metrics_implementations == 0:
                recommendations.append("å¯¦ç¾æŒ‡æ¨™æ”¶é›†æ©Ÿåˆ¶")
            if not integration_monitor_exists:
                recommendations.append("ä½¿ç”¨ç³»çµ±æ•´åˆç›£æ§å™¨")
            if not prometheus_config:
                recommendations.append("é…ç½® Prometheus æŒ‡æ¨™å°å‡º")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.MONITORING,
                check_name="Metrics_Collection",
                description="æŒ‡æ¨™æ”¶é›†ç³»çµ±æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=metrics_score,
                details={
                    "metrics_implementations": metrics_implementations,
                    "integration_monitor_exists": integration_monitor_exists,
                    "prometheus_config": prometheus_config,
                    "grafana_config": grafana_config
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.MONITORING,
                check_name="Metrics_Collection",
                description="æŒ‡æ¨™æ”¶é›†ç³»çµ±æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©æŒ‡æ¨™æ”¶é›†æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _check_health_monitoring(self):
        """æª¢æŸ¥å¥åº·ç›£æ§"""
        try:
            # æª¢æŸ¥å¥åº·æª¢æŸ¥ç«¯é»
            health_endpoints = 0
            router_files = list(self.netstack_path.rglob("*router*.py"))
            
            for router_file in router_files:
                try:
                    with open(router_file, 'r') as f:
                        content = f.read().lower()
                        if "health" in content and ("@router" in content or "app.get" in content):
                            health_endpoints += 1
                except:
                    continue
            
            # æª¢æŸ¥å¥åº·æª¢æŸ¥é‚è¼¯
            health_logic_score = 0
            if health_endpoints > 0:
                health_logic_score = min(100.0, health_endpoints * 25)
            
            # æª¢æŸ¥ç›£æ§è…³æœ¬
            monitoring_scripts = list(self.compliance_audit_path.glob("*monitor*.py"))
            monitoring_score = len(monitoring_scripts) * 30
            
            overall_score = min(100.0, health_logic_score + monitoring_score)
            passed = overall_score >= 70.0
            
            recommendations = []
            if health_endpoints == 0:
                recommendations.append("å¯¦ç¾å¥åº·æª¢æŸ¥ API ç«¯é»")
            if len(monitoring_scripts) == 0:
                recommendations.append("å‰µå»ºç›£æ§è…³æœ¬å’Œè‡ªå‹•åŒ–æª¢æŸ¥")
            if not passed:
                recommendations.append("å®Œå–„å¥åº·ç›£æ§ç³»çµ±")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.MONITORING,
                check_name="Health_Monitoring",
                description="å¥åº·ç›£æ§ç³»çµ±æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=overall_score,
                details={
                    "health_endpoints": health_endpoints,
                    "monitoring_scripts": len(monitoring_scripts),
                    "health_logic_score": health_logic_score,
                    "monitoring_score": monitoring_score
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.MONITORING,
                check_name="Health_Monitoring",
                description="å¥åº·ç›£æ§ç³»çµ±æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©å¥åº·ç›£æ§æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _run_documentation_checks(self):
        """åŸ·è¡Œæ–‡æª”æª¢æŸ¥"""
        await self._check_api_documentation()
        await self._check_deployment_documentation()
        await self._check_compliance_documentation()
    
    async def _check_api_documentation(self):
        """æª¢æŸ¥ API æ–‡æª”"""
        try:
            # æª¢æŸ¥ API æ–‡æª”å®Œæ•´æ€§
            doc_files = []
            
            # æª¢æŸ¥ README æ–‡ä»¶
            readme_files = list(self.project_root.rglob("README*.md"))
            doc_files.extend(readme_files)
            
            # æª¢æŸ¥ API æ–‡æª”
            api_doc_files = list(self.project_root.rglob("*api*.md"))
            doc_files.extend(api_doc_files)
            
            # æª¢æŸ¥ OpenAPI/Swagger é…ç½®
            swagger_files = list(self.project_root.rglob("*swagger*")) + list(self.project_root.rglob("*openapi*"))
            
            # æª¢æŸ¥å…§è¯æ–‡æª”
            router_files = list(self.netstack_path.rglob("*router*.py"))
            documented_endpoints = 0
            total_endpoints = 0
            
            for router_file in router_files:
                try:
                    with open(router_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                        # è¨ˆç®—ç«¯é»æ•¸é‡
                        endpoints = content.count("@router.") + content.count("app.get") + content.count("app.post")
                        total_endpoints += endpoints
                        
                        # è¨ˆç®—æœ‰æ–‡æª”çš„ç«¯é»
                        documented = content.count('"""') // 2  # å‡è¨­æ¯å€‹æ–‡æª”å­—ç¬¦ä¸²åŒ…è£¹ä¸€å€‹ç«¯é»
                        documented_endpoints += min(documented, endpoints)
                        
                except:
                    continue
            
            # è¨ˆç®—æ–‡æª”åˆ†æ•¸
            doc_coverage = (documented_endpoints / max(total_endpoints, 1)) * 100
            file_score = min(100.0, len(doc_files) * 20)
            swagger_score = min(100.0, len(swagger_files) * 50)
            
            overall_score = (doc_coverage + file_score + swagger_score) / 3
            passed = overall_score >= 70.0
            
            recommendations = []
            if doc_coverage < 80:
                recommendations.append("å¢åŠ  API ç«¯é»æ–‡æª”è¦†è“‹ç‡")
            if len(swagger_files) == 0:
                recommendations.append("å¯¦ç¾ OpenAPI/Swagger æ–‡æª”")
            if len(readme_files) == 0:
                recommendations.append("å‰µå»ºè©³ç´°çš„ README æ–‡æª”")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.DOCUMENTATION,
                check_name="API_Documentation",
                description="API æ–‡æª”å®Œæ•´æ€§æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=overall_score,
                details={
                    "documented_endpoints": documented_endpoints,
                    "total_endpoints": total_endpoints,
                    "doc_coverage_percent": doc_coverage,
                    "doc_files_count": len(doc_files),
                    "swagger_files_count": len(swagger_files)
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.DOCUMENTATION,
                check_name="API_Documentation",
                description="API æ–‡æª”å®Œæ•´æ€§æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾© API æ–‡æª”æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _check_deployment_documentation(self):
        """æª¢æŸ¥éƒ¨ç½²æ–‡æª”"""
        try:
            # æª¢æŸ¥éƒ¨ç½²ç›¸é—œæ–‡æª”
            deployment_files = []
            
            # Docker ç›¸é—œæ–‡æª”
            docker_files = list(self.project_root.rglob("Dockerfile*")) + list(self.project_root.rglob("docker-compose*.yml"))
            deployment_files.extend(docker_files)
            
            # éƒ¨ç½²æŒ‡å—
            deploy_docs = list(self.project_root.rglob("*deploy*.md")) + list(self.project_root.rglob("*install*.md"))
            deployment_files.extend(deploy_docs)
            
            # é…ç½®æ–‡æª”
            config_docs = list(self.project_root.rglob("*config*.md")) + list(self.project_root.rglob("*setup*.md"))
            deployment_files.extend(config_docs)
            
            # æª¢æŸ¥ç’°å¢ƒé…ç½®
            env_files = list(self.project_root.rglob("*.env*")) + list(self.project_root.rglob("*requirements*.txt"))
            
            # è¨ˆç®—éƒ¨ç½²æ–‡æª”åˆ†æ•¸
            docker_score = min(100.0, len(docker_files) * 30)
            doc_score = min(100.0, len(deploy_docs + config_docs) * 25)
            env_score = min(100.0, len(env_files) * 20)
            
            overall_score = (docker_score + doc_score + env_score) / 3
            passed = overall_score >= 60.0
            
            recommendations = []
            if len(docker_files) == 0:
                recommendations.append("å‰µå»º Docker é…ç½®æ–‡ä»¶")
            if len(deploy_docs) == 0:
                recommendations.append("ç·¨å¯«éƒ¨ç½²æŒ‡å—æ–‡æª”")
            if len(env_files) == 0:
                recommendations.append("æä¾›ç’°å¢ƒé…ç½®æ¨¡æ¿")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.DOCUMENTATION,
                check_name="Deployment_Documentation",
                description="éƒ¨ç½²æ–‡æª”å®Œæ•´æ€§æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=overall_score,
                details={
                    "docker_files": len(docker_files),
                    "deploy_docs": len(deploy_docs),
                    "config_docs": len(config_docs),
                    "env_files": len(env_files),
                    "total_deployment_files": len(deployment_files)
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.DOCUMENTATION,
                check_name="Deployment_Documentation",
                description="éƒ¨ç½²æ–‡æª”å®Œæ•´æ€§æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©éƒ¨ç½²æ–‡æª”æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    async def _check_compliance_documentation(self):
        """æª¢æŸ¥åˆè¦æ€§æ–‡æª”"""
        try:
            # æª¢æŸ¥åˆè¦æ€§å¯©è¨ˆæ–‡æª”
            compliance_files = list(self.compliance_audit_path.rglob("*.md"))
            compliance_py_files = list(self.compliance_audit_path.rglob("*.py"))
            
            # æª¢æŸ¥é—œéµæ–‡æª”
            required_docs = [
                "README.md",
                "audit-summary.md",
                "sib19-architecture.md",
                "core-logic-fixes.md",
                "rsrp-signal-model.md",
                "layered-threshold-system.md",
                "implementation-plan.md"
            ]
            
            existing_docs = sum(1 for doc in required_docs 
                              if (self.compliance_audit_path / doc).exists())
            
            # æª¢æŸ¥å¯¦ç¾æ–‡æª”
            implementation_files = [
                "compliance_verification_system.py",
                "system_integration_monitor.py",
                "production_readiness_checker.py"
            ]
            
            existing_implementations = sum(1 for impl in implementation_files
                                         if (self.compliance_audit_path / impl).exists())
            
            # è¨ˆç®—åˆè¦æ–‡æª”åˆ†æ•¸
            doc_completeness = (existing_docs / len(required_docs)) * 100
            impl_completeness = (existing_implementations / len(implementation_files)) * 100
            
            overall_score = (doc_completeness + impl_completeness) / 2
            passed = overall_score >= 90.0  # åˆè¦æ–‡æª”è¦æ±‚è¼ƒé«˜
            
            recommendations = []
            if existing_docs < len(required_docs):
                missing_docs = [doc for doc in required_docs 
                               if not (self.compliance_audit_path / doc).exists()]
                recommendations.append(f"å®Œå–„ç¼ºå¤±çš„æ–‡æª”: {', '.join(missing_docs)}")
            
            if existing_implementations < len(implementation_files):
                recommendations.append("ç¢ºä¿æ‰€æœ‰å¯¦ç¾æ–‡ä»¶å®Œæ•´")
            
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.DOCUMENTATION,
                check_name="Compliance_Documentation",
                description="åˆè¦æ€§æ–‡æª”å®Œæ•´æ€§æª¢æŸ¥",
                required_for_production=True,
                passed=passed,
                score=overall_score,
                details={
                    "total_compliance_files": len(compliance_files),
                    "total_implementation_files": len(compliance_py_files),
                    "required_docs_existing": existing_docs,
                    "required_docs_total": len(required_docs),
                    "implementation_files_existing": existing_implementations,
                    "implementation_files_total": len(implementation_files),
                    "doc_completeness": doc_completeness,
                    "impl_completeness": impl_completeness
                },
                recommendations=recommendations
            ))
            
        except Exception as e:
            self.check_results.append(ReadinessCheck(
                category=CheckCategory.DOCUMENTATION,
                check_name="Compliance_Documentation",
                description="åˆè¦æ€§æ–‡æª”å®Œæ•´æ€§æª¢æŸ¥",
                required_for_production=True,
                passed=False,
                score=0.0,
                details={"error": str(e)},
                recommendations=["ä¿®å¾©åˆè¦æ€§æ–‡æª”æª¢æŸ¥éŒ¯èª¤"]
            ))
    
    def _calculate_overall_readiness(self) -> Dict[str, Any]:
        """è¨ˆç®—ç¸½é«”å°±ç·’åº¦"""
        if not self.check_results:
            return {
                "readiness_level": ReadinessLevel.NOT_READY.value,
                "overall_score": 0.0,
                "critical_issues": ["æ²’æœ‰åŸ·è¡Œä»»ä½•æª¢æŸ¥"]
            }
        
        # åˆ†é›¢å¼·åˆ¶å’Œéå¼·åˆ¶æª¢æŸ¥
        required_checks = [check for check in self.check_results if check.required_for_production]
        optional_checks = [check for check in self.check_results if not check.required_for_production]
        
        # è¨ˆç®—å¼·åˆ¶æª¢æŸ¥åˆ†æ•¸
        if required_checks:
            required_score = sum(check.score for check in required_checks) / len(required_checks)
            required_passed = sum(1 for check in required_checks if check.passed)
            required_pass_rate = (required_passed / len(required_checks)) * 100
        else:
            required_score = 0.0
            required_pass_rate = 0.0
        
        # è¨ˆç®—å¯é¸æª¢æŸ¥åˆ†æ•¸
        if optional_checks:
            optional_score = sum(check.score for check in optional_checks) / len(optional_checks)
        else:
            optional_score = 100.0  # å¦‚æœæ²’æœ‰å¯é¸æª¢æŸ¥ï¼Œä¸å½±éŸ¿åˆ†æ•¸
        
        # åŠ æ¬Šç¸½åˆ† (å¼·åˆ¶æª¢æŸ¥ä½” 85%ï¼Œå¯é¸æª¢æŸ¥ä½” 15%)
        overall_score = required_score * 0.85 + optional_score * 0.15
        
        # ç¢ºå®šå°±ç·’ç­‰ç´š
        if required_pass_rate == 100.0 and overall_score >= 95.0:
            readiness_level = ReadinessLevel.PRODUCTION_READY
        elif required_pass_rate >= 90.0 and overall_score >= 85.0:
            readiness_level = ReadinessLevel.STAGING_READY
        elif required_pass_rate >= 70.0 and overall_score >= 70.0:
            readiness_level = ReadinessLevel.DEVELOPMENT_ONLY
        else:
            readiness_level = ReadinessLevel.NOT_READY
        
        # è­˜åˆ¥é—œéµå•é¡Œ
        critical_issues = []
        for check in required_checks:
            if not check.passed and check.required_for_production:
                critical_issues.append(f"{check.check_name}: {check.description}")
        
        return {
            "readiness_level": readiness_level.value,
            "overall_score": overall_score,
            "required_score": required_score,
            "optional_score": optional_score,
            "required_pass_rate": required_pass_rate,
            "required_checks_total": len(required_checks),
            "required_checks_passed": required_passed if required_checks else 0,
            "optional_checks_total": len(optional_checks),
            "critical_issues": critical_issues,
            "production_ready": readiness_level == ReadinessLevel.PRODUCTION_READY
        }
    
    def _generate_category_summaries(self) -> Dict[str, Any]:
        """ç”Ÿæˆé¡åˆ¥æ‘˜è¦"""
        summaries = {}
        
        for category in CheckCategory:
            category_checks = [check for check in self.check_results 
                             if check.category == category]
            
            if category_checks:
                passed_checks = sum(1 for check in category_checks if check.passed)
                avg_score = sum(check.score for check in category_checks) / len(category_checks)
                
                summaries[category.value] = {
                    "total_checks": len(category_checks),
                    "passed_checks": passed_checks,
                    "pass_rate": (passed_checks / len(category_checks)) * 100,
                    "average_score": avg_score,
                    "status": "PASS" if passed_checks == len(category_checks) else "FAIL"
                }
            else:
                summaries[category.value] = {
                    "total_checks": 0,
                    "passed_checks": 0,
                    "pass_rate": 0.0,
                    "average_score": 0.0,
                    "status": "NOT_TESTED"
                }
        
        return summaries
    
    def _generate_deployment_recommendation(self, overall_readiness: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆéƒ¨ç½²å»ºè­°"""
        readiness_level = ReadinessLevel(overall_readiness["readiness_level"])
        
        if readiness_level == ReadinessLevel.PRODUCTION_READY:
            return {
                "recommendation": "DEPLOY_TO_PRODUCTION",
                "confidence": "HIGH",
                "message": "ç³»çµ±å·²å®Œå…¨æº–å‚™å¥½é€²è¡Œç”Ÿç”¢éƒ¨ç½²",
                "next_steps": [
                    "åŸ·è¡Œæœ€çµ‚å‚™ä»½",
                    "é€šçŸ¥ç›¸é—œåœ˜éšŠ",
                    "åŸ·è¡Œéƒ¨ç½²",
                    "ç›£æ§ç³»çµ±ç‹€æ…‹"
                ]
            }
        elif readiness_level == ReadinessLevel.STAGING_READY:
            return {
                "recommendation": "DEPLOY_TO_STAGING",
                "confidence": "MEDIUM",
                "message": "ç³»çµ±é©åˆéƒ¨ç½²åˆ°æ¸¬è©¦ç’°å¢ƒï¼Œéœ€è¦ä¿®å¾©å°‘é‡å•é¡Œå¾Œå†è€ƒæ…®ç”Ÿç”¢éƒ¨ç½²",
                "next_steps": [
                    "ä¿®å¾©å‰©é¤˜çš„é—œéµå•é¡Œ",
                    "åœ¨æ¸¬è©¦ç’°å¢ƒé€²è¡Œå…¨é¢æ¸¬è©¦",
                    "é‡æ–°åŸ·è¡Œå°±ç·’æª¢æŸ¥",
                    "æº–å‚™ç”Ÿç”¢éƒ¨ç½²"
                ]
            }
        elif readiness_level == ReadinessLevel.DEVELOPMENT_ONLY:
            return {
                "recommendation": "CONTINUE_DEVELOPMENT",
                "confidence": "LOW",
                "message": "ç³»çµ±ä»éœ€è¦é‡å¤§æ”¹é€²æ‰èƒ½è€ƒæ…®éƒ¨ç½²",
                "next_steps": [
                    "ä¿®å¾©æ‰€æœ‰é—œéµå•é¡Œ",
                    "æå‡ç³»çµ±å¯é æ€§",
                    "å®Œå–„ç›£æ§å’Œæ–‡æª”",
                    "é‡æ–°é€²è¡Œå…¨é¢æª¢æŸ¥"
                ]
            }
        else:
            return {
                "recommendation": "BLOCK_DEPLOYMENT",
                "confidence": "HIGH",
                "message": "ç³»çµ±æœªæº–å‚™å¥½ä»»ä½•å½¢å¼çš„éƒ¨ç½²ï¼Œéœ€è¦é‡å¤§ä¿®å¾©",
                "next_steps": [
                    "ç«‹å³åœæ­¢éƒ¨ç½²è¨ˆåŠƒ",
                    "ä¿®å¾©æ‰€æœ‰é—œéµå®‰å…¨å’ŒåŠŸèƒ½å•é¡Œ",
                    "é‡æ–°è¨­è¨ˆä¸åˆæ ¼çš„çµ„ä»¶",
                    "å¾åŸºç¤é‡æ–°é©—è­‰ç³»çµ±"
                ]
            }
    
    def _generate_action_items(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆè¡Œå‹•é …ç›®"""
        action_items = []
        
        # æ”¶é›†æ‰€æœ‰å»ºè­°
        for check in self.check_results:
            if not check.passed and check.recommendations:
                for recommendation in check.recommendations:
                    action_items.append({
                        "category": check.category.value,
                        "check_name": check.check_name,
                        "priority": "HIGH" if check.required_for_production else "MEDIUM",
                        "action": recommendation,
                        "impact": "BLOCKS_PRODUCTION" if check.required_for_production else "IMPROVEMENT"
                    })
        
        # æŒ‰å„ªå…ˆç´šæ’åº
        action_items.sort(key=lambda x: (x["priority"] == "HIGH", x["impact"] == "BLOCKS_PRODUCTION"), reverse=True)
        
        return action_items
    
    def _check_to_dict(self, check: ReadinessCheck) -> Dict[str, Any]:
        """å°‡æª¢æŸ¥çµæœè½‰æ›ç‚ºå­—å…¸"""
        return {
            "category": check.category.value,
            "check_name": check.check_name,
            "description": check.description,
            "required_for_production": check.required_for_production,
            "passed": check.passed,
            "score": check.score,
            "details": check.details,
            "recommendations": check.recommendations
        }
    
    def save_readiness_report(self, report: Dict[str, Any], output_path: str):
        """ä¿å­˜å°±ç·’åº¦å ±å‘Š"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            logger.info(f"ğŸ“„ å°±ç·’åº¦å ±å‘Šå·²ä¿å­˜è‡³: {output_path}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å°±ç·’åº¦å ±å‘Šå¤±æ•—: {e}")


async def main():
    """ä¸»ç¨‹åº - é‹è¡Œç”Ÿç”¢å°±ç·’æª¢æŸ¥"""
    print("ğŸ” LEO è¡›æ˜Ÿæ›æ‰‹ç³»çµ± - ç”Ÿç”¢å°±ç·’åº¦æª¢æŸ¥å™¨")
    print("=" * 60)
    
    # åˆå§‹åŒ–æª¢æŸ¥å™¨
    checker = ProductionReadinessChecker()
    
    # åŸ·è¡Œå®Œæ•´æª¢æŸ¥
    report = await checker.run_comprehensive_readiness_check()
    
    # é¡¯ç¤ºçµæœæ‘˜è¦
    if "overall_readiness" in report:
        overall = report["overall_readiness"]
        
        print(f"\nğŸ“Š ç”Ÿç”¢å°±ç·’åº¦æª¢æŸ¥çµæœ:")
        print(f"å°±ç·’ç­‰ç´š: {overall['readiness_level'].upper()}")
        print(f"ç¸½é«”åˆ†æ•¸: {overall['overall_score']:.1f}%")
        print(f"å¼·åˆ¶æª¢æŸ¥é€šéç‡: {overall['required_pass_rate']:.1f}%")
        print(f"ç”Ÿç”¢å°±ç·’: {'âœ… æ˜¯' if overall['production_ready'] else 'âŒ å¦'}")
        
        print(f"\nğŸ“‹ é¡åˆ¥æ‘˜è¦:")
        for category, summary in report["category_summaries"].items():
            status_icon = "âœ…" if summary["status"] == "PASS" else "âŒ"
            print(f"  {status_icon} {category}: {summary['pass_rate']:.1f}% ({summary['passed_checks']}/{summary['total_checks']})")
        
        print(f"\nğŸ¯ éƒ¨ç½²å»ºè­°:")
        deployment = report["production_deployment_recommendation"]
        print(f"  å»ºè­°: {deployment['recommendation']}")
        print(f"  ä¿¡å¿ƒåº¦: {deployment['confidence']}")
        print(f"  èªªæ˜: {deployment['message']}")
        
        if overall.get("critical_issues"):
            print(f"\nğŸš¨ é—œéµå•é¡Œ:")
            for issue in overall["critical_issues"][:5]:  # é¡¯ç¤ºå‰5å€‹å•é¡Œ
                print(f"  âŒ {issue}")
        
        print(f"\nğŸ’¡ å„ªå…ˆè¡Œå‹•é …ç›®:")
        for item in report["action_items"][:5]:  # é¡¯ç¤ºå‰5å€‹è¡Œå‹•é …ç›®
            priority_icon = "ğŸ”¥" if item["priority"] == "HIGH" else "âš ï¸"
            print(f"  {priority_icon} [{item['category']}] {item['action']}")
    
    # ä¿å­˜å ±å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = f"/home/sat/ntn-stack/leo-handover-research/design-phase/compliance-audit/production_readiness_report_{timestamp}.json"
    checker.save_readiness_report(report, report_path)
    
    # è¿”å›çµæœ
    return report


if __name__ == "__main__":
    results = asyncio.run(main())