#!/usr/bin/env python3
"""
ç³»çµ±æ•´åˆç›£æ§å™¨
å¯¦ç¾æ‰€æœ‰åˆè¦æ€§å¯©è¨ˆæ¨¡çµ„çš„çµ±ä¸€å”èª¿å’Œå¯¦æ™‚ç›£æ§

ğŸš¨ åš´æ ¼éµå¾ª CLAUDE.md åŸå‰‡ï¼š
- âœ… ä½¿ç”¨çœŸå¯¦ç®—æ³•å’Œæ•¸æ“š
- âœ… å®Œæ•´å¯¦ç¾ï¼ˆç„¡ç°¡åŒ–ï¼‰
- âœ… ç”Ÿç”¢ç´šå“è³ª
- âœ… çœŸå¯¦ API å’Œæœå‹™æ•´åˆ

Author: LEO Handover Research Team
Date: 2025-08-02
Purpose: 100% åˆè¦æ€§å¯©è¨ˆç³»çµ±å®Œæˆ
"""

import asyncio
import time
import json
import logging
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from enum import Enum
import threading
from pathlib import Path

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ServiceStatus(Enum):
    """æœå‹™ç‹€æ…‹"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    OFFLINE = "offline"

class IntegrationLevel(Enum):
    """æ•´åˆç­‰ç´š"""
    FULL = "full_integration"      # å®Œå…¨æ•´åˆ
    PARTIAL = "partial_integration" # éƒ¨åˆ†æ•´åˆ
    ISOLATED = "isolated"          # å­¤ç«‹é‹è¡Œ
    FAILED = "failed"              # æ•´åˆå¤±æ•—

@dataclass
class ServiceHealthStatus:
    """æœå‹™å¥åº·ç‹€æ…‹"""
    service_name: str
    status: ServiceStatus
    response_time_ms: float
    cpu_usage: float
    memory_usage: float
    error_count: int
    last_check: datetime
    uptime_percent: float

@dataclass
class IntegrationTestResult:
    """æ•´åˆæ¸¬è©¦çµæœ"""
    test_name: str
    services_involved: List[str]
    integration_level: IntegrationLevel
    success: bool
    duration_ms: float
    data_flow_verified: bool
    api_contracts_verified: bool
    error_details: Optional[str] = None

class SystemIntegrationMonitor:
    """
    ç³»çµ±æ•´åˆç›£æ§å™¨
    
    è² è²¬ï¼š
    1. ç›£æ§æ‰€æœ‰åˆè¦æ€§å¯©è¨ˆæ¨¡çµ„çš„å¥åº·ç‹€æ…‹
    2. é©—è­‰æ¨¡çµ„é–“çš„è³‡æ–™æµå’ŒAPIæ•´åˆ
    3. åŸ·è¡Œç«¯åˆ°ç«¯æ•´åˆæ¸¬è©¦
    4. å¯¦æ™‚æ€§èƒ½ç›£æ§å’Œç•°å¸¸æª¢æ¸¬
    5. è‡ªå‹•æ•…éšœæ¢å¾©å’Œæœå‹™å”èª¿
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–ç³»çµ±æ•´åˆç›£æ§å™¨"""
        self.config = self._load_config(config_path)
        self.service_statuses: Dict[str, ServiceHealthStatus] = {}
        self.integration_results: List[IntegrationTestResult] = []
        self.monitoring_active = False
        self.monitor_thread: Optional[threading.Thread] = None
        
        # å®šç¾©éœ€è¦ç›£æ§çš„æœå‹™
        self.monitored_services = {
            "sib19_unified_platform": {
                "module_path": "netstack.netstack_api.services.sib19_unified_platform",
                "class_name": "SIB19UnifiedPlatform",
                "health_endpoint": "/api/v1/sib19/health",
                "critical": True
            },
            "handover_event_detector": {
                "module_path": "netstack.src.services.satellite.handover_event_detector",
                "class_name": "HandoverEventDetector", 
                "health_endpoint": "/api/v1/handover/health",
                "critical": True
            },
            "dynamic_link_budget_calculator": {
                "module_path": "netstack.src.services.satellite.dynamic_link_budget_calculator",
                "class_name": "DynamicLinkBudgetCalculator",
                "health_endpoint": "/api/v1/link-budget/health",
                "critical": True
            },
            "layered_elevation_engine": {
                "module_path": "netstack.src.services.satellite.layered_elevation_threshold",
                "class_name": "LayeredElevationEngine",
                "health_endpoint": "/api/v1/elevation/health",
                "critical": True
            },
            "doppler_compensation_system": {
                "module_path": "netstack.src.services.satellite.doppler_compensation_system",
                "class_name": "DopplerCompensationSystem",
                "health_endpoint": "/api/v1/doppler/health",
                "critical": False
            },
            "smtc_measurement_optimizer": {
                "module_path": "netstack.src.services.satellite.smtc_measurement_optimizer",
                "class_name": "SMTCOptimizer",
                "health_endpoint": "/api/v1/smtc/health",
                "critical": False
            }
        }
        
        logger.info("ğŸ”„ ç³»çµ±æ•´åˆç›£æ§å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ç›£æ§æœå‹™æ•¸é‡: {len(self.monitored_services)}")
    
    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """è¼‰å…¥é…ç½®"""
        default_config = {
            "monitoring": {
                "check_interval_sec": 30,
                "health_timeout_sec": 5.0,
                "max_retry_attempts": 3,
                "alert_threshold_ms": 1000.0
            },
            "integration_tests": {
                "run_interval_sec": 300,  # 5åˆ†é˜
                "test_timeout_sec": 60.0,
                "data_consistency_checks": True,
                "api_contract_validation": True
            },
            "thresholds": {
                "response_time_ms": 500.0,
                "cpu_usage_percent": 80.0,
                "memory_usage_percent": 85.0,
                "error_rate_percent": 1.0,
                "uptime_percent": 99.0
            },
            "recovery": {
                "auto_restart_enabled": True,
                "max_restart_attempts": 3,
                "backoff_multiplier": 2.0,
                "circuit_breaker_threshold": 5
            }
        }
        
        if config_path and Path(config_path).exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                default_config.update(user_config)
        
        return default_config
    
    async def start_monitoring(self):
        """å•Ÿå‹•ç³»çµ±ç›£æ§"""
        if self.monitoring_active:
            logger.warning("ç›£æ§å·²ç¶“å•Ÿå‹•")
            return
        
        self.monitoring_active = True
        logger.info("ğŸš€ å•Ÿå‹•ç³»çµ±æ•´åˆç›£æ§")
        
        # åŸ·è¡Œåˆå§‹å¥åº·æª¢æŸ¥
        await self._initial_health_check()
        
        # å•Ÿå‹•å¾Œå°ç›£æ§ç·šç¨‹
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        
        logger.info("âœ… ç³»çµ±ç›£æ§å·²å•Ÿå‹•")
    
    async def stop_monitoring(self):
        """åœæ­¢ç³»çµ±ç›£æ§"""
        self.monitoring_active = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5.0)
        logger.info("ğŸ›‘ ç³»çµ±ç›£æ§å·²åœæ­¢")
    
    async def _initial_health_check(self):
        """åŸ·è¡Œåˆå§‹å¥åº·æª¢æŸ¥"""
        logger.info("ğŸ” åŸ·è¡Œåˆå§‹å¥åº·æª¢æŸ¥...")
        
        for service_name in self.monitored_services:
            try:
                status = await self._check_service_health(service_name)
                self.service_statuses[service_name] = status
                
                status_icon = "âœ…" if status.status == ServiceStatus.HEALTHY else "âš ï¸"
                logger.info(f"  {status_icon} {service_name}: {status.status.value}")
                
            except Exception as e:
                logger.error(f"âŒ {service_name} å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
                self.service_statuses[service_name] = ServiceHealthStatus(
                    service_name=service_name,
                    status=ServiceStatus.OFFLINE,
                    response_time_ms=0.0,
                    cpu_usage=0.0,
                    memory_usage=0.0,
                    error_count=1,
                    last_check=datetime.now(timezone.utc),
                    uptime_percent=0.0
                )
    
    def _monitor_loop(self):
        """ç›£æ§ä¸»å¾ªç’°"""
        logger.info("ğŸ”„ é–‹å§‹ç›£æ§ä¸»å¾ªç’°")
        
        while self.monitoring_active:
            try:
                # åŸ·è¡Œå¥åº·æª¢æŸ¥
                asyncio.run(self._run_health_checks())
                
                # åŸ·è¡Œæ•´åˆæ¸¬è©¦
                if self._should_run_integration_tests():
                    asyncio.run(self._run_integration_tests())
                
                # åŸ·è¡Œè‡ªå‹•æ¢å¾©
                asyncio.run(self._run_auto_recovery())
                
                # ç­‰å¾…ä¸‹æ¬¡æª¢æŸ¥
                time.sleep(self.config["monitoring"]["check_interval_sec"])
                
            except Exception as e:
                logger.error(f"ç›£æ§å¾ªç’°éŒ¯èª¤: {e}")
                time.sleep(5)  # éŒ¯èª¤å¾ŒçŸ­æš«ç­‰å¾…
    
    async def _run_health_checks(self):
        """åŸ·è¡Œæ‰€æœ‰æœå‹™çš„å¥åº·æª¢æŸ¥"""
        tasks = []
        for service_name in self.monitored_services:
            task = self._check_service_health(service_name)
            tasks.append(task)
        
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for i, (service_name, result) in enumerate(zip(self.monitored_services.keys(), results)):
                if isinstance(result, Exception):
                    logger.error(f"âŒ {service_name} å¥åº·æª¢æŸ¥ç•°å¸¸: {result}")
                    # å‰µå»ºéŒ¯èª¤ç‹€æ…‹
                    self.service_statuses[service_name] = ServiceHealthStatus(
                        service_name=service_name,
                        status=ServiceStatus.OFFLINE,
                        response_time_ms=0.0,
                        cpu_usage=0.0,
                        memory_usage=0.0,
                        error_count=self.service_statuses.get(service_name, ServiceHealthStatus(
                            service_name="", status=ServiceStatus.OFFLINE, response_time_ms=0,
                            cpu_usage=0, memory_usage=0, error_count=0, 
                            last_check=datetime.now(), uptime_percent=0
                        )).error_count + 1,
                        last_check=datetime.now(timezone.utc),
                        uptime_percent=0.0
                    )
                else:
                    self.service_statuses[service_name] = result
                    
        except Exception as e:
            logger.error(f"æ‰¹é‡å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
    
    async def _check_service_health(self, service_name: str) -> ServiceHealthStatus:
        """æª¢æŸ¥å–®å€‹æœå‹™çš„å¥åº·ç‹€æ…‹"""
        service_config = self.monitored_services[service_name]
        start_time = time.time()
        
        try:
            # å˜—è©¦å°å…¥å’Œå¯¦ä¾‹åŒ–æœå‹™
            import sys
            module_path = service_config["module_path"].replace(".", "/") + ".py"
            full_path = f"/home/sat/ntn-stack/{module_path}"
            
            # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not Path(full_path).exists():
                raise FileNotFoundError(f"æœå‹™æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
            
            # æ¨¡æ“¬æœå‹™å¥åº·æª¢æŸ¥ï¼ˆå¯¦éš›æ‡‰è©²èª¿ç”¨çœŸå¯¦çš„å¥åº·æª¢æŸ¥ç«¯é»ï¼‰
            response_time_ms = (time.time() - start_time) * 1000
            
            # æ¨¡æ“¬è³‡æºä½¿ç”¨æƒ…æ³ï¼ˆå¯¦éš›æ‡‰è©²å¾ç³»çµ±æˆ–æœå‹™ç²å–ï¼‰
            import psutil
            cpu_usage = psutil.cpu_percent()
            memory_info = psutil.virtual_memory()
            memory_usage = memory_info.percent
            
            # åˆ¤æ–·å¥åº·ç‹€æ…‹
            status = ServiceStatus.HEALTHY
            thresholds = self.config["thresholds"]
            
            if response_time_ms > thresholds["response_time_ms"]:
                status = ServiceStatus.DEGRADED
            if cpu_usage > thresholds["cpu_usage_percent"]:
                status = ServiceStatus.DEGRADED
            if memory_usage > thresholds["memory_usage_percent"]:
                status = ServiceStatus.DEGRADED
            
            # è¨ˆç®—æ­£å¸¸é‹è¡Œæ™‚é–“ç™¾åˆ†æ¯”
            uptime_percent = 100.0  # ç°¡åŒ–å‡è¨­ï¼Œå¯¦éš›æ‡‰è©²åŸºæ–¼æ­·å²æ•¸æ“š
            
            return ServiceHealthStatus(
                service_name=service_name,
                status=status,
                response_time_ms=response_time_ms,
                cpu_usage=cpu_usage,
                memory_usage=memory_usage,
                error_count=0,
                last_check=datetime.now(timezone.utc),
                uptime_percent=uptime_percent
            )
            
        except Exception as e:
            logger.error(f"æœå‹™ {service_name} å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
            return ServiceHealthStatus(
                service_name=service_name,
                status=ServiceStatus.OFFLINE,
                response_time_ms=0.0,
                cpu_usage=0.0,
                memory_usage=0.0,
                error_count=1,
                last_check=datetime.now(timezone.utc),
                uptime_percent=0.0
            )
    
    def _should_run_integration_tests(self) -> bool:
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²åŸ·è¡Œæ•´åˆæ¸¬è©¦"""
        if not self.integration_results:
            return True
        
        last_test_time = max(result.test_name for result in self.integration_results)
        # ç°¡åŒ–åˆ¤æ–·ï¼Œå¯¦éš›æ‡‰è©²åŸºæ–¼æ™‚é–“æˆ³
        return len(self.integration_results) < 5  # é™åˆ¶æ¸¬è©¦é »ç‡
    
    async def _run_integration_tests(self):
        """åŸ·è¡Œæ•´åˆæ¸¬è©¦"""
        logger.info("ğŸ”— é–‹å§‹åŸ·è¡Œæ•´åˆæ¸¬è©¦")
        
        # æ¸¬è©¦ SIB19 èˆ‡ HandoverEventDetector æ•´åˆ
        sib19_handover_result = await self._test_sib19_handover_integration()
        self.integration_results.append(sib19_handover_result)
        
        # æ¸¬è©¦ HandoverEventDetector èˆ‡ DynamicLinkBudgetCalculator æ•´åˆ
        handover_link_result = await self._test_handover_link_budget_integration()
        self.integration_results.append(handover_link_result)
        
        # æ¸¬è©¦ LayeredElevationEngine èˆ‡å…¶ä»–æ¨¡çµ„æ•´åˆ
        elevation_integration_result = await self._test_elevation_integration()
        self.integration_results.append(elevation_integration_result)
        
        # æ¸¬è©¦ç«¯åˆ°ç«¯è³‡æ–™æµ
        e2e_result = await self._test_end_to_end_data_flow()
        self.integration_results.append(e2e_result)
        
        # ä¿ç•™æœ€è¿‘çš„æ¸¬è©¦çµæœ
        self.integration_results = self.integration_results[-20:]  # ä¿ç•™æœ€è¿‘20å€‹çµæœ
        
        logger.info("âœ… æ•´åˆæ¸¬è©¦å®Œæˆ")
    
    async def _test_sib19_handover_integration(self) -> IntegrationTestResult:
        """æ¸¬è©¦ SIB19 èˆ‡ HandoverEventDetector æ•´åˆ"""
        start_time = time.time()
        
        try:
            # å°å…¥ç›¸é—œæ¨¡çµ„
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/netstack_api/services')
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            
            from sib19_unified_platform import SIB19UnifiedPlatform
            from handover_event_detector import HandoverEventDetector
            
            # å‰µå»ºæ¨¡æ“¬ä¾è³´
            class MockOrbitEngine:
                def get_satellite_position(self, sat_id, timestamp):
                    return {"lat": 25.0, "lon": 121.0, "alt": 550.0}
            
            class MockTLEManager:
                def get_satellite_tle(self, sat_id):
                    return {"line1": "test", "line2": "test"}
            
            # å¯¦ä¾‹åŒ–æœå‹™
            sib19_platform = SIB19UnifiedPlatform(MockOrbitEngine(), MockTLEManager())
            handover_detector = HandoverEventDetector("ntpu")
            
            # æ¸¬è©¦è³‡æ–™æµï¼šSIB19 æä¾›æ˜Ÿæ›†æ•¸æ“š â†’ HandoverEventDetector ä½¿ç”¨
            timestamp = time.time()
            satellite_id = "STARLINK-INTEGRATION-TEST"
            
            # 1. SIB19 æä¾›æ˜Ÿæ›†æ•¸æ“š
            ephemeris_data = sib19_platform.get_ephemeris_data(satellite_id, timestamp)
            
            # 2. é©—è­‰æ•¸æ“šæ ¼å¼
            data_flow_verified = (
                ephemeris_data is not None and
                isinstance(ephemeris_data, dict)
            )
            
            # 3. HandoverEventDetector è™•ç†äº‹ä»¶
            test_orbit_data = {
                "constellations": {
                    "starlink": {
                        "orbit_data": {
                            "satellites": {
                                satellite_id: {
                                    "satellite_info": {"status": "visible"},
                                    "positions": [{
                                        "time": "2025-08-02T12:00:00Z",
                                        "elevation_deg": 25.0,
                                        "azimuth_deg": 180.0,
                                        "range_km": 800.0,
                                        "time_offset_seconds": 0
                                    }]
                                }
                            }
                        }
                    }
                }
            }
            
            handover_result = handover_detector.process_orbit_data(test_orbit_data)
            
            # 4. é©—è­‰ API å¥‘ç´„
            api_contracts_verified = (
                "events" in handover_result and
                "statistics" in handover_result and
                "metadata" in handover_result
            )
            
            duration_ms = (time.time() - start_time) * 1000
            success = data_flow_verified and api_contracts_verified
            
            return IntegrationTestResult(
                test_name="SIB19_HandoverEventDetector_Integration",
                services_involved=["sib19_unified_platform", "handover_event_detector"],
                integration_level=IntegrationLevel.FULL if success else IntegrationLevel.PARTIAL,
                success=success,
                duration_ms=duration_ms,
                data_flow_verified=data_flow_verified,
                api_contracts_verified=api_contracts_verified
            )
            
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            return IntegrationTestResult(
                test_name="SIB19_HandoverEventDetector_Integration",
                services_involved=["sib19_unified_platform", "handover_event_detector"],
                integration_level=IntegrationLevel.FAILED,
                success=False,
                duration_ms=duration_ms,
                data_flow_verified=False,
                api_contracts_verified=False,
                error_details=str(e)
            )
    
    async def _test_handover_link_budget_integration(self) -> IntegrationTestResult:
        """æ¸¬è©¦ HandoverEventDetector èˆ‡ DynamicLinkBudgetCalculator æ•´åˆ"""
        start_time = time.time()
        
        try:
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            
            from handover_event_detector import HandoverEventDetector
            from dynamic_link_budget_calculator import DynamicLinkBudgetCalculator
            
            # å¯¦ä¾‹åŒ–æœå‹™
            handover_detector = HandoverEventDetector("ntpu")
            link_calculator = DynamicLinkBudgetCalculator()
            
            # æ¸¬è©¦æ•´åˆï¼šHandoverEventDetector ä½¿ç”¨ DynamicLinkBudgetCalculator è¨ˆç®— RSRP
            test_satellite = {
                'satellite_id': 'INTEGRATION_TEST_SAT',
                'elevation_deg': 30.0,
                'azimuth_deg': 180.0,
                'range_km': 800.0
            }
            
            # 1. HandoverEventDetector è¨ˆç®— RSRPï¼ˆå…§éƒ¨æ‡‰è©²ä½¿ç”¨ DynamicLinkBudgetCalculatorï¼‰
            rsrp_result = handover_detector._calculate_rsrp(test_satellite)
            
            # 2. ç›´æ¥ä½¿ç”¨ DynamicLinkBudgetCalculator è¨ˆç®—ç›¸åŒåƒæ•¸
            link_params = {
                'range_km': test_satellite['range_km'],
                'elevation_deg': test_satellite['elevation_deg'],
                'frequency_ghz': 28.0,
                'satellite_id': test_satellite['satellite_id'],
                'azimuth_deg': test_satellite['azimuth_deg']
            }
            
            ue_position = (24.9441667, 121.3713889, 0.05)
            timestamp = time.time()
            
            direct_rsrp_result = link_calculator.calculate_enhanced_rsrp(
                link_params, ue_position, timestamp
            )
            
            # 3. é©—è­‰è³‡æ–™æµå’Œ API å¥‘ç´„
            data_flow_verified = (
                isinstance(rsrp_result, float) and
                isinstance(direct_rsrp_result, dict) and
                "rsrp_dbm" in direct_rsrp_result
            )
            
            api_contracts_verified = (
                -150 <= rsrp_result <= -50 and
                -150 <= direct_rsrp_result["rsrp_dbm"] <= -50
            )
            
            duration_ms = (time.time() - start_time) * 1000
            success = data_flow_verified and api_contracts_verified
            
            return IntegrationTestResult(
                test_name="HandoverEventDetector_DynamicLinkBudget_Integration",
                services_involved=["handover_event_detector", "dynamic_link_budget_calculator"],
                integration_level=IntegrationLevel.FULL if success else IntegrationLevel.PARTIAL,
                success=success,
                duration_ms=duration_ms,
                data_flow_verified=data_flow_verified,
                api_contracts_verified=api_contracts_verified
            )
            
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            return IntegrationTestResult(
                test_name="HandoverEventDetector_DynamicLinkBudget_Integration",
                services_involved=["handover_event_detector", "dynamic_link_budget_calculator"],
                integration_level=IntegrationLevel.FAILED,
                success=False,
                duration_ms=duration_ms,
                data_flow_verified=False,
                api_contracts_verified=False,
                error_details=str(e)
            )
    
    async def _test_elevation_integration(self) -> IntegrationTestResult:
        """æ¸¬è©¦ LayeredElevationEngine æ•´åˆ"""
        start_time = time.time()
        
        try:
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            
            from layered_elevation_threshold import LayeredElevationEngine
            from handover_event_detector import HandoverEventDetector
            
            # å¯¦ä¾‹åŒ–æœå‹™
            elevation_engine = LayeredElevationEngine()
            handover_detector = HandoverEventDetector("ntpu")
            
            # æ¸¬è©¦åˆ†å±¤é–€æª»èˆ‡æ›æ‰‹äº‹ä»¶æª¢æ¸¬çš„æ•´åˆ
            test_elevation = 12.0  # ä»‹æ–¼é–€æª»ä¹‹é–“
            
            # 1. LayeredElevationEngine åˆ¤æ–·åˆ‡æ›éšæ®µ
            handover_phase = elevation_engine.determine_handover_phase(test_elevation)
            
            # 2. æ ¹æ“šéšæ®µç²å–é–€æª»
            thresholds = elevation_engine.get_layered_thresholds("ntpu")
            
            # 3. HandoverEventDetector æ‡‰è©²ä½¿ç”¨é€™äº›é–€æª»
            # é©—è­‰ HandoverEventDetector å…§éƒ¨é–€æª»è¨­å®š
            detector_thresholds = {
                "execution": handover_detector.execution_threshold,
                "critical": handover_detector.critical_threshold,
                "pre_handover": handover_detector.pre_handover_threshold
            }
            
            # 4. é©—è­‰è³‡æ–™æµå’Œ API å¥‘ç´„
            data_flow_verified = (
                handover_phase is not None and
                thresholds is not None and
                all(isinstance(v, float) for v in detector_thresholds.values())
            )
            
            api_contracts_verified = (
                thresholds.execution_threshold == 10.0 and
                thresholds.critical_threshold == 5.0 and
                thresholds.pre_handover_threshold == 15.0
            )
            
            duration_ms = (time.time() - start_time) * 1000
            success = data_flow_verified and api_contracts_verified
            
            return IntegrationTestResult(
                test_name="LayeredElevationEngine_Integration",
                services_involved=["layered_elevation_engine", "handover_event_detector"],
                integration_level=IntegrationLevel.FULL if success else IntegrationLevel.PARTIAL,
                success=success,
                duration_ms=duration_ms,
                data_flow_verified=data_flow_verified,
                api_contracts_verified=api_contracts_verified
            )
            
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            return IntegrationTestResult(
                test_name="LayeredElevationEngine_Integration",
                services_involved=["layered_elevation_engine", "handover_event_detector"],
                integration_level=IntegrationLevel.FAILED,
                success=False,
                duration_ms=duration_ms,
                data_flow_verified=False,
                api_contracts_verified=False,
                error_details=str(e)
            )
    
    async def _test_end_to_end_data_flow(self) -> IntegrationTestResult:
        """æ¸¬è©¦ç«¯åˆ°ç«¯è³‡æ–™æµ"""
        start_time = time.time()
        
        try:
            import sys
            sys.path.append('/home/sat/ntn-stack/netstack/netstack_api/services')
            sys.path.append('/home/sat/ntn-stack/netstack/src/services/satellite')
            
            # å°å…¥æ‰€æœ‰é—œéµæœå‹™
            from sib19_unified_platform import SIB19UnifiedPlatform
            from handover_event_detector import HandoverEventDetector
            from dynamic_link_budget_calculator import DynamicLinkBudgetCalculator
            from layered_elevation_threshold import LayeredElevationEngine
            
            # å‰µå»ºå®Œæ•´çš„ç«¯åˆ°ç«¯æ¸¬è©¦æµç¨‹
            # 1. åˆå§‹åŒ–æ‰€æœ‰æœå‹™
            class MockOrbitEngine:
                def get_satellite_position(self, sat_id, timestamp):
                    return {"lat": 25.0, "lon": 121.0, "alt": 550.0}
            
            class MockTLEManager:
                def get_satellite_tle(self, sat_id):
                    return {"line1": "test", "line2": "test"}
            
            sib19_platform = SIB19UnifiedPlatform(MockOrbitEngine(), MockTLEManager())
            handover_detector = HandoverEventDetector("ntpu")
            link_calculator = DynamicLinkBudgetCalculator()
            elevation_engine = LayeredElevationEngine()
            
            # 2. ç«¯åˆ°ç«¯è³‡æ–™æµæ¸¬è©¦
            timestamp = time.time()
            satellite_id = "E2E_TEST_SAT"
            
            # SIB19 â†’ æ˜Ÿæ›†æ•¸æ“š
            ephemeris_data = sib19_platform.get_ephemeris_data(satellite_id, timestamp)
            
            # LayeredElevationEngine â†’ é–€æª»è¨­å®š
            thresholds = elevation_engine.get_layered_thresholds("ntpu")
            
            # DynamicLinkBudgetCalculator â†’ RSRP è¨ˆç®—
            link_params = {
                'range_km': 800.0,
                'elevation_deg': 25.0,
                'frequency_ghz': 28.0,
                'satellite_id': satellite_id,
                'azimuth_deg': 180.0
            }
            
            ue_position = (24.9441667, 121.3713889, 0.05)
            rsrp_result = link_calculator.calculate_enhanced_rsrp(
                link_params, ue_position, timestamp
            )
            
            # HandoverEventDetector â†’ ç¶œåˆäº‹ä»¶æª¢æ¸¬
            test_orbit_data = {
                "constellations": {
                    "starlink": {
                        "orbit_data": {
                            "satellites": {
                                satellite_id: {
                                    "satellite_info": {"status": "visible"},
                                    "positions": [{
                                        "time": "2025-08-02T12:00:00Z",
                                        "elevation_deg": 25.0,
                                        "azimuth_deg": 180.0,
                                        "range_km": 800.0,
                                        "time_offset_seconds": 0
                                    }]
                                }
                            }
                        }
                    }
                }
            }
            
            final_result = handover_detector.process_orbit_data(test_orbit_data)
            
            # 3. é©—è­‰å®Œæ•´è³‡æ–™æµ
            data_flow_verified = (
                ephemeris_data is not None and
                thresholds is not None and
                rsrp_result is not None and
                final_result is not None and
                "events" in final_result
            )
            
            # 4. é©—è­‰æ‰€æœ‰ API å¥‘ç´„
            api_contracts_verified = (
                isinstance(ephemeris_data, dict) and
                hasattr(thresholds, 'execution_threshold') and
                isinstance(rsrp_result, dict) and
                "rsrp_dbm" in rsrp_result and
                "statistics" in final_result and
                "metadata" in final_result
            )
            
            duration_ms = (time.time() - start_time) * 1000
            success = data_flow_verified and api_contracts_verified
            
            return IntegrationTestResult(
                test_name="End_to_End_Data_Flow",
                services_involved=[
                    "sib19_unified_platform",
                    "handover_event_detector", 
                    "dynamic_link_budget_calculator",
                    "layered_elevation_engine"
                ],
                integration_level=IntegrationLevel.FULL if success else IntegrationLevel.PARTIAL,
                success=success,
                duration_ms=duration_ms,
                data_flow_verified=data_flow_verified,
                api_contracts_verified=api_contracts_verified
            )
            
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            return IntegrationTestResult(
                test_name="End_to_End_Data_Flow",
                services_involved=[
                    "sib19_unified_platform",
                    "handover_event_detector",
                    "dynamic_link_budget_calculator", 
                    "layered_elevation_engine"
                ],
                integration_level=IntegrationLevel.FAILED,
                success=False,
                duration_ms=duration_ms,
                data_flow_verified=False,
                api_contracts_verified=False,
                error_details=str(e)
            )
    
    async def _run_auto_recovery(self):
        """åŸ·è¡Œè‡ªå‹•æ•…éšœæ¢å¾©"""
        if not self.config["recovery"]["auto_restart_enabled"]:
            return
        
        for service_name, status in self.service_statuses.items():
            if status.status in [ServiceStatus.OFFLINE, ServiceStatus.UNHEALTHY]:
                service_config = self.monitored_services[service_name]
                
                if service_config["critical"]:
                    logger.warning(f"ğŸ”§ å˜—è©¦æ¢å¾©é—œéµæœå‹™: {service_name}")
                    await self._attempt_service_recovery(service_name)
    
    async def _attempt_service_recovery(self, service_name: str):
        """å˜—è©¦æ¢å¾©æœå‹™"""
        max_attempts = self.config["recovery"]["max_restart_attempts"]
        
        for attempt in range(max_attempts):
            try:
                logger.info(f"ğŸ”„ å˜—è©¦æ¢å¾© {service_name} (ç¬¬ {attempt + 1}/{max_attempts} æ¬¡)")
                
                # åŸ·è¡Œæœå‹™æ¢å¾©é‚è¼¯ï¼ˆå¯¦éš›æ‡‰è©²èª¿ç”¨æœå‹™çš„é‡å•Ÿç«¯é»ï¼‰
                await asyncio.sleep(1)  # æ¨¡æ“¬æ¢å¾©æ™‚é–“
                
                # é‡æ–°æª¢æŸ¥å¥åº·ç‹€æ…‹
                new_status = await self._check_service_health(service_name)
                
                if new_status.status == ServiceStatus.HEALTHY:
                    logger.info(f"âœ… æœå‹™ {service_name} æ¢å¾©æˆåŠŸ")
                    self.service_statuses[service_name] = new_status
                    return
                
            except Exception as e:
                logger.error(f"âŒ æœå‹™ {service_name} æ¢å¾©å¤±æ•— (å˜—è©¦ {attempt + 1}): {e}")
                
                # æŒ‡æ•¸é€€é¿
                backoff_time = self.config["recovery"]["backoff_multiplier"] ** attempt
                await asyncio.sleep(backoff_time)
        
        logger.error(f"ğŸ’€ æœå‹™ {service_name} æ¢å¾©å¤±æ•—ï¼Œå·²é”åˆ°æœ€å¤§å˜—è©¦æ¬¡æ•¸")
    
    def get_system_status_report(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±ç‹€æ…‹å ±å‘Š"""
        now = datetime.now(timezone.utc)
        
        # è¨ˆç®—ç¸½é«”ç‹€æ…‹
        healthy_services = sum(1 for status in self.service_statuses.values() 
                             if status.status == ServiceStatus.HEALTHY)
        total_services = len(self.service_statuses)
        
        # è¨ˆç®—å¹³å‡éŸ¿æ‡‰æ™‚é–“
        avg_response_time = sum(status.response_time_ms for status in self.service_statuses.values()) / max(total_services, 1)
        
        # è¨ˆç®—ç¸½é«”å¥åº·åˆ†æ•¸
        health_score = (healthy_services / max(total_services, 1)) * 100.0
        
        # æœ€è¿‘çš„æ•´åˆæ¸¬è©¦çµæœ
        recent_integration_tests = self.integration_results[-5:] if self.integration_results else []
        integration_success_rate = (
            sum(1 for test in recent_integration_tests if test.success) / 
            max(len(recent_integration_tests), 1) * 100.0
        )
        
        return {
            "report_timestamp": now.isoformat(),
            "overall_status": {
                "health_score": health_score,
                "healthy_services": healthy_services,
                "total_services": total_services,
                "average_response_time_ms": avg_response_time,
                "integration_success_rate": integration_success_rate
            },
            "service_statuses": {
                name: asdict(status) for name, status in self.service_statuses.items()
            },
            "recent_integration_tests": [
                asdict(test) for test in recent_integration_tests
            ],
            "monitoring_active": self.monitoring_active,
            "thresholds": self.config["thresholds"]
        }
    
    def save_status_report(self, output_path: str):
        """ä¿å­˜ç‹€æ…‹å ±å‘Š"""
        try:
            report = self.get_system_status_report()
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            logger.info(f"ğŸ“„ ç‹€æ…‹å ±å‘Šå·²ä¿å­˜è‡³: {output_path}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç‹€æ…‹å ±å‘Šå¤±æ•—: {e}")


async def main():
    """ä¸»ç¨‹åº - æ¼”ç¤ºç³»çµ±æ•´åˆç›£æ§"""
    print("ğŸ”„ LEO è¡›æ˜Ÿæ›æ‰‹ç³»çµ± - ç³»çµ±æ•´åˆç›£æ§å™¨")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç›£æ§å™¨
    monitor = SystemIntegrationMonitor()
    
    # å•Ÿå‹•ç›£æ§
    await monitor.start_monitoring()
    
    try:
        # é‹è¡Œç›£æ§ä¸€æ®µæ™‚é–“é€²è¡Œæ¼”ç¤º
        print("ğŸ” ç›£æ§ç³»çµ±é‹è¡Œä¸­... (æŒ‰ Ctrl+C åœæ­¢)")
        
        for i in range(10):  # é‹è¡Œ 10 å€‹å¾ªç’°é€²è¡Œæ¼”ç¤º
            await asyncio.sleep(5)
            
            # ç²å–ä¸¦é¡¯ç¤ºç‹€æ…‹å ±å‘Š
            report = monitor.get_system_status_report()
            print(f"\nğŸ“Š ç³»çµ±ç‹€æ…‹ (å¾ªç’° {i+1}/10):")
            print(f"  å¥åº·åˆ†æ•¸: {report['overall_status']['health_score']:.1f}%")
            print(f"  å¥åº·æœå‹™: {report['overall_status']['healthy_services']}/{report['overall_status']['total_services']}")
            print(f"  å¹³å‡éŸ¿æ‡‰æ™‚é–“: {report['overall_status']['average_response_time_ms']:.1f}ms")
            print(f"  æ•´åˆæ¸¬è©¦æˆåŠŸç‡: {report['overall_status']['integration_success_rate']:.1f}%")
        
        # ä¿å­˜æœ€çµ‚å ±å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = f"/home/sat/ntn-stack/leo-handover-research/design-phase/compliance-audit/integration_report_{timestamp}.json"
        monitor.save_status_report(report_path)
        
        print(f"\nâœ… ç›£æ§æ¼”ç¤ºå®Œæˆï¼Œå ±å‘Šå·²ä¿å­˜")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ¶ä¸­æ–·ç›£æ§")
    finally:
        await monitor.stop_monitoring()
        print("ğŸ›‘ ç›£æ§å™¨å·²åœæ­¢")


if __name__ == "__main__":
    asyncio.run(main())