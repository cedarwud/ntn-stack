#!/usr/bin/env python3
"""
æ€§èƒ½å„ªåŒ–é©—è­‰å™¨ - Phase 3.5
===========================

å¯¦æ–½å¯é…ç½®çš„é©—è­‰ç´šåˆ¥ä»¥å¤§å¹…é™ä½æ€§èƒ½é–‹éŠ·ï¼š
- å¿«é€Ÿé©—è­‰ (FAST): é—œéµæª¢æŸ¥é …ç›® (~5% é–‹éŠ·)
- æ¨™æº–é©—è­‰ (STANDARD): å¹³è¡¡æª¢æŸ¥ (~10% é–‹éŠ·) 
- å®Œæ•´é©—è­‰ (COMPREHENSIVE): æ‰€æœ‰æª¢æŸ¥ (~15% é–‹éŠ·)

åŒ…å«æ™ºèƒ½ç·©å­˜æ©Ÿåˆ¶å’Œä¸¦è¡Œé©—è­‰æ”¯æŒ
"""

import asyncio
import time
import hashlib
from typing import Dict, Any, List, Optional, Set
from enum import Enum
from dataclasses import dataclass
from pathlib import Path
import logging

# è¨­ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

class ValidationLevel(Enum):
    """é©—è­‰ç´šåˆ¥æšèˆ‰"""
    FAST = "fast"                    # å¿«é€Ÿé©—è­‰ï¼šåƒ…é—œéµæª¢æŸ¥
    STANDARD = "standard"            # æ¨™æº–é©—è­‰ï¼šå¹³è¡¡æª¢æŸ¥
    COMPREHENSIVE = "comprehensive"  # å®Œæ•´é©—è­‰ï¼šæ‰€æœ‰æª¢æŸ¥

@dataclass
class ValidationResult:
    """é©—è­‰çµæœæ•¸æ“šé¡åˆ¥"""
    passed: bool
    level: ValidationLevel
    execution_time_ms: float
    checks_performed: int
    total_available_checks: int
    cached_results: int
    details: Dict[str, Any]
    issues: List[str]

class ValidationCache:
    """é©—è­‰çµæœç·©å­˜ç³»çµ±"""
    
    def __init__(self, max_size: int = 1000, ttl_seconds: int = 300):
        self.cache = {}
        self.timestamps = {}
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
    
    def _generate_key(self, data: Dict[str, Any], validation_type: str) -> str:
        """ç”Ÿæˆç·©å­˜éµ"""
        # ä½¿ç”¨é—œéµå­—æ®µç”Ÿæˆç©©å®šçš„å“ˆå¸Œå€¼
        key_data = {
            'validation_type': validation_type,
            'satellite_count': len(data.get('satellites', [])),
            'metadata_hash': hash(str(data.get('metadata', {}))),
            'constellation_count': len(data.get('constellations', {}))
        }
        return hashlib.md5(str(key_data).encode()).hexdigest()
    
    def get(self, data: Dict[str, Any], validation_type: str) -> Optional[Dict[str, Any]]:
        """ç²å–ç·©å­˜çš„é©—è­‰çµæœ"""
        key = self._generate_key(data, validation_type)
        
        if key in self.cache:
            # æª¢æŸ¥æ˜¯å¦éæœŸ
            if time.time() - self.timestamps[key] < self.ttl_seconds:
                logger.debug(f"ç·©å­˜å‘½ä¸­: {validation_type}")
                return self.cache[key]
            else:
                # æ¸…ç†éæœŸç·©å­˜
                del self.cache[key]
                del self.timestamps[key]
        
        return None
    
    def set(self, data: Dict[str, Any], validation_type: str, result: Dict[str, Any]):
        """è¨­ç½®ç·©å­˜çµæœ"""
        key = self._generate_key(data, validation_type)
        
        # æª¢æŸ¥ç·©å­˜å¤§å°é™åˆ¶
        if len(self.cache) >= self.max_size:
            # æ¸…ç†æœ€èˆŠçš„ç·©å­˜é …ç›®
            oldest_key = min(self.timestamps.keys(), key=lambda k: self.timestamps[k])
            del self.cache[oldest_key]
            del self.timestamps[oldest_key]
        
        self.cache[key] = result
        self.timestamps[key] = time.time()
        logger.debug(f"ç·©å­˜è¨­ç½®: {validation_type}")

class PerformanceOptimizedValidator:
    """æ€§èƒ½å„ªåŒ–é©—è­‰å™¨"""
    
    def __init__(self, validation_level: ValidationLevel = ValidationLevel.STANDARD):
        self.validation_level = validation_level
        self.cache = ValidationCache()
        self.performance_metrics = {
            'total_validations': 0,
            'cache_hits': 0,
            'average_execution_time': 0.0
        }
    
    def validate_stage1_optimized(self, processing_results: Dict[str, Any]) -> ValidationResult:
        """Stage 1 å„ªåŒ–é©—è­‰ - è»Œé“è¨ˆç®—"""
        start_time = time.time()
        
        # æª¢æŸ¥ç·©å­˜
        cached_result = self.cache.get(processing_results, 'stage1')
        if cached_result:
            self.performance_metrics['cache_hits'] += 1
            return ValidationResult(
                passed=cached_result['passed'],
                level=self.validation_level,
                execution_time_ms=0.1,  # ç·©å­˜å¹¾ä¹ç„¡æ™‚é–“é–‹éŠ·
                checks_performed=cached_result['checks_performed'],
                total_available_checks=cached_result['total_available_checks'],
                cached_results=1,
                details=cached_result['details'],
                issues=cached_result['issues']
            )
        
        checks = {}
        issues = []
        
        # æ ¹æ“šé©—è­‰ç´šåˆ¥é¸æ“‡æª¢æŸ¥é …ç›®
        if self.validation_level == ValidationLevel.FAST:
            checks.update(self._stage1_fast_checks(processing_results, issues))
        elif self.validation_level == ValidationLevel.STANDARD:
            checks.update(self._stage1_fast_checks(processing_results, issues))
            checks.update(self._stage1_standard_checks(processing_results, issues))
        else:  # COMPREHENSIVE
            checks.update(self._stage1_fast_checks(processing_results, issues))
            checks.update(self._stage1_standard_checks(processing_results, issues))
            checks.update(self._stage1_comprehensive_checks(processing_results, issues))
        
        # è¨ˆç®—çµæœ
        passed_checks = sum(1 for passed in checks.values() if passed)
        total_checks = len(checks)
        overall_passed = passed_checks == total_checks
        
        execution_time = (time.time() - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’
        
        # ç·©å­˜çµæœ
        cache_data = {
            'passed': overall_passed,
            'checks_performed': total_checks,
            'total_available_checks': self._get_total_stage1_checks(),
            'details': checks,
            'issues': issues
        }
        self.cache.set(processing_results, 'stage1', cache_data)
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ¨™
        self.performance_metrics['total_validations'] += 1
        current_avg = self.performance_metrics['average_execution_time']
        total_validations = self.performance_metrics['total_validations']
        self.performance_metrics['average_execution_time'] = (
            (current_avg * (total_validations - 1) + execution_time) / total_validations
        )
        
        return ValidationResult(
            passed=overall_passed,
            level=self.validation_level,
            execution_time_ms=execution_time,
            checks_performed=total_checks,
            total_available_checks=self._get_total_stage1_checks(),
            cached_results=0,
            details=checks,
            issues=issues
        )
    
    def _stage1_fast_checks(self, processing_results: Dict[str, Any], issues: List[str]) -> Dict[str, bool]:
        """Stage 1 å¿«é€Ÿæª¢æŸ¥ - åƒ…é—œéµé …ç›®"""
        checks = {}
        
        # 1. åŸºæœ¬æ•¸æ“šå­˜åœ¨æ€§æª¢æŸ¥
        constellations = processing_results.get('constellations', {})
        checks["æ•¸æ“šå­˜åœ¨æ€§"] = bool(constellations)
        
        if not constellations:
            issues.append("ç¼ºå°‘æ˜Ÿåº§æ•¸æ“š")
            return checks
        
        # 2. æ˜Ÿåº§å®Œæ•´æ€§æª¢æŸ¥
        constellation_names = [name.lower() for name in constellations.keys()]
        required_constellations = ['starlink', 'oneweb']
        checks["æ˜Ÿåº§å®Œæ•´æ€§"] = all(name in constellation_names for name in required_constellations)
        
        if not checks["æ˜Ÿåº§å®Œæ•´æ€§"]:
            missing = [name for name in required_constellations if name not in constellation_names]
            issues.append(f"ç¼ºå°‘æ˜Ÿåº§æ•¸æ“š: {', '.join(missing)}")
        
        # 3. è¡›æ˜Ÿæ•¸é‡åˆç†æ€§æª¢æŸ¥
        total_satellites = sum(len(data.get('satellites', [])) for data in constellations.values())
        checks["è¡›æ˜Ÿæ•¸é‡åˆç†æ€§"] = total_satellites > 100  # æœ€åŸºæœ¬çš„æ•¸é‡æª¢æŸ¥
        
        if not checks["è¡›æ˜Ÿæ•¸é‡åˆç†æ€§"]:
            issues.append(f"è¡›æ˜Ÿæ•¸é‡éå°‘: {total_satellites}")
        
        return checks
    
    def _stage1_standard_checks(self, processing_results: Dict[str, Any], issues: List[str]) -> Dict[str, bool]:
        """Stage 1 æ¨™æº–æª¢æŸ¥ - å¹³è¡¡æ€§èƒ½å’Œè¦†è“‹åº¦"""
        checks = {}
        
        constellations = processing_results.get('constellations', {})
        
        # 4. SGP4è¨ˆç®—å®Œæ•´æ€§æª¢æŸ¥ (æŠ½æ¨£)
        sample_satellites = []
        for constellation_data in constellations.values():
            satellites = constellation_data.get('satellites', [])
            # æŠ½æ¨£æª¢æŸ¥ï¼šæ¯å€‹æ˜Ÿåº§æœ€å¤šæª¢æŸ¥10é¡†è¡›æ˜Ÿ
            sample_satellites.extend(satellites[:10])
        
        sgp4_valid_count = 0
        for sat in sample_satellites[:20]:  # ç¸½å…±æœ€å¤šæª¢æŸ¥20é¡†è¡›æ˜Ÿ
            timeseries = sat.get('position_timeseries', [])
            if len(timeseries) >= 100:  # åŸºæœ¬å®Œæ•´æ€§æª¢æŸ¥
                sgp4_valid_count += 1
        
        checks["SGP4è¨ˆç®—å®Œæ•´æ€§"] = sgp4_valid_count >= len(sample_satellites) * 0.8 if sample_satellites else False
        
        if not checks["SGP4è¨ˆç®—å®Œæ•´æ€§"]:
            issues.append(f"SGP4è¨ˆç®—å®Œæ•´æ€§ä¸è¶³: {sgp4_valid_count}/{len(sample_satellites)}")
        
        # 5. ECIåº§æ¨™é›¶å€¼æª¢æ¸¬ (é‡é»æª¢æŸ¥OneWeb)
        oneweb_data = constellations.get('oneweb', {})
        oneweb_satellites = oneweb_data.get('satellites', [])
        
        zero_eci_count = 0
        checked_oneweb = 0
        
        for sat in oneweb_satellites[:5]:  # æª¢æŸ¥å‰5é¡†OneWebè¡›æ˜Ÿ
            timeseries = sat.get('position_timeseries', [])
            if timeseries:
                first_point = timeseries[0]
                position_eci = first_point.get('position_eci', {})
                if position_eci:
                    x, y, z = position_eci.get('x', 0), position_eci.get('y', 0), position_eci.get('z', 0)
                    if x == 0 and y == 0 and z == 0:
                        zero_eci_count += 1
                    checked_oneweb += 1
        
        checks["ECIé›¶å€¼æª¢æ¸¬"] = zero_eci_count == 0 if checked_oneweb > 0 else True
        
        if not checks["ECIé›¶å€¼æª¢æ¸¬"]:
            issues.append(f"ç™¼ç¾ {zero_eci_count} å€‹é›¶å€¼ECIåº§æ¨™")
        
        return checks
    
    def _stage1_comprehensive_checks(self, processing_results: Dict[str, Any], issues: List[str]) -> Dict[str, bool]:
        """Stage 1 å®Œæ•´æª¢æŸ¥ - æ‰€æœ‰é©—è­‰é …ç›®"""
        checks = {}
        
        constellations = processing_results.get('constellations', {})
        
        # 6. è»Œé“åƒæ•¸ç‰©ç†é‚Šç•Œé©—è­‰
        physics_valid_count = 0
        total_checked = 0
        
        for constellation_data in constellations.values():
            satellites = constellation_data.get('satellites', [])
            for sat in satellites[:5]:  # æ¯å€‹æ˜Ÿåº§æª¢æŸ¥5é¡†è¡›æ˜Ÿ
                timeseries = sat.get('position_timeseries', [])
                if timeseries:
                    first_point = timeseries[0]
                    position_eci = first_point.get('position_eci', {})
                    if position_eci:
                        x, y, z = position_eci.get('x', 0), position_eci.get('y', 0), position_eci.get('z', 0)
                        distance_km = (x*x + y*y + z*z)**0.5
                        
                        # LEOé«˜åº¦æª¢æŸ¥ (200-2000km + åœ°çƒåŠå¾‘6371km)
                        if 6500 <= distance_km <= 8400:
                            physics_valid_count += 1
                        total_checked += 1
        
        checks["è»Œé“åƒæ•¸ç‰©ç†é‚Šç•Œ"] = physics_valid_count >= total_checked * 0.9 if total_checked > 0 else True
        
        if not checks["è»Œé“åƒæ•¸ç‰©ç†é‚Šç•Œ"]:
            issues.append(f"è»Œé“åƒæ•¸è¶…å‡ºç‰©ç†é‚Šç•Œ: {total_checked - physics_valid_count}/{total_checked}")
        
        # 7. æ™‚é–“åŸºæº–æº–ç¢ºæ€§æª¢æŸ¥
        metadata = processing_results.get('metadata', {})
        calculation_time = metadata.get('calculation_base_time')
        
        checks["æ™‚é–“åŸºæº–æº–ç¢ºæ€§"] = bool(calculation_time and 'UTC' in str(calculation_time))
        
        if not checks["æ™‚é–“åŸºæº–æº–ç¢ºæ€§"]:
            issues.append("æ™‚é–“åŸºæº–ä¸æ˜¯UTCæ¨™æº–æ™‚é–“")
        
        # 8. çµ±ä¸€æ ¼å¼åˆè¦æª¢æŸ¥
        old_format_satellites = processing_results.get('satellites', [])
        checks["çµ±ä¸€æ ¼å¼åˆè¦"] = len(old_format_satellites) == 0
        
        if not checks["çµ±ä¸€æ ¼å¼åˆè¦"]:
            issues.append(f"ç™¼ç¾èˆŠæ ¼å¼å†—é¤˜æ•¸æ“š: {len(old_format_satellites)} å€‹è¡›æ˜Ÿ")
        
        return checks
    
    def _get_total_stage1_checks(self) -> int:
        """ç²å– Stage 1 ç¸½æª¢æŸ¥é …ç›®æ•¸"""
        return 8  # ç•¶å‰å¯¦æ–½çš„ç¸½æª¢æŸ¥é …ç›®æ•¸
    
    async def validate_stage_async(self, stage_name: str, processing_results: Dict[str, Any]) -> ValidationResult:
        """ç•°æ­¥é©—è­‰æ¥å£"""
        if stage_name == 'stage1':
            return await asyncio.get_event_loop().run_in_executor(
                None, self.validate_stage1_optimized, processing_results
            )
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„éšæ®µ: {stage_name}")
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½å ±å‘Š"""
        cache_hit_rate = (
            self.performance_metrics['cache_hits'] / self.performance_metrics['total_validations'] * 100
            if self.performance_metrics['total_validations'] > 0 else 0
        )
        
        return {
            'validation_level': self.validation_level.value,
            'total_validations': self.performance_metrics['total_validations'],
            'cache_hits': self.performance_metrics['cache_hits'],
            'cache_hit_rate_percent': cache_hit_rate,
            'average_execution_time_ms': self.performance_metrics['average_execution_time'],
            'cache_size': len(self.cache.cache),
            'estimated_performance_improvement': f"{cache_hit_rate:.1f}% æ™‚é–“ç¯€çœ"
        }

class ValidationLevelManager:
    """é©—è­‰ç´šåˆ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.validators = {}
        self._create_validators()
    
    def _create_validators(self):
        """å‰µå»ºä¸åŒç´šåˆ¥çš„é©—è­‰å™¨"""
        for level in ValidationLevel:
            self.validators[level] = PerformanceOptimizedValidator(level)
    
    def get_validator(self, level: ValidationLevel) -> PerformanceOptimizedValidator:
        """ç²å–æŒ‡å®šç´šåˆ¥çš„é©—è­‰å™¨"""
        return self.validators[level]
    
    def recommend_level(self, system_load: float, time_constraint: float) -> ValidationLevel:
        """æ ¹æ“šç³»çµ±è² è¼‰å’Œæ™‚é–“ç´„æŸæ¨è–¦é©—è­‰ç´šåˆ¥"""
        if system_load > 80 or time_constraint < 30:  # é«˜è² è¼‰æˆ–æ™‚é–“ç·Šè¿«
            return ValidationLevel.FAST
        elif system_load > 50 or time_constraint < 60:  # ä¸­ç­‰è² è¼‰
            return ValidationLevel.STANDARD
        else:  # ä½è² è¼‰ä¸”æ™‚é–“å……è£•
            return ValidationLevel.COMPREHENSIVE
    
    def get_all_performance_reports(self) -> Dict[str, Dict[str, Any]]:
        """ç²å–æ‰€æœ‰ç´šåˆ¥çš„æ€§èƒ½å ±å‘Š"""
        reports = {}
        for level, validator in self.validators.items():
            reports[level.value] = validator.get_performance_report()
        return reports

# å…¨å±€é©—è­‰ç´šåˆ¥ç®¡ç†å™¨å¯¦ä¾‹
validation_manager = ValidationLevelManager()

# ä¾¿æ·å‡½æ•¸
def validate_with_level(stage_name: str, processing_results: Dict[str, Any], 
                       level: ValidationLevel = ValidationLevel.STANDARD) -> ValidationResult:
    """ä½¿ç”¨æŒ‡å®šç´šåˆ¥é€²è¡Œé©—è­‰"""
    validator = validation_manager.get_validator(level)
    if stage_name == 'stage1':
        return validator.validate_stage1_optimized(processing_results)
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„éšæ®µ: {stage_name}")

def get_recommended_level(system_load: float = 50.0, time_constraint: float = 120.0) -> ValidationLevel:
    """ç²å–æ¨è–¦çš„é©—è­‰ç´šåˆ¥"""
    return validation_manager.recommend_level(system_load, time_constraint)

if __name__ == "__main__":
    # æ¸¬è©¦ç¯„ä¾‹
    import json
    
    # æ¨¡æ“¬æ¸¬è©¦æ•¸æ“š
    test_data = {
        'constellations': {
            'starlink': {
                'satellites': [
                    {
                        'position_timeseries': [
                            {
                                'position_eci': {'x': 7000, 'y': 0, 'z': 0},
                                'relative_to_observer': {'elevation_deg': 45}
                            }
                        ] * 150
                    }
                ] * 100
            },
            'oneweb': {
                'satellites': [
                    {
                        'position_timeseries': [
                            {
                                'position_eci': {'x': 7500, 'y': 0, 'z': 0},
                                'relative_to_observer': {'elevation_deg': 30}
                            }
                        ] * 150
                    }
                ] * 50
            }
        },
        'metadata': {
            'calculation_base_time': '2025-09-09T12:00:00Z UTC'
        }
    }
    
    # æ¸¬è©¦ä¸åŒé©—è­‰ç´šåˆ¥
    print("ğŸ§ª æ€§èƒ½å„ªåŒ–é©—è­‰å™¨æ¸¬è©¦")
    print("=" * 50)
    
    for level in ValidationLevel:
        print(f"\næ¸¬è©¦é©—è­‰ç´šåˆ¥: {level.value.upper()}")
        
        start_time = time.time()
        result = validate_with_level('stage1', test_data, level)
        end_time = time.time()
        
        print(f"  âœ… é©—è­‰é€šé: {result.passed}")
        print(f"  â±ï¸  åŸ·è¡Œæ™‚é–“: {result.execution_time_ms:.2f}ms")
        print(f"  ğŸ“Š æª¢æŸ¥é …ç›®: {result.checks_performed}/{result.total_available_checks}")
        print(f"  ğŸš« ç™¼ç¾å•é¡Œ: {len(result.issues)}")
        
        if result.issues:
            for issue in result.issues:
                print(f"     - {issue}")
    
    print(f"\nğŸ“ˆ æ€§èƒ½å ±å‘Š:")
    reports = validation_manager.get_all_performance_reports()
    for level, report in reports.items():
        if report['total_validations'] > 0:
            print(f"  {level.upper()}: {report['average_execution_time_ms']:.2f}ms å¹³å‡åŸ·è¡Œæ™‚é–“")