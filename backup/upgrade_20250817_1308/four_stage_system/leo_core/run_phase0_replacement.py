#!/usr/bin/env python3
# ğŸ”¥ Phase 0: ç³»çµ±æ›¿æ›æ•´åˆåŸ·è¡Œè…³æœ¬
"""
Phase 0 System Replacement Executor
åŠŸèƒ½: ä¸€éµåŸ·è¡Œ leo_restructure æ›¿æ›åŸ6éšæ®µç³»çµ±
ä½¿ç”¨: python run_phase0_replacement.py
"""

import asyncio
import sys
import os
import shutil
import subprocess
from pathlib import Path
import argparse
import logging
from datetime import datetime

class Phase0Executor:
    """Phase 0 ç³»çµ±æ›¿æ›åŸ·è¡Œå™¨"""
    
    def __init__(self, dry_run=False, backup=True):
        self.dry_run = dry_run
        self.backup = backup
        self.logger = self._setup_logger()
        
        # è·¯å¾‘é…ç½®
        self.project_root = Path("/home/sat/ntn-stack")
        self.leo_restructure_path = self.project_root / "leo_restructure"
        self.netstack_path = self.project_root / "netstack"
        
        # å‚™ä»½è·¯å¾‘
        self.backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        self.backup_root = self.project_root / "phase0_backup" / self.backup_timestamp
        
    def _setup_logger(self):
        """è¨­ç½®æ—¥èªŒ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - Phase0 - %(levelname)s - %(message)s'
        )
        return logging.getLogger('Phase0Executor')
    
    async def execute_complete_replacement(self):
        """åŸ·è¡Œå®Œæ•´çš„ç³»çµ±æ›¿æ›æµç¨‹"""
        self.logger.info("ğŸ”¥ å•Ÿå‹• Phase 0: ç³»çµ±æ›¿æ›æ•´åˆæµç¨‹")
        
        try:
            # P0.1: Dockerå»ºæ§‹æ•´åˆ
            await self._p01_docker_integration()
            
            # P0.2: é…ç½®ç³»çµ±çµ±ä¸€  
            await self._p02_config_unification()
            
            # P0.3: è¼¸å‡ºæ ¼å¼å°æ¥
            await self._p03_output_formatting()
            
            # P0.4: ç³»çµ±æ›¿æ›èˆ‡é©—è­‰
            await self._p04_system_replacement()
            
            self.logger.info("ğŸ‰ Phase 0 ç³»çµ±æ›¿æ›å®Œæˆï¼")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Phase 0 åŸ·è¡Œå¤±æ•—: {e}")
            if self.backup:
                await self._emergency_rollback()
            return False
    
    async def _p01_docker_integration(self):
        """P0.1: Dockerå»ºæ§‹æ•´åˆ"""
        self.logger.info("ğŸ“¡ P0.1: é–‹å§‹Dockerå»ºæ§‹æ•´åˆ...")
        
        # å‚™ä»½åŸå»ºæ§‹è…³æœ¬
        if self.backup:
            await self._backup_file(
                self.netstack_path / "docker" / "build_with_phase0_data.py",
                "build_with_phase0_data.py.backup"
            )
        
        # ä¿®æ”¹å»ºæ§‹è…³æœ¬
        build_script_path = self.netstack_path / "docker" / "build_with_phase0_data.py"
        
        if not self.dry_run:
            await self._modify_build_script(build_script_path)
        
        self.logger.info("âœ… P0.1: Dockerå»ºæ§‹æ•´åˆå®Œæˆ")
    
    async def _p02_config_unification(self):
        """P0.2: é…ç½®ç³»çµ±çµ±ä¸€"""
        self.logger.info("âš™ï¸ P0.2: é–‹å§‹é…ç½®ç³»çµ±çµ±ä¸€...")
        
        # è¤‡è£½é…ç½®ç®¡ç†å™¨
        source_config = self.leo_restructure_path / "shared_core" / "config_manager.py"
        target_config = self.netstack_path / "config" / "leo_config.py"
        
        if not self.dry_run:
            if source_config.exists():
                shutil.copy2(source_config, target_config)
                self.logger.info(f"âœ… é…ç½®ç®¡ç†å™¨å·²è¤‡è£½: {target_config}")
            else:
                self.logger.warning(f"âš ï¸ æºé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {source_config}")
        
        self.logger.info("âœ… P0.2: é…ç½®ç³»çµ±çµ±ä¸€å®Œæˆ")
    
    async def _p03_output_formatting(self):
        """P0.3: è¼¸å‡ºæ ¼å¼å°æ¥"""
        self.logger.info("ğŸ“Š P0.3: é–‹å§‹è¼¸å‡ºæ ¼å¼å°æ¥...")
        
        # å‰µå»ºè¼¸å‡ºæ ¼å¼åŒ–å™¨
        formatter_content = '''"""
å‰ç«¯å…¼å®¹çš„è¼¸å‡ºæ ¼å¼åŒ–å™¨
å°‡ leo_restructure è¼¸å‡ºè½‰æ›ç‚ºå‰ç«¯æœŸæœ›æ ¼å¼
"""

import json
from pathlib import Path
from datetime import datetime

class FrontendCompatibleFormatter:
    """å‰ç«¯å…¼å®¹çš„è¼¸å‡ºæ ¼å¼åŒ–å™¨"""
    
    def format_for_frontend(self, satellite_pools, output_path="/app/data"):
        """æ ¼å¼åŒ–ç‚ºå‰ç«¯éœ€è¦çš„æ ¼å¼"""
        
        # ç”Ÿæˆå‰ç«¯å…¼å®¹çš„JSONæ ¼å¼
        frontend_data = {
            "metadata": {
                "generation_time": datetime.now().isoformat(),
                "data_source": "leo_restructure_phase1",
                "format_version": "1.0"
            },
            "satellites": self._format_satellites(satellite_pools),
            "timeline": self._format_timeline(satellite_pools),
            "handover_events": self._format_handover_events(satellite_pools)
        }
        
        # è¼¸å‡ºåˆ°æŒ‡å®šè·¯å¾‘
        output_file = Path(output_path) / "frontend_compatible_data.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(frontend_data, f, indent=2, ensure_ascii=False)
        
        return frontend_data
    
    def _format_satellites(self, pools):
        """æ ¼å¼åŒ–è¡›æ˜Ÿæ•¸æ“š"""
        satellites = []
        
        if hasattr(pools, 'starlink_satellites'):
            for sat in pools.starlink_satellites:
                satellites.append({
                    "id": f"starlink_{sat.get('satellite_id', 'unknown')}",
                    "constellation": "starlink",
                    "name": sat.get('satellite_name', ''),
                    "orbital_parameters": sat.get('orbital_parameters', {}),
                    "positions": sat.get('timeline_positions', [])
                })
        
        if hasattr(pools, 'oneweb_satellites'):
            for sat in pools.oneweb_satellites:
                satellites.append({
                    "id": f"oneweb_{sat.get('satellite_id', 'unknown')}",
                    "constellation": "oneweb", 
                    "name": sat.get('satellite_name', ''),
                    "orbital_parameters": sat.get('orbital_parameters', {}),
                    "positions": sat.get('timeline_positions', [])
                })
        
        return satellites
    
    def _format_timeline(self, pools):
        """æ ¼å¼åŒ–æ™‚é–“è»¸æ•¸æ“š"""
        # ç”Ÿæˆ200å€‹æ™‚é–“é»ï¼Œ30ç§’é–“éš”
        timeline = []
        
        for i in range(200):
            timestamp = datetime.now().timestamp() + (i * 30)
            timeline.append({
                "timestamp": datetime.fromtimestamp(timestamp).isoformat(),
                "visible_starlink": [],  # å¯¦éš›æ•¸æ“šéœ€è¦å¾poolsè¨ˆç®—
                "visible_oneweb": []
            })
        
        return timeline
    
    def _format_handover_events(self, pools):
        """æ ¼å¼åŒ–æ›æ‰‹äº‹ä»¶æ•¸æ“š"""
        events = []
        
        # å¾poolsä¸­æå–A4/A5/D2äº‹ä»¶
        if hasattr(pools, 'handover_events'):
            for event in pools.handover_events:
                events.append({
                    "timestamp": event.get('timestamp', ''),
                    "event_type": event.get('type', ''),
                    "source_satellite": event.get('source', ''),
                    "target_satellite": event.get('target', ''),
                    "signal_quality": event.get('signal_metrics', {})
                })
        
        return events
'''
        
        formatter_path = self.leo_restructure_path / "shared_core" / "frontend_formatter.py"
        
        if not self.dry_run:
            with open(formatter_path, 'w', encoding='utf-8') as f:
                f.write(formatter_content)
            self.logger.info(f"âœ… è¼¸å‡ºæ ¼å¼åŒ–å™¨å·²å‰µå»º: {formatter_path}")
        
        self.logger.info("âœ… P0.3: è¼¸å‡ºæ ¼å¼å°æ¥å®Œæˆ")
    
    async def _p04_system_replacement(self):
        """P0.4: ç³»çµ±æ›¿æ›èˆ‡é©—è­‰"""
        self.logger.info("ğŸ”„ P0.4: é–‹å§‹ç³»çµ±æ›¿æ›èˆ‡é©—è­‰...")
        
        # å‚™ä»½èˆŠç³»çµ±
        if self.backup:
            await self._backup_old_system()
        
        # éƒ¨ç½²æ–°ç³»çµ±
        await self._deploy_new_system()
        
        # é©—è­‰ç³»çµ±
        await self._verify_system()
        
        self.logger.info("âœ… P0.4: ç³»çµ±æ›¿æ›èˆ‡é©—è­‰å®Œæˆ")
    
    async def _backup_old_system(self):
        """å‚™ä»½èˆŠç³»çµ±"""
        self.logger.info("ğŸ“¦ é–‹å§‹å‚™ä»½èˆŠç³»çµ±...")
        
        self.backup_root.mkdir(parents=True, exist_ok=True)
        
        # å‚™ä»½stagesç›®éŒ„
        stages_src = self.netstack_path / "src" / "stages"
        stages_backup = self.backup_root / "stages"
        
        if stages_src.exists():
            shutil.copytree(stages_src, stages_backup)
            self.logger.info(f"âœ… å·²å‚™ä»½stagesç›®éŒ„: {stages_backup}")
        
        # å‚™ä»½services/satelliteç›®éŒ„
        services_src = self.netstack_path / "src" / "services" / "satellite"
        services_backup = self.backup_root / "services_satellite"
        
        if services_src.exists():
            shutil.copytree(services_src, services_backup)
            self.logger.info(f"âœ… å·²å‚™ä»½services/satelliteç›®éŒ„: {services_backup}")
        
        # å‚™ä»½æ ¹ç›®éŒ„çš„èˆŠpipelineæª”æ¡ˆ
        old_files = [
            "run_stage6_independent.py",
            "verify_complete_pipeline.py", 
            "fix_stage2_filtering.py",
            "complete_pipeline.py"
        ]
        
        for file_name in old_files:
            src_file = self.project_root / file_name
            if src_file.exists():
                dst_file = self.backup_root / file_name
                shutil.copy2(src_file, dst_file)
                self.logger.info(f"âœ… å·²å‚™ä»½æª”æ¡ˆ: {file_name}")
    
    async def _deploy_new_system(self):
        """éƒ¨ç½²æ–°ç³»çµ±"""
        self.logger.info("ğŸš€ é–‹å§‹éƒ¨ç½²æ–°ç³»çµ±...")
        
        if not self.dry_run:
            # ç§»é™¤èˆŠstagesç›®éŒ„
            stages_path = self.netstack_path / "src" / "stages"
            if stages_path.exists():
                shutil.rmtree(stages_path)
                self.logger.info("âœ… å·²ç§»é™¤èˆŠstagesç›®éŒ„")
            
            # éƒ¨ç½²leo_restructureç‚ºleo_core
            leo_core_path = self.netstack_path / "src" / "leo_core"
            if leo_core_path.exists():
                shutil.rmtree(leo_core_path)
            
            shutil.copytree(self.leo_restructure_path, leo_core_path)
            self.logger.info(f"âœ… å·²éƒ¨ç½²leo_restructureç‚º: {leo_core_path}")
        
        self.logger.info("âœ… æ–°ç³»çµ±éƒ¨ç½²å®Œæˆ")
    
    async def _verify_system(self):
        """é©—è­‰ç³»çµ±"""
        self.logger.info("ğŸ” é–‹å§‹ç³»çµ±é©—è­‰...")
        
        # æª¢æŸ¥é—œéµæª”æ¡ˆæ˜¯å¦å­˜åœ¨
        leo_core_path = self.netstack_path / "src" / "leo_core"
        key_files = [
            "run_phase1.py",
            "phase1_core_system/main_pipeline.py",
            "shared_core/config_manager.py"
        ]
        
        for file_path in key_files:
            full_path = leo_core_path / file_path
            if full_path.exists():
                self.logger.info(f"âœ… é—œéµæª”æ¡ˆå­˜åœ¨: {file_path}")
            else:
                raise FileNotFoundError(f"é—œéµæª”æ¡ˆç¼ºå¤±: {file_path}")
        
        self.logger.info("âœ… ç³»çµ±é©—è­‰é€šé")
    
    async def _modify_build_script(self, build_script_path):
        """ä¿®æ”¹å»ºæ§‹è…³æœ¬"""
        if not build_script_path.exists():
            self.logger.warning(f"âš ï¸ å»ºæ§‹è…³æœ¬ä¸å­˜åœ¨: {build_script_path}")
            return
        
        # è®€å–åŸæª”æ¡ˆ
        with open(build_script_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ·»åŠ leo_restructureèª¿ç”¨çš„è¨»é‡‹æ¨™è¨˜
        leo_integration = '''
# === LEO_RESTRUCTURE INTEGRATION (Phase 0) ===
# æ›¿æ›åŸ6éšæ®µè™•ç†ç‚ºleo_restructure Phase 1
import sys
sys.path.append('/app/src/leo_core')

try:
    from run_phase1 import main as leo_main
    import asyncio
    
    logger.info("ğŸ›°ï¸ å•Ÿå‹•LEOé‡æ§‹ç³»çµ±Phase 1...")
    
    # åŸ·è¡Œleo_restructure with output to /app/data
    result = asyncio.run(leo_main([
        '--output-dir', '/app/data',
        '--fast',  # ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
        '--verbose'
    ]))
    
    if result:
        logger.info("âœ… LEOé‡æ§‹ç³»çµ±Phase 1åŸ·è¡ŒæˆåŠŸ")
    else:
        logger.error("âŒ LEOé‡æ§‹ç³»çµ±Phase 1åŸ·è¡Œå¤±æ•—")
        
except Exception as e:
    logger.error(f"âŒ LEOé‡æ§‹ç³»çµ±åŸ·è¡ŒéŒ¯èª¤: {e}")
    # å¯ä»¥åœ¨é€™è£¡æ·»åŠ fallbackæ©Ÿåˆ¶
# === LEO_RESTRUCTURE INTEGRATION END ===
'''
        
        # åœ¨æª”æ¡ˆæœ«å°¾æ·»åŠ leo_restructureæ•´åˆ
        modified_content = content + leo_integration
        
        # å¯«å›æª”æ¡ˆ
        with open(build_script_path, 'w', encoding='utf-8') as f:
            f.write(modified_content)
        
        self.logger.info(f"âœ… å»ºæ§‹è…³æœ¬å·²ä¿®æ”¹: {build_script_path}")
    
    async def _backup_file(self, source_path, backup_name):
        """å‚™ä»½å–®å€‹æª”æ¡ˆ"""
        if source_path.exists():
            backup_path = self.backup_root / backup_name
            backup_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(source_path, backup_path)
            self.logger.info(f"âœ… å·²å‚™ä»½æª”æ¡ˆ: {backup_name}")
    
    async def _emergency_rollback(self):
        """ç·Šæ€¥å›é€€"""
        self.logger.warning("ğŸš¨ åŸ·è¡Œç·Šæ€¥å›é€€...")
        
        # æ¢å¾©stagesç›®éŒ„
        stages_backup = self.backup_root / "stages"
        stages_target = self.netstack_path / "src" / "stages"
        
        if stages_backup.exists():
            if stages_target.exists():
                shutil.rmtree(stages_target)
            shutil.copytree(stages_backup, stages_target)
            self.logger.info("âœ… å·²æ¢å¾©stagesç›®éŒ„")
        
        # ç§»é™¤leo_core
        leo_core_path = self.netstack_path / "src" / "leo_core"
        if leo_core_path.exists():
            shutil.rmtree(leo_core_path)
            self.logger.info("âœ… å·²ç§»é™¤leo_coreç›®éŒ„")
        
        self.logger.info("âœ… ç·Šæ€¥å›é€€å®Œæˆ")

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(
        description="Phase 0: leo_restructure ç³»çµ±æ›¿æ›åŸ·è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ä¹¾é‹è¡Œæ¨¡å¼ï¼Œåªé¡¯ç¤ºå°‡è¦åŸ·è¡Œçš„æ“ä½œ'
    )
    
    parser.add_argument(
        '--no-backup',
        action='store_true',
        help='ä¸é€²è¡Œå‚™ä»½ï¼ˆä¸å»ºè­°åœ¨ç”Ÿç”¢ç’°å¢ƒä½¿ç”¨ï¼‰'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true', 
        help='è©³ç´°è¼¸å‡º'
    )
    
    return parser.parse_args()

async def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    args = parse_arguments()
    
    print("ğŸ”¥ Phase 0: LEOé‡æ§‹ç³»çµ±æ›¿æ›åŸ·è¡Œå™¨")
    print("=" * 60)
    print("ğŸ¯ ç›®æ¨™: å®Œå…¨æ›¿ä»£åŸ6éšæ®µç³»çµ±ç‚ºleo_restructure")
    print("ğŸ“‹ æµç¨‹: P0.1â†’P0.2â†’P0.3â†’P0.4 (Dockerâ†’é…ç½®â†’æ ¼å¼â†’æ›¿æ›)")
    
    if args.dry_run:
        print("ğŸ” ä¹¾é‹è¡Œæ¨¡å¼: åªé¡¯ç¤ºæ“ä½œï¼Œä¸å¯¦éš›åŸ·è¡Œ")
    
    if args.no_backup:
        print("âš ï¸ ç„¡å‚™ä»½æ¨¡å¼: å°‡ä¸é€²è¡Œå®‰å…¨å‚™ä»½")
    
    print("-" * 60)
    
    # ç¢ºèªåŸ·è¡Œ
    if not args.dry_run:
        confirm = input("ç¢ºå®šè¦åŸ·è¡Œç³»çµ±æ›¿æ›å—ï¼Ÿ (y/N): ")
        if confirm.lower() != 'y':
            print("âŒ ç”¨æˆ¶å–æ¶ˆåŸ·è¡Œ")
            return False
    
    # å‰µå»ºåŸ·è¡Œå™¨
    executor = Phase0Executor(
        dry_run=args.dry_run,
        backup=not args.no_backup
    )
    
    # åŸ·è¡Œæ›¿æ›
    success = await executor.execute_complete_replacement()
    
    if success:
        print("\n" + "=" * 60)
        print("ğŸ‰ Phase 0 ç³»çµ±æ›¿æ›æˆåŠŸå®Œæˆï¼")
        print("âœ… leo_restructure å·²æˆç‚ºä¸»è¦è™•ç†ç³»çµ±")
        print("âœ… åŸ6éšæ®µç³»çµ±å·²å®Œå…¨æ›¿æ›")
        print("ğŸ“‹ ä¸‹ä¸€æ­¥: åŸ·è¡Œ 'make down-v && make build-n && make up' æ¸¬è©¦")
        print("=" * 60)
        return True
    else:
        print("\n" + "=" * 60)  
        print("âŒ Phase 0 ç³»çµ±æ›¿æ›å¤±æ•—")
        print("ğŸš¨ ç³»çµ±å·²å›é€€åˆ°åŸç‹€æ…‹")
        print("ğŸ’¡ å»ºè­°æª¢æŸ¥éŒ¯èª¤æ—¥èªŒä¸¦é‡æ–°å˜—è©¦")
        print("=" * 60)
        return False

if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
        sys.exit(130)
    except Exception as e:
        print(f"\nğŸ’¥ æœªé æœŸéŒ¯èª¤: {e}")
        sys.exit(1)