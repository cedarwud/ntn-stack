# ğŸ”§ NTN Stack æŠ€è¡“å¯¦æ–½æŒ‡å—

**ç‰ˆæœ¬**: 3.0.0  
**æ›´æ–°æ—¥æœŸ**: 2025-08-18  
**å°ˆæ¡ˆç‹€æ…‹**: âœ… ç”Ÿç”¢å°±ç·’  
**é©ç”¨æ–¼**: LEO è¡›æ˜Ÿåˆ‡æ›ç ”ç©¶ç³»çµ± - å®Œæ•´æŠ€è¡“å¯¦æ–½

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—æä¾› NTN Stack çš„**å®Œæ•´æŠ€è¡“å¯¦æ–½ç´°ç¯€**ï¼ŒåŒ…æ‹¬éƒ¨ç½²é…ç½®ã€é–‹ç™¼ç’°å¢ƒè¨­ç½®ã€ç³»çµ±èª¿å„ªå’Œæ•…éšœæ’é™¤ã€‚æ¶µè“‹å¾é›¶é–‹å§‹çš„ç³»çµ±æ­å»ºåˆ°ç”Ÿç”¢ç’°å¢ƒçš„ç¶­è­·æ“ä½œã€‚

**ğŸ“‹ ç›¸é—œæ–‡æª”**ï¼š
- **ç³»çµ±æ¶æ§‹**ï¼š[ç³»çµ±æ¶æ§‹ç¸½è¦½](./system_architecture.md) - é«˜å±¤ç³»çµ±è¨­è¨ˆ
- **æ•¸æ“šè™•ç†æµç¨‹**ï¼š[æ•¸æ“šè™•ç†æµç¨‹](./data_processing_flow.md) - Pure Cron é©…å‹•æ¶æ§‹
- **ç®—æ³•å¯¦ç¾**ï¼š[ç®—æ³•å¯¦ç¾æ‰‹å†Š](./algorithms_implementation.md) - æ ¸å¿ƒç®—æ³•ç´°ç¯€
- **è¡›æ˜Ÿæ¨™æº–**ï¼š[è¡›æ˜Ÿæ›æ‰‹æ¨™æº–](./satellite_handover_standards.md) - 3GPP NTN æ¨™æº–
- **API ä»‹é¢**ï¼š[API åƒè€ƒæ‰‹å†Š](./api_reference.md) - ç«¯é»æ–‡æª”

## ğŸš€ å¿«é€Ÿéƒ¨ç½²æŒ‡å—

### ç³»çµ±éœ€æ±‚
```bash
# ç¡¬é«”è¦æ±‚
CPU: 4 æ ¸å¿ƒ @ 2.4GHz+
RAM: 16GB+ (æ¨è–¦ 32GB)  
å­˜å„²: 100GB+ SSD
ç¶²è·¯: 100Mbps+ (TLE æ•¸æ“šä¸‹è¼‰)

# è»Ÿé«”éœ€æ±‚
Docker: 24.0+
Docker Compose: 2.20+
Python: 3.11+
Node.js: 18+
```

### âš¡ 30 ç§’å¿«é€Ÿå•Ÿå‹•
```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone <repository_url>
cd ntn-stack

# 2. å•Ÿå‹•æ‰€æœ‰æœå‹™
make up

# 3. ç­‰å¾…æœå‹™å¥åº·æª¢æŸ¥ (ç´„ 30 ç§’)
make status

# 4. é©—è­‰æœå‹™å¯ç”¨æ€§
curl http://localhost:8080/health     # NetStack API
curl http://localhost:5173           # SimWorld å‰ç«¯
curl http://localhost:8888/api/health # SimWorld å¾Œç«¯
```

### ğŸ”§ è©³ç´°éƒ¨ç½²æµç¨‹
```bash
# Step 1: ç’°å¢ƒæº–å‚™
sudo apt update && sudo apt install -y docker.io docker-compose
sudo usermod -aG docker $USER
newgrp docker

# Step 2: å°ˆæ¡ˆé…ç½®
cp .env.example .env                 # è¤‡è£½ç’°å¢ƒé…ç½®
vim .env                            # æ ¹æ“šéœ€è¦èª¿æ•´é…ç½®

# Step 3: æœå‹™å•Ÿå‹•
make up                             # å•Ÿå‹•æ‰€æœ‰å®¹å™¨
docker-compose logs -f              # è§€å¯Ÿå•Ÿå‹•æ—¥èªŒ

# Step 4: é©—è­‰éƒ¨ç½²
make status                         # æª¢æŸ¥å®¹å™¨ç‹€æ…‹
./scripts/deployment-verification.sh # åŸ·è¡Œéƒ¨ç½²é©—è­‰è…³æœ¬
```

## ğŸ³ Docker é…ç½®è©³è§£

### æ ¸å¿ƒæœå‹™é…ç½®
```yaml
# docker-compose.yml é—œéµé…ç½®
services:
  netstack-api:
    build: ./netstack
    ports: ["8080:8080"]
    depends_on:
      - netstack-postgres
      - netstack-redis
    volumes:
      - tle_data:/app/tle_data
      - leo_outputs:/app/data/leo_outputs
    environment:
      - SGP4_MODE=runtime_precision
      - POSTGRES_HOST=netstack-rl-postgres
      - REDIS_URL=redis://netstack-redis:6379
    
  simworld-backend:
    build: ./simworld/backend
    ports: ["8888:8888"]
    depends_on:
      - simworld-postgres
    volumes:
      - satellite_data:/app/satellite_data
      - leo_outputs:/app/data/leo_outputs
    
  simworld-frontend:
    build: ./simworld/frontend
    ports: ["5173:80"]
    nginx_config: |
      location /api {
        proxy_pass http://simworld-backend:8888;
      }
```

### Volume å­˜å„²é…ç½®
```yaml
volumes:
  # æŒä¹…åŒ–æ•¸æ“š
  postgres_data:
    driver: local
  rl_postgres_data:
    driver: local
    
  # å…±äº«æ•¸æ“š
  tle_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./netstack/tle_data
      
  satellite_data:
    driver: local
    driver_opts:
      type: none
      o: bind  
      device: ./data/satellite_data
      
  leo_outputs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/leo_outputs
```

### ç¶²è·¯é…ç½®
```yaml
networks:
  ntn-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1
          
# æœå‹™IPåˆ†é…
services:
  netstack-api:
    networks:
      ntn-network:
        ipv4_address: 172.20.0.10
  
  netstack-rl-postgres:
    networks:
      ntn-network:
        ipv4_address: 172.20.0.51
  
  simworld-backend:
    networks:
      ntn-network:
        ipv4_address: 172.20.0.20
```

## âš™ï¸ çµ±ä¸€é…ç½®ç®¡ç†

### ğŸ”§ æ ¸å¿ƒé…ç½®ç³»çµ±
**å¯¦ç¾ä½ç½®**: `netstack/src/core/config/satellite_config.py`

```python
@dataclass
class SatelliteConfig:
    """è¡›æ˜Ÿç³»çµ±çµ±ä¸€é…ç½®é¡"""
    
    # 3GPP NTN åˆè¦é…ç½®
    MAX_CANDIDATE_SATELLITES: int = 8
    
    # è¡›æ˜Ÿç¯©é¸é…ç½®  
    PREPROCESS_SATELLITES: Dict[str, int] = field(default_factory=lambda: {
        "starlink": 0,  # å‹•æ…‹æ±ºç­–ï¼Œéå›ºå®šæ•¸é‡
        "oneweb": 0     # å‹•æ…‹æ±ºç­–ï¼Œéå›ºå®šæ•¸é‡  
    })
    
    # æ™ºèƒ½ç¯©é¸é…ç½®
    INTELLIGENT_SELECTION: bool = True
    GEOGRAPHIC_FILTERING: bool = True
    ELEVATION_THRESHOLD_DEG: float = 10.0
    
    # è»Œé“è¨ˆç®—ç²¾åº¦é…ç½®
    SGP4_MODE: str = "runtime_precision"  # é‹è¡Œæ™‚ç²¾åº¦æ¨¡å¼
    PERTURBATION_MODELING: bool = True    # å•Ÿç”¨æ”å‹•å»ºæ¨¡
    HIGH_ORDER_TERMS: bool = True         # é«˜éšé …ä¿®æ­£
    
    # Pure Cron é©…å‹•é…ç½®
    CRON_UPDATE_INTERVAL: int = 6         # 6å°æ™‚æ›´æ–°é€±æœŸ
    INCREMENTAL_PROCESSING: bool = True   # å¢é‡è™•ç†
    DATA_VALIDATION: bool = True          # æ•¸æ“šé©—è­‰
```

### ç’°å¢ƒè®Šæ•¸é…ç½®
```bash
# .env æ–‡ä»¶é…ç½®ç¯„ä¾‹
# ç³»çµ±é…ç½®
NODE_ENV=production
LOG_LEVEL=info

# NetStack é…ç½®
NETSTACK_API_PORT=8080
NETSTACK_POSTGRES_HOST=netstack-rl-postgres
NETSTACK_POSTGRES_PORT=5432
NETSTACK_POSTGRES_DB=rl_research
NETSTACK_POSTGRES_USER=rl_user
NETSTACK_POSTGRES_PASSWORD=secure_password

# SimWorld é…ç½®  
SIMWORLD_API_PORT=8888
SIMWORLD_FRONTEND_PORT=5173
SIMWORLD_POSTGRES_HOST=simworld-postgres

# è¡›æ˜Ÿé…ç½®
SGP4_MODE=runtime_precision
MAX_CANDIDATE_SATELLITES=8
OBSERVER_LAT=24.9441667
OBSERVER_LON=121.3713889
ELEVATION_THRESHOLD=10.0

# Cron é…ç½®
CRON_UPDATE_INTERVAL=6
TLE_DATA_SOURCE=celestrak
INCREMENTAL_PROCESSING=true
```

### åˆ†å±¤ä»°è§’é–€æª»ç³»çµ±
```python
elevation_thresholds = {
    # åŸºç¤é–€æª» (åº¦)
    "ideal_service": 15.0,        # ç†æƒ³æœå‹™é–€æª» (â‰¥99.9% æˆåŠŸç‡)
    "standard_service": 10.0,     # æ¨™æº–æœå‹™é–€æª» (â‰¥99.5% æˆåŠŸç‡)  
    "minimum_service": 5.0,       # æœ€ä½æœå‹™é–€æª» (â‰¥98% æˆåŠŸç‡)
    "emergency_only": 3.0,        # ç·Šæ€¥é€šè¨Šé–€æª» (ç‰¹æ®Šæˆæ¬Š)
    
    # ç’°å¢ƒèª¿æ•´ä¿‚æ•¸
    "environment_factors": {
        "open_area": 0.9,         # æµ·æ´‹ã€å¹³åŸ
        "standard": 1.0,          # ä¸€èˆ¬é™¸åœ°
        "urban": 1.2,             # åŸå¸‚å»ºç¯‰é®è”½
        "complex_terrain": 1.5,   # å±±å€ã€é«˜æ¨“
        "severe_weather": 1.8     # æš´é›¨ã€é›ªç½
    }
}
```

## ğŸ”„ Pure Cron é©…å‹•ç³»çµ±

### Cron èª¿åº¦é…ç½®
```bash
# /etc/cron.d/ntn-stack
# æ¯6å°æ™‚æ›´æ–°TLEæ•¸æ“š
0 */6 * * * /home/sat/ntn-stack/scripts/daily_tle_download_enhanced.sh >> /var/log/tle_update.log 2>&1

# æ¯æ—¥å‡Œæ™¨åŸ·è¡Œå®Œæ•´å…­éšæ®µè™•ç†
0 2 * * * cd /home/sat/ntn-stack && /home/sat/ntn-stack/netstack/src/leo_core/main.py >> /var/log/leo_processing.log 2>&1

# æ¯å°æ™‚æª¢æŸ¥ç³»çµ±å¥åº·ç‹€æ…‹
0 * * * * curl -f http://localhost:8080/health || systemctl restart ntn-stack >> /var/log/health_check.log 2>&1

# æ¯é€±æ¸…ç†èˆŠæ•¸æ“š
0 3 * * 0 /home/sat/ntn-stack/scripts/safe_data_cleanup.sh >> /var/log/data_cleanup.log 2>&1
```

### æ™ºèƒ½å¢é‡è™•ç†æ©Ÿåˆ¶
**å¯¦ç¾ä½ç½®**: `netstack/src/shared_core/incremental_update_manager.py`

```python
class IncrementalUpdateManager:
    def detect_tle_changes(self, old_tle_data, new_tle_data):
        """æ™ºèƒ½TLEè®Šæ›´åµæ¸¬"""
        changes = []
        
        # å»ºç«‹å¿«é€ŸæŸ¥æ‰¾ç´¢å¼•
        old_index = {tle.satellite_id: tle for tle in old_tle_data}
        new_index = {tle.satellite_id: tle for tle in new_tle_data}
        
        # æª¢æ¸¬è®Šæ›´
        for sat_id in new_index:
            if sat_id not in old_index:
                changes.append({
                    'type': 'ADDED',
                    'satellite_id': sat_id,
                    'new_tle': new_index[sat_id]
                })
            elif self._is_tle_significantly_different(
                old_index[sat_id], new_index[sat_id]
            ):
                changes.append({
                    'type': 'MODIFIED', 
                    'satellite_id': sat_id,
                    'old_tle': old_index[sat_id],
                    'new_tle': new_index[sat_id]
                })
        
        return changes
    
    def _is_tle_significantly_different(self, old_tle, new_tle):
        """åˆ¤æ–·TLEæ˜¯å¦æœ‰é¡¯è‘—è®Šæ›´"""
        # epochæ™‚é–“å·®ç•°
        epoch_diff = abs(old_tle.epoch - new_tle.epoch)
        if epoch_diff > 0.1:  # 0.1å¤©
            return True
        
        # è»Œé“åƒæ•¸è®ŠåŒ–
        param_changes = [
            abs(old_tle.inclination - new_tle.inclination) > 0.001,
            abs(old_tle.mean_motion - new_tle.mean_motion) > 0.0001,
            abs(old_tle.eccentricity - new_tle.eccentricity) > 0.00001
        ]
        
        return any(param_changes)
```

### è‡ªå‹•æ¸…ç†ç®¡ç†
```python
# å¯¦ç¾ä½ç½®: netstack/src/shared_core/auto_cleanup_manager.py  
class AutoCleanupManager:
    def cleanup_old_outputs(self):
        """æ¸…ç†éæœŸè¼¸å‡º"""
        cutoff_time = datetime.now() - timedelta(days=7)
        
        for stage_dir in self.output_directories:
            for file_path in glob.glob(f"{stage_dir}/*.json"):
                if os.path.getmtime(file_path) < cutoff_time.timestamp():
                    os.remove(file_path)
    
    def preserve_critical_data(self):
        """ä¿è­·é‡è¦æ•¸æ“š"""
        # ä¿ç•™æœ€æ–°çš„æˆåŠŸè™•ç†çµæœ
        latest_files = self._find_latest_successful_outputs()
        for file_path in latest_files:
            self._mark_as_protected(file_path)
    
    def optimize_storage_usage(self):
        """å„ªåŒ–å­˜å„²ä½¿ç”¨"""
        # å£“ç¸®èˆŠæ•¸æ“šæª”æ¡ˆ
        old_files = self._find_compressible_files()
        for file_path in old_files:
            self._compress_file(file_path)
```

## ğŸ”§ é–‹ç™¼ç’°å¢ƒè¨­ç½®

### æœ¬åœ°é–‹ç™¼ç’°å¢ƒ
```bash
# 1. Python è™›æ“¬ç’°å¢ƒè¨­ç½®
cd /home/sat/ntn-stack
python3 -m venv ntn_dev_env
source ntn_dev_env/bin/activate

# 2. å®‰è£é–‹ç™¼ä¾è³´
pip install -r netstack/requirements.txt
pip install -r netstack/requirements-dev.txt  # é–‹ç™¼å·¥å…·

# 3. å‰ç«¯é–‹ç™¼ç’°å¢ƒ
cd simworld/frontend
npm install
npm run dev  # é–‹ç™¼æ¨¡å¼å•Ÿå‹•

# 4. ä»£ç¢¼å“è³ªå·¥å…·
pip install flake8 black pytest mypy
npm install -g eslint prettier
```

### IDE é…ç½® (VS Code)
```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./ntn_dev_env/bin/python",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests/"],
    
    "typescript.preferences.importModuleSpecifier": "relative",
    "eslint.workingDirectories": ["simworld/frontend"],
    
    "files.associations": {
        "*.tle": "plaintext",
        "*.json": "jsonc"
    }
}

// .vscode/launch.json 
{
    "configurations": [
        {
            "name": "NetStack API Debug",
            "type": "python",
            "request": "launch",
            "program": "netstack/main.py",
            "env": {
                "PYTHONPATH": "${workspaceFolder}/netstack",
                "ENV": "development"
            }
        }
    ]
}
```

### æ¸¬è©¦ç’°å¢ƒé…ç½®
```bash
# å–®å…ƒæ¸¬è©¦
cd netstack
python -m pytest tests/unit/ -v

# æ•´åˆæ¸¬è©¦  
python -m pytest tests/integration/ -v --slow

# æ€§èƒ½æ¸¬è©¦
python -m pytest tests/performance/ -v --benchmark-only

# å‰ç«¯æ¸¬è©¦
cd simworld/frontend
npm test                    # å–®å…ƒæ¸¬è©¦
npm run test:e2e           # ç«¯åˆ°ç«¯æ¸¬è©¦
npm run test:coverage      # è¦†è“‹ç‡å ±å‘Š
```

## ğŸ“Š æ€§èƒ½ç›£æ§èˆ‡èª¿å„ª

### ç³»çµ±ç›£æ§æŒ‡æ¨™
```python
# æ€§èƒ½åŸºæº–é…ç½®
performance_benchmarks = {
    "api_response_time": {
        "satellite_position": "< 50ms",
        "handover_decision": "< 100ms", 
        "trajectory_query": "< 200ms"
    },
    "algorithm_latency": {
        "sgp4_calculation": "< 15ms",
        "fine_grained_handover": "< 25ms",
        "ml_prediction": "< 50ms"
    },
    "system_resources": {
        "cpu_usage": "< 80%",
        "memory_usage": "< 85%",
        "disk_io": "< 80%",
        "network_latency": "< 10ms"
    },
    "accuracy_metrics": {
        "position_accuracy": "< 100m",
        "prediction_accuracy": "> 94%", 
        "handover_success_rate": "> 99%"
    }
}
```

### ç›£æ§å„€è¡¨æ¿é…ç½®
```yaml
# docker-compose.monitoring.yml
services:
  prometheus:
    image: prom/prometheus:latest
    ports: ["9090:9090"]
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    
  grafana:
    image: grafana/grafana:latest
    ports: ["3000:3000"]
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/dashboards:/etc/grafana/provisioning/dashboards

  node-exporter:
    image: prom/node-exporter:latest
    ports: ["9100:9100"]
    
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    ports: ["8081:8080"]
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
```

### æ€§èƒ½èª¿å„ªæŒ‡å—
```bash
# 1. æ•¸æ“šåº«å„ªåŒ–
# PostgreSQL é…ç½®èª¿å„ª
sudo vim /etc/postgresql/14/main/postgresql.conf
```

```sql
-- PostgreSQL æ€§èƒ½é…ç½®
shared_buffers = 4GB                    -- 25% çš„ç³»çµ±è¨˜æ†¶é«”
effective_cache_size = 12GB             -- 75% çš„ç³»çµ±è¨˜æ†¶é«”
maintenance_work_mem = 1GB
work_mem = 256MB
random_page_cost = 1.1                  -- SSD å„ªåŒ–
effective_io_concurrency = 200

-- ç´¢å¼•å„ªåŒ–
CREATE INDEX CONCURRENTLY idx_satellite_orbital_cache_timestamp 
ON satellite_orbital_cache (timestamp);

CREATE INDEX CONCURRENTLY idx_satellite_tle_data_constellation 
ON satellite_tle_data (constellation, satellite_id);
```

```bash
# 2. Docker å®¹å™¨å„ªåŒ–
# docker-compose.yml è³‡æºé™åˆ¶
services:
  netstack-api:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

# 3. Python æ‡‰ç”¨å„ªåŒ–
# ä½¿ç”¨ gunicorn å¤šé€²ç¨‹æ¨¡å¼
gunicorn --workers 4 --worker-class uvicorn.workers.UvicornWorker \
         --bind 0.0.0.0:8080 --max-requests 1000 \
         netstack.main:app

# 4. å‰ç«¯å„ªåŒ–
cd simworld/frontend
npm run build                           # ç”Ÿç”¢æ§‹å»º
npm run analyze                         # åŒ…å¤§å°åˆ†æ
```

## ğŸ” æ•…éšœæ’é™¤æŒ‡å—

### å¸¸è¦‹å•é¡Œè¨ºæ–·
```bash
# 1. æœå‹™å•Ÿå‹•å•é¡Œ
make status                             # æª¢æŸ¥å®¹å™¨ç‹€æ…‹
docker-compose logs netstack-api        # æŸ¥çœ‹ API æ—¥èªŒ
docker-compose logs simworld-backend    # æŸ¥çœ‹å¾Œç«¯æ—¥èªŒ

# 2. æ•¸æ“šåº«é€£æ¥å•é¡Œ
docker exec -it netstack-rl-postgres psql -U rl_user -d rl_research
\dt                                     # æª¢æŸ¥è¡¨çµæ§‹
SELECT COUNT(*) FROM satellite_orbital_cache;  # æª¢æŸ¥æ•¸æ“š

# 3. TLE æ•¸æ“šæ›´æ–°å•é¡Œ
tail -f /var/log/tle_update.log         # TLE æ›´æ–°æ—¥èªŒ
ls -la netstack/tle_data/starlink/tle/  # æª¢æŸ¥ TLE æ–‡ä»¶
curl -I https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink  # æ¸¬è©¦æ•¸æ“šæº

# 4. API éŸ¿æ‡‰å•é¡Œ  
curl -v http://localhost:8080/health    # API å¥åº·æª¢æŸ¥
curl -v http://localhost:8888/api/health # å¾Œç«¯å¥åº·æª¢æŸ¥
netstat -tulpn | grep :8080             # æª¢æŸ¥ç«¯å£å ç”¨
```

### éŒ¯èª¤è™•ç†æµç¨‹
```python
# ç³»çµ±éŒ¯èª¤è™•ç†ç­–ç•¥
class SystemErrorHandler:
    def handle_database_connection_error(self, error):
        """æ•¸æ“šåº«é€£æ¥éŒ¯èª¤è™•ç†"""
        # 1. è¨˜éŒ„éŒ¯èª¤è©³æƒ…
        logger.error(f"Database connection failed: {error}")
        
        # 2. å˜—è©¦é‡æ–°é€£æ¥ (æŒ‡æ•¸é€€é¿)
        for attempt in range(5):
            time.sleep(2 ** attempt)  # 1, 2, 4, 8, 16 ç§’
            if self._test_database_connection():
                return True
        
        # 3. ä½¿ç”¨ç·©å­˜æ•¸æ“šä½œç‚ºå‚™ç”¨
        return self._use_cached_data()
    
    def handle_tle_download_failure(self, url, error):
        """TLE ä¸‹è¼‰å¤±æ•—è™•ç†"""
        # 1. è¨˜éŒ„å¤±æ•—è©³æƒ…
        logger.warning(f"TLE download failed from {url}: {error}")
        
        # 2. å˜—è©¦å‚™ç”¨æ•¸æ“šæº
        backup_urls = self._get_backup_tle_sources()
        for backup_url in backup_urls:
            if self._download_tle_data(backup_url):
                return True
        
        # 3. ä½¿ç”¨æœ¬åœ°ç·©å­˜æ•¸æ“š
        return self._use_local_tle_cache()
    
    def handle_sgp4_calculation_error(self, tle_data, error):
        """SGP4 è¨ˆç®—éŒ¯èª¤è™•ç†"""
        # 1. è¨˜éŒ„éŒ¯èª¤å’Œ TLE æ•¸æ“š
        logger.error(f"SGP4 calculation failed for {tle_data.satellite_id}: {error}")
        
        # 2. æª¢æŸ¥ TLE æ•¸æ“šæœ‰æ•ˆæ€§
        if not self._validate_tle_data(tle_data):
            return self._skip_invalid_satellite(tle_data)
        
        # 3. ä½¿ç”¨ç°¡åŒ–ç®—æ³•ä½œç‚ºå‚™ç”¨
        return self._fallback_to_simplified_calculation(tle_data)
```

### ç³»çµ±æ¢å¾©ç¨‹åº
```bash
# å®Œæ•´ç³»çµ±é‡å•Ÿç¨‹åº
./scripts/system-recovery.sh
```

```bash
#!/bin/bash
# scripts/system-recovery.sh - ç³»çµ±æ¢å¾©è…³æœ¬

echo "ğŸš¨ é–‹å§‹ç³»çµ±æ¢å¾©ç¨‹åº..."

# 1. åœæ­¢æ‰€æœ‰æœå‹™
echo "ğŸ“ åœæ­¢æ‰€æœ‰å®¹å™¨..."
make down
sleep 10

# 2. æ¸…ç†ç„¡ç”¨è³‡æº
echo "ğŸ“ æ¸…ç† Docker è³‡æº..."
docker system prune -f
docker volume prune -f

# 3. æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
echo "ğŸ“ æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§..."
if [ ! -f "netstack/tle_data/starlink/tle/starlink_$(date +%Y%m%d).tle" ]; then
    echo "âš ï¸  TLE æ•¸æ“šç¼ºå¤±ï¼Œé‡æ–°ä¸‹è¼‰..."
    ./scripts/daily_tle_download_enhanced.sh
fi

# 4. é‡æ–°å•Ÿå‹•æœå‹™
echo "ğŸ“ é‡å•Ÿç³»çµ±æœå‹™..."
make up

# 5. ç­‰å¾…æœå‹™å°±ç·’
echo "ğŸ“ ç­‰å¾…æœå‹™å¥åº·æª¢æŸ¥..."
sleep 30

# 6. é©—è­‰ç³»çµ±ç‹€æ…‹
echo "ğŸ“ é©—è­‰ç³»çµ±ç‹€æ…‹..."
make status

# 7. åŸ·è¡Œå¥åº·æª¢æŸ¥
echo "ğŸ“ åŸ·è¡Œå®Œæ•´å¥åº·æª¢æŸ¥..."
curl -f http://localhost:8080/health || exit 1
curl -f http://localhost:8888/api/health || exit 1

echo "âœ… ç³»çµ±æ¢å¾©å®Œæˆï¼"
```

### æ—¥èªŒç®¡ç†
```bash
# æ—¥èªŒè¼ªè½‰é…ç½® (/etc/logrotate.d/ntn-stack)
/var/log/ntn-stack/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0644 sat sat
    postrotate
        docker-compose restart rsyslog || true
    endscript
}

# æ—¥èªŒæ”¶é›†å‘½ä»¤
./scripts/collect-logs.sh
```

```bash
#!/bin/bash
# scripts/collect-logs.sh - æ—¥èªŒæ”¶é›†è…³æœ¬

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
LOG_DIR="logs_$TIMESTAMP"
mkdir -p "$LOG_DIR"

# æ”¶é›† Docker æ—¥èªŒ
echo "æ”¶é›† Docker å®¹å™¨æ—¥èªŒ..."
for service in netstack-api simworld-backend simworld-frontend; do
    docker-compose logs --tail=1000 "$service" > "$LOG_DIR/${service}.log" 2>&1
done

# æ”¶é›†ç³»çµ±æ—¥èªŒ
echo "æ”¶é›†ç³»çµ±æ—¥èªŒ..."
cp /var/log/tle_update.log "$LOG_DIR/" 2>/dev/null
cp /var/log/leo_processing.log "$LOG_DIR/" 2>/dev/null
cp /var/log/health_check.log "$LOG_DIR/" 2>/dev/null

# æ”¶é›†æ€§èƒ½æ•¸æ“š
echo "æ”¶é›†æ€§èƒ½æ•¸æ“š..."
docker stats --no-stream > "$LOG_DIR/docker_stats.txt"
df -h > "$LOG_DIR/disk_usage.txt"
free -h > "$LOG_DIR/memory_usage.txt"
ps aux --sort=-%cpu | head -20 > "$LOG_DIR/cpu_usage.txt"

# æ‰“åŒ…æ—¥èªŒ
tar -czf "ntn_stack_logs_$TIMESTAMP.tar.gz" "$LOG_DIR"
echo "æ—¥èªŒå·²æ”¶é›†åˆ°: ntn_stack_logs_$TIMESTAMP.tar.gz"
```

## ğŸš¨ ç¶­è­·èˆ‡é‹ç¶­

### æ—¥å¸¸ç¶­è­·æª¢æŸ¥æ¸…å–®
```bash
# æ¯æ—¥æª¢æŸ¥ (è‡ªå‹•åŒ–)
- [ ] æª¢æŸ¥æ‰€æœ‰å®¹å™¨å¥åº·ç‹€æ…‹
- [ ] é©—è­‰ API ç«¯é»å›æ‡‰æ­£å¸¸
- [ ] æª¢æŸ¥ TLE æ•¸æ“šæ›´æ–°ç‹€æ…‹
- [ ] ç›£æ§ç³»çµ±è³‡æºä½¿ç”¨ç‡
- [ ] æª¢æŸ¥éŒ¯èª¤æ—¥èªŒæ•¸é‡

# æ¯é€±æª¢æŸ¥ (æ‰‹å‹•)
- [ ] æª¢æŸ¥ç£ç¢Ÿç©ºé–“ä½¿ç”¨ç‡
- [ ] é©—è­‰æ•¸æ“šå‚™ä»½å®Œæ•´æ€§
- [ ] æª¢æŸ¥æ€§èƒ½æŒ‡æ¨™è¶¨å‹¢
- [ ] æ›´æ–°å®‰å…¨è£œä¸
- [ ] æ¸…ç†èˆŠæ•¸æ“šå’Œæ—¥èªŒ

# æ¯æœˆæª¢æŸ¥ (æ‰‹å‹•)
- [ ] æª¢æŸ¥ç³»çµ±æ€§èƒ½åŸºæº–
- [ ] é©—è­‰ç®—æ³•æº–ç¢ºæ€§
- [ ] æª¢æŸ¥ä¾è³´å¥—ä»¶æ›´æ–°
- [ ] åŸ·è¡Œç½é›£æ¢å¾©æ¸¬è©¦
- [ ] æ›´æ–°æ–‡æª”å’Œé…ç½®
```

### å‚™ä»½èˆ‡æ¢å¾©ç­–ç•¥
```bash
# æ•¸æ“šå‚™ä»½è…³æœ¬
./scripts/backup-system.sh
```

```bash
#!/bin/bash
# scripts/backup-system.sh - ç³»çµ±å‚™ä»½è…³æœ¬

BACKUP_DIR="/backup/ntn-stack/$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

echo "ğŸ—‚ï¸  é–‹å§‹ç³»çµ±å‚™ä»½..."

# 1. å‚™ä»½ PostgreSQL æ•¸æ“šåº«
echo "ğŸ“¦ å‚™ä»½æ•¸æ“šåº«..."
docker exec netstack-rl-postgres pg_dump -U rl_user rl_research > "$BACKUP_DIR/rl_research.sql"
docker exec simworld-postgres pg_dump -U postgres simworld > "$BACKUP_DIR/simworld.sql"

# 2. å‚™ä»½é…ç½®æ–‡ä»¶
echo "ğŸ“¦ å‚™ä»½é…ç½®æ–‡ä»¶..."
cp -r netstack/src/core/config/ "$BACKUP_DIR/config/"
cp .env "$BACKUP_DIR/"
cp docker-compose.yml "$BACKUP_DIR/"

# 3. å‚™ä»½é‡è¦æ•¸æ“š
echo "ğŸ“¦ å‚™ä»½æ•¸æ“šæ–‡ä»¶..."
cp -r data/leo_outputs/ "$BACKUP_DIR/leo_outputs/" 2>/dev/null || true
cp -r netstack/tle_data/ "$BACKUP_DIR/tle_data/" 2>/dev/null || true

# 4. å‰µå»ºæ¢å¾©è…³æœ¬
cat > "$BACKUP_DIR/restore.sh" << 'EOF'
#!/bin/bash
echo "é–‹å§‹æ¢å¾©ç³»çµ±..."
# æ¢å¾©æ•¸æ“šåº«
docker exec -i netstack-rl-postgres psql -U rl_user rl_research < rl_research.sql
docker exec -i simworld-postgres psql -U postgres simworld < simworld.sql
echo "ç³»çµ±æ¢å¾©å®Œæˆï¼"
EOF
chmod +x "$BACKUP_DIR/restore.sh"

echo "âœ… å‚™ä»½å®Œæˆ: $BACKUP_DIR"
```

### å®‰å…¨æœ€ä½³å¯¦å‹™
```bash
# 1. å®¹å™¨å®‰å…¨é…ç½®
# docker-compose.security.yml
services:
  netstack-api:
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp
    user: 1000:1000
    
# 2. ç¶²è·¯å®‰å…¨é…ç½®  
# åªæš´éœ²å¿…è¦ç«¯å£
ports:
  - "127.0.0.1:8080:8080"  # åƒ…æœ¬åœ°è¨ªå•
  
# ä½¿ç”¨ secrets ç®¡ç†æ•æ„Ÿè³‡è¨Š
secrets:
  postgres_password:
    file: ./secrets/postgres_password.txt
    
# 3. å­˜å–æ§åˆ¶
# è¨­å®šé©ç•¶çš„æª”æ¡ˆæ¬Šé™
chmod 600 .env
chmod 600 secrets/*
chmod 755 scripts/*.sh

# 4. æ—¥èªŒå®‰å…¨
# ç¦æ­¢åœ¨æ—¥èªŒä¸­è¨˜éŒ„æ•æ„Ÿä¿¡æ¯
logging:
  options:
    max-size: "100m"
    max-file: "5"
```

## ğŸ”® ç”Ÿç”¢ç’°å¢ƒæœ€ä½³å¯¦è¸

### é«˜å¯ç”¨é…ç½®
```yaml
# docker-compose.prod.yml
services:
  netstack-api:
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    
  # è² è¼‰å‡è¡¡å™¨
  nginx-lb:
    image: nginx:alpine
    ports: ["80:80", "443:443"]
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - netstack-api
```

### CI/CD æµç¨‹æ•´åˆ
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]
    
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Build and Test
        run: |
          make test
          make build
          
      - name: Deploy to Production
        run: |
          docker-compose -f docker-compose.prod.yml up -d
          ./scripts/deployment-verification.sh
          
      - name: Notify on Success
        if: success()
        run: |
          curl -X POST "$SLACK_WEBHOOK" \
            -d '{"text":"âœ… NTN Stack éƒ¨ç½²æˆåŠŸï¼"}'
```

---

**æœ¬æŠ€è¡“å¯¦æ–½æŒ‡å—ç¢ºä¿ NTN Stack çš„å®Œæ•´éƒ¨ç½²ã€é…ç½®å’Œç¶­è­·ï¼Œç‚ºç ”ç©¶äººå“¡å’Œé–‹ç™¼åœ˜éšŠæä¾›å¯é çš„æŠ€è¡“æ”¯æ´åŸºç¤ã€‚**

*æœ€å¾Œæ›´æ–°ï¼š2025-08-18 | æŠ€è¡“å¯¦æ–½æŒ‡å—ç‰ˆæœ¬ 3.0.0*