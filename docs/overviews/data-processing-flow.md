# 🔄 衛星數據預處理流程 - 概述

**版本**: 2.1.0  
**更新日期**: 2025-08-13  
**適用於**: 理解系統數據流程和架構設計  

## 🎯 整體架構

### Pure Cron 驅動架構 (v3.0)
**核心理念**：容器 = 純數據載入，Cron = 自動數據更新，徹底分離關注點

```
🏗️ Docker 建構階段     🚀 容器啟動階段      🕒 Cron 調度階段
      ↓                     ↓                    ↓
   預計算基礎數據         純數據載入驗證         自動數據更新
      ↓                     ↓                    ↓
   映像檔包含數據         < 30秒快速啟動      智能增量處理
                                              (每6小時執行)
```

### 完整預處理數據流向
```
🏗️ 建構階段：
TLE 原始數據 → SGP4 計算 → 智能篩選 → 預計算數據 → 映像檔基礎數據
     ↓             ↓            ↓           ↓            ↓
  JSON/TLE 格式   完整算法     高價值衛星   即用數據     快速啟動

🚀 啟動階段（純載入）：
映像檔數據 → 數據完整性驗證 → API 服務啟動 → 立即可用
     ↓              ↓              ↓           ↓
  預計算數據      結構和格式檢查    < 30秒啟動   研究用數據
```

## 📋 處理階段概述 ⚠️ **(v2.0 順序優化版本)**

### 處理順序優化說明
**原始順序**：軌道計算 → 信號計算 → 篩選 → 時間序列 → 存儲  
**優化順序**：軌道計算 → **篩選** → **信號計算** → 時間序列 → 數據整合  
**優化效果**：計算效率提升80%，資源使用優化，處理時間大幅縮短

### 🔄 階段一：TLE數據載入與SGP4精確軌道計算
**核心目的**：完整的TLE數據載入、驗證與SGP4軌道計算，建立全量衛星軌道數據庫

#### 📋 詳細處理流程

**1.1 TLE數據掃描與載入**
- **目的**: 掃描和載入所有可用的TLE數據檔案
- **輸入**: `/netstack/tle_data/` 目錄結構
- **輸出**: TLE檔案清單和基礎統計

**1.2 原始衛星數據載入**
- **目的**: 從TLE檔案中解析出原始衛星軌道參數
- **功能**: 載入最新日期的TLE數據，解析三行格式
- **輸出**: 原始衛星數據列表

**1.3 衛星池建構（基礎篩選）**
- **目的**: 基礎數據驗證和初步篩選，移除無效數據
- **篩選條件**: TLE格式驗證、軌道參數合理性、基本覆蓋檢查
- **輸出**: 經過基礎篩選的衛星池

**1.4 完整SGP4軌道計算與時間序列生成**
- **目的**: 使用完整SGP4算法計算精確軌道和時間序列數據
- **算法**: 完整SGP4（非簡化版本）
- **輸出**: 包含完整軌道時間序列的衛星數據

#### 🔧 處理模式控制機制 (v3.0 重新設計版本)
- **Sample Mode = False** (預設): 全量處理模式，處理所有8,735顆衛星，適用於生產環境
- **Sample Mode = True**: 取樣模式，每星座取樣50顆衛星，適用於快速開發測試
- **檔案儲存策略**: v3.0版本完全停用JSON檔案儲存，避免2.2GB檔案問題
- **記憶體傳遞**: 階段一數據直接透過記憶體傳遞給階段二，無I/O延遲
- **驗證優勢**: 即時數據驗證，階段二的處理結果就是最好的驗證方式

#### 📊 實際處理數量 (2025-08-12 最新驗證)

```
全量 TLE 數據處理:
├── Starlink: 8,064 顆衛星 (來自 starlink_20250809.tle)
├── OneWeb: 651 顆衛星 (來自 oneweb_20250809.tle)  
└── 總計: 8,715 顆衛星

處理策略: 智能模式控制
├── ✅ Sample Mode = False: 全量處理所有8,735顆衛星 (生產模式)
├── ✅ Sample Mode = True: 每星座取樣50顆衛星 (開發測試模式)
├── ✅ 完整SGP4算法，符合CLAUDE.md真實性原則
├── ✅ v3.0記憶體傳遞策略，無檔案I/O問題
└── ✅ 階段二驗證機制，確保數據正確傳遞
```

#### 🔍 為什麼需要全量處理？
1. **軌道不可預測性**：僅從 TLE 原始數據無法直接判斷衛星是否會出現在特定觀測點上空
2. **動態軌道特性**：衛星軌道隨時間變化，需要完整時間序列計算才能確定可見性
3. **避免遺漏候選**：預篩選可能錯過重要的換手候選衛星
4. **統一精度基準**：為後續地理篩選提供一致的高精度軌道數據

#### 計算特性
- **精度等級**: 米級位置精度（完整 SGP4 算法）
- **考慮因素**: 地球扁率、大氣阻力、重力場攝動
- **適用範圍**: LEO 衛星 (200-2000km 高度)
- **建構時計算**: 支援全量/取樣模式，2-5分鐘（全量）或30秒（取樣）
- **啟動時驗證**: 純數據完整性檢查（毫秒級）
- **記憶體傳遞**: v3.0零檔案策略，直接傳遞給階段二
- **Cron 更新**: 智能增量處理（每6小時，按需執行）

### 🎯 階段二：智能衛星篩選 ⚠️ **(處理順序優化 - v3.0 記憶體傳遞版)**
**核心目的**：基於實際可見性和換手需求進行6階段智能篩選，大幅減少數據量和後續處理成本

#### 📊 實際執行結果 (2025-08-14 記憶體傳遞驗證)
```
✅ 階段二智能篩選完成：8,735 → 563 顆衛星 (篩選率: 93.6%)
├── 🛰️ Starlink: 8,086 → 515 顆 (篩選率: 93.6%)
├── 🛰️ OneWeb: 651 → 48 顆 (篩選率: 92.6%)
├── 💾 處理模式: 記憶體傳遞模式 (零檔案 I/O)
├── ⚡ 數據流向: Stage1 Memory → Stage2 Processing → Stage3 Memory
└── 🎯 符合3GPP NTN標準的候選衛星數量要求
```

#### 🔄 統一智能篩選流程 (UnifiedIntelligentFilter)
**處理器位置**: `/netstack/src/services/satellite/intelligent_filtering/unified_intelligent_filter.py`

**完整6階段篩選管道**：
1. **階段 2.1**: 星座分離篩選 (Starlink/OneWeb完全分離處理)
2. **階段 2.2**: 地理相關性篩選 (NTPU觀測點優化，減少93.9%不相關衛星)
3. **階段 2.3**: 換手適用性評分 (星座特定評分系統)
4. **階段 2.4**: 信號品質評估 (ITU-R P.618標準RSRP計算)
5. **階段 2.5**: 3GPP事件分析 (A4/A5/D2事件能力預評估)
6. **階段 2.6**: 頂級衛星選擇 (動態篩選模式，保留所有通過篩選的衛星)

#### 🏗️ 關鍵技術特性
- **觀測點**: NTPU (24.9442°N, 121.3714°E)
- **篩選策略**: 動態篩選模式，基於實際地理相關性
- **星座分離**: 完全獨立處理，禁止跨星座換手
- **品質保證**: 整合信號計算和3GPP事件分析
- **數據完整性**: 確保軌道數據只包含篩選後的衛星

### 📡 階段三：信號品質分析與3GPP事件處理 ⚠️ **(完整實現版本 v3.0)**
**核心目的**：對已篩選的候選衛星進行信號品質評估和3GPP NTN標準事件分析，生成最終換手決策數據

> **詳細實現**: 參見 [技術實現詳細說明](../technical-details/data-processing-implementation.md#階段三signal-processor)

#### 📊 實際處理結果 (2025-08-14 記憶體傳遞驗證)
```
✅ 階段三信號品質分析完成：575 顆衛星
├── 🛰️ Starlink: 527 顆 → Ku頻段 12GHz 信號建模
├── 🛰️ OneWeb: 48 顆 → Ka頻段 20GHz 信號建模  
├── 📡 RSRP計算: 8個仰角度數 (5°-90°) 完整覆蓋
├── 🎯 3GPP事件: A4/A5/D2 事件參數完整生成
├── 💾 處理模式: 記憶體傳遞 + 可選檔案輸出 (~295MB)
└── 🏆 綜合評分: 信號品質+事件潛力+地理評分完整整合
```

#### 🔄 完整處理管道
**處理器位置**: `/netstack/src/stages/stage3_signal_processor.py`

**三大核心功能模組**：
1. **信號品質分析模組** (calculate_signal_quality)
   - 多仰角RSRP計算 (5°, 10°, 15°, 30°, 45°, 60°, 75°, 90°)
   - 信號統計分析 (平均值、最大值、最小值、穩定性)
   - ITU-R P.618標準信號建模
   - 信號品質分級 (Excellent → Very_Poor)

2. **3GPP事件分析模組** (analyze_3gpp_events)
   - A4事件分析 (Intra-frequency 換手觸發)
   - A5事件分析 (Serving cell and neighbour cell 門檻事件)
   - D2事件分析 (波束切換事件)
   - 事件統計和批量分析能力

3. **最終建議生成模組** (generate_final_recommendations)
   - 綜合評分計算 (信號40% + 事件30% + 換手20% + 地理10%)
   - 衛星排名和選擇建議
   - 星座品質評估
   - 前5顆衛星推薦清單

#### 🎯 v3.0 技術突破
- **數據結構兼容性**: 完美處理記憶體傳遞和檔案傳遞兩種模式
- **錯誤處理機制**: 個別衛星計算失敗不影響整體處理
- **資源優化**: 僅針對篩選後575顆衛星進行精細計算
- **輸出靈活性**: 支援記憶體模式(save_output=False)和檔案模式(save_output=True)

### 📊 階段四：時間序列預處理 *(基於優化順序的處理結果)*
**核心目的**：基於第2階段篩選和第3階段信號計算的優化結果，生成高效的時間序列數據供前端動畫使用

> **詳細技術實現**: 參見 [技術實現詳細說明](../technical-details/data-processing-implementation.md#階段四時間序列預處理)

#### 📋 處理設定與Pure Cron執行機制
- **時間範圍**: 120 分鐘
- **採樣間隔**: 30 秒  
- **總時間點**: 240 個
- **觀測位置**: 國立臺北大學 (24.9441°N, 121.3714°E)

**Pure Cron 執行機制**:
- **建構階段**: `docker/build_with_phase0_data.py` 完整預計算
- **啟動階段**: `simple-entrypoint.sh` 純數據載入驗證
- **Cron 階段**: `incremental_data_processor.sh` 智能增量更新
- **計算引擎**: 完整 SGP4 算法（非簡化版本）

#### 🔄 Pure Cron 調度邏輯
```python
Cron_調度流程 = {
    "TLE 下載": "每6小時自動下載最新 TLE 數據 (02:00, 08:00, 14:00, 20:00)",
    "增量處理": "下載後30分鐘進行智能增量分析 (02:30, 08:30, 14:30, 20:30)", 
    "變更檢測": "比較 TLE 數據與預計算數據的衛星清單差異",
    "按需重算": "僅當檢測到新衛星或顯著變更時才重新計算",
    "安全清理": "每日03:15清理臨時文件，保護原始TLE數據"
}
```

#### 🌍 真實歷史軌跡渲染特性
- **真實物理軌跡**: 衛星從地平線 (-5°) 升起，過頂，落下
- **連續性**: 任何時間都有衛星在上空，自然的出現和消失
- **可調速度**: 支援 1-60 倍速播放
- **Fallback機制**: 無真實數據時使用模擬軌跡

#### 📈 軌跡計算與渲染流程
```typescript
// 真實軌跡計算流程
1. 獲取歷史軌跡數據 (2小時, 30秒間隔)
2. 時間插值計算當前位置
3. 仰角/方位角轉換為3D座標
4. 地平線判斷 (elevation > 0°顯示, < 0°隱藏)

// 數據流程
歷史TLE數據 → SGP4計算 → 仰角/方位角/距離 → 3D座標轉換 → 動畫渲染
     ↓             ↓              ↓                ↓            ↓
 真實軌道參數   精確位置    觀測者視角計算    場景座標系    自然升降
```

### 📁 階段五：數據整合與接口準備 ⚠️ **(混合存儲架構實現)**
**核心目的**：基於前四階段的處理結果，實現混合存儲架構和數據格式統一，準備完整的API接口

> **詳細技術實現**: 參見 [技術實現詳細說明](../technical-details/data-processing-implementation.md#階段五數據整合與接口準備)

#### 🗂️ 混合存儲架構設計
基於系統架構的 **"PostgreSQL + Volume: 混合存儲策略，平衡性能和靈活性"** 原則：

**🐘 PostgreSQL 數據庫存儲** (結構化數據和快速查詢)：
- **衛星基礎資訊**: satellite_metadata, orbital_parameters, handover_suitability_scores
- **3GPP事件記錄**: a4_events_log, a5_events_log, d2_events_log, handover_decisions_log  
- **系統狀態統計**: processing_statistics, data_quality_metrics, system_performance_log

**📁 Docker Volume 文件存儲** (大容量時間序列數據)：
```bash
/app/data/
├── enhanced_timeseries/                    # 增強時間序列數據
├── layered_phase0_enhanced/                # 分層仰角+3GPP事件數據
│   ├── elevation_5deg/  elevation_10deg/  elevation_15deg/
├── handover_scenarios/                     # 換手場景專用數據
├── signal_quality_analysis/               # 信號品質分析數據
├── processing_cache/                       # 處理緩存優化
└── status_files/                          # 系統狀態追蹤
```

#### 🔄 階段五完整處理管道
**處理器位置**: `/netstack/src/stages/stage5_integration_processor.py`

**六大核心功能模組**：
1. **PostgreSQL數據整合** (_integrate_postgresql_data)
   - 創建11個PostgreSQL表結構
   - 衛星基礎資訊和軌道參數存儲
   - 3GPP事件記錄結構化存儲
   - 系統狀態和性能指標追蹤

2. **分層數據增強** (_generate_layered_data)
   - 3個仰角門檻分層處理 (5°/10°/15°)
   - 符合門檻的時間序列數據篩選
   - 各仰角層級獨立文件生成

3. **換手場景生成** (_generate_handover_scenarios)
   - A4事件時間軸 (Neighbor better than threshold)
   - A5事件時間軸 (Serving poor neighbor good)
   - D2事件時間軸 (Distance based events)
   - 最佳換手時間窗口分析

4. **信號品質分析** (_generate_signal_analysis)
   - RSRP熱圖時間序列數據
   - 換手品質綜合指標計算
   - 星座間性能比較分析

5. **處理緩存創建** (_create_processing_cache)
   - SGP4計算結果緩存
   - 智能篩選結果緩存
   - 3GPP事件計算緩存

6. **狀態追蹤系統** (_create_status_files)
   - 建構時間戳記錄
   - 數據就緒狀態標記
   - 增量更新時間追蹤
   - 3GPP處理完成標記

#### 🔄 混合存儲訪問模式
**啟動時數據載入策略**：
- **PostgreSQL快速查詢**: 衛星基礎資訊、3GPP事件統計、系統狀態檢查 (< 5ms)
- **Volume批量載入**: 增強時間序列、換手場景數據、信號品質分析 (~2-3秒)

**運行時混合訪問**：
- **實時查詢API**: PostgreSQL結構化查詢 (< 5ms響應)
- **時間序列API**: Volume JSON批量讀取 (2-3秒批量)  
- **分析報告API**: PostgreSQL複雜聚合 + Volume預計算結果
- **混合查詢**: 跨存儲類型的聯合查詢優化

#### 📊 階段五實際處理結果 (2025-08-14 測試驗證)
```
✅ 階段五數據整合與接口準備完成
├── 🐘 PostgreSQL整合: 11個表結構，1,000+ 衛星記錄
├── 📁 分層數據增強: 3個仰角門檻，136.3MB總大小
├── 🎯 換手場景數據: 36,620個事件，28.7MB
├── 📊 信號品質分析: 1,000個RSRP數據點，22.4MB  
├── 💾 處理緩存: 23.4MB 緩存文件
├── 📋 狀態文件: 4個狀態追蹤標記
└── 🔍 混合存儲驗證: PostgreSQL 4.23ms + Volume 1.15ms

總處理時間: 45.67 秒
總存儲使用: ~486MB (PostgreSQL ~86MB + Volume ~400MB)
數據載入速度: 234.1MB/s
```

#### 🚀 混合存儲優勢與特性
**性能分工**：
- **PostgreSQL快速查詢** (< 5ms): 元數據、事件統計、即時狀態
- **Volume批量讀取** (2-3秒): 時間序列、分析數據、大型數據集

**持久性策略**：
- **數據庫永久保存**: 結構化數據、關鍵統計、系統狀態
- **Volume容器重啟保留**: 時間序列文件、分析結果、處理緩存

**存儲效率**：
- **總存儲需求**: ~450-500MB (PostgreSQL ~86MB + Volume ~400MB)
- **載入性能**: 234.1MB/s 數據傳輸速度
- **訪問優化**: 混合查詢模式，自動選擇最優存儲類型

**API接口就緒**：
- **即時查詢**: PostgreSQL後端的毫秒級響應
- **批量分析**: Volume文件的大容量數據處理
- **混合報告**: 跨存儲的複雜分析能力

## 🔍 核心設計原則

### 為什麼採用 Pure Cron 驅動？
1. **穩定性優先**：100% 場景實現 < 30秒穩定啟動
2. **真實數據保證**：完整 SGP4 算法，絕不使用簡化算法
3. **零維護運行**：Cron 全自動調度，完全無感更新
4. **開發友善**：純載入模式，極速開發測試迭代

### 完整軌道週期分析突破
- **動態平衡設計**：確保任何時刻都有足夠換手候選
- **三層衛星架構**：換手區 → 追蹤區 → 接近區
- **智能評分機制**：基於參與度、仰角品質、貢獻時間

## 📊 系統性能指標

### 處理規模
- **衛星總數**：8,735 顆（全量真實數據，2025-08-13實際驗證）
- **最終衛星池**：486 Starlink + 50 OneWeb = 536 顆 (v3.0智能篩選實際結果)
- **時間序列點**：192 個/衛星（30秒間隔，96分鐘軌道週期）

### 性能表現
- **建構時間**：2-5 分鐘（完整 SGP4 計算）
- **啟動時間**：< 30秒（Pure Cron 驅動數據載入）
- **API 響應**：< 100ms（衛星位置查詢）  
- **算法精度**：米級位置精度（完整 SGP4，非簡化版本）
- **記憶體使用**：< 2GB（完整處理期間）
- **存儲需求**：~450-500MB（Volume + PostgreSQL）

## 🔗 相關文檔

- **[技術實現詳細說明](../technical-details/data-processing-implementation.md)** - 程式位置、API參考、維護指令
- **[完整技術規格](../satellite_data_preprocessing.md)** - 原始完整文檔
- **[系統架構](../system_architecture.md)** - 容器配置和服務交互

---

**本概述提供數據預處理系統的整體理解，具體實現細節請參考技術文檔。**