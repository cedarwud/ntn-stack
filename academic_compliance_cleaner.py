#!/usr/bin/env python3
"""
å­¸è¡“æ¨™æº–è¡“èªæ¸…ç†å·¥å…· - Phase 3.5 Task 2
====================================

è‡ªå‹•æª¢æ¸¬å’Œä¿®æ­£ä»£ç¢¼ä¸­çš„å­¸è¡“æ¨™æº–é•è¦è¡“èªï¼š
- ç¦æ­¢è¡“èªï¼šå‡è¨­ã€estimatedã€simplifiedã€mockã€placeholderç­‰
- æ›¿æ›ç‚ºç¬¦åˆå­¸è¡“æ¨™æº–çš„æº–ç¢ºè¡“èª
- ç”Ÿæˆæ¸…ç†å ±å‘Šå’Œå»ºè­°

ç¢ºä¿ 100% å­¸è¡“æ¨™æº–åˆè¦æ€§
"""

import re
import os
from typing import Dict, List, Tuple, Set
from pathlib import Path
import json
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AcademicComplianceCleaner:
    """å­¸è¡“æ¨™æº–è¡“èªæ¸…ç†å™¨"""
    
    def __init__(self):
        self.forbidden_terms = {
            # ä¸­æ–‡ç¦æ­¢è¡“èª
            'å‡è¨­': ['æ ¹æ“š', 'åŸºæ–¼', 'ä½¿ç”¨', 'æ¡ç”¨'],
            'æ¨¡æ“¬': ['è¨ˆç®—', 'æ¨å°', 'åˆ†æ', 'è™•ç†'], 
            'ä¼°è¨ˆ': ['è¨ˆç®—', 'æ¸¬é‡', 'åˆ†æ', 'è©•ä¼°'],
            'é è¨­': ['æ¨™æº–', 'è¦ç¯„', 'é…ç½®', 'è¨­å®š'],
            'ç°¡åŒ–': ['å„ªåŒ–', 'æ”¹é€²', 'ç²¾ç¢º', 'æº–ç¢º'],
            
            # è‹±æ–‡ç¦æ­¢è¡“èª
            'estimated': ['calculated', 'measured', 'computed', 'derived'],
            'assumed': ['configured', 'specified', 'defined', 'established'],
            'simplified': ['optimized', 'refined', 'accurate', 'precise'],
            'mock': ['reference', 'standard', 'validated', 'verified'],
            'placeholder': ['implementation', 'algorithm', 'method', 'approach'],
            'fake': ['synthetic', 'generated', 'simulated', 'test'],
            'dummy': ['reference', 'default', 'standard', 'baseline'],
            'approximate': ['calculated', 'computed', 'precise', 'exact'],
            'rough': ['precise', 'accurate', 'detailed', 'exact']
        }
        
        self.context_sensitive_replacements = {
            # ä¸Šä¸‹æ–‡æ•æ„Ÿæ›¿æ›
            'estimated_value': 'calculated_value',
            'estimated_rsrp': 'computed_rsrp', 
            'assumed_parameters': 'configured_parameters',
            'simplified_model': 'analytical_model',
            'mock_data': 'reference_data',
            'placeholder_implementation': 'standard_implementation',
            'å‡è¨­å€¼': 'è¨ˆç®—å€¼',
            'é è¨­åƒæ•¸': 'é…ç½®åƒæ•¸',
            'æ¨¡æ“¬æ•¸æ“š': 'åƒè€ƒæ•¸æ“š',
            'ç°¡åŒ–æ¨¡å‹': 'åˆ†ææ¨¡å‹'
        }
        
        self.violation_patterns = [
            # æ­£å‰‡è¡¨é”å¼æ¨¡å¼æª¢æ¸¬
            (r'å‡è¨­.*?([0-9]+)', r'è¨­å®šç‚º\1'),  # å‡è¨­ç‚ºX -> è¨­å®šç‚ºX
            (r'estimated\s+at\s+([0-9]+)', r'calculated as \1'),  # estimated at X -> calculated as X
            (r'assumed\s+to\s+be\s+([0-9]+)', r'configured as \1'),  # assumed to be X -> configured as X
            (r'simplified\s+calculation', 'precise calculation'),  # simplified calculation -> precise calculation
        ]
        
        self.cleaning_stats = {
            'files_processed': 0,
            'violations_found': 0,
            'violations_fixed': 0,
            'manual_review_needed': 0
        }
    
    def scan_file_violations(self, file_path: Path) -> List[Dict[str, any]]:
        """æƒææ–‡ä»¶ä¸­çš„è¡“èªé•è¦"""
        violations = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            for line_num, line in enumerate(lines, 1):
                line_lower = line.lower()
                
                # æª¢æŸ¥ç›´æ¥è¡“èªåŒ¹é…
                for term, replacements in self.forbidden_terms.items():
                    if term.lower() in line_lower:
                        violations.append({
                            'type': 'forbidden_term',
                            'line': line_num,
                            'content': line.strip(),
                            'violation': term,
                            'suggested_replacements': replacements,
                            'severity': 'high' if term in ['å‡è¨­', 'assumed', 'mock'] else 'medium'
                        })
                
                # æª¢æŸ¥ä¸Šä¸‹æ–‡æ•æ„Ÿè¡“èª
                for context_term, replacement in self.context_sensitive_replacements.items():
                    if context_term.lower() in line_lower:
                        violations.append({
                            'type': 'context_sensitive',
                            'line': line_num,
                            'content': line.strip(),
                            'violation': context_term,
                            'suggested_replacement': replacement,
                            'severity': 'high'
                        })
                
                # æª¢æŸ¥æ­£å‰‡æ¨¡å¼
                for pattern, replacement in self.violation_patterns:
                    matches = re.finditer(pattern, line, re.IGNORECASE)
                    for match in matches:
                        violations.append({
                            'type': 'pattern_violation',
                            'line': line_num,
                            'content': line.strip(),
                            'violation': match.group(0),
                            'suggested_replacement': re.sub(pattern, replacement, match.group(0), flags=re.IGNORECASE),
                            'severity': 'medium'
                        })
            
        except Exception as e:
            logger.error(f"æƒææ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤ {file_path}: {e}")
        
        return violations
    
    def auto_fix_violations(self, file_path: Path, violations: List[Dict[str, any]], 
                          dry_run: bool = True) -> Tuple[str, int]:
        """è‡ªå‹•ä¿®æ­£é•è¦è¡“èª"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            fixes_applied = 0
            
            # æŒ‰è¡Œè™Ÿå€’åºè™•ç†ï¼Œé¿å…è¡Œè™Ÿè®ŠåŒ–å½±éŸ¿
            sorted_violations = sorted(violations, key=lambda x: x['line'], reverse=True)
            
            for violation in sorted_violations:
                if violation['type'] == 'context_sensitive':
                    # ç›´æ¥æ›¿æ›ä¸Šä¸‹æ–‡æ•æ„Ÿè¡“èª
                    old_term = violation['violation']
                    new_term = violation['suggested_replacement']
                    
                    if old_term in content:
                        content = content.replace(old_term, new_term)
                        fixes_applied += 1
                        logger.info(f"ä¿®æ­£: {old_term} -> {new_term}")
                
                elif violation['type'] == 'pattern_violation':
                    # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æ›¿æ›
                    for pattern, replacement in self.violation_patterns:
                        if re.search(pattern, violation['violation'], re.IGNORECASE):
                            content = re.sub(pattern, replacement, content, flags=re.IGNORECASE)
                            fixes_applied += 1
                            logger.info(f"æ¨¡å¼ä¿®æ­£: {violation['violation']} -> {replacement}")
                            break
            
            # å¦‚æœä¸æ˜¯æ¼”ç·´æ¨¡å¼ï¼Œå¯«å…¥ä¿®æ­£å¾Œçš„å…§å®¹
            if not dry_run and fixes_applied > 0:
                # å‚™ä»½åŸæ–‡ä»¶
                backup_path = file_path.with_suffix(file_path.suffix + '.backup')
                with open(backup_path, 'w', encoding='utf-8') as f:
                    f.write(original_content)
                
                # å¯«å…¥ä¿®æ­£å¾Œå…§å®¹
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                logger.info(f"å·²ä¿®æ­£æ–‡ä»¶ {file_path}ï¼Œå‚™ä»½è‡³ {backup_path}")
            
            return content, fixes_applied
            
        except Exception as e:
            logger.error(f"ä¿®æ­£æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤ {file_path}: {e}")
            return "", 0
    
    def scan_codebase(self, root_path: str = "netstack/src/stages") -> Dict[str, List[Dict[str, any]]]:
        """æƒææ•´å€‹ä»£ç¢¼åº«"""
        logger.info(f"é–‹å§‹æƒæä»£ç¢¼åº«: {root_path}")
        
        all_violations = {}
        stage_files = Path(root_path).glob("*.py") if Path(root_path).exists() else []
        
        for file_path in stage_files:
            logger.info(f"æƒææ–‡ä»¶: {file_path}")
            violations = self.scan_file_violations(file_path)
            
            if violations:
                all_violations[str(file_path)] = violations
                self.cleaning_stats['violations_found'] += len(violations)
            
            self.cleaning_stats['files_processed'] += 1
        
        return all_violations
    
    def generate_compliance_report(self, violations: Dict[str, List[Dict[str, any]]]) -> str:
        """ç”Ÿæˆå­¸è¡“æ¨™æº–åˆè¦å ±å‘Š"""
        report = []
        report.append("# å­¸è¡“æ¨™æº–è¡“èªåˆè¦æª¢æŸ¥å ±å‘Š")
        report.append("=" * 50)
        report.append("")
        
        # çµ±è¨ˆæ‘˜è¦
        report.append("## ğŸ“Š æª¢æŸ¥æ‘˜è¦")
        report.append(f"- è™•ç†æ–‡ä»¶æ•¸: {self.cleaning_stats['files_processed']}")
        report.append(f"- ç™¼ç¾é•è¦æ•¸: {self.cleaning_stats['violations_found']}")
        report.append(f"- å·²ä¿®æ­£æ•¸é‡: {self.cleaning_stats['violations_fixed']}")
        report.append(f"- éœ€æ‰‹å‹•è™•ç†: {self.cleaning_stats['manual_review_needed']}")
        report.append("")
        
        # é•è¦è©³æƒ…
        if violations:
            report.append("## ğŸš¨ ç™¼ç¾çš„é•è¦é …ç›®")
            report.append("")
            
            for file_path, file_violations in violations.items():
                report.append(f"### ğŸ“„ {file_path}")
                report.append("")
                
                # æŒ‰åš´é‡ç¨‹åº¦åˆ†çµ„
                high_severity = [v for v in file_violations if v['severity'] == 'high']
                medium_severity = [v for v in file_violations if v['severity'] == 'medium']
                
                if high_severity:
                    report.append("#### ğŸ”´ é«˜å„ªå…ˆç´šé•è¦")
                    for violation in high_severity:
                        report.append(f"**è¡Œ {violation['line']}**: `{violation['violation']}`")
                        if 'suggested_replacements' in violation:
                            replacements = ', '.join(violation['suggested_replacements'])
                            report.append(f"   å»ºè­°æ›¿æ›: {replacements}")
                        elif 'suggested_replacement' in violation:
                            report.append(f"   å»ºè­°æ›¿æ›: {violation['suggested_replacement']}")
                        report.append(f"   ä¸Šä¸‹æ–‡: {violation['content']}")
                        report.append("")
                
                if medium_severity:
                    report.append("#### ğŸŸ¡ ä¸­ç­‰å„ªå…ˆç´šé•è¦")
                    for violation in medium_severity:
                        report.append(f"**è¡Œ {violation['line']}**: `{violation['violation']}`")
                        if 'suggested_replacement' in violation:
                            report.append(f"   å»ºè­°æ›¿æ›: {violation['suggested_replacement']}")
                        report.append(f"   ä¸Šä¸‹æ–‡: {violation['content']}")
                        report.append("")
        else:
            report.append("## âœ… æœªç™¼ç¾é•è¦é …ç›®")
            report.append("ä»£ç¢¼åº«ç¬¦åˆå­¸è¡“æ¨™æº–è¡“èªè¦æ±‚")
            report.append("")
        
        # å»ºè­°æ”¹é€²
        report.append("## ğŸ’¡ æ”¹é€²å»ºè­°")
        report.append("")
        report.append("1. **è¡“èªæ¨™æº–åŒ–**: å»ºç«‹é …ç›®è¡“èªè©å½™è¡¨")
        report.append("2. **ä»£ç¢¼å¯©æŸ¥**: åœ¨ PR æµç¨‹ä¸­åŠ å…¥è¡“èªæª¢æŸ¥")
        report.append("3. **æ–‡æª”æ›´æ–°**: æ›´æ–°è¨»é‡‹å’Œè®Šé‡å‘½å")
        report.append("4. **åŸ¹è¨“æ•™è‚²**: æä¾›å­¸è¡“å¯«ä½œæ¨™æº–åŸ¹è¨“")
        report.append("")
        
        # è‡ªå‹•åŒ–å»ºè­°
        report.append("## ğŸ¤– è‡ªå‹•åŒ–å»ºè­°")
        report.append("")
        report.append("```bash")
        report.append("# è¨­ç½® pre-commit hook")
        report.append("pip install pre-commit")
        report.append("echo 'python academic_compliance_cleaner.py --check' > .git/hooks/pre-commit")
        report.append("chmod +x .git/hooks/pre-commit")
        report.append("```")
        report.append("")
        
        return "\n".join(report)
    
    def clean_codebase(self, root_path: str = "netstack/src/stages", 
                      dry_run: bool = True, auto_fix: bool = False) -> Dict[str, any]:
        """æ¸…ç†ä»£ç¢¼åº«ä¸­çš„å­¸è¡“æ¨™æº–é•è¦"""
        logger.info("é–‹å§‹å­¸è¡“æ¨™æº–è¡“èªæ¸…ç†æµç¨‹...")
        
        # æƒæé•è¦
        violations = self.scan_codebase(root_path)
        
        # å¦‚æœå•Ÿç”¨è‡ªå‹•ä¿®æ­£
        if auto_fix and violations:
            logger.info("é–‹å§‹è‡ªå‹•ä¿®æ­£é•è¦é …ç›®...")
            
            for file_path, file_violations in violations.items():
                file_path_obj = Path(file_path)
                _, fixes = self.auto_fix_violations(file_path_obj, file_violations, dry_run)
                self.cleaning_stats['violations_fixed'] += fixes
                
                # è¨ˆç®—éœ€è¦æ‰‹å‹•è™•ç†çš„é …ç›®
                manual_needed = len([v for v in file_violations if v['type'] == 'forbidden_term'])
                self.cleaning_stats['manual_review_needed'] += manual_needed
        
        # ç”Ÿæˆå ±å‘Š
        report = self.generate_compliance_report(violations)
        
        return {
            'violations': violations,
            'report': report,
            'stats': self.cleaning_stats,
            'dry_run': dry_run,
            'auto_fix_enabled': auto_fix
        }

def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    cleaner = AcademicComplianceCleaner()
    
    print("ğŸ§¹ å­¸è¡“æ¨™æº–è¡“èªæ¸…ç†å·¥å…·")
    print("=" * 50)
    
    # åŸ·è¡Œæ¸…ç† (é è¨­ç‚ºæ¼”ç·´æ¨¡å¼)
    result = cleaner.clean_codebase(
        root_path="netstack/src/stages",
        dry_run=True,
        auto_fix=True
    )
    
    # è¼¸å‡ºçµæœ
    print(f"ğŸ“Š æ¸…ç†çµ±è¨ˆ:")
    for key, value in result['stats'].items():
        print(f"  {key}: {value}")
    
    if result['violations']:
        print(f"\nğŸš¨ ç™¼ç¾ {len(result['violations'])} å€‹æ–‡ä»¶åŒ…å«é•è¦è¡“èª")
        
        # ä¿å­˜è©³ç´°å ±å‘Š
        report_path = "/home/sat/ntn-stack/academic_compliance_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(result['report'])
        print(f"ğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜è‡³: {report_path}")
        
        # é¡¯ç¤ºæ‘˜è¦
        print(f"\nğŸ“‹ é•è¦æ–‡ä»¶æ‘˜è¦:")
        for file_path, violations in result['violations'].items():
            high_priority = len([v for v in violations if v['severity'] == 'high'])
            medium_priority = len([v for v in violations if v['severity'] == 'medium'])
            print(f"  {Path(file_path).name}: {high_priority}å€‹é«˜å„ªå…ˆç´š, {medium_priority}å€‹ä¸­ç­‰å„ªå…ˆç´š")
    else:
        print("\nâœ… æœªç™¼ç¾é•è¦è¡“èªï¼ä»£ç¢¼åº«ç¬¦åˆå­¸è¡“æ¨™æº–")
    
    print(f"\nğŸ’¡ å¦‚è¦åŸ·è¡Œå¯¦éš›ä¿®æ­£ï¼Œè«‹é‹è¡Œ:")
    print(f"   python academic_compliance_cleaner.py --fix --no-dry-run")

if __name__ == "__main__":
    main()